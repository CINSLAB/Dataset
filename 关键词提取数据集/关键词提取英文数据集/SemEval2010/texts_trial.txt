Evaluating Adaptive Resource Management for Distributed Real-Time Embedded Systems Nishanth Shankaran, ∗ Xenofon Koutsoukos, Douglas C. Schmidt, and Aniruddha Gokhale Dept. of EECS, Vanderbilt University, Nashville ABSTRACT A challenging problem faced by researchers and developers of distributed real-time and embedded (DRE) systems is  devising and implementing effective adaptive resource  management strategies that can meet end-to-end quality of service (QoS) requirements in varying operational conditions. This paper presents two contributions to research in adaptive  resource management for DRE systems. First, we describe the structure and functionality of the Hybrid Adaptive  Resourcemanagement Middleware (HyARM), which provides  adaptive resource management using hybrid control techniques for adapting to workload fluctuations and resource  availability. Second, we evaluate the adaptive behavior of HyARM via experiments on a DRE multimedia system that distributes video in real-time. Our results indicate that HyARM yields predictable, stable, and high system performance, even in the face of fluctuating workload and resource availability. Categories and Subject Descriptors C.2.4 [Distributed Systems]: Distributed Applications; D.4.7 [Organization and Design]: Real-time Systems and Embedded Systems . INTRODUCTION Achieving end-to-end real-time quality of service (QoS) is particularly important for open distributed real-time and embedded (DRE) systems that face resource constraints, such as limited computing power and network bandwidth.  Overutilization of these system resources can yield unpredictable and unstable behavior, whereas under-utilization can yield excessive system cost. A promising approach to meeting these end-to-end QoS requirements effectively, therefore, is to develop and apply adaptive middleware [10, 15], which is software whose functional and QoS-related properties can be modified either statically or dynamically. Static  modifications are carried out to reduce footprint, leverage  capabilities that exist in specific platforms, enable functional  subsetting, and/or minimize hardware/software infrastructure dependencies. Objectives of dynamic modifications include optimizing system responses to changing environments or  requirements, such as changing component interconnections, power-levels, CPU and network bandwidth availability,  latency/jitter, and workload. In open DRE systems, adaptive middleware must make such modifications dependably, i.e., while meeting  stringent end-to-end QoS requirements, which requires the  specification and enforcement of upper and lower bounds on system resource utilization to ensure effective use of  system resources. To meet these requirements, we have  developed the Hybrid Adaptive Resource-management  Middleware (HyARM), which is an open-source1 distributed  resource management middleware. HyARM is based on hybrid control theoretic techniques [8], which provide a theoretical framework for designing  control of complex system with both continuous and discrete dynamics. In our case study, which involves a distributed real-time video distribution system, the task of adaptive  resource management is to control the utilization of the  different resources, whose utilizations are described by  continuous variables. We achieve this by adapting the resolution of the transmitted video, which is modeled as a continuous variable, and by changing the frame-rate and the  compression, which are modeled by discrete actions. We have  implemented HyARM atop The ACE ORB (TAO) [13], which is an implementation of the Real-time CORBA  specification [12]. Our results show that (1) HyARM ensures  effective system resource utilization and (2) end-to-end QoS requirements of higher priority applications are met, even in the face of fluctuations in workload. The remainder of the paper is organized as follows:  Section 2 describes the architecture, functionality, and resource utilization model of our DRE multimedia system case study; Section 3 explains the structure and functionality of HyARM; Section 4 evaluates the adaptive behavior of HyARM via  experiments on our multimedia system case study; Section 5 compares our research on HyARM with related work; and Section 6 presents concluding remarks.  The code and examples for HyARM are available at www. dre.vanderbilt.edu/∼nshankar/HyARM/. Article 7 . CASE STUDY: DRE MULTIMEDIA  SYSTEM This section describes the architecture and QoS  requirements of our DRE multimedia system. .1 Multimedia System Architecture Wireless Link Wireless Link Wireless Link ` ` ` Physical Link Physical Link Physical Link Base Station End Receiver End Receiver End Receiver` Physical Link End Receiver UAV Camera Video Encoder Camera Video Encoder Camera Video Encoder UAV Camera Video Encoder Camera Video Encoder Camera Video Encoder UAV Camera Video Encoder Camera Video Encoder Camera Video Encoder Figure 1: DRE Multimedia System Architecture The architecture for our DRE multimedia system is shown in Figure 1 and consists of the following entities: (1)Data source (video capture by UAV), where video is captured (related to subject of interest) by camera(s) on each UAV, followed by encoding of raw video using a specific encoding scheme and transmitting the video to the next stage in the pipeline. (2)Data distributor (base station), where the video is processed to remove noise, followed by  retransmission of the processed video to the next stage in the pipeline. (3) Sinks (command and control center), where the received video is again processed to remove noise, then  decoded and finally rendered to end user via graphical displays. Significant improvements in video encoding/decoding and (de)compression techniques have been made as a result of recent advances in video encoding and compression  techniques [14]. Common video compression schemes are  MPEG1, MPEG-2, Real Video, and MPEG-4. Each compression scheme is characterized by its resource requirement, e.g., the computational power to (de)compress the video signal and the network bandwidth required to transmit the compressed video signal. Properties of the compressed video, such as  resolution and frame-rate determine both the quality and the resource requirements of the video. Our multimedia system case study has the following  endto-end real-time QoS requirements: (1) latency, (2)  interframe delay (also know as jitter), (3) frame rate, and (4) picture resolution. These QoS requirements can be  classified as being either hard or soft. Hard QoS requirements should be met by the underlying system at all times, whereas soft QoS requirements can be missed occasionally.2 For our case study, we treat QoS requirements such as latency and jitter as harder QoS requirements and strive to meet these requirements at all times. In contrast, we treat QoS  requirements such as video frame rate and picture resolution as softer QoS requirements and modify these video properties adaptively to handle dynamic changes in resource  availabil2 Although hard and soft are often portrayed as two discrete requirement sets, in practice they are usually two ends of a continuum ranging from softer to harder rather than two disjoint points. ity effectively. .2 DRE Multimedia System Rresources There are two primary types of resources in our DRE multimedia system: (1) processors that provide  computational power available at the UAVs, base stations, and end receivers and (2) network links that provide communication bandwidth between UAVs, base stations, and end receivers. The computing power required by the video capture and encoding tasks depends on dynamic factors, such as speed of the UAV, speed of the subject (if the subject is mobile), and distance between UAV and the subject. The wireless network bandwidth available to transmit video captured by UAVs to base stations also depends on the wireless  connectivity between the UAVs and the base station, which in-turn depend on dynamic factors such as the speed of the UAVs and the relative distance between UAVs and base stations. The bandwidth of the link between the base station and the end receiver is limited, but more stable than the  bandwidth of the wireless network. Resource requirements and availability of resources are subjected to dynamic changes. Two classes of applications - QoS-enabled and best-effort - use the multimedia system infrastructure described above to transmit video to their respective receivers. QoS-enabled class of applications have higher priority over best-effort class of application. In our study, emergency response  applications belong to QoS-enabled and surveillance applications belong to best-effort class. For example, since a stream from an emergency response application is of higher importance than a video stream from a surveillance application, it  receives more resources end-to-end. Since resource availability significantly affects QoS, we use current resource utilization as the primary indicator of  system performance. We refer to the current level of system resource utilization as the system condition. Based on this definition, we can classify system conditions as being either under, over, or effectively utilized. Under-utilization of system resources occurs when the  current resource utilization is lower than the desired lower bound on resource utilization. In this system condition, residual system resources (i.e., network bandwidth and  computational power) are available in large amounts after meeting end-to-end QoS requirements of applications. These  residual resources can be used to increase the QoS of the  applications. For example, residual CPU and network bandwidth can be used to deliver better quality video (e.g., with greater resolution and higher frame rate) to end receivers. Over-utilization of system resources occurs when the  current resource utilization is higher than the desired upper bound on resource utilization. This condition can arise from loss of resources - network bandwidth and/or  computing power at base station, end receiver or at UAV - or may be due to an increase in resource demands by  applications. Over-utilization is generally undesirable since the quality of the received video (such as resolution and frame rate) and timeliness properties (such as latency and jitter) are degraded and may result in an unstable (and thus  ineffective) system. Effective resource utilization is the desired system  condition since it ensures that end-to-end QoS requirements of the UAV-based multimedia system are met and utilization of both system resources, i.e., network bandwidth and  computational power, are within their desired utilization bounds. Article 7 Section 3 describes techniques we applied to achieve effective utilization, even in the face of fluctuating resource  availability and/or demand. . OVERVIEW OF HYARM This section describes the architecture of the Hybrid  Adaptive Resource-management Middleware (HyARM). HyARM ensures efficient and predictable system performance by  providing adaptive resource management, including monitoring of system resources and enforcing bounds on application  resource utilization. .1 HyARM Structure and Functionality Resource Utilization Legend Resource Allocation Application Parameters Figure 2: HyARM Architecture HyARM is composed of three types of entities shown in Figure 2 and described below: Resource monitors observe the overall resource  utilization for each type of resource and resource utilization per application. In our multimedia system, there are resource monitors for CPU utilization and network bandwidth. CPU monitors observe the CPU resource utilization of UAVs, base station, and end receivers. Network bandwidth monitors  observe the network resource utilization of (1) wireless network link between UAVs and the base station and (2) wired  network link between the base station and end receivers. The central controller maintains the system resource utilization below a desired bound by (1) processing periodic updates it receives from resource monitors and (2)  modifying the execution of applications accordingly, e.g., by  using different execution algorithms or operating the  application with increased/decreased QoS. This adaptation  process ensures that system resources are utilized efficiently and end-to-end application QoS requirements are met. In our multimedia system, the HyARM controller determines the value of application parameters such as (1) video  compression schemes, such as Real Video and MPEG-4, and/or (2) frame rate, and (3) picture resolution. From the perspective of hybrid control theoretic techniques [8], the different video compression schemes and frame rate form the discrete  variables of application execution and picture resolution forms the continuous variables. Application adapters modify application execution  according to parameters recommended by the controller and ensures that the operation of the application is in accordance with the recommended parameters. In the current  mplementation of HyARM, the application adapter modifies the input parameters to the application that affect application QoS and resource utilization - compression scheme, frame rate, and picture resolution. In our future implementations, we plan to use resource reservation mechanisms such as  Differentiated Service [7, 3] and Class-based Kernel Resource Management [4] to provision/reserve network and CPU  resources. In our multimedia system, the application adapter ensures that the video is encoded at the recommended frame rate and resolution using the specified compression scheme. .2 Applying HyARM to the Multimedia  System Case Study HyARM is built atop TAO [13], a widely used open-source implementation of Real-time CORBA [12]. HyARM can be applied to ensure efficient, predictable and adaptive resource management of any DRE system where resource availability and requirements are subject to dynamic change. Figure 3 shows the interaction of various parts of the DRE multimedia system developed with HyARM, TAO, and TAO"s A/V Streaming Service. TAO"s A/V Streaming service is an implementation of the CORBA A/V  Streaming Service specification. TAO"s A/V Streaming Service is a QoS-enabled video distribution service that can transfer video in real-time to one or more receivers. We use the A/V Streaming Service to transmit the video from the UAVs to the end receivers via the base station. Three entities of Receiver UAV TAO Resource Utilization HyARM Central Controller A/V Streaming Service : Sender MPEG1 MPEG4 Real Video HyARM Resource Monitor A/V Streaming Service : Receiver Compressed Video Compressed Video Application HyARM Application Adapter Remote Object Call Control Inputs Resource Utilization Resource Utilization / Control Inputs Control Inputs Legend Figure 3: Developing the DRE Multimedia System with HyARM HyARM, namely the resource monitors, central controller, and application adapters are built as CORBA servants, so they can be distributed throughout a DRE system.  Resource monitors are remote CORBA objects that update the central controller periodically with the current resource utilization. Application adapters are collocated with  applications since the two interact closely. As shown in Figure 3, UAVs compress the data using  various compression schemes, such as MPEG1, MPEG4, and Real Video, and uses TAO"s A/V streaming service to  transmit the video to end receivers. HyARM"s resource monitors continuously observe the system resource utilization and  notify the central controller with the current utilization. 3 The interaction between the controller and the resource monitors uses the Observer pattern [5]. When the controller receives resource utilization updates from monitors, it  computes the necessary modifications to application(s)  parameters and notifies application adapter(s) via a remote  operation call. Application adapter(s), that are collocated with the application, modify the input parameters to the  application - in our case video encoder - to modify the application resource utilization and QoS.  The base station is not included in the figure since it only retransmits the video received from UAVs to end receivers. Article 7 . PERFORMANCE RESULTS AND  ANALYSIS This section first describes the testbed that provides the infrastructure for our DRE multimedia system, which was used to evaluate the performance of HyARM. We then  describe our experiments and analyze the results obtained to empirically evaluate how HyARM behaves during  underand over-utilization of system resources. .1 Overview of the Hardware and Software Testbed Our experiments were performed on the Emulab testbed at University of Utah. The hardware configuration consists of two nodes acting as UAVs, one acting as base station, and one as end receiver. Video from the two UAVs were transmitted to a base station via a LAN configured with the following properties: average packet loss ratio of 0.3 and bandwidth 1 Mbps. The network bandwidth was chosen to be 1 Mbps since each UAV in the DRE multimedia system is allocated 250 Kbps. These parameters were chosen to  emulate an unreliable wireless network with limited bandwidth between the UAVs and the base station. From the base  station, the video was retransmitted to the end receiver via a reliable wireline link of 10 Mbps bandwidth with no packet loss. The hardware configuration of all the nodes was chosen as follows: 600 MHz Intel Pentium III processor, 256 MB  physical memory, 4 Intel EtherExpress Pro 10/100 Mbps Ethernet ports, and 13 GB hard drive. A real-time version of Linux - TimeSys Linux/NET 3.1.214 based on RedHat Linux  was used as the operating system for all nodes. The  following software packages were also used for our experiments: (1) Ffmpeg 0.4.9-pre1, which is an open-source library (http: //www.ffmpeg.sourceforge.net/download.php) that  compresses video into MPEG-2, MPEG-4, Real Video, and many other video formats. (2) Iftop 0.16, which is an  opensource library (http://www.ex-parrot.com/∼pdw/iftop/) we used for monitoring network activity and bandwidth  utilization. (3) ACE 5.4.3 + TAO 1.4.3, which is an  opensource (http://www.dre.vanderbilt.edu/TAO)  implementation of the Real-time CORBA [12] specification upon which HyARM is built. TAO provides the CORBA Audio/Video (A/V) Streaming Service that we use to transmit the video from the UAVs to end receivers via the base station. .2 Experiment Configuration Our experiment consisted of two (emulated) UAVs that  simultaneously send video to the base station using the  experimentation setup described in Section 4.1. At the base  station, video was retransmitted to the end receivers (without any modifications), where it was stored to a file. Each UAV hosted two applications, one QoS-enabled application  (emergency response), and one best-effort application  (surveillance). Within each UAV, computational power is shared between the applications, while the network bandwidth is shared among all applications. To evaluate the QoS provided by HyARM, we monitored CPU utilization at the two UAVs, and network bandwidth utilization between the UAV and the base station. CPU  resource utilization was not monitored at the base station and the end receiver since they performed no  computationallyintensive operations. The resource utilization of the 10 Mpbs physical link between the base station and the end receiver does not affect QoS of applications and is not monitored by HyARM since it is nearly 10 times the 1 MB bandwidth of the LAN between the UAVs and the base station. The experiment also monitors properties of the video that affect the QoS of the applications, such as latency, jitter, frame rate, and resolution. The set point on resource utilization for each resource was specified at 0.69, which is the upper bound typically  recommended by scheduling techniques, such as rate monotonic algorithm [9]. Since studies [6] have shown that human eyes can perceive delays more than 200ms, we use this as the upper bound on jitter of the received video. QoS  requirements for each class of application is specified during system initialization and is shown in Table 1. .3 Empirical Results and Analysis This section presents the results obtained from running the experiment described in Section 4.2 on our DRE  multimedia system testbed. We used system resource utilization as a metric to evaluate the adaptive resource management capabilities of HyARM under varying input work loads. We also used application QoS as a metric to evaluate HyARM"s capabilities to support end-to-end QoS requirements of the various classes of applications in the DRE multimedia  system. We analyze these results to explain the significant  differences in system performance and application QoS. Comparison of system performance is decomposed into comparison of resource utilization and application QoS. For system resource utilization, we compare (1) network  bandwidth utilization of the local area network and (2) CPU utilization at the two UAV nodes. For application QoS, we compare mean values of video parameters, including (1)  picture resolution, (2) frame rate, (3) latency, and (4) jitter. Comparison of resource utilization. Over-utilization of system resources in DRE systems can yield an unstable system. In contrast, under-utilization of system resources increases system cost. Figure 4 and Figure 5 compare the system resource utilization with and without HyARM.  Figure 4 shows that HyARM maintains system utilization close to the desired utilization set point during fluctuation in  input work load by transmitting video of higher (or lower) QoS for QoS-enabled (or best-effort) class of applications during over (or under) utilization of system resources. Figure 5 shows that without HyARM, network  utilization was as high as 0.9 during increase in workload  conditions, which is greater than the utilization set point of 0.7 by 0.2. As a result of over-utilization of resources, QoS of the received video, such as average latency and jitter, was affected significantly. Without HyARM, system resources were either under-utilized or over-utilized, both of which are undesirable. In contrast, with HyARM, system resource utilization is always close to the desired set point, even during fluctuations in application workload. During  sudden fluctuation in application workload, system conditions may be temporarily undesirable, but are restored to the  desired condition within several sampling periods. Temporary over-utilization of resources is permissible in our multimedia system since the quality of the video may be degraded for a short period of time, though application QoS will be  degraded significantly if poor quality video is transmitted for a longer period of time. Comparison of application QoS. Figures 6, Figure 7, and Table 2 compare latency, jitter, resolution, and  frameArticle 7 Class Resolution Frame Rate Latency (msec ) Jitter (msec) QoS Enabled 1024 x 768 25 200 200 Best-effort 320 x 240 15 300 250 Table 1: Application QoS Requirements Figure 4: Resource utilization with HyARM Figure 5: Resource utilization without HyARM rate of the received video, respectively. Table 2 shows that HyARM increases the resolution and frame video of  QoSenabled applications, but decreases the resolution and frame rate of best effort applications. During over utilization of system resources, resolution and frame rate of lower priority applications are reduced to adapt to fluctuations in  application workload and to maintain the utilization of resources at the specified set point. It can be seen from Figure 6 and Figure 7 that HyARM reduces the latency and jitter of the received video  significantly. These figures show that the QoS of QoS-enabled applications is greatly improved by HyARM. Although  application parameters, such as frame rate and resolutions, which affect the soft QoS requirements of best-effort  applications may be compromised, the hard QoS requirements, such as latency and jitter, of all applications are met. HyARM responds to fluctuation in resource availability and/or demand by constant monitoring of resource  utilization. As shown in Figure 4, when resources utilization  increases above the desired set point, HyARM lowers the  utilization by reducing the QoS of best-effort applications. This adaptation ensures that enough resources are available for QoS-enabled applications to meet their QoS needs.  Figures 6 and 7 show that the values of latency and jitter of the received video of the system with HyARM are nearly half of the corresponding value of the system without HyARM. With HyARM, values of these parameters are well below the specified bounds, whereas without HyARM, these value are significantly above the specified bounds due to  overutilization of the network bandwidth, which leads to network congestion and results in packet loss. HyARM avoids this by reducing video parameters such as resolution, frame-rate, and/or modifying the compression scheme used to compress the video. Our conclusions from analyzing the results described above are that applying adaptive middleware via hybrid control to DRE system helps to (1) improve application QoS, (2)  increase system resource utilization, and (3) provide better predictability (lower latency and inter-frame delay) to  QoSenabled applications. These improvements are achieved largely due to monitoring of system resource utilization, efficient system workload management, and adaptive resource  provisioning by means of HyARM"s network/CPU resource  monitors, application adapter, and central controller,  respectively. . RELATED WORK A number of control theoretic approaches have been  applied to DRE systems recently. These techniques aid in  overcoming limitations with traditional scheduling approaches that handle dynamic changes in resource availability poorly and result in a rigidly scheduled system that adapts poorly to change. A survey of these techniques is presented in [1]. One such approach is feedback control scheduling (FCS) [2, 1]. FCS algorithms dynamically adjust resource allocation by means of software feedback control loops. FCS  algorithms are modeled and designed using rigorous  controltheoretic methodologies. These algorithms provide robust and analytical performance assurances despite uncertainties in resource availability and/or demand. Although existing FCS algorithms have shown promise, these algorithms often assume that the system has continuous control variable(s) that can continuously be adjusted. While this assumption holds for certain classes of systems, there are many classes of DRE systems, such as avionics and total-ship computing environments that only support a finite a priori set of  discrete configurations. The control variables in such systems are therefore intrinsically discrete. HyARM handles both continuous control variables, such as picture resolution, and discrete control variable, such as discrete set of frame rates. HyARM can therefore be applied to system that support continuous and/or discrete set of control variables. The DRE multimedia system as described in Section 2 is an example DRE system that offers both  continuous (picture resolution) and discrete set (frame-rate) of control variables. These variables are modified by HyARM to achieve efficient resource utilization and improved  application QoS. . CONCLUDING REMARKS Article 7 Figure 6: Comparison of Video Latency Figure 7: Comparison of Video Jitter Source Picture Size / Frame Rate With HyARM Without HyARM UAV1 QoS Enabled Application 1122 X 1496 / 25 960 X 720 / 20 UAV1 Best-effort Application 288 X 384 / 15 640 X 480 / 20 UAV2 QoS Enabled Application 1126 X 1496 / 25 960 X 720 / 20 UAV2 Best-effort Application 288 X 384 / 15 640 X 480 / 20 Table 2: Comparison of Video Quality Many distributed real-time and embedded (DRE) systems demand end-to-end quality of service (QoS) enforcement from their underlying platforms to operate correctly. These systems increasingly run in open environments, where  resource availability is subject to dynamic change. To meet end-to-end QoS in dynamic environments, DRE systems can benefit from an adaptive middleware that monitors system resources, performs efficient application workload  management, and enables efficient resource provisioning for  executing applications. This paper described HyARM, an adaptive middleware, that provides effective resource management to DRE  systems. HyARM employs hybrid control techniques to  provide the adaptive middleware capabilities, such as resource monitoring and application adaptation that are key to  providing the dynamic resource management capabilities for open DRE systems. We employed HyARM to a  representative DRE multimedia system that is implemented using Real-time CORBA and CORBA A/V Streaming Service. We evaluated the performance of HyARM in a system composed of three distributed resources and two classes of applications with two applications each. Our empirical  results indicate that HyARM ensures (1) efficient resource  utilization by maintaining the resource utilization of system  resources within the specified utilization bounds, (2) QoS  requirements of QoS-enabled applications are met at all times. Overall, HyARM ensures efficient, predictable, and adaptive resource management for DRE systems. . REFERENCES [1] T. F. Abdelzaher, J. Stankovic, C. Lu, R. Zhang, and Y. Lu. Feddback Performance Control in Software Services. IEEE: Control Systems, 23(3), June 2003. [2] L. Abeni, L. Palopoli, G. Lipari, and J. Walpole. Analysis of a reservation-based feedback scheduler. In IEEE Real-Time Systems Symposium, Dec. 2002. [3] S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, and W. Weiss. An architecture for differentiated services. Network Information Center RFC 2475, Dec. 1998. [4] H. Franke, S. Nagar, C. Seetharaman, and V. Kashyap. Enabling Autonomic Workload Management in Linux. In Proceedings of the International Conference on Autonomic Computing (ICAC), New York, New York, May 2004. IEEE. [5] E. Gamma, R. Helm, R. Johnson, and J. Vlissides. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley, Reading, MA, 1995. [6] G. Ghinea and J. P. Thomas. Qos impact on user perception and understanding of multimedia video clips. In MULTIMEDIA "98: Proceedings of the sixth ACM international conference on Multimedia, pages 49-54, Bristol, United Kingdom, 1998. ACM Press. [7] Internet Engineering Task Force. Differentiated Services Working Group (diffserv) Charter. www.ietf.org/html.charters/diffserv-charter.html, 2000. [8] X. Koutsoukos, R. Tekumalla, B. Natarajan, and C. Lu. Hybrid Supervisory Control of Real-Time Systems. In 11th IEEE Real-Time and Embedded Technology and Applications Symposium, San Francisco, California, Mar. 2005. [9] J. Lehoczky, L. Sha, and Y. Ding. The Rate Monotonic Scheduling Algorithm: Exact Characterization and Average Case Behavior. In Proceedings of the 10th IEEE Real-Time Systems Symposium (RTSS 1989), pages 166-171. IEEE Computer Society Press, 1989. [10] J. Loyall, J. Gossett, C. Gill, R. Schantz, J. Zinky, P. Pal, R. Shapiro, C. Rodrigues, M. Atighetchi, and D. Karr. Comparing and Contrasting Adaptive Middleware Support in Wide-Area and Embedded Distributed Object Applications. In Proceedings of the 21st International Conference on Distributed Computing Systems (ICDCS-21), pages 625-634. IEEE, Apr. 2001. [11] C. Lu, J. A. Stankovic, G. Tao, and S. H. Son. Feedback Control Real-Time Scheduling: Framework, Modeling, and Algorithms. Real-Time Systems Journal, 23(1/2):85-126, July 002. [12] Object Management Group. Real-time CORBA Specification, OMG Document formal/02-08-02 edition, Aug. 2002. [13] D. C. Schmidt, D. L. Levine, and S. Mungee. The Design and Performance of Real-Time Object Request Brokers. Computer Communications, 21(4):294-324, Apr. 1998. [14] Thomas Sikora. Trends and Perspectives in Image and Video Coding. In Proceedings of the IEEE, Jan. 2005. [15] X. Wang, H.-M. Huang, V. Subramonian, C. Lu, and C. Gill. CAMRIT: Control-based Adaptive Middleware for Real-time Image Transmission. In Proc. of the 10th IEEE Real-Time and Embedded Tech. and Applications Symp. (RTAS), Toronto, Canada, May 2004. Article 7
Demonstration of Grid-Enabled Ensemble Kalman Filter Data Assimilation Methodology for Reservoir Characterization Ravi Vadapalli High Performance Computing Center Texas Tech University Lubbock, TX 79409 01-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, TX 77843 01-979-847-8735 akumar@tamu.edu Ping Luo Supercomputing Facility Texas A&M University College Station, TX 77843 01-979-862-3107 pingluo@sc.tamu.edu Shameem Siddiqui Department of Petroleum Engineering Texas Tech University Lubbock, TX 79409 01-806-742-3573 Shameem.Siddiqui@ttu.edu Taesung Kim Supercomputing Facility Texas A&M University College Station, TX 77843 01-979-204-5076 tskim@sc.tamu.edu ABSTRACT Ensemble Kalman filter data assimilation methodology is a popular approach for hydrocarbon reservoir simulations in energy exploration. In this approach, an ensemble of geological models and production data of oil fields is used to forecast the dynamic response of oil wells. The Schlumberger ECLIPSE software is used for these simulations. Since models in the ensemble do not communicate, message-passing implementation is a good choice. Each model checks out an ECLIPSE license and therefore, parallelizability of reservoir simulations depends on the number licenses available. We have Grid-enabled the ensemble Kalman filter data assimilation methodology for the TIGRE Grid computing environment. By pooling the licenses and computing resources across the collaborating institutions using GridWay metascheduler and TIGRE environment, the computational accuracy can be increased while reducing the simulation runtime. In this paper, we provide an account of our efforts in  Gridenabling the ensemble Kalman Filter data assimilation methodology. Potential benefits of this approach, observations and lessons learned will be discussed. Categories and Subject Descriptors C 2.4 [Distributed Systems]: Distributed applications General Terms Algorithms, Design, Performance . INTRODUCTION Grid computing [1] is an emerging collaborative computing paradigm to extend institution/organization specific high performance computing (HPC) capabilities greatly beyond local resources. Its importance stems from the fact that ground breaking research in strategic application areas such as bioscience and medicine, energy exploration and environmental modeling involve strong interdisciplinary components and often require intercampus collaborations and computational capabilities beyond institutional limitations. The Texas Internet Grid for Research and Education (TIGRE) [2,3] is a state funded cyberinfrastructure development project carried out by five (Rice, A&M, TTU, UH and UT Austin) major university systems - collectively called TIGRE Institutions. The purpose of TIGRE is to create a higher education Grid to sustain and extend research and educational opportunities across Texas. TIGRE is a project of the High Performance Computing across Texas (HiPCAT) [4] consortium. The goal of HiPCAT is to support advanced computational technologies to enhance research, development, and educational activities. The primary goal of TIGRE is to design and deploy state-of-the-art Grid middleware that enables integration of computing systems, storage systems and databases, visualization laboratories and displays, and even instruments and sensors across Texas. The secondary goal is to demonstrate the TIGRE capabilities to enhance research and educational opportunities in strategic application areas of interest to the State of Texas. These are bioscience and medicine, energy exploration and air quality modeling. Vision of the TIGRE project is to foster interdisciplinary and intercampus collaborations, identify novel approaches to extend academic-government-private partnerships, and become a competitive model for external funding opportunities. The overall goal of TIGRE is to support local, campus and regional user interests and offer avenues to connect with national Grid projects such as Open Science Grid [5], and TeraGrid [6]. Within the energy exploration strategic application area, we have Grid-enabled the ensemble Kalman Filter (EnKF) [7] approach for data assimilation in reservoir modeling and demonstrated the extensibility of the application using the TIGRE environment and the GridWay [8] metascheduler. Section 2 provides an overview of the TIGRE environment and capabilities. Application description and the need for Grid-enabling EnKF methodology is provided in Section 3. The implementation details and merits of our approach are discussed in Section 4. Conclusions are provided in Section . Finally, observations and lessons learned are documented in Section 6. . TIGRE ENVIRONMENT The TIGRE Grid middleware consists of minimal set of components derived from a subset of the Virtual Data Toolkit (VDT) [9] which supports a variety of operating systems. The purpose of choosing a minimal software stack is to support applications at hand, and to simplify installation and distribution of client/server stacks across TIGRE sites. Additional components will be added as they become necessary. The PacMan [10] packaging and distribution mechanism is employed for TIGRE client/server installation and management. The PacMan distribution mechanism involves retrieval, installation, and often configuration of the packaged software. This approach allows the clients to keep current, consistent versions of TIGRE software. It also helps TIGRE sites to install the needed components on resources distributed throughout the participating sites. The TIGRE client/server stack consists of an authentication and authorization layer, Globus GRAM4-based job submission via web services (pre-web services installations are available up on request). The tools for handling Grid proxy generation, Grid-enabled file transfer and Grid-enabled remote login are supported. The pertinent details of TIGRE services and tools for job scheduling and management are provided below. .1. Certificate Authority The TIGRE security infrastructure includes a certificate authority (CA) accredited by the International Grid Trust Federation (IGTF) for issuing X. 509 user and resource Grid certificates [11]. The Texas Advanced Computing Center (TACC), University of Texas at Austin is the TIGRE"s shared CA. The TIGRE Institutions serve as Registration Authorities (RA) for their respective local user base. For up-to-date information on securing user and resource certificates and their installation instructions see ref [2]. The users and hosts on TIGRE are identified by their distinguished name (DN) in their X.509 certificate provided by the CA. A native Grid-mapfile that contains a list of authorized DNs is used to authenticate and authorize user job scheduling and management on TIGRE site resources. At Texas Tech University, the users are dynamically allocated one of the many generic pool accounts. This is accomplished through the Grid User Management System (GUMS) [12]. .2. Job Scheduling and Management The TIGRE environment supports GRAM4-based job submission via web services. The job submission scripts are generated using XML. The web services GRAM translates the XML scripts into target cluster specific batch schedulers such as LSF, PBS, or SGE. The high bandwidth file transfer protocols such as GridFTP are utilized for staging files in and out of the target machine. The login to remote hosts for compilation and debugging is only through GSISSH service which requires resource authentication through X.509 certificates. The authentication and authorization of Grid jobs are managed by issuing Grid certificates to both users and hosts. The certificate revocation lists (CRL) are updated on a daily basis to maintain high security standards of the TIGRE Grid services. The TIGRE portal [2] documentation area provides a quick start tutorial on running jobs on TIGRE. .3. Metascheduler The metascheduler interoperates with the cluster level batch schedulers (such as LSF, PBS) in the overall Grid workflow management. In the present work, we have employed GridWay [8] metascheduler - a Globus incubator project - to schedule and manage jobs across TIGRE. The GridWay is a light-weight metascheduler that fully utilizes Globus functionalities. It is designed to provide efficient use of dynamic Grid resources by multiple users for Grid infrastructures built on top of Globus services. The TIGRE site administrator can control the resource sharing through a powerful built-in scheduler provided by GridWay or by extending GridWay"s external scheduling module to provide their own scheduling policies. Application users can write job descriptions using GridWay"s simple and direct job template format (see Section 4 for details) or standard Job Submission Description Language (JSDL). See section 4 for implementation details. .4. Customer Service Management System A TIGRE portal [2] was designed and deployed to interface users and resource providers. It was designed using GridPort [13] and is maintained by TACC. The TIGRE environment is supported by open source tools such as the Open Ticket Request System (OTRS) [14] for servicing trouble tickets, and MoinMoin [15] Wiki for TIGRE content and knowledge management for education, outreach and training. The links for OTRS and Wiki are consumed by the TIGRE portal [2] - the gateway for users and resource providers. The TIGRE resource status and loads are monitored by the Grid Port Information Repository (GPIR) service of the GridPort toolkit [13] which interfaces with local cluster load monitoring service such as Ganglia. The GPIR utilizes cron jobs on each resource to gather site specific resource characteristics such as jobs that are running, queued and waiting for resource allocation. . ENSEMBLE KALMAN FILTER APPLICATION The main goal of hydrocarbon reservoir simulations is to forecast the production behavior of oil and gas field (denoted as field hereafter) for its development and optimal management. In reservoir modeling, the field is divided into several geological models as shown in Figure 1. For accurate performance forecasting of the field, it is necessary to reconcile several geological models to the dynamic response of the field through history matching [16-20]. Figure 1. Cross-sectional view of the Field. Vertical layers correspond to different geological models and the nails are oil wells whose historical information will be used for forecasting the production behavior. (Figure Ref:http://faculty.smu.edu/zchen/research.html). The EnKF is a Monte Carlo method that works with an ensemble of reservoir models. This method utilizes  crosscovariances [21] between the field measurements and the reservoir model parameters (derived from several models) to estimate prediction uncertainties. The geological model parameters in the ensemble are sequentially updated with a goal to minimize the prediction uncertainties. Historical production response of the field for over 50 years is used in these simulations. The main advantage of EnKF is that it can be readily linked to any reservoir simulator, and can assimilate latest production data without the need to re-run the simulator from initial conditions. Researchers in Texas are large subscribers of the Schlumberger ECLIPSE [22] package for reservoir simulations. In the reservoir modeling, each geological model checks out an ECLIPSE license. The simulation runtime of the EnKF methodology depends on the number of geological models used, number of ECLIPSE licenses available, production history of the field, and propagated uncertainties in history matching. The overall EnKF workflow is shown Figure 2. Figure 2. Ensemble Kaman Filter Data Assimilation Workflow. Each site has L licenses. At START, the master/control process (EnKF main program) reads the simulation configuration file for number (N) of models, and model-specific input files. Then, N working directories are created to store the output files. At the end of iteration, the master/control process collects the output files from N models and post processes  crosscovariances [21] to estimate the prediction uncertainties. This information will be used to update models (or input files) for the next iteration. The simulation continues until the production histories are exhausted. Typical EnKF simulation with N=50 and field histories of 50-60 years, in time steps ranging from three months to a year, takes about three weeks on a serial computing environment. In parallel computing environment, there is no interprocess communication between the geological models in the ensemble. However, at the end of each simulation time-step, model-specific output files are to be collected for analyzing cross covariances [21] and to prepare next set of input files. Therefore, master-slave model in  messagepassing (MPI) environment is a suitable paradigm. In this approach, the geological models are treated as slaves and are distributed across the available processors. The master Cluster or (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N. . . ECLIPSE on site A ECLIPSE on Site B ECLIPSE on Site Z Collect N Model Outputs, Post-process Output files END . . . process collects model-specific output files, analyzes and prepares next set of input files for the simulation. Since each geological model checks out an ECLIPSE license, parallelizability of the simulation depends on the number of licenses available. When the available number of licenses is less than the number of models in the ensemble, one or more of the nodes in the MPI group have to handle more than one model in a serial fashion and therefore, it takes longer to complete the simulation. A Petroleum Engineering Department usually procures 0-15 ECLIPSE licenses while at least ten-fold increase in the number of licenses would be necessary for industry standard simulations. The number of licenses can be increased by involving several Petroleum Engineering Departments that support ECLIPSE package. Since MPI does not scale very well for applications that involve remote compute clusters, and to get around the firewall issues with license servers across administrative domains, Grid-enabling the EnKF workflow seems to be necessary. With this motivation, we have implemented Grid-enabled EnKF workflow for the TIGRE environment and demonstrated parallelizability of the application across TIGRE using GridWay metascheduler. Further details are provided in the next section. . IMPLEMENTATION DETAILS To Grid-enable the EnKF approach, we have eliminated the MPI code for parallel processing and replaced with N single processor jobs (or sub-jobs) where, N is the number of geological models in the ensemble. These model-specific sub-jobs were distributed across TIGRE sites that support ECLIPSE package using the GridWay [8] metascheduler. For each sub-job, we have constructed a GridWay job template that specifies the executable, input and output files, and resource requirements. Since the TIGRE compute resources are not expected to change frequently, we have used static resource discovery policy for GridWay and the sub-jobs were scheduled dynamically across the TIGRE resources using GridWay. Figure 3 represents the sub-job template file for the GridWay metascheduler. Figure 3. GridWay Sub-Job Template In Figure 3, REQUIREMENTS flag is set to choose the resources that satisfy the application requirements. In the case of EnKF application, for example, we need resources that support ECLIPSE package. ARGUMENTS flag specifies the model in the ensemble that will invoke ECLIPSE at a remote site. INPUT_FILES is prepared by the EnKF main program (or master/control process) and is transferred by GridWay to the remote site where it is  untared and is prepared for execution. Finally, OUTPUT_FILES specifies the name and location where the output files are to be written. The command-line features of GridWay were used to collect and process the model-specific outputs to prepare new set of input files. This step mimics MPI process synchronization in master-slave model. At the end of each iteration, the compute resources and licenses are committed back to the pool. Table 1 shows the sub-jobs in TIGRE Grid via GridWay using gwps command and for clarity, only selected columns were shown . USER JID DM EM NAME HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hpcc.ttu.edu/LSF pingluo 91 wrap pend enkf.jt minigar.hpcc.ttu.edu/LSF pingluo 92 wrap done enkf.jt cosmos.tamu.edu/PBS pingluo 93 wrap epil enkf.jt cosmos.tamu.edu/PBS Table 1. Job scheduling across TIGRE using GridWay Metascheduler. DM: Dispatch state, EM: Execution state, JID is the job id and HOST corresponds to site specific cluster and its local batch scheduler. When a job is submitted to GridWay, it will go through a series of dispatch (DM) and execution (EM) states. For DM, the states include pend(ing), prol(og), wrap(per), epil(og), and done. DM=prol means the job has been scheduled to a resource and the remote working directory is in preparation. DM=warp implies that GridWay is executing the wrapper which in turn executes the application. DM=epil implies the job has finished running at the remote site and results are being transferred back to the GridWay server. Similarly, when EM=pend implies the job is waiting in the queue for resource and the job is running when EM=actv. For complete list of message flags and their descriptions, see the documentation in ref [8]. We have demonstrated the Grid-enabled EnKF runs using GridWay for TIGRE environment. The jobs are so chosen that the runtime doesn"t exceed more than a half hour. The simulation runs involved up to 20 jobs between A&M and TTU sites with TTU serving 10 licenses. For resource information, see Table I. One of the main advantages of Grid-enabled EnKF simulation is that both the resources and licenses are released back to the pool at the end of each simulation time step unlike in the case of MPI implementation where licenses and nodes are locked until the completion of entire simulation. However, the fact that each sub-job gets scheduled independently via GridWay could possibly incur another time delay caused by waiting in queue for execution in each simulation time step. Such delays are not expected EXECUTABLE=runFORWARD REQUIREMENTS=HOSTNAME=cosmos.tamu.edu | HOSTNAME=antaeus.hpcc.ttu.edu | HOSTNAME=minigar.hpcc.ttu.edu | ARGUMENTS=001 INPUT_FILES=001.in.tar OUTPUT_FILES=001.out.tar in MPI implementation where the node is blocked for processing sub-jobs (model-specific calculation) until the end of the simulation. There are two main scenarios for comparing Grid and cluster computing approaches. Scenario I: The cluster is heavily loaded. The conceived average waiting time of job requesting large number of CPUs is usually longer than waiting time of jobs requesting single CPU. Therefore, overall waiting time could be shorter in Grid approach which requests single CPU for each sub-job many times compared to MPI implementation that requests large number of CPUs at a single time. It is apparent that Grid scheduling is beneficial especially when cluster is heavily loaded and requested number of CPUs for the MPI job is not readily available. Scenario II: The cluster is relatively less loaded or largely available. It appears the MPI implementation is favorable compared to the Grid scheduling. However, parallelizability of the EnKF application depends on the number of ECLIPSE licenses and ideally, the number of licenses should be equal to the number of models in the ensemble. Therefore, if a single institution does not have sufficient number of licenses, the cluster availability doesn"t help as much as it is expected. Since the collaborative environment such as TIGRE can address both compute and software resource requirements for the EnKF application, Grid-enabled approach is still advantageous over the conventional MPI implementation in any of the above scenarios. . CONCLUSIONS AND FUTURE WORK TIGRE is a higher education Grid development project and its purpose is to sustain and extend research and educational opportunities across Texas. Within the energy exploration application area, we have Grid-enabled the MPI implementation of the ensemble Kalman filter data assimilation methodology for reservoir characterization. This task was accomplished by removing MPI code for parallel processing and replacing with single processor jobs one for each geological model in the ensemble. These single processor jobs were scheduled across TIGRE via GridWay metascheduler. We have demonstrated that by pooling licenses across TIGRE sites, more geological models can be handled in parallel and therefore conceivably better simulation accuracy. This approach has several advantages over MPI implementation especially when a site specific cluster is heavily loaded and/or the number licenses required for the simulation is more than those available at a single site. Towards the future work, it would be interesting to compare the runtime between MPI, and Grid implementations for the EnKF application. This effort could shed light on quality of service (QoS) of Grid environments in comparison with cluster computing. Another aspect of interest in the near future would be managing both compute and license resources to address the job (or processor)-to-license ratio management. . OBSERVATIONS AND LESSIONS LEARNED The Grid-enabling efforts for EnKF application have provided ample opportunities to gather insights on the visibility and promise of Grid computing environments for application development and support. The main issues are industry standard data security and QoS comparable to cluster computing. Since the reservoir modeling research involves proprietary data of the field, we had to invest substantial efforts initially in educating the application researchers on the ability of Grid services in supporting the industry standard data security through role- and privilege-based access using X.509 standard. With respect to QoS, application researchers expect cluster level QoS with Grid environments. Also, there is a steep learning curve in Grid computing compared to the conventional cluster computing. Since Grid computing is still an emerging technology, and it spans over several administrative domains, Grid computing is still premature especially in terms of the level of QoS although, it offers better data security standards compared to commodity clusters. It is our observation that training and outreach programs that compare and contrast the Grid and cluster computing environments would be a suitable approach for enhancing user participation in Grid computing. This approach also helps users to match their applications and abilities Grids can offer. In summary, our efforts through TIGRE in Grid-enabling the EnKF data assimilation methodology showed substantial promise in engaging Petroleum Engineering researchers through intercampus collaborations. Efforts are under way to involve more schools in this effort. These efforts may result in increased collaborative research, educational opportunities, and workforce development through graduate/faculty research programs across TIGRE Institutions. . ACKNOWLEDGMENTS The authors acknowledge the State of Texas for supporting the TIGRE project through the Texas Enterprise Fund, and TIGRE Institutions for providing the mechanism, in which the authors (Ravi Vadapalli, Taesung Kim, and Ping Luo) are also participating. The authors thank the application researchers Prof. Akhil Datta-Gupta of Texas A&M University and Prof. Lloyd Heinze of Texas Tech University for their discussions and interest to exploit the TIGRE environment to extend opportunities in research and development. . REFERENCES [1] Foster, I. and Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infrastructure (The Elsevier series in Grid computing) [2] TIGRE Portal: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., and Chaffin, D. 2007. Demonstration of TIGRE environment for Grid enabled/suitable applications. 8th IEEE/ACM Int. Conf. on Grid Computing, Sept 19-21, Austin [4] The High Performance Computing across Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gardner, R. Wilde, M. Blatecky, A. McGee, J. and Quick, R. 2007. The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 and http://www.opensciencegrid.org [6] Reed, D.A. 2003. Grids, the TeraGrid and Beyond, Computer, vol 30, no. 1 and http://www.teragrid.org [7] Evensen, G. 2006. Data Assimilation: The Ensemble Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. and Llorente, I. M. 005. Scientific Programming, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. The GriPhyN project: Towards petascale virtual data grids, technical report  GriPhyN-200115 and http://vdt.cs.wisc.edu [10] The PacMan documentation and installation guide http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. and Sill, A. 2007. Case studies in identify management for virtual organizations, EDUCAUSE Southwest Reg. Conf., Feb 21-23, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] The Grid User Management System (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. and Boisseau, J. 2003. Building grid computing portals: The NPACI grid portal toolkit, Grid computing: making the global infrastructure a reality, Chapter 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. and Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http://otrs.org [15] The MoinMoin Wiki Engine http://moinmoin.wikiwikiweb.de [16] Vasco, D.W. Yoon, S. and Datta-Gupta, A. 1999. Integrating dynamic data into high resolution reservoir models using streamline-based analytic sensitivity coefficients, Society of Petroleum Engineers (SPE) Journal, 4 (4). [17] Emanuel, A. S. and Milliken, W. J. 1998. History matching finite difference models with 3D streamlines, SPE 49000, Proc of the Annual Technical Conf and Exhibition, Sept  730, New Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. and Vefring, E.H. 003. Reservoir monitoring and Continuous Model Updating using Ensemble Kalman Filter, SPE 84372, Proc of the Annual Technical Conf and Exhibition, Oct 5-8, Denver, CO. [19] Jafarpour B. and McLaughlin, D.B. 2007. History matching with an ensemble Kalman filter and discrete cosine parameterization, SPE 108761, Proc of the Annual Technical Conf and Exhibition, Nov 11-14, Anaheim, CA [20] Li, G. and Reynolds, A. C. 2007. An iterative ensemble Kalman filter for data assimilation, SPE 109808, Proc of the SPE Annual Technical Conf and Exhibition, Nov 11-14, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Streamline assisted ensemble Kalman filter for rapid and continuous reservoir model updating. Proc of the Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp
MSP: Multi-Sequence Positioning of Wireless Sensor Nodes∗ Ziguo Zhong Computer Science and Engineering University of Minnesota zhong@cs.umn.edu Tian He Computer Science and Engineering University of Minnesota tianhe@cs.umn.edu Abstract Wireless Sensor Networks have been proposed for use in many location-dependent applications. Most of these need to identify the locations of wireless sensor nodes, a challenging task because of the severe constraints on cost, energy and  effective range of sensor devices. To overcome limitations in  existing solutions, we present a Multi-Sequence Positioning (MSP) method for large-scale stationary sensor node localization in outdoor environments. The novel idea behind MSP is to  reconstruct and estimate two-dimensional location information for each sensor node by processing multiple one-dimensional node sequences, easily obtained through loosely guided event  distribution. Starting from a basic MSP design, we propose four optimizations, which work together to increase the localization accuracy. We address several interesting issues, such as  incomplete (partial) node sequences and sequence flip, found in the Mirage test-bed we built. We have evaluated the MSP system through theoretical analysis, extensive simulation as well as two physical systems (an indoor version with 46 MICAz motes and an outdoor version with 20 MICAz motes). This  evaluation demonstrates that MSP can achieve an accuracy within one foot, requiring neither additional costly hardware on  sensor nodes nor precise event distribution. It also provides a nice tradeoff between physical cost (anchors) and soft cost (events), while maintaining localization accuracy. Categories and Subject Descriptors C.2.4 [Computer Communications Networks]:  Distributed Systems General Terms Algorithms, Measurement, Design, Performance,  Experimentation  Introduction Although Wireless Sensor Networks (WSN) have shown promising prospects in various applications [5], researchers still face several challenges for massive deployment of such networks. One of these is to identify the location of  individual sensor nodes in outdoor environments. Because of  unpredictable flow dynamics in airborne scenarios, it is not currently feasible to localize sensor nodes during massive UVA-based deployment. On the other hand, geometric information is  indispensable in these networks, since users need to know where events of interest occur (e.g., the location of intruders or of a bomb explosion). Previous research on node localization falls into two  categories: range-based approaches and range-free approaches. Range-based approaches [13, 17, 19, 24] compute per-node location information iteratively or recursively based on  measured distances among target nodes and a few anchors which precisely know their locations. These approaches generally require costly hardware (e.g., GPS) and have limited  effective range due to energy constraints (e.g., ultrasound-based TDOA [3, 17]). Although range-based solutions can be  suitably used in small-scale indoor environments, they are  considered less cost-effective for large-scale deployments. On the other hand, range-free approaches [4, 8, 10, 13, 14, 15] do not require accurate distance measurements, but localize the node based on network connectivity (proximity) information.  Unfortunately, since wireless connectivity is highly influenced by the environment and hardware calibration, existing solutions fail to deliver encouraging empirical results, or require substantial survey [2] and calibration [24] on a case-by-case basis. Realizing the impracticality of existing solutions for the large-scale outdoor environment, researchers have recently proposed solutions (e.g., Spotlight [20] and Lighthouse [18]) for sensor node localization using the spatiotemporal  correlation of controlled events (i.e., inferring nodes" locations based on the detection time of controlled events). These solutions demonstrate that long range and high accuracy localization can be achieved simultaneously with little additional cost at  sensor nodes. These benefits, however, come along with an  implicit assumption that the controlled events can be precisely distributed to a specified location at a specified time. We argue that precise event distribution is difficult to achieve, especially at large scale when terrain is uneven, the event distribution  device is not well calibrated and its position is difficult to  maintain (e.g., the helicopter-mounted scenario in [20]). To address these limitations in current approaches, in this paper we present a multi-sequence positioning (MSP) method 5 for large-scale stationary sensor node localization, in  deployments where an event source has line-of-sight to all sensors. The novel idea behind MSP is to estimate each sensor node"s two-dimensional location by processing multiple easy-to-get one-dimensional node sequences (e.g., event detection order) obtained through loosely-guided event distribution. This design offers several benefits. First, compared to a range-based approach, MSP does not require additional costly hardware. It works using sensors typically used by sensor  network applications, such as light and acoustic sensors, both of which we specifically consider in this work. Second, compared to a range-free approach, MSP needs only a small number of anchors (theoretically, as few as two), so high accuracy can be achieved economically by introducing more events instead of more anchors. And third, compared to Spotlight, MSP does not require precise and sophisticated event distribution, an  advantage that significantly simplifies the system design and reduces calibration cost. This paper offers the following additional intellectual  contributions: • We are the first to localize sensor nodes using the concept of node sequence, an ordered list of sensor nodes, sorted by the detection time of a disseminated event. We  demonstrate that making full use of the information embedded in one-dimensional node sequences can significantly  improve localization accuracy. Interestingly, we discover that repeated reprocessing of one-dimensional node  sequences can further increase localization accuracy. • We propose a distribution-based location estimation  strategy that obtains the final location of sensor nodes using the marginal probability of joint distribution among  adjacent nodes within the sequence. This new algorithm  outperforms the widely adopted Centroid estimation [4, 8]. • To the best of our knowledge, this is the first work to improve the localization accuracy of nodes by adaptive events. The generation of later events is guided by  localization results from previous events. • We evaluate line-based MSP on our new Mirage test-bed, and wave-based MSP in outdoor environments. Through system implementation, we discover and address several interesting issues such as partial sequence and sequence flips. To reveal MSP performance at scale, we provide analytic results as well as a complete simulation study. All the simulation and implementation code is available online at http://www.cs.umn.edu/∼zhong/MSP. The rest of the paper is organized as follows. Section 2 briefly surveys the related work. Section 3 presents an overview of the MSP localization system. In sections 4 and 5, basic MSP and four advanced processing methods are  introduced. Section 6 describes how MSP can be applied in a wave propagation scenario. Section 7 discusses several  implementation issues. Section 8 presents simulation results, and Section 9 reports an evaluation of MSP on the Mirage test-bed and an outdoor test-bed. Section 10 concludes the paper.  Related Work Many methods have been proposed to localize wireless  sensor devices in the open air. Most of these can be  classified into two categories: range-based and range-free  localization. Range-based localization systems, such as GPS [23], Cricket [17], AHLoS [19], AOA [16], Robust  Quadrilaterals [13] and Sweeps [7], are based on fine-grained  point-topoint distance estimation or angle estimation to identify  pernode location. Constraints on the cost, energy and hardware footprint of each sensor node make these range-based  methods undesirable for massive outdoor deployment. In addition, ranging signals generated by sensor nodes have a very limited effective range because of energy and form factor concerns. For example, ultrasound signals usually effectively propagate 0-30 feet using an on-board transmitter [17]. Consequently, these range-based solutions require an undesirably high  deployment density. Although the received signal strength  indicator (RSSI) related [2, 24] methods were once considered an ideal low-cost solution, the irregularity of radio  propagation [26] seriously limits the accuracy of such systems. The recently proposed RIPS localization system [11] superimposes two RF waves together, creating a low-frequency envelope that can be accurately measured. This ranging technique performs very well as long as antennas are well oriented and  environmental factors such as multi-path effects and background noise are sufficiently addressed. Range-free methods don"t need to estimate or measure  accurate distances or angles. Instead, anchors or controlled-event distributions are used for node localization. Range-free  methods can be generally classified into two types: anchor-based and anchor-free solutions. • For anchor-based solutions such as Centroid [4], APIT [8], SeRLoc [10], Gradient [13] , and APS [15], the main idea is that the location of each node is estimated based on the known locations of the anchor nodes. Different anchor combinations narrow the areas in which the target nodes can possibly be located. Anchor-based solutions normally require a high density of anchor nodes so as to achieve good accuracy. In practice, it is desirable to have as few anchor nodes as possible so as to lower the system cost. • Anchor-free solutions require no anchor nodes. Instead, external event generators and data processing platforms are used. The main idea is to correlate the event detection time at a sensor node with the known space-time  relationship of controlled events at the generator so that detection time-stamps can be mapped into the locations of sensors. Spotlight [20] and Lighthouse [18] work in this fashion. In Spotlight [20], the event distribution needs to be  precise in both time and space. Precise event distribution is difficult to achieve without careful calibration,  especially when the event-generating devices require certain mechanical maneuvers (e.g., the telescope mount used in Spotlight). All these increase system cost and reduce  localization speed. StarDust [21], which works much faster, uses label relaxation algorithms to match light spots  reflected by corner-cube retro-reflectors (CCR) with sensor nodes using various constraints. Label relaxation  algorithms converge only when a sufficient number of robust constraints are obtained. Due to the environmental impact on RF connectivity constraints, however, StarDust is less accurate than Spotlight. In this paper, we propose a balanced solution that avoids the limitations of both anchor-based and anchor-free solutions. Unlike anchor-based solutions [4, 8], MSP allows a flexible tradeoff between the physical cost (anchor nodes) with the soft 6  A B     Target nodeAnchor node A 5 3 B2 4  B2 5A 43 A25B4 3  52 AB 4 3      (b) (c)(d) (a) Event 1 Node Sequence generated by event 1 Event 3 Node Sequence generated by event 2 Node Sequence generated by event 3 Node Sequence generated by event 4 Event 2 Event 4 Figure 1. The MSP System Overview cost (localization events). MSP uses only a small number of anchors (theoretically, as few as two). Unlike anchor-free  solutions, MSP doesn"t need to maintain rigid time-space  relationships while distributing events, which makes system design simpler, more flexible and more robust to calibration errors.  System Overview MSP works by extracting relative location information from multiple simple one-dimensional orderings of nodes.  Figure 1(a) shows a layout of a sensor network with anchor nodes and target nodes. Target nodes are defined as the nodes to be localized. Briefly, the MSP system works as follows. First, events are generated one at a time in the network area (e.g., ultrasound propagations from different locations, laser scans with diverse angles). As each event propagates, as shown in Figure 1(a), each node detects it at some particular time  instance. For a single event, we call the ordering of nodes, which is based on the sequential detection of the event, a node  sequence. Each node sequence includes both the targets and the anchors as shown in Figure 1(b). Second, a multi-sequence processing algorithm helps to narrow the possible location of each node to a small area (Figure 1(c)). Finally, a  distributionbased estimation method estimates the exact location of each sensor node, as shown in Figure 1(d). Figure 1 shows that the node sequences can be obtained much more economically than accurate pair-wise distance measurements between target nodes and anchor nodes via  ranging methods. In addition, this system does not require a rigid time-space relationship for the localization events, which is critical but hard to achieve in controlled event distribution  scenarios (e.g., Spotlight [20]). For the sake of clarity in presentation, we present our system in two cases: • Ideal Case, in which all the node sequences obtained from the network are complete and correct, and nodes are time-synchronized [12, 9]. • Realistic Deployment, in which (i) node sequences can be partial (incomplete), (ii) elements in sequences could flip (i.e., the order obtained is reversed from reality), and (iii) nodes are not time-synchronized. To introduce the MSP algorithm, we first consider a simple straight-line scan scenario. Then, we describe how to  implement straight-line scans as well as other event types, such as sound wave propagation.  A     B C     Straight-line Scan 1 Straight-lineScan2    A  C     B    C 5   A 4 6 B  8 Target node Anchor node Figure 2. Obtaining Multiple Node Sequences  Basic MSP Let us consider a sensor network with N target nodes and M anchor nodes randomly deployed in an area of size S. The top-level idea for basic MSP is to split the whole sensor  network area into small pieces by processing node sequences.  Because the exact locations of all the anchors in a node sequence are known, all the nodes in this sequence can be divided into O(M +1) parts in the area. In Figure 2, we use numbered circles to denote target nodes and numbered hexagons to denote anchor nodes. Basic MSP uses two straight lines to scan the area from different directions, treating each scan as an event. All the nodes react to the event sequentially generating two node sequences. For vertical scan , the node sequence is (8,1,5,A,6,C,4,3,7,2,B,9), as shown outside the right boundary of the area in Figure 2; for  horizontal scan 2, the node sequence is (3,1,C,5,9,2,A,4,6,B,7,8), as shown under the bottom boundary of the area in Figure 2. Since the locations of the anchor nodes are available, the anchor nodes in the two node sequences actually split the area vertically and horizontally into 16 parts, as shown in Figure 2. To extend this process, suppose we have M anchor nodes and perform d scans from different angles, obtaining d node  sequences and dividing the area into many small parts.  Obviously, the number of parts is a function of the number of  anchors M, the number of scans d, the anchors" location as well as the slop k for each scan line. According to the pie-cutting  theorem [22], the area can be divided into O(M2d2) parts. When M and d are appropriately large, the polygon for each target node may become sufficiently small so that accurate  estimation can be achieved. We emphasize that accuracy is affected not only by the number of anchors M, but also by the number of events d. In other words, MSP provides a tradeoff between the physical cost of anchors and the soft cost of events. Algorithm 1 depicts the computing architecture of basic MSP. Each node sequence is processed within line 1 to 8. For each node, GetBoundaries() in line 5 searches for the  predecessor and successor anchors in the sequence so as to  determine the boundaries of this node. Then in line 6 UpdateMap() shrinks the location area of this node according to the newly obtained boundaries. After processing all sequences, Centroid Estimation (line 11) set the center of gravity of the final  polygon as the estimated location of the target node. Basic MSP only makes use of the order information  between a target node and the anchor nodes in each sequence. Actually, we can extract much more location information from 7 Algorithm 1 Basic MSP Process Output: The estimated location of each node. : repeat : GetOneUnprocessedSeqence(); : repeat : GetOneNodeFromSequenceInOrder(); : GetBoundaries(); : UpdateMap(); : until All the target nodes are updated; : until All the node sequences are processed; : repeat 0: GetOneUnestimatedNode(); 1: CentroidEstimation(); 2: until All the target nodes are estimated; each sequence. Section 5 will introduce advanced MSP, in which four novel optimizations are proposed to improve the performance of MSP significantly.  Advanced MSP Four improvements to basic MSP are proposed in this  section. The first three improvements do not need additional sensing and communication in the networks but require only slightly more off-line computation. The objective of all these improvements is to make full use of the information embedded in the node sequences. The results we have obtained  empirically indicate that the implementation of the first two methods can dramatically reduce the localization error, and that the third and fourth methods are helpful for some system deployments. .1 Sequence-Based MSP As shown in Figure 2, each scan line and M anchors, splits the whole area into M + 1 parts. Each target node falls into one polygon shaped by scan lines. We noted that in basic MSP, only the anchors are used to narrow down the polygon of each target node, but actually there is more information in the node sequence that we can made use of. Let"s first look at a simple example shown in Figure 3. The previous scans narrow the locations of target node 1 and node  into two dashed rectangles shown in the left part of Figure 3. Then a new scan generates a new sequence (1, 2). With  knowledge of the scan"s direction, it is easy to tell that node 1 is located to the left of node 2. Thus, we can further narrow the location area of node 2 by eliminating the shaded part of node "s rectangle. This is because node 2 is located on the right of node 1 while the shaded area is outside the lower boundary of node 1. Similarly, the location area of node 1 can be narrowed by eliminating the shaded part out of node 2"s right boundary. We call this procedure sequence-based MSP which means that the whole node sequence needs to be processed node by node in order. Specifically, sequence-based MSP follows this exact processing rule:    2   Lower boundary of 1 Upper boundary of 1 Lower boundary of 2 Upper boundary of 2 New sequence New upper boundary of 1 New Lower boundary of 2 EventPropagation Figure 3. Rule Illustration in Sequence Based MSP Algorithm 2 Sequence-Based MSP Process Output: The estimated location of each node. : repeat : GetOneUnprocessedSeqence(); : repeat : GetOneNodeByIncreasingOrder(); : ComputeLowbound(); : UpdateMap(); : until The last target node in the sequence; : repeat : GetOneNodeByDecreasingOrder(); 0: ComputeUpbound(); 1: UpdateMap(); 2: until The last target node in the sequence; 3: until All the node sequences are processed; 4: repeat 5: GetOneUnestimatedNode(); 6: CentroidEstimation(); 7: until All the target nodes are estimated; Elimination Rule: Along a scanning direction, the lower boundary of the successor"s area must be equal to or larger than the lower boundary of the predecessor"s area, and the  upper boundary of the predecessor"s area must be equal to or smaller than the upper boundary of the successor"s area. In the case of Figure 3, node 2 is the successor of node 1, and node 1 is the predecessor of node 2. According to the elimination rule, node 2"s lower boundary cannot be smaller than that of node 1 and node 1"s upper boundary cannot exceed node 2"s upper boundary. Algorithm 2 illustrates the pseudo code of sequence-based MSP. Each node sequence is processed within line 3 to 13. The sequence processing contains two steps: Step 1 (line 3 to 7): Compute and modify the lower  boundary for each target node by increasing order in the node  sequence. Each node"s lower boundary is determined by the lower boundary of its predecessor node in the sequence, thus the processing must start from the first node in the sequence and by increasing order. Then update the map according to the new lower boundary. Step 2 (line 8 to 12): Compute and modify the upper  boundary for each node by decreasing order in the node sequence. Each node"s upper boundary is determined by the upper  boundary of its successor node in the sequence, thus the processing must start from the last node in the sequence and by  decreasing order. Then update the map according to the new upper boundary. After processing all the sequences, for each node, a polygon bounding its possible location has been found. Then,  center-ofgravity-based estimation is applied to compute the exact  location of each node (line 14 to 17). An example of this process is shown in Figure 4. The third scan generates the node sequence (B,9,2,7,4,6,3,8,C,A,5,1). In addition to the anchor split lines, because nodes 4 and 7 come after node 2 in the sequence, node 4 and 7"s polygons could be narrowed according to node 2"s lower boundary (the lower right-shaded area); similarly, the shaded area in node 2"s  rectangle could be eliminated since this part is beyond node 7"s upper boundary indicated by the dotted line. Similar  eliminating can be performed for node 3 as shown in the figure. 8  A     B C     Straight-line Scan 1 Straight-lineScan2 Straight-line Scan 3 Target node Anchor node Figure 4. Sequence-Based MSP Example  A     B C     Straight-line Scan 1 Straight-lineScan2 Straight-line Scan 3 Reprocessing Scan 1 Target node Anchor node Figure 5. Iterative MSP: Reprocessing Scan 1 From above, we can see that the sequence-based MSP makes use of the information embedded in every sequential node pair in the node sequence. The polygon boundaries of the target nodes obtained in prior could be used to further split other target nodes" areas. Our evaluation in Sections 8 and 9 shows that sequence-based MSP considerably enhances system accuracy. .2 Iterative MSP Sequence-based MSP is preferable to basic MSP because it extracts more information from the node sequence. In fact,  further useful information still remains! In sequence-based MSP, a sequence processed later benefits from information produced by previously processed sequences (e.g., the third scan in  Figure 5). However, the first several sequences can hardly benefit from other scans in this way. Inspired by this phenomenon, we propose iterative MSP. The basic idea of iterative MSP is to process all the sequences iteratively several times so that the processing of each single sequence can benefit from the results of other sequences. To illustrate the idea more clearly, Figure 4 shows the results of three scans that have provided three sequences. Now if we process the sequence (8,1,5,A,6,C,4,3,7,2,B,9) obtained from scan 1 again, we can make progress, as shown in Figure 5. The reprocessing of the node sequence 1 provides information in the way an additional vertical scan would. From  sequencebased MSP, we know that the upper boundaries of nodes 3 and  along the scan direction must not extend beyond the upper boundary of node 7, therefore the grid parts can be eliminated (a) Central of Gravity (b) Joint Distribution  2   1    2   2   1  Figure 6. Example of Joint Distribution Estimation …... vm ap[0] vm ap[1] vm ap[2] vm ap[3] Combine m ap Figure 7. Idea of DBE MSP for Each Node for the nodes 3 and node 4, respectively, as shown in Figure 5. From this example, we can see that iterative processing of the sequence could help further shrink the polygon of each target node, and thus enhance the accuracy of the system. The implementation of iterative MSP is straightforward: process all the sequences multiple times using sequence-based MSP. Like sequence-based MSP, iterative MSP introduces no additional event cost. In other words, reprocessing does not actually repeat the scan physically. Evaluation results in  Section 8 will show that iterative MSP contributes noticeably to a lower localization error. Empirical results show that after 5 iterations, improvements become less significant. In summary, iterative processing can achieve better performance with only a small computation overhead. .3 Distribution-Based Estimation After determining the location area polygon for each node, estimation is needed for a final decision. Previous research mostly applied the Center of Gravity (COG) method [4] [8] [10] which minimizes average error. If every node is  independent of all others, COG is the statistically best solution. In MSP, however, each node may not be independent. For  example, two neighboring nodes in a certain sequence could have overlapping polygon areas. In this case, if the marginal  probability of joint distribution is used for estimation, better  statistical results are achieved. Figure 6 shows an example in which node 1 and node 2 are located in the same polygon. If COG is used, both nodes are localized at the same position (Figure 6(a)). However, the node sequences obtained from two scans indicate that node 1 should be to the left of and above node 2, as shown in Figure 6(b). The high-level idea of distribution-based estimation  proposed for MSP, which we call DBE MSP, is illustrated in  Figure 7. The distributions of each node under the ith scan (for the ith node sequence) are estimated in node.vmap[i], which is a data structure for remembering the marginal distribution over scan i. Then all the vmaps are combined to get a single map and weighted estimation is used to obtain the final location. For each scan, all the nodes are sorted according to the gap, which is the diameter of the polygon along the direction of the scan, to produce a second, gap-based node sequence. Then, the estimation starts from the node with the smallest gap. This is because it is statistically more accurate to assume a uniform distribution of the node with smaller gap. For each node  processed in order from the gap-based node sequence, either if 9 Pred. node"s area Predecessor node exists: conditional distribution based on pred. node"s area Alone: Uniformly Distributed Succ. node"s area Successor node exists: conditional distribution based on succ. node"s area Succ. node"s area Both predecessor and successor nodes exist: conditional distribution based on both of them Pred. node"s area Figure 8. Four Cases in DBE Process no neighbor node in the original event-based node sequence shares an overlapping area, or if the neighbors have not been processed due to bigger gaps, a uniform distribution Uniform() is applied to this isolated node (the Alone case in Figure 8). If the distribution of its neighbors sharing overlapped areas has been processed, we calculate the joint distribution for the node. As shown in Figure 8, there are three possible cases  depending on whether the distribution of the overlapping predecessor and/or successor nodes have/has already been estimated. The estimation"s strategy of starting from the most accurate node (smallest gap node) reduces the problem of estimation  error propagation. The results in the evaluation section indicate that applying distribution-based estimation could give  statistically better results. .4 Adaptive MSP So far, all the enhancements to basic MSP focus on  improving the multi-sequence processing algorithm given a fixed set of scan directions. All these enhancements require only more computing time without any overhead to the sensor nodes.  Obviously, it is possible to have some choice and optimization on how events are generated. For example, in military situations, artillery or rocket-launched mini-ultrasound bombs can be used for event generation at some selected locations. In adaptive MSP, we carefully generate each new localization event so as to maximize the contribution of the new event to the refinement of localization, based on feedback from previous events. Figure 9 depicts the basic architecture of adaptive MSP. Through previous localization events, the whole map has been partitioned into many small location areas. The idea of  adaptive MSP is to generate the next localization event to achieve best-effort elimination, which ideally could shrink the location area of individual node as much as possible. We use a weighted voting mechanism to evaluate candidate localization events. Every node wants the next event to split its area evenly, which would shrink the area fast. Therefore, every node votes for the parameters of the next event (e.g., the scan angle k of the straight-line scan). Since the area map is  maintained centrally, the vote is virtually done and there is no need for the real sensor nodes to participate in it. After gathering all the voting results, the event parameters with the most votes win the election. There are two factors that determine the weight of each vote: • The vote for each candidate event is weighted according to the diameter D of the node"s location area. Nodes with bigger location areas speak louder in the voting, because Map Partitioned by the Localization Events Diameter of Each Area Candidate Localization Events Evaluation Trigger Next Localization Evet Figure 9. Basic Architecture of Adaptive MSP   Diameter D3   k  k  k  k  k  k  k 2 k 3 k  k4 k 5 k Weight el small i opt i j ii j i S S DkkDfkWeight arg ),(,()( ⋅=∆=   opt k Target node Anchor node Center of Gravity Node 3's area Figure 10. Candidate Slops for Node 3 at Anchor 1 overall system error is reduced mostly by splitting the larger areas. • The vote for each candidate event is also weighted  according to its elimination efficiency for a location area, which is defined as how equally in size (or in diameter) an event can cut an area. In other words, an optimal scan event cuts an area in the middle, since this cut shrinks the area quickly and thus reduces localization uncertainty quickly. Combining the above two aspects, the weight for each vote is computed according to the following equation (1): Weight(k j i ) = f(Di,△(k j i ,k opt i )) (1) k j i is node i"s jth supporting parameter for next event  generation; Di is diameter of node i"s location area; △(k j i ,k opt i ) is the distance between k j i and the optimal parameter k opt i for node i, which should be defined to fit the specific application. Figure 10 presents an example for node 1"s voting for the slopes of the next straight-line scan. In the system, there are a fixed number of candidate slopes for each scan (e.g., k1,k2,k3,k4...). The location area of target node 3 is shown in the figure. The candidate events k1 ,k2 ,k3 ,k4 ,k5 ,k6  are  evaluated according to their effectiveness compared to the optimal ideal event which is shown as a dotted line with appropriate weights computed according to equation (1). For this  specific example, as is illustrated in the right part of Figure 10, f(Di,△(k j i ,kopt i )) is defined as the following equation (2): Weight(kj i ) = f(Di,△(kj i ,kopt i )) = Di · Ssmall Slarge (2) Ssmall and Slarge are the sizes of the smaller part and larger part of the area cut by the candidate line respectively. In this case, node 3 votes 0 for the candidate lines that do not cross its area since Ssmall = 0. We show later that adaptive MSP improves localization  accuracy in WSNs with irregularly shaped deployment areas. 0 .5 Overhead and MSP Complexity Analysis This section provides a complexity analysis of the MSP  design. We emphasize that MSP adopts an asymmetric design in which sensor nodes need only to detect and report the events. They are blissfully oblivious to the processing methods  proposed in previous sections. In this section, we analyze the  computational cost on the node sequence processing side, where resources are plentiful. According to Algorithm 1, the computational complexity of Basic MSP is O(d · N · S), and the storage space required is O(N · S), where d is the number of events, N is the number of target nodes, and S is the area size. According to Algorithm 2, the computational complexity of both sequence-based MSP and iterative MSP is O(c·d ·N ·S), where c is the number of iterations and c = 1 for  sequencebased MSP, and the storage space required is O(N ·S). Both the computational complexity and storage space are equal within a constant factor to those of basic MSP. The computational complexity of the distribution-based  estimation (DBE MSP) is greater. The major overhead comes from the computation of joint distributions when both  predecessor and successor nodes exit. In order to compute the marginal probability, MSP needs to enumerate the locations of the predecessor node and the successor node. For example, if node A has predecessor node B and successor node C, then the marginal probability PA(x,y) of node A"s being at location (x,y) is: PA(x,y) = ∑ i ∑ j ∑ m ∑ n  NB,A,C ·PB(i, j)·PC(m,n) (3) NB,A,C is the number of valid locations for A satisfying the sequence (B, A, C) when B is at (i, j) and C is at (m,n); PB(i, j) is the available probability of node B"s being located at (i, j); PC(m,n) is the available probability of node C"s  being located at (m,n). A naive algorithm to compute equation (3) has complexity O(d · N · S3). However, since the marginal probability indeed comes from only one dimension along the scanning direction (e.g., a line), the complexity can be reduced to O(d · N · S1.5) after algorithm optimization. In addition, the final location areas for every node are much smaller than the original field S; therefore, in practice, DBE MSP can be  computed much faster than O(d ·N ·S1.5).  Wave Propagation Example So far, the description of MSP has been solely in the  context of straight-line scan. However, we note that MSP is  conceptually independent of how the event is propagated as long as node sequences can be obtained. Clearly, we can also  support wave-propagation-based events (e.g., ultrasound  propagation, air blast propagation), which are polar coordinate  equivalences of the line scans in the Cartesian coordinate system. This section illustrates the effects of MSP"s implementation in the wave propagation-based situation. For easy modelling, we have made the following assumptions: • The wave propagates uniformly in all directions,  therefore the propagation has a circle frontier surface. Since MSP does not rely on an accurate space-time relationship, a certain distortion in wave propagation is tolerable. If any directional wave is used, the propagation frontier surface can be modified accordingly.     Target node Anchor node Previous Event location A  Center of Gravity    B  C A line of preferred locations for next event Figure 11. Example of Wave Propagation Situation • Under the situation of line-of-sight, we allow obstacles to reflect or deflect the wave. Reflection and deflection are not problems because each node reacts only to the first detected event. Those reflected or deflected waves come later than the line-of-sight waves. The only thing the  system needs to maintain is an appropriate time interval  between two successive localization events. • We assume that background noise exists, and therefore we run a band-pass filter to listen to a particular wave  frequency. This reduces the chances of false detection. The parameter that affects the localization event generation here is the source location of the event. The different  distances between each node and the event source determine the rank of each node in the node sequence. Using the node  sequences, the MSP algorithm divides the whole area into many non-rectangular areas as shown in Figure 11. In this figure, the stars represent two previous event sources. The previous two propagations split the whole map into many areas by those dashed circles that pass one of the anchors. Each node is  located in one of the small areas. Since sequence-based MSP, iterative MSP and DBE MSP make no assumptions about the type of localization events and the shape of the area, all three optimization algorithms can be applied for the wave  propagation scenario. However, adaptive MSP needs more explanation. Figure 11 illustrates an example of nodes" voting for next event source locations. Unlike the straight-line scan, the critical parameter now is the location of the event source, because the distance between each node and the event source determines the rank of the node in the sequence. In Figure 11, if the next event breaks out along/near the solid thick gray line, which perpendicularly bisects the solid dark line between anchor C and the center of gravity of node 9"s area (the gray area), the wave would reach anchor C and the center of gravity of node 9"s area at roughly the same time, which would relatively equally divide node 9"s area. Therefore, node 9 prefers to vote for the positions around the thick gray line.  Practical Deployment Issues For the sake of presentation, until now we have described MSP in an ideal case where a complete node sequence can be obtained with accurate time synchronization. In this section we describe how to make MSP work well under more realistic conditions. 1 .1 Incomplete Node Sequence For diverse reasons, such as sensor malfunction or natural obstacles, the nodes in the network could fail to detect  localization events. In such cases, the node sequence will not be complete. This problem has two versions: • Anchor nodes are missing in the node sequence If some anchor nodes fail to respond to the localization events, then the system has fewer anchors. In this case, the solution is to generate more events to compensate for the loss of anchors so as to achieve the desired accuracy requirements. • Target nodes are missing in the node sequence There are two consequences when target nodes are  missing. First, if these nodes are still be useful to sensing  applications, they need to use other backup localization  approaches (e.g., Centroid) to localize themselves with help from their neighbors who have already learned their own locations from MSP. Secondly, since in advanced MSP each node in the sequence may contribute to the overall system accuracy, dropping of target nodes from sequences could also reduce the accuracy of the localization. Thus, proper compensation procedures such as adding more  localization events need to be launched. .2 Localization without Time Synchronization In a sensor network without time synchronization support, nodes cannot be ordered into a sequence using timestamps. For such cases, we propose a listen-detect-assemble-report  protocol, which is able to function independently without time  synchronization. listen-detect-assemble-report requires that every node  listens to the channel for the node sequence transmitted from its neighbors. Then, when the node detects the localization event, it assembles itself into the newest node sequence it has heard and reports the updated sequence to other nodes. Figure 12 (a) illustrates an example for the listen-detect-assemble-report protocol. For simplicity, in this figure we did not differentiate the target nodes from anchor nodes. A solid line between two nodes stands for a communication link. Suppose a straight line scans from left to right. Node 1 detects the event, and then it broadcasts the sequence (1) into the network. Node 2 and node  receive this sequence. When node 2 detects the event, node  adds itself into the sequence and broadcasts (1, 2). The  sequence propagates in the same direction with the scan as shown in Figure 12 (a). Finally, node 6 obtains a complete sequence (1,2,3,5,7,4,6). In the case of ultrasound propagation, because the event propagation speed is much slower than that of radio, the  listendetect-assemble-report protocol can work well in a situation where the node density is not very high. For instance, if the distance between two nodes along one direction is 10 meters, the 340m/s sound needs 29.4ms to propagate from one node to the other. While normally the communication data rate is 50Kbps in the WSN (e.g., CC2420 [1]), it takes only about  ∼ 3 ms to transmit an assembled packet for one hop. One problem that may occur using the  listen-detectassemble-report protocol is multiple partial sequences as shown in Figure 12 (b). Two separate paths in the network may result in two sequences that could not be further combined. In this case, since the two sequences can only be processed as  separate sequences, some order information is lost. Therefore the ,2,5,4 ,3,7,4 ,2,3,5 1,2,3,5,7,4 ,2,3,5,7 ,2,3,5 ,3 ,2          ,3 1,2,3,5,7,4,6 ,2,5 ,3,7 ,3 ,2          ,3,7,4,6 ,2,5,4,6 (a) (b) (c) ,3,2,5 1,3,2,5,7,4 ,3,2,5,7 ,3,2,5 ,3 ,2          ,3 1,3,2,5,7,4,6 Event Propagation Event Propagation Event Propagation Figure 12. Node Sequence without Time Synchronization accuracy of the system would decrease. The other problem is the sequence flip problem. As shown in Figure 12 (c), because node 2 and node 3 are too close to each other along the scan direction, they detect the scan  almost simultaneously. Due to the uncertainty such as media access delay, two messages could be transmitted out of order. For example, if node 3 sends out its report first, then the order of node 2 and node 3 gets flipped in the final node sequence. The sequence flip problem would appear even in an accurately synchronized system due to random jitter in node detection if an event arrives at multiple nodes almost simultaneously. A method addressing the sequence flip is presented in the next section. .3 Sequence Flip and Protection Band Sequence flip problems can be solved with and without time synchronization. We firstly start with a scenario  applying time synchronization. Existing solutions for time  synchronization [12, 6] can easily achieve sub-millisecond-level  accuracy. For example, FTSP [12] achieves 16.9µs (microsecond) average error for a two-node single-hop case. Therefore, we can comfortably assume that the network is synchronized with maximum error of 1000µs. However, when multiple nodes are located very near to each other along the event propagation  direction, even when time synchronization with less than 1ms error is achieved in the network, sequence flip may still occur. For example, in the sound wave propagation case, if two nodes are less than 0.34 meters apart, the difference between their detection timestamp would be smaller than 1 millisecond. We find that sequence flip could not only damage system  accuracy, but also might cause a fatal error in the MSP algorithm. Figure 13 illustrates both detrimental results. In the left side of Figure 13(a), suppose node 1 and node 2 are so close to each other that it takes less than 0.5ms for the localization event to propagate from node 1 to node 2. Now unfortunately, the node sequence is mistaken to be (2,1). So node 1 is expected to be located to the right of node 2, such as at the position of the dashed node 1. According to the elimination rule in  sequencebased MSP, the left part of node 1"s area is cut off as shown in the right part of Figure 13(a). This is a potentially fatal error, because node 1 is actually located in the dashed area which has been eliminated by mistake. During the subsequent  eliminations introduced by other events, node 1"s area might be cut off completely, thus node 1 could consequently be erased from the map! Even in cases where node 1 still survives, its area actually does not cover its real location. 2   2  Lower boundary of 1 Upper boundary of 1 Flipped Sequence Fatal Elimination Error EventPropagation  1 Fatal Error    2  Lower boundary of 1 Upper boundary of 1 Flipped Sequence Safe Elimination EventPropagation  1 New lower boundary of 1  B (a) (b) B: Protection band Figure 13. Sequence Flip and Protection Band Another problem is not fatal but lowers the localization  accuracy. If we get the right node sequence (1,2), node 1 has a new upper boundary which can narrow the area of node 1 as in Figure 3. Due to the sequence flip, node 1 loses this new upper boundary. In order to address the sequence flip problem, especially to prevent nodes from being erased from the map, we propose a protection band compensation approach. The basic idea of protection band is to extend the boundary of the location area a little bit so as to make sure that the node will never be erased from the map. This solution is based on the fact that nodes have a high probability of flipping in the sequence if they are near to each other along the event propagation direction. If two nodes are apart from each other more than some distance, say, B, they rarely flip unless the nodes are faulty. The width of a protection band B, is largely determined by the maximum error in system time synchronization and the localization event propagation speed. Figure 13(b) presents the application of the protection band. Instead of eliminating the dashed part in Figure 13(a) for node , the new lower boundary of node 1 is set by shifting the  original lower boundary of node 2 to the left by distance B. In this case, the location area still covers node 1 and protects it from being erased. In a practical implementation, supposing that the ultrasound event is used, if the maximum error of system time synchronization is 1ms, two nodes might flip with high  probability if the timestamp difference between the two nodes is smaller than or equal to 1ms. Accordingly, we set the  protection band B as 0.34m (the distance sound can propagate within  millisecond). By adding the protection band, we reduce the chances of fatal errors, although at the cost of localization  accuracy. Empirical results obtained from our physical test-bed verified this conclusion. In the case of using the listen-detect-assemble-report  protocol, the only change we need to make is to select the protection band according to the maximum delay uncertainty introduced by the MAC operation and the event propagation speed. To bound MAC delay at the node side, a node can drop its report message if it experiences excessive MAC delay. This converts the sequence flip problem to the incomplete sequence problem, which can be more easily addressed by the method proposed in Section 7.1.  Simulation Evaluation Our evaluation of MSP was conducted on three platforms: (i) an indoor system with 46 MICAz motes using straight-line scan, (ii) an outdoor system with 20 MICAz motes using sound wave propagation, and (iii) an extensive simulation under  various kinds of physical settings. In order to understand the behavior of MSP under  numerous settings, we start our evaluation with simulations. Then, we implemented basic MSP and all the advanced MSP methods for the case where time synchronization is available in the network. The simulation and  implementation details are omitted in this paper due to space  constraints, but related documents [25] are provided online at http://www.cs.umn.edu/∼zhong/MSP. Full implementation and evaluation of system without time synchronization are yet to be completed in the near future. In simulation, we assume all the node sequences are perfect so as to reveal the performance of MSP achievable in the  absence of incomplete node sequences or sequence flips. In our simulations, all the anchor nodes and target nodes are assumed to be deployed uniformly. The mean and maximum errors are averaged over 50 runs to obtain high confidence. For legibility reasons, we do not plot the confidence intervals in this paper. All the simulations are based on the straight-line scan example. We implement three scan strategies: • Random Scan: The slope of the scan line is randomly  chosen at each time. • Regular Scan: The slope is predetermined to rotate  uniformly from 0 degree to 180 degrees. For example, if the system scans 6 times, then the scan angles would be: 0, 0, 60, 90, 120, and 150. • Adaptive Scan: The slope of each scan is determined based on the localization results from previous scans. We start with basic MSP and then demonstrate the  performance improvements one step at a time by adding (i)  sequencebased MSP, (ii) iterative MSP, (iii) DBE MSP and (iv) adaptive MSP. .1 Performance of Basic MSP The evaluation starts with basic MSP, where we compare the performance of random scan and regular scan under different configurations. We intend to illustrate the impact of the number of anchors M, the number of scans d, and target node density (number of target nodes N in a fixed-size region) on the  localization error. Table 1 shows the default simulation parameters. The error of each node is defined as the distance between the estimated location and the real position. We note that by  default we only use three anchors, which is considerably fewer than existing range-free solutions [8, 4]. Impact of the Number of Scans: In this experiment, we  compare regular scan with random scan under a different number of scans from 3 to 30 in steps of 3. The number of anchors Table 1. Default Configuration Parameters Parameter Description Field Area 200×200 (Grid Unit) Scan Type Regular (Default)/Random Scan Anchor Number 3 (Default) Scan Times 6 (Default) Target Node Number 100 (Default) Statistics Error Mean/Max Random Seeds 50 runs 3  5 10 15 20 25 30  0 0 0 0 0 0 0 0 0 Mean Error and Max Error VS Scan Time Scan Time Error Max Error of Random Scan Max Error of Regular Scan Mean Error of Random Scan Mean Error of Regular Scan (a) Error vs. Number of Scans  5 10 15 20 25 30  0 0 0 0 0 0 Mean Error and Max Error VS Anchor Number Anchor Number Error Max Error of Random Scan Max Error of Regular Scan Mean Error of Random Scan Mean Error of Regular Scan (b) Error vs. Anchor Number  50 100 150 200 0 0 0 0 0 0 0 Mean Error and Max Error VS Target Node Number Target Node Number Error Max Error of Random Scan Max Error of Regular Scan Mean Error of Random Scan Mean Error of Regular Scan (c) Error vs. Number of Target Nodes Figure 14. Evaluation of Basic MSP under Random and Regular Scans  5 10 15 20 25 30  0 0 0 0 0 0 0 Basic MSP VS Sequence Based MSP II Scan Time Error Max Error of Basic MSP Max Error of Seq MSP Mean Error of Basic MSP Mean Error of Seq MSP (a) Error vs. Number of Scans  5 10 15 20 25 30   0 5 0 5 0 5 0 5 0 Basic MSP VS Sequence Based MSP I Anchor Number Error Max Error of Basic MSP Max Error of Seq MSP Mean Error of Basic MSP Mean Error of Seq MSP (b) Error vs. Anchor Number  50 100 150 200  0 5 0 5 0 5 0 5 0 5 Basic MSP VS Sequence Based MSP III Target Node Number Error Max Error of Basic MSP Max Error of Seq MSP Mean Error of Basic MSP Mean Error of Seq MSP (c) Error vs. Number of Target Nodes Figure 15. Improvements of Sequence-Based MSP over Basic MSP is 3 by default. Figure 14(a) indicates the following: (i) as the number of scans increases, the localization error decreases significantly; for example, localization errors drop more than 0% from 3 scans to 30 scans; (ii) statistically, regular scan achieves better performance than random scan under identical number of scans. However, the performance gap reduces as the number of scans increases. This is expected since a large number of random numbers converges to a uniform  distribution. Figure 14(a) also demonstrates that MSP requires only a small number of anchors to perform very well, compared to existing range-free solutions [8, 4]. Impact of the Number of Anchors: In this experiment, we compare regular scan with random scan under different  number of anchors from 3 to 30 in steps of 3. The results shown in Figure 14(b) indicate that (i) as the number of anchor nodes increases, the localization error decreases, and (ii)  statistically, regular scan obtains better results than random scan with identical number of anchors. By combining Figures 14(a) and 14(b), we can conclude that MSP allows a flexible tradeoff between physical cost (anchor nodes) and soft cost  (localization events). Impact of the Target Node Density: In this experiment, we confirm that the density of target nodes has no impact on the accuracy, which motivated the design of sequence-based MSP. In this experiment, we compare regular scan with random scan under different number of target nodes from 10 to 190 in steps of 20. Results in Figure 14(c) show that mean localization  errors remain constant across different node densities. However, when the number of target nodes increases, the average  maximum error increases. Summary: From the above experiments, we can conclude that in basic MSP, regular scan are better than random scan under different numbers of anchors and scan events. This is because regular scans uniformly eliminate the map from different  directions, while random scans would obtain sequences with  redundant overlapping information, if two scans choose two similar scanning slopes. .2 Improvements of Sequence-Based MSP This section evaluates the benefits of exploiting the order information among target nodes by comparing sequence-based MSP with basic MSP. In this and the following sections,  regular scan is used for straight-line scan event generation. The purpose of using regular scan is to keep the scan events and the node sequences identical for both sequence-based MSP and basic MSP, so that the only difference between them is the  sequence processing procedure. Impact of the Number of Scans: In this experiment, we compare sequence-based MSP with basic MSP under different number of scans from 3 to 30 in steps of 3. Figure 15(a)  indicates significant performance improvement in sequence-based MSP over basic MSP across all scan settings, especially when the number of scans is large. For example, when the number of scans is 30, errors in sequence-based MSP are about 20% of that of basic MSP. We conclude that sequence-based MSP performs extremely well when there are many scan events. Impact of the Number of Anchors: In this experiment, we use different number of anchors from 3 to 30 in steps of 3. As seen in Figure 15(b), the mean error and maximum error of sequence-based MSP is much smaller than that of basic MSP. Especially when there is limited number of anchors in the  system, e.g., 3 anchors, the error rate was almost halved by  using sequence-based MSP. This phenomenon has an interesting explanation: the cutting lines created by anchor nodes are  exploited by both basic MSP and sequence-based MSP, so as the 4  2 4 6 8 10   0 5 0 5 0 5 0 5 0 Basic MSP VS Iterative MSP Iterative Times Error Max Error of Iterative Seq MSP Mean Error of Iterative Seq MSP Max Error of Basic MSP Mean Error of Basic MSP Figure 16. Improvements of Iterative MSP  2 4 6 8 10 12 14 16  .1 .2 .3 .4 .5 .6 .7 .8 .9  DBE VS Non−DBE Error CumulativeDistrubutioinFunctions(CDF) Mean Error CDF of DBE MSP Mean Error CDF of Non−DBE MSP Max Error CDF of DBE MSP Max Error CDF of Non−DBE MSP Figure 17. Improvements of DBE MSP  20 40 60 80 100  0 0 0 0 0 0 0 Adaptive MSP for 500by80 Target Node Number Error Max Error of Regualr Scan Max Error of Adaptive Scan Mean Error of Regualr Scan Mean Error of Adaptive Scan (a) Adaptive MSP for 500 by 80 field  10 20 30 40 50  .1 .2 .3 .4 .5 .6 .7 .8 .9  Mean Error CDF at Different Angle Steps in Adaptive Scan Mean Error CumulativeDistrubutioinFunctions(CDF)  Degree Angle Step Adaptive 0 Degree Angle Step Adaptive 0 Degree Angle Step Adaptive 0 Degree Step Regular Scan (b) Impact of the Number of Candidate Events Figure 18. The Improvements of Adaptive MSP number of anchor nodes increases, anchors tend to dominate the contribution. Therefore the performance gaps lessens. Impact of the Target Node Density: Figure 15(c)  demonstrates the benefits of exploiting order information among  target nodes. Since sequence-based MSP makes use of the  information among the target nodes, having more target nodes contributes to the overall system accuracy. As the number of target nodes increases, the mean error and maximum error of sequence-based MSP decreases. Clearly the mean error in  basic MSP is not affected by the number of target nodes, as shown in Figure 15(c). Summary: From the above experiments, we can conclude that exploiting order information among target nodes can improve accuracy significantly, especially when the number of events is large but with few anchors. .3 Iterative MSP over Sequence-Based MSP In this experiment, the same node sequences were processed iteratively multiple times. In Figure 16, the two single marks are results from basic MSP, since basic MSP doesn"t perform iterations. The two curves present the performance of  iterative MSP under different numbers of iterations c. We note that when only a single iteration is used, this method degrades to sequence-based MSP. Therefore, Figure 16 compares the three methods to one another. Figure 16 shows that the second iteration can reduce the mean error and maximum error dramatically. After that, the performance gain gradually reduces, especially when c > 5. This is because the second iteration allows earlier scans to  exploit the new boundaries created by later scans in the first  iteration. Such exploitation decays quickly over iterations. .4 DBE MSP over Iterative MSP Figure 17, in which we augment iterative MSP with distribution-based estimation (DBE MSP), shows that DBE MSP could bring about statistically better performance.  Figure 17 presents cumulative distribution localization errors. In general, the two curves of the DBE MSP lay slightly to the left of that of non-DBE MSP, which indicates that DBE MSP has a smaller statistical mean error and averaged maximum error than non-DBE MSP. We note that because DBE is augmented on top of the best solution so far, the performance  improvement is not significant. When we apply DBE on basic MSP methods, the improvement is much more significant. We omit these results because of space constraints. .5 Improvements of Adaptive MSP This section illustrates the performance of adaptive MSP over non-adaptive MSP. We note that feedback-based  adaptation can be applied to all MSP methods, since it affects only the scanning angles but not the sequence processing. In this experiment, we evaluated how adaptive MSP can improve the best solution so far. The default angle granularity (step) for adaptive searching is 5 degrees. Impact of Area Shape: First, if system settings are regular, the adaptive method hardly contributes to the results. For a square area (regular), the performance of adaptive MSP and regular scans are very close. However, if the shape of the area is not regular, adaptive MSP helps to choose the appropriate localization events to compensate. Therefore, adaptive MSP can achieve a better mean error and maximum error as shown in Figure 18(a). For example, adaptive MSP improves  localization accuracy by 30% when the number of target nodes is 0. Impact of the Target Node Density: Figure 18(a) shows that when the node density is low, adaptive MSP brings more  benefit than when node density is high. This phenomenon makes statistical sense, because the law of large numbers tells us that node placement approaches a truly uniform distribution when the number of nodes is increased. Adaptive MSP has an edge 5 Figure 19. The Mirage Test-bed (Line Scan) Figure 20. The 20-node Outdoor Experiments (Wave) when layout is not uniform. Impact of Candidate Angle Density: Figure 18(b) shows that the smaller the candidate scan angle step, the better the  statistical performance in terms of mean error. The rationale is clear, as wider candidate scan angles provide adaptive MSP more  opportunity to choose the one approaching the optimal angle. .6 Simulation Summary Starting from basic MSP, we have demonstrated  step-bystep how four optimizations can be applied on top of each other to improve localization performance. In other words, these  optimizations are compatible with each other and can jointly  improve the overall performance. We note that our simulations were done under assumption that the complete node sequence can be obtained without sequence flips. In the next section, we present two real-system implementations that reveal and  address these practical issues.  System Evaluation In this section, we present a system implementation of MSP on two physical test-beds. The first one is called Mirage, a large indoor test-bed composed of six 4-foot by 8-foot boards, illustrated in Figure 19. Each board in the system can be used as an individual sub-system, which is powered, controlled and metered separately. Three Hitachi CP-X1250 projectors,  connected through a Matorx Triplehead2go graphics expansion box, are used to create an ultra-wide integrated display on six boards. Figure 19 shows that a long tilted line is generated by the projectors. We have implemented all five versions of MSP on the Mirage test-bed, running 46 MICAz motes. Unless  mentioned otherwise, the default setting is 3 anchors and 6 scans at the scanning line speed of 8.6 feet/s. In all of our graphs, each data point represents the average value of 50 trials. In the  outdoor system, a Dell A525 speaker is used to generate 4.7KHz sound as shown in Figure 20. We place 20 MICAz motes in the backyard of a house. Since the location is not completely open, sound waves are reflected, scattered and absorbed by various objects in the vicinity, causing a multi-path effect. In the  system evaluation, simple time synchronization mechanisms are applied on each node. .1 Indoor System Evaluation During indoor experiments, we encountered several  realworld problems that are not revealed in the simulation. First, sequences obtained were partial due to misdetection and  message losses. Second, elements in the sequences could flip due to detection delay, uncertainty in media access, or error in time synchronization. We show that these issues can be addressed by using the protection band method described in Section 7.3. .1.1 On Scanning Speed and Protection Band In this experiment, we studied the impact of the scanning speed and the length of protection band on the performance of the system. In general, with increasing scanning speed, nodes have less time to respond to the event and the time gap between two adjacent nodes shrinks, leading to an increasing number of partial sequences and sequence flips. Figure 21 shows the node flip situations for six scans with distinct angles under different scan speeds. The x-axis shows the distance between the flipped nodes in the correct node  sequence. y-axis shows the total number of flips in the six scans. This figure tells us that faster scan brings in not only  increasing number of flips, but also longer-distance flips that require wider protection band to prevent from fatal errors. Figure 22(a) shows the effectiveness of the protection band in terms of reducing the number of unlocalized nodes. When we use a moderate scan speed (4.3feet/s), the chance of flipping is rare, therefore we can achieve 0.45 feet mean accuracy  (Figure 22(b)) with 1.6 feet maximum error (Figure 22(c)). With increasing speeds, the protection band needs to be set to a larger value to deal with flipping. Interesting phenomena can be  observed in Figures 22: on one hand, the protection band can sharply reduce the number of unlocalized nodes; on the other hand, protection bands enlarge the area in which a target would potentially reside, introducing more uncertainty. Thus there is a concave curve for both mean and maximum error when the scan speed is at 8.6 feet/s. .1.2 On MSP Methods and Protection Band In this experiment, we show the improvements resulting from three different methods. Figure 23(a) shows that a  protection band of 0.35 feet is sufficient for the scan speed of .57feet/s. Figures 23(b) and 23(c) show clearly that iterative MSP (with adaptation) achieves best performance. For  example, Figures 23(b) shows that when we set the protection band at 0.05 feet, iterative MSP achieves 0.7 feet accuracy, which is 42% more accurate than the basic design. Similarly,  Figures 23(b) and 23(c) show the double-edged effects of  protection band on the localization accuracy.  5 10 15 20  0 0 (3) Flip Distribution for 6 Scans at Line Speed of 14.6feet/s Flips Node Distance in the Ideal Node Sequence  5 10 15 20  0 0 (2) Flip Distribution for 6 Scans at Line Speed of 8.6feet/s Flips  5 10 15 20  0 0 (1) Flip Distribution for 6 Scans at Line Speed of 4.3feet/s Flips Figure 21. Number of Flips for Different Scan Speeds 6  0.2 0.4 0.6 0.8 1      0 2 4 6 8 0 Unlocalized Node Number(Line Scan at Different Speed) Protection Band (in feet) UnlocalizedNodeNumber Scan Line Speed: 14.6feet/s Scan Line Speed: 8.6feet/s Scan Line Speed: 4.3feet/s (a) Number of Unlocalized Nodes  0.2 0.4 0.6 0.8 1 .4 .5 .6 .7 .8 .9  .1 Mean Error(Line Scan at Different Speed) Protection Band (in feet) Error(infeet) Scan Line Speed:14.6feet/s Scan Line Speed: 8.6feet/s Scan Line Speed: 4.3feet/s (b) Mean Localization Error  0.2 0.4 0.6 0.8 1 .5  .5  .5  Max Error(Line Scan at Different Speed) Protection Band (in feet) Error(infeet) Scan Line Speed: 14.6feet/s Scan Line Speed: 8.6feet/s Scan Line Speed: 4.3feet/s (c) Max Localization Error Figure 22. Impact of Protection Band and Scanning Speed  0.2 0.4 0.6 0.8 1      0 2 4 6 8 0 Unlocalized Node Number(Scan Line Speed 8.57feet/s) Protection Band (in feet) Numberofunlocalizednodeoutof46 Unlocalized node of Basic MSP Unlocalized node of Sequence Based MSP Unlocalized node of Iterative MSP (a) Number of Unlocalized Nodes  0.2 0.4 0.6 0.8 1 .7 .8 .9  .1 .2 .3 .4 Mean Error(Scan Line Speed 8.57feet/s) Protection Band (in feet) Error(infeet) Mean Error of Basic MSP Mean Error of Sequence Based MSP Mean Error of Iterative MSP (b) Mean Localization Error  0.2 0.4 0.6 0.8 1 .5  .5  .5  Max Error(Scan Line Speed 8.57feet/s) Protection Band (in feet) Error(infeet) Max Error of Basic MSP Max Error of Sequence Based MSP Max Error of Iterative MSP (c) Max Localization Error Figure 23. Impact of Protection Band under Different MSP Methods  4 5 6 7 8 9 10 11  .5  .5  .5 Unlocalized Node Number(Protection Band: 0.35 feet) Anchor Number UnlocalizedNodeNumber  Scan Events at Speed 8.75feet/s  Scan Events at Speed 8.75feet/s  Scan Events at Speed 8.75feet/s (a) Number of Unlocalized Nodes  4 5 6 7 8 9 10 11 .2 .3 .4 .5 .6 .7 .8 .9  Mean Error(Protection Band: 0.35 feet) Anchor Number Error(infeet) Mean Error of 4 Scan Events at Speed 8.75feet/s Mean Error of 6 Scan Events at Speed 8.75feet/s Mean Error of 8 Scan Events at Speed 8.75feet/s (b) Mean Localization Error  4 5 6 7 8 9 10 11 .8  .2 .4 .6 .8  .2 .4 .6 .8 Max Error(Protection Band: 0.35 feet) Anchor Number Error(infeet) Max Error of 4 Scan Events at Speed 8.75feet/s Max Error of 6 Scan Events at Speed 8.75feet/s Max Error of 8 Scan Events at Speed 8.75feet/s (c) Max Localization Error Figure 24. Impact of the Number of Anchors and Scans .1.3 On Number of Anchors and Scans In this experiment, we show a tradeoff between hardware cost (anchors) with soft cost (events). Figure 24(a) shows that with more cutting lines created by anchors, the chance of  unlocalized nodes increases slightly. We note that with a 0.35 feet protection band, the percentage of unlocalized nodes is very small, e.g., in the worst-case with 11 anchors, only 2 out of 46 nodes are not localized due to flipping. Figures 24(b) and 24(c) show the tradeoff between number of anchors and the number of scans. Obviously, with the number of anchors increases, the error drops significantly. With 11 anchors we can achieve a  localization accuracy as low as 0.25 ∼ 0.35 feet, which is nearly a 0% improvement. Similarly, with increasing number of scans, the accuracy drops significantly as well. We can observe about 0% across all anchor settings when we increase the number of scans from 4 to 8. For example, with only 3 anchors, we can achieve 0.6-foot accuracy with 8 scans. .2 Outdoor System Evaluation The outdoor system evaluation contains two parts: (i)  effective detection distance evaluation, which shows that the node sequence can be readily obtained, and (ii) sound  propagation based localization, which shows the results of  wavepropagation-based localization. .2.1 Effective Detection Distance Evaluation We firstly evaluate the sequence flip phenomenon in wave propagation. As shown in Figure 25, 20 motes were placed as five groups in front of the speaker, four nodes in each group at roughly the same distances to the speaker. The gap between each group is set to be 2, 3, 4 and 5 feet respectively in four  experiments. Figure 26 shows the results. The x-axis in each  subgraph indicates the group index. There are four nodes in each group (4 bars). The y-axis shows the detection rank (order) of each node in the node sequence. As distance between each group increases, number of flips in the resulting node sequence 7 Figure 25. Wave Detection  2 3 4 5   0 5 0  feet group distance Rank Group Index  2 3 4 5   0 5 0  feet group distance Rank Group Index  2 3 4 5   0 5 0  feet group distance Rank Group Index  2 3 4 5   0 5 0  feet group distance Rank Group Index Figure 26. Ranks vs. Distances      0 2 4 6 8 0 2 4  2 4 6 8 10 12 14 Y-Dimension(feet) X-Dimension (feet) Node      0 2 4 6 8 0 2 4  2 4 6 8 10 12 14 Y-Dimension(feet) X-Dimension (feet) Anchor Figure 27. Localization Error (Sound) decreases. For example, in the 2-foot distance subgraph, there are quite a few flips between nodes in adjacent and even  nonadjacent groups, while in the 5-foot subgraph, flips between different groups disappeared in the test. .2.2 Sound Propagation Based Localization As shown in Figure 20, 20 motes are placed as a grid  including 5 rows with 5 feet between each row and 4 columns with  feet between each column. Six 4KHz acoustic wave  propagation events are generated around the mote grid by a speaker. Figure 27 shows the localization results using iterative MSP (3 times iterative processing) with a protection band of 3 feet. The average error of the localization results is 3 feet and the maximum error is 5 feet with one un-localized node. We found that sequence flip in wave propagation is more severe than that in the indoor, line-based test. This is expected due to the high propagation speed of sound. Currently we use MICAz mote, which is equipped with a low quality  microphone. We believe that using a better speaker and more events, the system can yield better accuracy. Despite the hardware  constrains, the MSP algorithm still successfully localized most of the nodes with good accuracy. 0 Conclusions In this paper, we present the first work that exploits the  concept of node sequence processing to localize sensor nodes. We demonstrated that we could significantly improve localization accuracy by making full use of the information embedded in multiple easy-to-get one-dimensional node sequences. We  proposed four novel optimization methods, exploiting order and marginal distribution among non-anchor nodes as well as the feedback information from early localization results.  Importantly, these optimization methods can be used together, and improve accuracy additively. The practical issues of partial node sequence and sequence flip were identified and addressed in two physical system test-beds. We also evaluated  performance at scale through analysis as well as extensive  simulations. Results demonstrate that requiring neither costly  hardware on sensor nodes nor precise event distribution, MSP can achieve a sub-foot accuracy with very few anchor nodes  provided sufficient events. 1 References [1] CC2420 Data Sheet. Avaiable at http://www.chipcon.com/. [2] P. Bahl and V. N. Padmanabhan. Radar: An In-Building RF-Based User Location and Tracking System. In IEEE Infocom "00. [3] M. Broxton, J. Lifton, and J. Paradiso. Localizing A Sensor Network via Collaborative Processing of Global Stimuli. In EWSN "05. [4] N. Bulusu, J. Heidemann, and D. Estrin. GPS-Less Low Cost Outdoor Localization for Very Small Devices. IEEE Personal Communications Magazine, 7(4), 2000. [5] D. Culler, D. Estrin, and M. Srivastava. Overview of Sensor Networks. IEEE Computer Magazine, 2004. [6] J. Elson, L. Girod, and D. Estrin. Fine-Grained Network Time  Synchronization Using Reference Broadcasts. In OSDI "02. [7] D. K. Goldenberg, P. Bihler, M. Gao, J. Fang, B. D. Anderson, A. Morse, and Y. Yang. Localization in Sparse Networks Using Sweeps. In  MobiCom "06. [8] T. He, C. Huang, B. M. Blum, J. A. Stankovic, and T. Abdelzaher.  RangeFree Localization Schemes in Large-Scale Sensor Networks. In  MobiCom "03. [9] B. Kusy, P. Dutta, P. Levis, M. Mar, A. Ledeczi, and D. Culler. Elapsed Time on Arrival: A Simple and Versatile Primitive for Canonical Time Synchronization Services. International Journal of ad-hoc and  Ubiquitous Computing, 2(1), 2006. [10] L. Lazos and R. Poovendran. SeRLoc: Secure Range-Independent  Localization for Wireless Sensor Networks. In WiSe "04. [11] M. Maroti, B. Kusy, G. Balogh, P. Volgyesi, A. Nadas, K. Molnar, S. Dora, and A. Ledeczi. Radio Interferometric Geolocation. In  SenSys "05. [12] M. Maroti, B. Kusy, G. Simon, and A. Ledeczi. The Flooding Time Synchronization Protocol. In SenSys "04. [13] D. Moore, J. Leonard, D. Rus, and S. Teller. Robust Distributed Network Localization with Noise Range Measurements. In SenSys "04. [14] R. Nagpal and D. Coore. An Algorithm for Group Formation in an  Amorphous Computer. In PDCS "98. [15] D. Niculescu and B. Nath. ad-hoc Positioning System. In GlobeCom "01. [16] D. Niculescu and B. Nath. ad-hoc Positioning System (APS) Using AOA. In InfoCom "03. [17] N. B. Priyantha, A. Chakraborty, and H. Balakrishnan. The Cricket Location-Support System. In MobiCom "00. [18] K. R¨omer. The Lighthouse Location System for Smart Dust. In MobiSys "03. [19] A. Savvides, C. C. Han, and M. B. Srivastava. Dynamic Fine-Grained Localization in ad-hoc Networks of Sensors. In MobiCom "01. [20] R. Stoleru, T. He, J. A. Stankovic, and D. Luebke. A High-Accuracy, Low-Cost Localization System for Wireless Sensor Networks. In SenSys "05. [21] R. Stoleru, P. Vicaire, T. He, and J. A. Stankovic. StarDust: a Flexible Architecture for Passive Localization in Wireless Sensor Networks. In SenSys "06. [22] E. W. Weisstein. Plane Division by Lines. mathworld.wolfram.com. [23] B. H. Wellenhoff, H. Lichtenegger, and J. Collins. Global Positions  System: Theory and Practice,Fourth Edition. Springer Verlag, 1997. [24] K. Whitehouse. The Design of Calamari: an ad-hoc Localization System for Sensor Networks. In University of California at Berkeley, 2002. [25] Z. Zhong. MSP Evaluation and Implementation Report. Avaiable at http://www.cs.umn.edu/∼zhong/MSP. [26] G. Zhou, T. He, and J. A. Stankovic. Impact of Radio Irregularity on Wireless Sensor Networks. In MobiSys "04. 8
StarDust: A Flexible Architecture for Passive Localization in Wireless Sensor Networks ∗ Radu Stoleru, Pascal Vicaire, Tian He†, John A. Stankovic Department of Computer Science, University of Virginia †Department of Computer Science and Engineering, University of Minnesota {stoleru, pv9f}@cs.virginia.edu, tianhe@cs.umn.edu, stankovic@cs.virginia.edu Abstract The problem of localization in wireless sensor networks where nodes do not use ranging hardware, remains a  challenging problem, when considering the required location  accuracy, energy expenditure and the duration of the  localization phase. In this paper we propose a framework, called StarDust, for wireless sensor network localization based on passive optical components. In the StarDust framework, sensor nodes are equipped with optical retro-reflectors. An aerial device projects light towards the deployed sensor  network, and records an image of the reflected light. An image processing algorithm is developed for obtaining the locations of sensor nodes. For matching a node ID to a location we propose a constraint-based label relaxation algorithm. We propose and develop localization techniques based on four types of constraints: node color, neighbor information,  deployment time for a node and deployment location for a node. We evaluate the performance of a localization system based on our framework by localizing a network of 26  sensor nodes deployed in a 120 × 60 ft2 area. The localization accuracy ranges from 2 ft to 5 ft while the localization time ranges from 10 milliseconds to 2 minutes. Categories and Subject Descriptors: C.2.4 [Computer Communications Networks]: Distributed Systems; C.3  [Special Purpose and Application Based Systems]: Real-time and embedded systems General Terms: Algorithms, Measurement, Performance, Design, Experimentation  Introduction Wireless Sensor Networks (WSN) have been envisioned to revolutionize the way humans perceive and interact with the surrounding environment. One vision is to embed tiny sensor devices in outdoor environments, by aerial  deployments from unmanned air vehicles. The sensor nodes form a network and collaborate (to compensate for the extremely scarce resources available to each of them: computational power, memory size, communication capabilities) to  accomplish the mission. Through collaboration, redundancy and fault tolerance, the WSN is then able to achieve  unprecedented sensing capabilities. A major step forward has been accomplished by  developing systems for several domains: military surveillance [1] [2] [3], habitat monitoring [4] and structural monitoring [5]. Even after these successes, several research problems remain open. Among these open problems is sensor node  localization, i.e., how to find the physical position of each sensor node. Despite the attention the localization problem in WSN has received, no universally acceptable solution has been  developed. There are several reasons for this. On one hand, localization schemes that use ranging are typically high end solutions. GPS ranging hardware consumes energy, it is  relatively expensive (if high accuracy is required) and poses form factor challenges that move us away from the vision of dust size sensor nodes. Ultrasound has a short range and is highly directional. Solutions that use the radio transceiver for ranging either have not produced encouraging results (if the received signal strength indicator is used) or are sensitive to environment (e.g., multipath). On the other hand,  localization schemes that only use the connectivity information for inferring location information are characterized by low accuracies: ≈ 10 ft in controlled environments, 40−50 ft in realistic ones. To address these challenges, we propose a framework for WSN localization, called StarDust, in which the  complexity associated with the node localization is completely  removed from the sensor node. The basic principle of the framework is localization through passivity: each sensor node is equipped with a corner-cube retro-reflector and  possibly an optical filter (a coloring device). An aerial  vehicle projects light onto the deployment area and records  images containing retro-reflected light beams (they appear as luminous spots). Through image processing techniques, the locations of the retro-reflectors (i.e., sensor nodes) is  deter57 mined. For inferring the identity of the sensor node present at a particular location, the StarDust framework develops a constraint-based node ID relaxation algorithm. The main contributions of our work are the following. We propose a novel framework for node localization in WSNs that is very promising and allows for many future extensions and more accurate results. We propose a constraint-based label relaxation algorithm for mapping node IDs to the  locations, and four constraints (node, connectivity, time and space), which are building blocks for very accurate and very fast localization systems. We develop a sensor node  hardware prototype, called a SensorBall. We evaluate the  performance of a localization system for which we obtain location accuracies of 2 − 5 ft with a localization duration ranging from 10 milliseconds to 2 minutes. We investigate the range of a system built on our framework by considering realities of physical phenomena that occurs during light propagation through the atmosphere. The rest of the paper is structured as follows. Section 2 is an overview of the state of art. The design of the  StarDust framework is presented in Section 3. One  implementation and its performance evaluation are in Sections 4 and , followed by a suite of system optimization techniques, in Section 6. In Section 7 we present our conclusions.  Related Work We present the prior work in localization in two major categories: the range-based, and the range-free schemes. The range-based localization techniques have been  designed to use either more expensive hardware (and hence higher accuracy) or just the radio transceiver. Ranging  techniques dependent on hardware are the time-of-flight (ToF) and the time-difference-of-arrival(TDoA). Solutions that use the radio are based on the received signal strength indicator (RSSI) and more recently on radio interferometry. The ToF localization technique that is most widely used is the GPS. GPS is a costly solution for a high accuracy  localization of a large scale sensor network. AHLoS [6] employs a TDoA ranging technique that requires extensive hardware and solves relatively large nonlinear systems of equations. The Cricket location-support system (TDoA) [7] can achieve a location granularity of tens of inches with highly  directional and short range ultrasound transceivers. In [2] the  location of a sniper is determined in an urban terrain, by  using the TDoA between an acoustic wave and a radio beacon. The PushPin project [8] uses the TDoA between ultrasound pulses and light flashes for node localization. The RADAR system [9] uses the RSSI to build a map of signal strengths as emitted by a set of beacon nodes. A mobile node is  located by the best match, in the signal strength space, with a previously acquired signature. In MAL [10], a mobile node assists in measuring the distances (acting as constraints)  between nodes until a rigid graph is generated. The localization problem is formulated as an on-line state estimation in a  nonlinear dynamic system [11]. A cooperative ranging that  attempts to achieve a global positioning from distributed local optimizations is proposed in [12]. A very recent, remarkable, localization technique is based on radio interferometry, RIPS [13], which utilizes two transmitters to create an interfering signal. The frequencies of the emitters are very close to each other, thus the interfering signal will have a low frequency envelope that can be easily measured. The ranging technique performs very well. The long time required for localization and multi-path environments pose significant challenges. Real environments create additional challenges for the range based localization schemes. These have been  emphasized by several studies [14] [15] [16]. To address these  challenges, and others (hardware cost, the energy expenditure, the form factor, the small range, localization time), several range-free localization schemes have been proposed. Sensor nodes use primarily connectivity information for inferring proximity to a set of anchors. In the Centroid localization scheme [17], a sensor node localizes to the centroid of its proximate beacon nodes. In APIT [18] each node decides its position based on the possibility of being inside or outside of a triangle formed by any three beacons within node"s  communication range. The Gradient algorithm [19], leverages the knowledge about the network density to infer the average one hop length. This, in turn, can be transformed into  distances to nodes with known locations. DV-Hop [20] uses the hop by hop propagation capability of the network to forward distances to landmarks. More recently, several localization schemes that exploit the sensing capabilities of sensor nodes, have been proposed. Spotlight [21] creates well controlled (in time and space) events in the network while the sensor nodes detect and timestamp this events. From the  spatiotemporal knowledge for the created events and the temporal information provided by sensor nodes, nodes" spatial  information can be obtained. In a similar manner, the Lighthouse system [22] uses a parallel light beam, that is emitted by an anchor which rotates with a certain period. A sensor node detects the light beam for a period of time, which is  dependent on the distance between it and the light emitting device. Many of the above localization solutions target specific sets of requirements and are useful for specific applications. StarDust differs in that it addresses a particular demanding set of requirements that are not yet solved well. StarDust is meant for localizing air dropped nodes where node  passiveness, high accuracy, low cost, small form factor and rapid  localization are all required. Many military applications have such requirements.  StarDust System Design The design of the StarDust system (and its name) was  inspired by the similarity between a deployed sensor network, in which sensor nodes indicate their presence by emitting light, and the Universe consisting of luminous and  illuminated objects: stars, galaxies, planets, etc. The main difficulty when applying the above ideas to the real world is the complexity of the hardware that needs to be put on a sensor node so that the emitted light can be  detected from thousands of feet. The energy expenditure for producing an intense enough light beam is also prohibitive. Instead, what we propose to use for sensor node  localization is a passive optical element called a retro-reflector. The most common retro-reflective optical component is a Corner-Cube Retroreflector (CCR), shown in Figure 1(a). It consists of three mutually perpendicular mirrors. The  inter58 (a) (b) Figure 1. Corner-Cube Retroreflector (a) and an array of CCRs molded in plastic (b) esting property of this optical component is that an incoming beam of light is reflected back, towards the source of the light, irrespective of the angle of incidence. This is in  contrast with a mirror, which needs to be precisely positioned to be perpendicular to the incident light. A very common and inexpensive implementation of an array of CCRs is the  retroreflective plastic material used on cars and bicycles for night time detection, shown in Figure 1(b). In the StarDust system, each node is equipped with a small (e.g. 0.5in2) array of CCRs and the enclosure has self-righting capabilities that orient the array of CCRs  predominantly upwards. It is critical to understand that the  upward orientation does not need to be exact. Even when large angular variations from a perfectly upward orientation are present, a CCR will return the light in the exact same  direction from which it came. In the remaining part of the section, we present the  architecture of the StarDust system and the design of its main components. .1 System Architecture The envisioned sensor network localization scenario is as follows: • The sensor nodes are released, possibly in a controlled manner, from an aerial vehicle during the night. • The aerial vehicle hovers over the deployment area and uses a strobe light to illuminate it. The sensor nodes, equipped with CCRs and optical filters (acting as  coloring devices) have self-righting capabilities and  retroreflect the incoming strobe light. The retro-reflected light is either white, as the originating source light, or colored, due to optical filters. • The aerial vehicle records a sequence of two images very close in time (msec level). One image is taken when the strobe light is on, the other when the strobe light is off. The acquired images are used for obtaining the locations of sensor nodes (which appear as luminous spots in the image). • The aerial vehicle executes the mapping of node IDs to the identified locations in one of the following ways: a) by using the color of a retro-reflected light, if a sensor node has a unique color; b) by requiring sensor nodes to establish neighborhood information and report it to a base station; c) by controlling the time sequence of sensor nodes deployment and recording additional  imLight Emitter Sensor Node i Transfer Function Φi(λ) Ψ(λ) Φ(Ψ(λ)) Image Processing Node ID Matching Radio Model R G(Λ,E) Central Device V" V" Figure 2. The StarDust system architecture ages; d) by controlling the location where a sensor node is deployed. • The computed locations are disseminated to the sensor network. The architecture of the StarDust system is shown in  Figure 2. The architecture consists of two main components: the first is centralized and it is located on a more powerful device. The second is distributed and it resides on all  sensor nodes. The Central Device consists of the following: the Light Emitter, the Image Processing module, the Node ID Mapping module and the Radio Model. The distributed  component of the architecture is the Transfer Function, which acts as a filter for the incoming light. The aforementioned modules are briefly described below: • Light Emitter - It is a strobe light, capable of producing very intense, collimated light pulses. The emitted light is non-monochromatic (unlike a laser) and it is  characterized by a spectral density Ψ(λ), a function of the wavelength. The emitted light is incident on the CCRs present on sensor nodes. • Transfer Function Φ(Ψ(λ)) - This is a bandpass filter for the incident light on the CCR. The filter allows a portion of the original spectrum, to be retro-reflected. From here on, we will refer to the transfer function as the color of a sensor node. • Image Processing - The Image Processing module  acquires high resolution images. From these images the locations and the colors of sensor nodes are obtained. If only one set of pictures can be taken (i.e., one  location of the light emitter/image analysis device), then the map of the field is assumed to be known as well as the distance between the imaging device and the field. The aforementioned assumptions (field map and distance to it) are not necessary if the images can be simultaneously taken from different locations. It is important to remark here that the identity of a node can not be directly  obtained through Image Processing alone, unless a  specific characteristic of a sensor node can be identified in the image. • Node ID Matching - This module uses the detected  locations and through additional techniques (e.g., sensor node coloring and connectivity information (G(Λ,E)) from the deployed network) to uniquely identify the sensor nodes observed in the image. The connectivity information is represented by neighbor tables sent from 9 Algorithm 1 Image Processing : Background filtering : Retro-reflected light recognition through intensity  filtering : Edge detection to obtain the location of sensor nodes : Color identification for each detected sensor node each sensor node to the Central Device. • Radio Model - This component provides an estimate of the radio range to the Node ID Matching module. It is only used by node ID matching techniques that are based on the radio connectivity in the network. The  estimate of the radio range R is based on the sensor node density (obtained through the Image Processing  module) and the connectivity information (i.e., G(Λ,E)). The two main components of the StarDust architecture are the Image Processing and the Node ID Mapping. Their design and analysis is presented in the sections that follow. .2 Image Processing The goal of the Image Processing Algorithm (IPA) is to identify the location of the nodes and their color. Note that IPA does not identify which node fell where, but only what is the set of locations where the nodes fell. IPA is executed after an aerial vehicle records two  pictures: one in which the field of deployment is illuminated and one when no illuminations is present. Let Pdark be the  picture of the deployment area, taken when no light was emitted and Plight be the picture of the same deployment area when a strong light beam was directed towards the sensor nodes. The proposed IPA has several steps, as shown in  Algorithm 1. The first step is to obtain a third picture Pfilter where only the differences between Pdark and Plight remain. Let us assume that Pdark has a resolution of n × m, where n is the number of pixels in a row of the picture, while m is the  number of pixels in a column of the picture. Then Pdark is  composed of n × m pixels noted Pdark(i, j), i ∈ 1 ≤ i ≤ n,1 ≤ j ≤ m. Similarly Plight is composed of n × m pixels noted Plight(i, j), 1 ≤ i ≤ n,1 ≤ j ≤ m. Each pixel P is described by an RGB value where the R value is denoted by PR, the G value is denoted by PG, and the B value is denoted by PB. IPA then generates the third picture, Pfilter, through the following transformations: PR filter(i, j) = PR light(i, j)−PR dark(i, j) PG filter(i, j) = PG light(i, j)−PG dark(i, j) PB filter(i, j) = PB light(i, j)−PB dark(i, j) (1) After this transformation, all the features that appeared in both Pdark and Plight are removed from Pfilter. This simplifies the recognition of light retro-reflected by sensor nodes. The second step consists of identifying the elements  contained in Pfilter that retro-reflect light. For this, an intensity filter is applied to Pfilter. First IPA converts Pfilter into a grayscale picture. Then the brightest pixels are identified and used to create Preflect. This step is eased by the fact that the reflecting nodes should appear much brighter than any other illuminated object in the picture. Support: Q(λk) ni P1 ... P2 ... PN λ1 ... λk ... λN Figure 3. Probabilistic label relaxation The third step runs an edge detection algorithm on Preflect to identify the boundary of the nodes present. A tool such as Matlab provides a number of edge detection techniques. We used the bwboundaries function. For the obtained edges, the location (x,y) (in the image) of each node is determined by computing the centroid of the points constituting its edges. Standard computer graphics techniques [23] are then used to transform the 2D locations of sensor nodes detected in multiple images into 3D sensor node locations. The color of the node is obtained as the color of the pixel located at (x,y) in Plight. .3 Node ID Matching The goal of the Node ID Matching module is to  obtain the identity (node ID) of a luminous spot in the  image, detected to be a sensor node. For this, we define V = {(x1,y1),(x2,y2),...,(xm,ym)} to be the set of locations of the sensor nodes, as detected by the Image Processing  module and Λ = {λ1,λ2,...,λm} to be the set of unique node IDs assigned to the m sensor nodes, before deployment. From here on, we refer to node IDs as labels. We model the problem of finding the label λj of a node ni as a probabilistic label relaxation problem, frequently used in image processing/understanding. In the image processing domain, scene labeling (i.e., identifying objects in an  image) plays a major role. The goal of scene labeling is to assign a label to each object detected in an image, such that an appropriate image interpretation is achieved. It is  prohibitively expensive to consider the interactions among all the objects in an image. Instead, constraints placed among nearby objects generate local consistencies and through  iteration, global consistencies can be obtained. The main idea of the sensor node localization through probabilistic label relaxation is to iteratively compute the probability of each label being the correct label for a  sensor node, by taking into account, at each iteration, the  support for a label. The support for a label can be understood as a hint or proof, that a particular label is more likely to be the correct one, when compared with the other potential  labels for a sensor node. We pictorially depict this main idea in Figure 3. As shown, node ni has a set of candidate  labels {λ1,...,λk}. Each of the labels has a different value for the Support function Q(λk). We defer the explanation of how the Support function is implemented until the  subsections that follow, where we provide four concrete  techniques. Formally, the algorithm is outlined in Algorithm 2, where the equations necessary for computing the new  probability Pni(λk) for a label λk of a node ni, are expressed by the 0 Algorithm 2 Label Relaxation : for each sensor node ni do : assign equal prob. to all possible labels : end for : repeat : converged ← true : for each sensor node ni do : for each each label λj of ni do : compute the Support label λj: Equation 4 : end for 0: compute K for the node ni: Equation 3 1: for each each label λj do 2: update probability of label λj: Equation 2 3: if |new prob.−old prob.| ≥ ε then 4: converged ← false 5: end if 6: end for 7: end for 8: until converged = true following equations: Ps+1 ni (λk) =  Kni Ps ni (λk)Qs ni (λk) (2) where Kni is a normalizing constant, given by: Kni = N ∑ k=1 Ps ni (λk)Qs ni (λk) (3) and Qs ni (λk) is: Qs ni (λk) = support for label λk of node ni (4) The label relaxation algorithm is iterative and it is  polynomial in the size of the network(number of nodes). The pseudo-code is shown in Algorithm 2. It initializes the  probabilities associated with each possible label, for a node ni, through a uniform distribution. At each iteration s, the  algorithm updates the probability associated with each label, by considering the Support Qs ni (λk) for each candidate label of a sensor node. In the sections that follow, we describe four different  techniques for implementing the Support function: based on node coloring, radio connectivity, the time of deployment (time) and the location of deployment (space). While some of these techniques are simplistic, they are primitives which, when combined, can create powerful localization systems. These design techniques have different trade-offs, which we will present in Section 3.3.6. .3.1 Relaxation with Color Constraints The unique mapping between a sensor node"s position (identified by the image processing) and a label can be  obtained by assigning a unique color to each sensor node. For this we define C = {c1,c2,...,cn} to be the set of unique  colors available and M : Λ → C to be a one-to-one mapping of labels to colors. This mapping is known prior to the sensor node deployment (from node manufacturing). In the case of color constrained label relaxation, the  support for label λk is expressed as follows: Qs ni (λk) = 1 (5) As a result, the label relaxation algorithm (Algorithm 2) consists of the following steps: one label is assigned to each sensor node (lines 1-3 of the algorithm), implicitly having a probability Pni(λk) = 1 ; the algorithm executes a single iteration, when the support function, simply, reiterates the confidence in the unique labeling. However, it is often the case that unique colors for each node will not be available. It is interesting to discuss here the influence that the size of the coloring space (i.e., |C|) has on the accuracy of the localization algorithm. Several cases are discussed below: • If |C| = 0, no colors are used and the sensor nodes are equipped with simple CCRs that reflect back all the  incoming light (i.e., no filtering, and no coloring of the  incoming light). From the image processing system, the position of sensor nodes can still be obtained. Since all nodes appear white, no single sensor node can be uniquely identified. • If |C| = m − 1 then there are enough unique colors for all nodes (one node remains white, i.e. no coloring), the problem is trivially solved. Each node can be identified, based on its unique color. This is the scenario for the relaxation with color constraints. • If |C| ≥ 1, there are several options for how to  partition the coloring space. If C = {c1} one possibility is to assign the color c1 to a single node, and leave the  remaining m−1 sensor nodes white, or to assign the color c1 to more than one sensor node. One can observe that once a color is assigned uniquely to a sensor node, in effect, that sensor node is given the status of anchor, or node with known location. It is interesting to observe that there is an entire spectrum of possibilities for how to partition the set of sensor nodes in equivalence classes (where an equivalence class is  represented by one color), in order to maximize the success of the localization algorithm. One of the goals of this paper is to understand how the size of the coloring space and its  partitioning affect localization accuracy. Despite the simplicity of this method of constraining the set of labels that can be assigned to a node, we will show that this technique is very powerful, when combined with other relaxation techniques. .3.2 Relaxation with Connectivity Constraints Connectivity information, obtained from the sensor  network through beaconing, can provide additional information for locating sensor nodes. In order to gather connectivity  information, the following need to occur: 1) after deployment, through beaconing of HELLO messages, sensor nodes build their neighborhood tables; 2) each node sends its neighbor table information to the Central device via a base station. First, let us define G = (Λ,E) to be the weighted  connectivity graph built by the Central device from the received neighbor table information. In G the edge (λi,λj) has a 1 λ1 λ2 ... λN ni nj gi2,j2 λ1 λ2 ... λN Pj,λ1 Pj,λ2 ... Pj,λN Pi,λ1 Pi,λ1 ... Pi,λN gi2,jm Figure 4. Label relaxation with connectivity constraints weight gij represented by the number of beacons sent by λj and received by λi. In addition, let R be the radio range of the sensor nodes. The main idea of the connectivity constrained label  relaxation is depicted in Figure 4 in which two nodes ni and nj have been assigned all possible labels. The confidence in each of the candidate labels for a sensor node, is represented by a probability, shown in a dotted rectangle. It is important to remark that through beaconing and the reporting of neighbor tables to the Central Device, a global view of all constraints in the network can be obtained. It is critical to observe that these constraints are among labels. As shown in Figure 4 two constraints exist between nodes ni and nj. The constraints are depicted by gi2,j2 and gi2,jM, the number of beacons sent the labels λj2 and λjM and received by the label λi2. The support for the label λk of sensor node ni, resulting from the interaction (i.e., within radio range) with sensor node nj is given by: Qs ni (λk) = M ∑ m=1 gλkλm Ps nj (λm) (6) As a result, the localization algorithm (Algorithm 3  consists of the following steps: all labels are assigned to each sensor node (lines 1-3 of the algorithm), and implicitly each label has a probability initialized to Pni(λk) = 1/|Λ|; in each iteration, the probabilities for the labels of a sensor node are updated, when considering the interaction with the labels of sensor nodes within R. It is important to remark that the  identity of the nodes within R is not known, only the candidate labels and their probabilities. The relaxation algorithm  converges when, during an iteration, the probability of no label is updated by more than ε. The label relaxation algorithm based on connectivity  constraints, enforces such constraints between pairs of sensor nodes. For a large scale sensor network deployment, it is not feasible to consider all pairs of sensor nodes in the network. Hence, the algorithm should only consider pairs of sensor nodes that are within a reasonable communication range (R). We assume a circular radio range and a symmetric  connectivity. In the remaining part of the section we propose a simple analytical model that estimates the radio range R for medium-connected networks (less than 20 neighbors per R). We consider the following to be known: the size of the  deployment field (L), the number of sensor nodes deployed (N) Algorithm 3 Localization : Estimate the radio range R : Execute the Label Relaxation Algorithm with Support Function given by Equation 6 for neighbors less than R apart : for each sensor node ni do : node identity is λk with max. prob. : end for and the total number of unidirectional (i.e., not symmetric) one-hop radio connections in the network (k). For our  analysis, we uniformly distribute the sensor nodes in a square area of length L, by using a grid of unit length L/ √ N. We use the substitution u = L/ √ N to simplify the notation, in order to distinguish the following cases: if u ≤ R ≤ √ u each node has four neighbors (the expected k = 4N); if √ u ≤ R ≤ 2u each node has eight neighbors (the expected k = 8N); if u ≤ R ≤ √ u each node has twelve neighbors ( the expected k = 12N); if √ u ≤ R ≤ 3u each node has twenty neighbors (the expected k = 20N) For a given t = k/4N we take R to be the middle of the interval. As an example, if t = 5 then R = (3 + √ )u/2. A quadratic fitting for R over the possible values of t, produces the following closed-form solution for the communication range R, as a function of network connectivity k, assuming L and N constant: R(k) = L √ N −0.051 k N  +0.66 k N +0.6 (7) We investigate the accuracy of our model in Section 5.2.1. .3.3 Relaxation with Time Constraints Time constraints can be treated similarly with color  constraints. The unique identification of a sensor node can be obtained by deploying sensor nodes individually, one by one, and recording a sequence of images. The sensor node that is identified as new in the last picture (it was not identified in the picture before last) must be the last sensor node dropped. In a similar manner with color constrained label  relaxation, the time constrained approach is very simple, but may take too long, especially for large scale systems. While it can be used in practice, it is unlikely that only a time  constrained label relaxation is used. As we will see, by  combining constrained-based primitives, realistic localization  systems can be implemented. The support function for the label relaxation with time constraints is defined identically with the color constrained relaxation: Qs ni (λk) = 1 (8) The localization algorithm (Algorithm 2 consists of the following steps: one label is assigned to each sensor node (lines 1-3 of the algorithm), and implicitly having a  probability Pni(λk) = 1 ; the algorithm executes a single iteration, 2 D1 D2 D4 D Node Label-1 Label-2 Label-3 Label-4 .2 .1 .5 .2 Figure 5. Relaxation with space constraints  .2 .4 .6 .8  .2 .4  1 2 3 4 5 6 7 8 PDF Distance D σ = 0.5 σ = 1 σ = 2 Figure 6. Probability distribution of distances -4 -3 -2 -1      X -4 -3 -2 -1      Y  .2 .4 .6 .8  Node Density Figure 7. Distribution of nodes when the support function, simply, reiterates the confidence in the unique labeling. .3.4 Relaxation with Space Constraints Spatial information related to sensor deployment can also be employed as another input to the label relaxation  algorithm. To do that, we use two types of locations: the node  location pn and the label location pl. The former pn is defined as the position of nodes (xn,yn,zn) after deployment, which can be obtained through Image Processing as mentioned in Section 3.3. The latter pl is defined as the location (xl,yl,zl) where a node is dropped. We use Dni λm to denote the  horizontal distance between the location of the label λm and the  location of the node ni. Clearly, Dni λm = (xn −xl)2 +(yn −yl)2. At the time of a sensor node release, the one-to-one  mapping between the node and its label is known. In other words, the label location is the same as the node location at the  release time. After release, the label location information is partially lost due to the random factors such as wind and  surface impact. However, statistically, the node locations are correlated with label locations. Such correlation depends on the airdrop methods employed and environments. For the sake of simplicity, let"s assume nodes are dropped from the air through a helicopter hovering in the air. Wind can be  decomposed into three components X,Y and Z. Only X and Y affect the horizontal distance a node can travel.  According to [24], we can assume that X and Y follow an  independent normal distribution. Therefore, the absolute value of the wind speed follows a Rayleigh distribution. Obviously the higher the wind speed is, the further a node would land away horizontally from the label location. If we assume that the distance D is a function of the wind speed V [25] [26], we can obtain the probability distribution of D under a given wind speed distribution. Without loss of generality, we  assume that D is proportional to the wind speed. Therefore, D follows the Rayleigh distribution as well. As shown in Figure 5, the spatial-based relaxation is a recursive process to assign the probability that a nodes has a certain label by using the distances between the location of a node with  multiple label locations. We note that the distribution of distance D affects the probability with which a label is assigned. It is not  necessarily true that the nearest label is always chosen. For example, if D follows the Rayleigh(σ2) distribution, we can obtain the Probability Density Function (PDF) of distances as shown in Figure 6. This figure indicates that the possibility of a node to fall vertically is very small under windy conditions (σ > 0), and that the distance D is affected by the σ. The spatial distribution of nodes for σ = 1 is shown in Figure 7. Strong wind with a high σ value leads to a larger node  dispersion. More formally, given a probability density function PDF(D), the support for label λk of sensor node ni can be formulated as: Qs ni (λk) = PDF(Dni λk ) (9) It is interesting to point out two special cases. First, if all nodes are released at once (i.e., only one label location for all released nodes), the distance D from a node to all labels is the same. In this case, Ps+1 ni (λk) = Ps ni (λk), which indicates that we can not use the spatial-based relaxation to recursively narrow down the potential labels for a node. Second, if nodes are released at different locations that are far away from each other, we have: (i) If node ni has label λk, Ps ni (λk) → 1 when s → ∞, (ii) If node ni does not have label λk, Ps ni (λk) → 0 when s → ∞. In this second scenario, there are multiple  labels (one label per release), hence it is possible to correlate release times (labels) with positions on the ground. These  results indicate that spatial-based relaxation can label the node with a very high probability if the physical separation among nodes is large. .3.5 Relaxation with Color and Connectivity  Constraints One of the most interesting features of the StarDust  architecture is that it allows for hybrid localization solutions to be built, depending on the system requirements. One example is a localization system that uses the color and connectivity constraints. In this scheme, the color constraints are used for reducing the number of candidate labels for sensor nodes, to a more manageable value. As a reminder, in the  connectivity constrained relaxation, all labels are candidate labels for each sensor node. The color constraints are used in the initialization phase of Algorithm 3 (lines 1-3). After the  initialization, the standard connectivity constrained relaxation algorithm is used. For a better understanding of how the label relaxation  algorithm works, we give a concrete example, exemplified in Figure 8. In part (a) of the figure we depict the data structures 3 1    2     ni nj 2  0 1 0 .2 .2 .2 .2 .2 .25 .25 .25 .25 (a) 1    2     ni nj 2  0 1 0 .2 .2 .2 .2 .2 .32  .68  (b) Figure 8. A step through the algorithm. After  initialization (a) and after the 1st iteration for node ni (b) associated with nodes ni and nj after the initialization steps of the algorithm (lines 1-6), as well as the number of beacons between different labels (as reported by the network, through G(Λ,E)). As seen, the potential labels (shown inside the  vertical rectangles) are assigned to each node. Node ni can be any of the following: 11,8,4,1. Also depicted in the figure are the probabilities associated with each of the labels. After initialization, all probabilities are equal. Part (b) of Figure 8 shows the result of the first iteration of the localization algorithm for node ni, assuming that node nj is the first wi chosen in line 7 of Algorithm 3. By using Equation 6, the algorithm computes the support Q(λi) for each of the possible labels for node ni. Once the Q(λi)"s are computed, the normalizing constant, given by Equation  can be obtained. The last step of the iteration is to update the probabilities associated with all potential labels of node ni, as given by Equation 2. One interesting problem, which we explore in the  performance evaluation section, is to assess the impact the  partitioning of the color set C has on the accuracy of  localization. When the size of the coloring set is smaller than the number of sensor nodes (as it is the case for our hybrid  connectivity/color constrained relaxation), the system designer has the option of allowing one node to uniquely have a color (acting as an anchor), or multiple nodes. Intuitively, by  assigning one color to more than one node, more constraints (distributed) can be enforced. .3.6 Relaxation Techniques Analysis The proposed label relaxation techniques have different trade-offs. For our analysis of the trade-offs, we consider the following metrics of interest: the localization time  (duration), the energy consumed (overhead), the network size (scale) that can be handled by the technique and the  localization accuracy. The parameters of interest are the following: the number of sensor nodes (N), the energy spent for one aerial drop (εd), the energy spent in the network for  collecting and reporting neighbor information εb and the time Td taken by a sensor node to reach the ground after being  aerially deployed. The cost comparison of the different label relaxation techniques is shown in Table 1. As shown, the relaxation techniques based on color and space constraints have the lowest localization duration, zero, for all practical purposes. The scalability of the color based relaxation technique is, however, limited to the number of (a) (b) Figure 9. SensorBall with self-righting capabilities (a) and colored CCRs (b) unique color filters that can be built. The narrower the  Transfer Function Ψ(λ), the larger the number of unique colors that can be created. The manufacturing costs, however, are increasing as well. The scalability issue is addressed by all other label relaxation techniques. Most notably, the time constrained relaxation, which is very similar to the  colorconstrained relaxation, addresses the scale issue, at a higher deployment cost. Criteria Color Connectivity Time Space Duration 0 NTb NTd 0 Overhead εd εd +Nεb Nεd εd Scale |C| |N| |N| |N| Accuracy High Low High Medium Table 1. Comparison of label relaxation techniques  System Implementation The StarDust localization framework, depicted in Figure , is flexible in that it enables the development of new  localization systems, based on the four proposed label  relaxation schemes, or the inclusion of other, yet to be invented, schemes. For our performance evaluation we implemented a version of the StarDust framework, namely the one proposed in Section 3.3.5, where the constraints are based on color and connectivity. The Central device of the StarDust system consists of the following: the Light Emitter - we used a  common-off-theshelf flash light (QBeam, 3 million candlepower); the  image acquisition was done with a 3 megapixel digital camera (Sony DSC-S50) which provided the input to the Image  Processing algorithm, implemented in Matlab. For sensor nodes we built a custom sensor node, called SensorBall, with self-righting capabilities, shown in Figure (a). The self-righting capabilities are necessary in order to orient the CCR predominantly upwards. The CCRs that we used were inexpensive, plastic molded, night time warning signs commonly available on bicycles, as shown in Figure (b). We remark here the low quality of the CCRs we used. The reflectivity of each CCR (there are tens molded in the plastic container) is extremely low, and each CCR is not built with mirrors. A reflective effect is achieved by employing finely polished plastic surfaces. We had 5 colors available, in addition to the standard CCR, which reflects all the  incoming light (white CCR). For a slightly higher price (ours were 20cents/piece), better quality CCRs can be employed. 4 Figure 10. The field in the dark Figure 11. The illuminated field Figure 12. The difference: Figure  0Figure 11 Higher quality (better mirrors) would translate in more  accurate image processing (better sensor node detection) and smaller form factor for the optical component (an array of CCRs with a smaller area can be used). The sensor node platform we used was the micaZ mote. The code that runs on each node is a simple application which broadcasts 100 beacons, and maintains a neighbor  table containing the percentage of successfully received  beacons, for each neighbor. On demand, the neighbor table is reported to a base station, where the node ID mapping is  performed.  System Evaluation In this section we present the performance evaluation of a system implementation of the StarDust localization  framework. The three major research questions that our evaluation tries to answer are: the feasibility of the proposed framework (can sensor nodes be optically detected at large distances), the localization accuracy of one actual implementation of the StarDust framework, and whether or not atmospheric  conditions can affect the recognition of sensor nodes in an  image. The first two questions are investigated by evaluating the two main components of the StarDust framework: the Image Processing and the Node ID Matching. These  components have been evaluated separately mainly because of lack of adequate facilities. We wanted to evaluate the  performance of the Image Processing Algorithm in a long range, realistic, experimental set-up, while the Node ID Matching required a relatively large area, available for long periods of time (for connectivity data gathering). The third research question is investigated through a computer modeling of  atmospheric phenomena. For the evaluation of the Image Processing module, we performed experiments in a football stadium where we  deploy 6 sensor nodes in a 3×2 grid. The distance between the Central device and the sensor nodes is approximately 500 ft. The metrics of interest are the number of false positives and false negatives in the Image Processing Algorithm. For the evaluation of the Node ID Mapping component, we deploy 26 sensor nodes in an 120 × 60 ft2 flat area of a stadium. In order to investigate the influence the radio connectivity has on localization accuracy, we vary the height above ground of the deployed sensor nodes. Two set-ups are used: one in which the sensor nodes are on the ground, and the second one, in which the sensor nodes are raised 3 inches above ground. From here on, we will refer to these two experimental set-ups as the low connectivity and the high connectivity networks, respectively because when nodes are on the ground the communication range is low resulting in less neighbors than when the nodes are elevated and have a greater communication range. The metrics of interest are: the localization error (defined as the distance between the computed location and the true location - known from the manual placement), the percentage of nodes correctly  localized, the convergence of the label relaxation algorithm, the time to localize and the robustness of the node ID mapping to errors in the Image Processing module. The parameters that we vary experimentally are: the  angle under which images are taken, the focus of the camera, and the degree of connectivity. The parameters that we vary in simulations (subsequent to image acquisition and  connectivity collection) the number of colors, the number of  anchors, the number of false positives or negatives as input to the Node ID Matching component, the distance between the imaging device and sensor network (i.e., range),  atmospheric conditions (light attenuation coefficient) and CCR reflectance (indicative of its quality). .1 Image Processing For the IPA evaluation, we deploy 6 sensor nodes in a  × 2 grid. We take 13 sets of pictures using different  orientations of the camera and different zooming factors. All pictures were taken from the same location. Each set is  composed of a picture taken in the dark and of a picture taken with a light beam pointed at the nodes. We process the  pictures offline using a Matlab implementation of IPA. Since we are interested in the feasibility of identifying colored sensor nodes at large distance, the end result of our IPA is the 2D location of sensor nodes (position in the image). The  transformation to 3D coordinates can be done through standard computer graphics techniques [23]. One set of pictures obtained as part of our experiment is shown in Figures 10 and 11. The execution of our IPA  algorithm results in Figure 12 which filters out the background, and Figure 13 which shows the output of the edge detection step of IPA. The experimental results are depicted in  Figure 14. For each set of pictures the graph shows the number of false positives (the IPA determines that there is a node 5 Figure 13. Retroreflectors detected in Figure 12      2 3 4 5 6 7 8 9 10 11 Experiment Number Count False Positives False Negatives Figure 14. False Positives and Negatives for the 6 nodes while there is none), and the number of false negatives (the IPA determines that there is no node while there is one). In about 45% of the cases, we obtained perfect results, i.e., no false positives and no false negatives. In the remaining cases, we obtained a number of false positives of at most one, and a number of false negatives of at most two. We exclude two pairs of pictures from Figure 14. In the first excluded pair, we obtain 42 false positives and in the second pair 10 false positives and 7 false negatives. By  carefully examining the pictures, we realized that the first pair was taken out of focus and that a car temporarily appeared in one of the pictures of the second pair. The anomaly in the second set was due to the fact that we waited too long to take the second picture. If the pictures had been taken a few milliseconds apart, the car would have been represented on either both or none of the pictures and the IPA would have filtered it out. .2 Node ID Matching We evaluate the Node ID Matching component of our  system by collecting empirical data (connectivity information) from the outdoor deployment of 26 nodes in the 120×60 ft2 area. We collect 20 sets of data for the high connectivity and low connectivity network deployments. Off-line we  investigate the influence of coloring on the metrics of interest, by randomly assigning colors to the sensor nodes. For one experimental data set we generate 50 random assignments of colors to sensor nodes. It is important to observe that, for the evaluation of the Node ID Matching algorithm (color and connectivity constrained), we simulate the color assignment to sensor nodes. As mentioned in Section 4 the size of the coloring space available to us was 5 (5 colors). Through  simulations of color assignment (not connectivity) we are able to investigate the influence that the size of the coloring space has on the accuracy of localization. The value of the  param0 0 0 0 0 0 0  10 20 30 40 50 60 70 80 90 Distance [feet] Count Connected Not Connected Figure 15. The number of existing and missing radio  connections in the sparse connectivity experiment  0 0 0 0 0 0 0  10 20 30 40 50 60 70 80 90 10 11 12 Distance [feet] Count Connected Not Connected Figure 16. The number of existing and missing radio  connections in the high connectivity experiment eter ε used in Algorithm 2 was 0.001. The results presented here represent averages over the randomly generated  colorings and over all experimental data sets. We first investigate the accuracy of our proposed Radio Model, and subsequently use the derived values for the radio range in the evaluation of the Node ID matching component. .2.1 Radio Model From experiments, we obtain the average number of  observed beacons (k, defined in Section 3.3.2) for the low  connectivity network of 180 beacons and for the high  connectivity network of 420 beacons. From our Radio Model  (Equation 7, we obtain a radio range R = 25 ft for the low  connectivity network and R = 40 ft for the high connectivity  network. To estimate the accuracy of our simple model, we plot the number of radio links that exist in the networks, and the number of links that are missing, as functions of the distance between nodes. The results are shown in Figures 15 and 16. We define the average radio range R to be the distance over which less than 20% of potential radio links, are missing. As shown in Figure 15, the radio range is between 20 ft and 5 ft. For the higher connectivity network, the radio range was between 30 ft and 40 ft. We choose two conservative estimates of the radio range: 0 ft for the low connectivity case and 35 ft for the high  connectivity case, which are in good agreement with the values predicted by our Radio Model. .2.2 Localization Error vs. Coloring Space Size In this experiment we investigate the effect of the number of colors on the localization accuracy. For this, we randomly assign colors from a pool of a given size, to the sensor nodes. 6   0 5 0 5 0 5 0 5  5 10 15 20 Number of Colors LocalizationError[feet] R=15feet R=20feet R=25feet Figure 17. Localization error  0 0 0 0 0 0 0 0 0 00  5 10 15 20 Number of Colors %CorrectLocalized[x100] R=15feet R=20feet R=25feet Figure 18. Percentage of nodes correctly localized We then execute the localization algorithm, which uses the empirical data. The algorithm is run for three different radio ranges: 15, 20 and 25 ft, to investigate its influence on the localization error. The results are depicted in Figure 17 (localization error) and Figure 18 (percentage of nodes correctly localized). As shown, for an estimate of 20 ft for the radio range (as  predicted by our Radio Model) we obtain the smallest  localization errors, as small as 2 ft, when enough colors are used. Both Figures 17 and 18 confirm our intuition that a larger number of colors available significantly decrease the error in localization. The well known fact that relaxation algorithms do not  always converge, was observed during our experiments. The percentage of successful runs (when the algorithm  converged) is depicted in Figure 19. As shown, in several  situations, the algorithm failed to converge (the algorithm  execution was stopped after 100 iterations per node). If the  algorithm does not converge in a predetermined number of steps, it will terminate and the label with the highest probability will provide the identity of the node. It is very probable that the chosen label is incorrect, since the probabilities of some of labels are constantly changing (with each iteration).The convergence of relaxation based algorithms is a well known issue. .2.3 Localization Error vs. Color Uniqueness As mentioned in the Section 3.3.1, a unique color gives a sensor node the statute of an anchor. A sensor node that is an anchor can unequivocally be identified through the Image Processing module. In this section we investigate the effect unique colors have on the localization accuracy. Specifically, we want to experimentally verify our intuition that assigning more nodes to a color can benefit the localization accuracy, by enforcing more constraints, as opposed to uniquely  assigning a color to a single node. 0 5 00 05  5 10 15 20 Number of Colors ConvergenceRate[x100] R=15feet R=20feet R=25feet Figure 19. Convergence error      0 2 4 6  6 8 Number of Colors LocalizationError[feet]  anchors  anchors  anchors  anchors  anchors Figure 20. Localization error vs. number of colors For this, we fix the number of available colors to either 4,  or 8 and vary the number of nodes that are given unique colors, from 0, up to the maximum number of colors (4, 6 or ). Naturally, if we have a maximum number of colors of 4, we can assign at most 4 anchors. The experimental results are depicted in Figure 20 (localization error) and Figure 21 (percentage of sensor node correctly localized). As expected, the localization accuracy increases with the increase in the number of colors available (larger coloring space). Also, for a given size of the coloring space (e.g., 6 colors available), if more colors are uniquely assigned to sensor nodes then the localization accuracy decreases. It is interesting to observe that by assigning colors uniquely to nodes, the benefit of  having additional colors is diminished. Specifically, if 8 colors are available and all are assigned uniquely, the system would be less accurately localized (error ≈ 7 ft), when compared to the case of 6 colors and no unique assignments of colors (≈ 5 ft localization error). The same trend, of a less accurate localization can be  observed in Figure 21, which shows the percentage of nodes correctly localized (i.e., 0 ft localization error). As shown, if we increase the number of colors that are uniquely assigned, the percentage of nodes correctly localized decreases. .2.4 Localization Error vs. Connectivity We collected empirical data for two network deployments with different degrees of connectivity (high and low) in  order to assess the influence of connectivity on location  accuracy. The results obtained from running our localization algorithm are depicted in Figure 22 and Figure 23. We  varied the number of colors available and assigned no anchors (i.e., no unique assignments of colors). In both scenarios, as expected, localization error decrease with an increase in the number of colors. It is interesting to observe, however, that the low connectivity scenario  im67  0 0 0 0 00 20 40  6 8 Number of Colors %CorrectLocalized[x100]  anchors  anchors  anchors  anchors  anchors Figure 21. Percentage of nodes correctly localized vs. number of colors   0 5 0 5 0 5 0 5  2 4 6 8 10 12 Number of Colors LocalizationError[feet] Low Connectivity High Connectivity Figure 22. Localization error vs. number of colors proves the localization accuracy quicker, from the additional number of colors available. When the number of colors  becomes relatively large (twelve for our 26 sensor node  network), both scenarios (low and high connectivity) have  comparable localization errors, of less that 2 ft. The same trend of more accurate location information is evidenced by  Figure 23 which shows that the percentage of nodes that are localized correctly grows quicker for the low connectivity deployment. .3 Localization Error vs. Image Processing Errors So far we investigated the sources for error in  localization that are intrinsic to the Node ID Matching component. As previously presented, luminous objects can be  mistakenly detected to be sensor nodes during the location  detection phase of the Image Processing module. These false  positives can be eliminated by the color recognition procedure of the Image Processing module. More problematic are false negatives (when a sensor node does not reflect back enough light to be detected). They need to be handled by the  localization algorithm. In this case, the localization algorithm is presented with two sets of nodes of different sizes, that need to be matched: one coming from the Image Processing (which misses some nodes) and one coming from the  network, with the connectivity information (here we assume a fully connected network, so that all sensor nodes report their connectivity information). In this experiment we investigate how Image Processing errors (false negatives) influence the localization accuracy. For this evaluation, we ran our localization algorithm with empirical data, but dropped a percentage of nodes from the list of nodes detected by the Image Processing algorithm (we artificially introduced false negatives in the Image  Process0 0 0 0 0 0 0 0 0 0 00  2 4 6 8 10 12 Number of Colors %CorrectLocalized[x100] Low Connectivity High Connectivity Figure 23. Percentage of nodes correctly localized      0 2 4  4 8 12 16 % False Negatives [x100] LocalizationError[feet]  colors  colors 2 colors Figure 24. Impact of false negatives on the localization error ing). The effect of false negatives on localization accuracy is depicted in Figure 24. As seen in the figure if the number of false negatives is 15%, the error in position estimation  doubles when 4 colors are available. It is interesting to observe that the scenario when more colors are available (e.g., 12  colors) is being affected more drastically than the scenario with less colors (e.g., 4 colors). The benefit of having more colors available is still being maintained, at least for the range of colors we investigated (4 through 12 colors). .4 Localization Time In this section we look more closely at the duration for each of the four proposed relaxation techniques and two combinations of them: color-connectivity and color-time. We assume that 50 unique color filters can be manufactured, that the sensor network is deployed from 2,400 ft  (necessary for the time-constrained relaxation) and that the time required for reporting connectivity grows linearly, with an initial reporting period of 160sec, as used in a real world tracking application [1]. The localization duration results, as presented in Table 1, are depicted in Figure 25. As shown, for all practical purposes the time required by the space constrained relaxation techniques is 0sec. The same applies to the color constrained relaxation, for which the localization time is 0sec (if the number of colors is  sufficient). Considering our assumptions, only for a network of size 50 the color constrained relaxation works. The  localization duration for all other network sizes (100, 150 and 200) is infinite (i.e., unique color assignments to sensor nodes can not be made, since only 50 colors are unique), when only color constrained relaxation is used. Both the  connectivity constrained and time constrained techniques increase linearly with the network size (for the time constrained, the Central device deploys sensor nodes one by one, recording an image after the time a sensor node is expected to reach the 8  00 000 500 000 500 000 Color Connectivity Time Space  ColorConenctivity Color-Time Localization technique Localizationtime[sec] 0 nodes 00 nodes 50 nodes 00 nodes Figure 25. Localization time for different  label relaxation schemes  2000 4000 6000 8000  .5  .5  .5  .5  r [feet] C r .3 .4 .5 .6 .7 .8 .9 .0 Figure 26. Apparent contrast in a clear atmosphere  2000 4000 6000 8000  .5  .5  .5  .5  r [feet] C r .3 .4 .5 .6 .7 .8 .9 .0 Figure 27. Apparent contrast in a hazing atmosphere ground). It is interesting to notice in Figure 25 the improvement in the localization time obtained by simply combining the color and the connectivity constrained techniques. The  localization duration in this case is identical with the connectivity constrained technique. The combination of color and time constrained  relaxations is even more interesting. For a reasonable  localization duration of 52seconds a perfect (i.e., 0 ft localization error) localization system can be built. In this scenario, the set of sensor nodes is split in batches, with each batch  having a set of unique colors. It would be very interesting to consider other scenarios, where the strength of the space constrained relaxation (0sec for any sensor network size) is used for improving the other proposed relaxation techniques. We leave the investigation and rigorous classification of such technique combination for future work. .5 System Range In this section we evaluate the feasibility of the  StarDust localization framework when considering the realities of light propagation through the atmosphere. The main factor that determines the range of our system is light scattering, which redirects the luminance of the source into the medium (in essence equally affecting the luminosity of the target and of the background). Scattering limits the visibility range by reducing the apparent contrast between the target and its background (approaches zero, as the  distance increases). The apparent contrast Cr is quantitatively expressed by the formula: Cr = (Nt r −Nb r )/Nb r (10) where Nt r and Nb r are the apparent target radiance and  apparent background radiance at distance r from the light source, respectively. The apparent radiance Nt r of a target at a  distance r from the light source, is given by: Nt r = Na + Iρte−2σr πr2 (11) where I is the intensity of the light source, ρt is the  target reflectance, σ is the spectral attenuation coefficient (≈ .12km−1 and ≈ 0.60km−1 for a clear and a hazy  atmosphere, respectively) and Na is the radiance of the  atmospheric backscatter, and it can be expressed as follows: Na = Gσ2I π σrZ .02σr e−x x2 dx (12) where G = 0.24 is a backscatter gain. The apparent  background radiance Nb r is given by formulas similar with  Equations 11 and 12, where only the target reflectance ρt is  substituted with the background reflectance ρb. It is important to remark that when Cr reaches its lower limit, no increase in the source luminance or receiver sensitivity will increase the range of the system. From Equations 11 and 12 it can be observed that the parameter which can be controlled and can influence the range of the system is ρt, the target reflectance. Figures 26 and 27 depict the apparent contrast Cr as a function of the distance r for a clear and for a hazy  atmosphere, respectively. The apparent contrast is investigated for reflectance coefficients ρt ranging from 0.3 to 1.0 (perfect  reflector). For a contrast C of at least 0.5, as it can be seen in Figure 26 a range of approximately 4,500 ft can be achieved if the atmosphere is clear. The performance dramatically  deteriorates, when the atmospheric conditions are problematic. As shown in Figure 27 a range of up to 1,500 ft is  achievable, when using highly reflective CCR components. While our light source (3 million candlepower) was  sufficient for a range of a few hundred feet, we remark that there exist commercially available light sources (20 million  candlepower) or military (150 million candlepower [27]),  powerful enough for ranges of a few thousand feet.  StarDust System Optimizations In this section we describe extensions of the proposed  architecture that can constitute future research directions. .1 Chained Constraint Primitives In this paper we proposed four primitives for  constraintbased relaxation algorithms: color, connectivity, time and space. To demonstrate the power that can be obtained by combining them, we proposed and evaluated one  combination of such primitives: color and connectivity. An  interesting research direction to pursue could be to chain more than two of these primitives. An example of such chain is: color, temporal, spatial and connectivity. Other research directions could be to use voting scheme for deciding which primitive to use or assign different weights to different relaxation  algorithms. 9 .2 Location Learning If after several iterations of the algorithm, none of the  label probabilities for a node ni converges to a higher value, the confidence in our labeling of that node is relatively low. It would be interesting to associate with a node, more than one label (implicitly more than one location) and defer the label assignment decision until events are detected in the network (if the network was deployed for target tracking). .3 Localization in Rugged Environments The initial driving force for the StarDust localization framework was to address the sensor node localization in  extremely rugged environments. Canopies, dense vegetation, extremely obstructing environments pose significant  challenges for sensor nodes localization. The hope, and our  original idea, was to consider the time period between the aerial deployment and the time when the sensor node disappears under the canopy. By recording the last visible position of a sensor node (as seen from the aircraft) a reasonable estimate of the sensor node location can be obtained. This would require that sensor nodes posses self-righting capabilities, while in mid-air. Nevertheless, we remark on the suitability of our localization framework for rugged, non-line-of-sight environments.  Conclusions StarDust solves the localization problem for aerial  deployments where passiveness, low cost, small form factor and rapid localization are required. Results show that  accuracy can be within 2 ft and localization time within  milliseconds. StarDust also shows robustness with respect to errors. We predict the influence the atmospheric conditions can have on the range of a system based on the StarDust framework, and show that hazy environments or daylight can pose  significant challenges. Most importantly, the properties of StarDust support the potential for even more accurate localization solutions as well as solutions for rugged, non-line-of-sight  environments.  References [1] T. He, S. Krishnamurthy, J. A. Stankovic, T. Abdelzaher, L. Luo, R. Stoleru, T. Yan, L. Gu, J. Hui, and B. Krogh, An energy-efficient surveillance system using wireless sensor networks, in MobiSys, 2004. [2] G. Simon, M. Maroti, A. Ledeczi, G. Balogh, B. Kusy, A. Nadas, G. Pap, J. Sallai, and K. Frampton, Sensor network-based  countersniper system, in SenSys, 2004. [3] A. Arora, P. Dutta, and B. Bapat, A line in the sand: A wireless sensor network for trage detection, classification and tracking, in Computer Networks, 2004. [4] R. Szewczyk, A. Mainwaring, J. Polastre, J. Anderson, and D. Culler, An analysis of a large scale habitat monitoring application, in ACM SenSys, 2004. [5] N. Xu, S. Rangwala, K. K. Chintalapudi, D. Ganesan, A. Broad, R. Govindan, and D. Estrin, A wireless sensor network for structural monitoring, in ACM SenSys, 2004. [6] A. Savvides, C. Han, and M. Srivastava, Dynamic fine-grained  localization in ad-hoc networks of sensors, in Mobicom, 2001. [7] N. Priyantha, A. Chakraborty, and H. Balakrishnan, The cricket location-support system, in Mobicom, 2000. [8] M. Broxton, J. Lifton, and J. Paradiso, Localizing a sensor network via collaborative processing of global stimuli, in EWSN, 2005. [9] P. Bahl and V. N. Padmanabhan, Radar: An in-building rf-based user location and tracking system, in IEEE Infocom, 2000. [10] N. Priyantha, H. Balakrishnan, E. Demaine, and S. Teller,  Mobileassisted topology generation for auto-localization in sensor networks, in IEEE Infocom, 2005. [11] P. N. Pathirana, A. Savkin, S. Jha, and N. Bulusu, Node localization using mobile robots in delay-tolerant sensor networks, IEEE  Transactions on Mobile Computing, 2004. [12] C. Savarese, J. M. Rabaey, and J. Beutel, Locationing in distribued ad-hoc wireless sensor networks, in ICAASSP, 2001. [13] M. Maroti, B. Kusy, G. Balogh, P. Volgyesi, A. Nadas, K. Molnar, S. Dora, and A. Ledeczi, Radio interferometric geolocation, in ACM SenSys, 2005. [14] K. Whitehouse, A. Woo, C. Karlof, F. Jiang, and D. Culler, The  effects of ranging noise on multi-hop localization: An empirical study, in IPSN, 2005. [15] Y. Kwon, K. Mechitov, S. Sundresh, W. Kim, and G. Agha, Resilient localization for sensor networks in outdoor environment, UIUC, Tech. Rep., 2004. [16] R. Stoleru and J. A. Stankovic, Probability grid: A location  estimation scheme for wireless sensor networks, in SECON, 2004. [17] N. Bulusu, J. Heidemann, and D. Estrin, GPS-less low cost outdoor localization for very small devices, IEEE Personal Communications Magazine, 2000. [18] T. He, C. Huang, B. Blum, J. A. Stankovic, and T. Abdelzaher, Range-Free localization schemes in large scale sensor networks, in ACM Mobicom, 2003. [19] R. Nagpal, H. Shrobe, and J. Bachrach, Organizing a global  coordinate system from local information on an ad-hoc sensor network, in IPSN, 2003. [20] D. Niculescu and B. Nath, ad-hoc positioning system, in IEEE GLOBECOM, 2001. [21] R. Stoleru, T. He, J. A. Stankovic, and D. Luebke, A high-accuracy low-cost localization system for wireless sensor networks, in ACM SenSys, 2005. [22] K. R¨omer, The lighthouse location system for smart dust, in ACM/USENIX MobiSys, 2003. [23] R. Y. Tsai, A versatile camera calibration technique for  highaccuracy 3d machine vision metrology using off-the-shelf tv cameras and lenses, IEEE JRA, 1987. [24] C. L. Archer and M. Z. Jacobson, Spatial and temporal distributions of U.S. winds and wind power at 80m derived from measurements, Geophysical Research Jrnl., 2003. [25] Team for advanced flow simulation and modeling. [Online]. Available: http://www.mems.rice.edu/TAFSM/RES/ [26] K. Stein, R. Benney, T. Tezduyar, V. Kalro, and J. Leonard, 3-D computation of parachute fluid-structure interactions - performance and control, in Aerodynamic Decelerator Systems Conference, 1999. [27] Headquarters Department of the Army, Technical manual for  searchlight infrared AN/GSS-14(V)1, 1982. 0
TSAR: A Two Tier Sensor Storage Architecture Using Interval Skip Graphs ∗ Peter Desnoyers, Deepak Ganesan, and Prashant Shenoy Department of Computer Science University of Massachusetts Amherst, MA 01003 pjd@cs.umass.edu, dganesan@cs.umass.edu, shenoy@cs.umass.edu ABSTRACT Archival storage of sensor data is necessary for applications that query, mine, and analyze such data for interesting features and trends. We argue that existing storage systems are designed primarily for flat hierarchies of homogeneous sensor nodes and do not fully exploit the multi-tier nature of emerging sensor networks, where an application can comprise tens of tethered proxies, each managing tens to hundreds of untethered sensors. We present TSAR, a fundamentally different storage architecture that  envisions separation of data from metadata by employing local archiving at the sensors and distributed indexing at the proxies. At the proxy tier, TSAR employs a novel multi-resolution ordered distributed index structure, the Interval Skip Graph, for efficiently supporting spatio-temporal and value queries. At the sensor tier, TSAR supports energy-aware adaptive  summarization that can trade off the cost of transmitting metadata to the proxies against the overhead of false hits resulting from querying a coarse-grain  index. We implement TSAR in a two-tier sensor testbed comprising  Stargatebased proxies and Mote-based sensors. Our experiments demonstrate the benefits and feasibility of using our energy-efficient storage architecture in multi-tier sensor networks. Categories and Subject Descriptors: C.2.4 [Computer -  Communication Networks]: Distributed Systems General Terms: Algorithms, performance, experimentation. . Introduction .1 Motivation Many different kinds of networked data-centric sensor  applications have emerged in recent years. Sensors in these applications sense the environment and generate data that must be processed, filtered, interpreted, and archived in order to provide a useful  infrastructure to its users. To achieve its goals, a typical sensor  application needs access to both live and past sensor data. Whereas access to live data is necessary in monitoring and surveillance  applications, access to past data is necessary for applications such as mining of sensor logs to detect unusual patterns, analysis of  historical trends, and post-mortem analysis of particular events. Archival storage of past sensor data requires a storage system, the key  attributes of which are: where the data is stored, whether it is indexed, and how the application can access this data in an energy-efficient manner with low latency. There have been a spectrum of approaches for constructing  sensor storage systems. In the simplest, sensors stream data or events to a server for long-term archival storage [3], where the server  often indexes the data to permit efficient access at a later time. Since sensors may be several hops from the nearest base station, network costs are incurred; however, once data is indexed and archived,  subsequent data accesses can be handled locally at the server without incurring network overhead. In this approach, the storage is  centralized, reads are efficient and cheap, while writes are expensive. Further, all data is propagated to the server, regardless of whether it is ever used by the application. An alternate approach is to have each sensor store data or events locally (e.g., in flash memory), so that all writes are local and incur no communication overheads. A read request, such as whether an event was detected by a particular sensor, requires a message to be sent to the sensor for processing. More complex read requests are handled by flooding. For instance, determining if an intruder was detected over a particular time interval requires the request to be flooded to all sensors in the system. Thus, in this approach, the storage is distributed, writes are local and inexpensive, while reads incur significant network overheads. Requests that require flooding, due to the lack of an index, are expensive and may waste precious sensor resources, even if no matching data is stored at those sensors. Research efforts such as Directed Diffusion [17] have attempted to reduce these read costs, however, by intelligent message routing. Between these two extremes lie a number of other sensor storage systems with different trade-offs, summarized in Table 1. The  geographic hash table (GHT) approach [24, 26] advocates the use of an in-network index to augment the fully distributed nature of  sensor storage. In this approach, each data item has a key associated with it, and a distributed or geographic hash table is used to map keys to nodes that store the corresponding data items. Thus, writes cause data items to be sent to the hashed nodes and also trigger  updates to the in-network hash table. A read request requires a lookup in the in-network hash table to locate the node that stores the data 9 item; observe that the presence of an index eliminates the need for flooding in this approach. Most of these approaches assume a flat, homogeneous  architecture in which every sensor node is energy-constrained. In this paper, we propose a novel storage architecture called TSAR1 that reflects and exploits the multi-tier nature of emerging sensor  networks, where the application is comprised of tens of tethered  sensor proxies (or more), each controlling tens or hundreds of  untethered sensors. TSAR is a component of our PRESTO [8] predictive storage architecture, which combines archival storage with caching and prediction. We believe that a fundamentally different storage architecture is necessary to address the multi-tier nature of future sensor networks. Specifically, the storage architecture needs to  exploit the resource-rich nature of proxies, while respecting resource constraints at the remote sensors. No existing sensor storage  architecture explicitly addresses this dichotomy in the resource  capabilities of different tiers. Any sensor storage system should also carefully exploit current technology trends, which indicate that the capacities of flash  memories continue to rise as per Moore"s Law, while their costs continue to plummet. Thus it will soon be feasible to equip each sensor with  GB of flash storage for a few tens of dollars. An even more  compelling argument is the energy cost of flash storage, which can be as much as two orders of magnitude lower than that for  communication. Newer NAND flash memories offer very low write and erase energy costs - our comparison of a 1GB Samsung NAND flash storage [16] and the Chipcon CC2420 802.15.4 wireless radio [4] in Section 6.2 indicates a 1:100 ratio in per-byte energy cost  between the two devices, even before accounting for network protocol overheads. These trends, together with the energy-constrained  nature of untethered sensors, indicate that local storage offers a viable, energy-efficient alternative to communication in sensor networks. TSAR exploits these trends by storing data or events locally on the energy-efficient flash storage at each sensor. Sensors send  concise identifying information, which we term metadata, to a nearby proxy; depending on the representation used, this metadata may be an order of magnitude or more smaller than the data itself,  imposing much lower communication costs. The resource-rich proxies interact with one another to construct a distributed index of the metadata reported from all sensors, and thus an index of the  associated data stored at the sensors. This index provides a unified, logical view of the distributed data, and enables an application to query and read past data efficiently - the index is used to  pinpoint all data that match a read request, followed by messages to retrieve that data from the corresponding sensors. In-network  index lookups are eliminated, reducing network overheads for read requests. This separation of data, which is stored at the sensors, and the metadata, which is stored at the proxies, enables TSAR to reduce energy overheads at the sensors, by leveraging resources at tethered proxies. .2 Contributions This paper presents TSAR, a novel two-tier storage architecture for sensor networks. To the best of our knowledge, this is the first sensor storage system that is explicitly tailored for emerging  multitier sensor networks. Our design and implementation of TSAR has resulted in four contributions. At the core of the TSAR architecture is a novel distributed index structure based on interval skip graphs that we introduce in this paper. This index structure can store coarse summaries of sensor data and organize them in an ordered manner to be easily  search1 TSAR: Tiered Storage ARchitecture for sensor networks. able. This data structure has O(log n) expected search and update complexity. Further, the index provides a logically unified view of all data in the system. Second, at the sensor level, each sensor maintains a local archive that stores data on flash memory. Our storage architecture is fully stateless at each sensor from the perspective of the metadata index; all index structures are maintained at the resource-rich proxies, and only direct requests or simple queries on explicitly identified  storage locations are sent to the sensors. Storage at the remote sensor is in effect treated as appendage of the proxy, resulting in low  implementation complexity, which makes it ideal for small,  resourceconstrained sensor platforms. Further, the local store is optimized for time-series access to archived data, as is typical in many  applications. Each sensor periodically sends a summary of its data to a proxy. TSAR employs a novel adaptive summarization technique that adapts the granularity of the data reported in each summary to the ratio of false hits for application queries. More fine grain  summaries are sent whenever more false positives are observed, thereby balancing the energy cost of metadata updates and false positives. Third, we have implemented a prototype of TSAR on a multi-tier testbed comprising Stargate-based proxies and Mote-based sensors. Our implementation supports spatio-temporal, value, and  rangebased queries on sensor data. Fourth, we conduct a detailed experimental evaluation of TSAR using a combination of EmStar/EmTOS [10] and our prototype. While our EmStar/EmTOS experiments focus on the scalability of TSAR in larger settings, our prototype evaluation involves latency and energy measurements in a real setting. Our results demonstrate the logarithmic scaling property of the sparse skip graph and the low latency of end-to-end queries in a duty-cycled multi-hop  network . The remainder of this paper is structured as follows. Section 2 presents key design issues that guide our work. Section 3 and 4 present the proxy-level index and the local archive and  summarization at a sensor, respectively. Section 5 discusses our prototype  implementation, and Section 6 presents our experimental results. We present related work in Section 7 and our conclusions in Section 8. . Design Considerations In this section, we first describe the various components of a multi-tier sensor network assumed in our work. We then present a description of the expected usage models for this system, followed by several principles addressing these factors which guide the  design of our storage system. .1 System Model We envision a multi-tier sensor network comprising multiple tiers - a bottom tier of untethered remote sensor nodes, a middle tier of tethered sensor proxies, and an upper tier of applications and user terminals (see Figure 1). The lowest tier is assumed to form a dense deployment of  lowpower sensors. A canonical sensor node at this tier is equipped with low-power sensors, a micro-controller, and a radio as well as a significant amount of flash memory (e.g., 1GB). The common constraint for this tier is energy, and the need for a long lifetime in spite of a finite energy constraint. The use of radio, processor, RAM, and the flash memory all consume energy, which needs to be limited. In general, we assume radio communication to be  substantially more expensive than accesses to flash memory. The middle tier consists of power-rich sensor proxies that have significant computation, memory and storage resources and can use 0 Table 1: Characteristics of sensor storage systems System Data Index Reads Writes Order preserving Centralized store Centralized Centralized index Handled at store Send to store Yes Local sensor store Fully distributed No index Flooding, diffusion Local No GHT/DCS [24] Fully distributed In-network index Hash to node Send to hashed node No TSAR/PRESTO Fully distributed Distributed index at proxies Proxy lookup + sensor query Local plus index update Yes User Unified Logical Store Queries (time, space, value) Query Response Cache Query forwarding Proxy Remote Sensors Local Data Archive on Flash Memory Interval Skip Graph Query forwarding summaries start index end index linear traversal Query Response Cache-miss triggered query forwarding summaries Figure 1: Architecture of a multi-tier sensor network. these resources continuously. In urban environments, the proxy tier would comprise a tethered base-station class nodes (e.g., Crossbow Stargate), each with with multiple radios-an 802.11 radio that connects it to a wireless mesh network and a low-power radio (e.g. 02.15.4) that connects it to the sensor nodes. In remote sensing applications [10], this tier could comprise a similar Stargate node with a solar power cell. Each proxy is assumed to manage several tens to hundreds of lower-tier sensors in its vicinity. A typical  sensor network deployment will contain multiple geographically  distributed proxies. For instance, in a building monitoring application, one sensor proxy might be placed per floor or hallway to monitor temperature, heat and light sensors in their vicinity. At the highest tier of our infrastructure are applications that query the sensor network through a query interface[20]. In this work, we focus on applications that require access to past sensor data. To support such queries, the system needs to archive data on a  persistent store. Our goal is to design a storage system that exploits the relative abundance of resources at proxies to mask the scarcity of resources at the sensors. .2 Usage Models The design of a storage system such as TSAR is affected by the queries that are likely to be posed to it. A large fraction of queries on sensor data can be expected to be spatio-temporal in nature. Sensors provide information about the physical world; two key  attributes of this information are when a particular event or activity occurred and where it occurred. Some instances of such queries  include the time and location of target or intruder detections (e.g.,  security and monitoring applications), notifications of specific types of events such as pressure and humidity values exceeding a  threshold (e.g., industrial applications), or simple data collection queries which request data from a particular time or location (e.g., weather or environment monitoring). Expected queries of such data include those requesting ranges of one or more attributes; for instance, a query for all image data from cameras within a specified geographic area for a certain  period of time. In addition, it is often desirable to support efficient access to data in a way that maintains spatial and temporal  ordering. There are several ways of supporting range queries, such as locality-preserving hashes such as are used in DIMS [18].  However, the most straightforward mechanism, and one which naturally provides efficient ordered access, is via the use of order-preserving data structures. Order-preserving structures such as the well-known B-Tree maintain relationships between indexed values and thus  allow natural access to ranges, as well as predecessor and successor operations on their key values. Applications may also pose value-based queries that involve  determining if a value v was observed at any sensor; the query  returns a list of sensors and the times at which they observed this value. Variants of value queries involve restricting the query to a geographical region, or specifying a range (v1, v2) rather than a single value v. Value queries can be handled by indexing on the values reported in the summaries. Specifically, if a sensor reports a numerical value, then the index is constructed on these values. A search involves finding matching values that are either contained in the search range (v1, v2) or match the search value v exactly. Hybrid value and spatio-temporal queries are also possible. Such queries specify a time interval, a value range and a spatial region and request all records that match these attributes - find all  instances where the temperature exceeded 100o F at location R  during the month of August. These queries require an index on both time and value. In TSAR our focus is on range queries on value or time, with planned extensions to include spatial scoping. .3 Design Principles Our design of a sensor storage system for multi-tier networks is based on the following set of principles, which address the issues arising from the system and usage models above. • Principle 1: Store locally, access globally: Current  technology allows local storage to be significantly more  energyefficient than network communication, while technology trends show no signs of erasing this gap in the near future. For maximum network life a sensor storage system should leverage the flash memory on sensors to archive data locally, substituting cheap memory operations for expensive radio transmission. But without efficient mechanisms for retrieval, the energy gains of local storage may be outweighed by  communication costs incurred by the application in searching for data. We believe that if the data storage system provides the abstraction of a single logical store to applications, as 1 does TSAR, then it will have additional flexibility to  optimize communication and storage costs. • Principle 2: Distinguish data from metadata: Data must be identified so that it may be retrieved by the application without exhaustive search. To do this, we associate  metadata with each data record - data fields of known syntax which serve as identifiers and may be queried by the storage system. Examples of this metadata are data attributes such as location and time, or selected or summarized data values. We leverage the presence of resource-rich proxies to index  metadata for resource-constrained sensors. The proxies share this metadata index to provide a unified logical view of all data in the system, thereby enabling efficient, low-latency lookups. Such a tier-specific separation of data storage from metadata indexing enables the system to exploit the idiosyncrasies of multi-tier networks, while improving performance and  functionality. • Principle 3: Provide data-centric query support: In a sensor application the specific location (i.e. offset) of a record in a stream is unlikely to be of significance, except if it conveys information concerning the location and/or time at which the information was generated. We thus expect that applications will be best served by a query interface which allows them to locate data by value or attribute (e.g. location and time), rather than a read interface for unstructured data. This in turn implies the need to maintain metadata in the form of an index that provides low cost lookups. .4 System Design TSAR embodies these design principles by employing local  storage at sensors and a distributed index at the proxies. The key  features of the system design are as follows: In TSAR, writes occur at sensor nodes, and are assumed to  consist of both opaque data as well as application-specific metadata. This metadata is a tuple of known types, which may be used by the application to locate and identify data records, and which may be searched on and compared by TSAR in the course of locating data for the application. In a camera-based sensing application, for  instance, this metadata might include coordinates describing the field of view, average luminance, and motion values, in addition to basic information such as time and sensor location. Depending on the application, this metadata may be two or three orders of magnitude smaller than the data itself, for instance if the metadata consists of features extracted from image or acoustic data. In addition to storing data locally, each sensor periodically sends a summary of reported metadata to a nearby proxy. The summary contains information such as the sensor ID, the interval (t1, t2) over which the summary was generated, a handle identifying the corresponding data record (e.g. its location in flash memory), and a coarse-grain representation of the metadata associated with the record. The precise data representation used in the summary is application-specific; for instance, a temperature sensor might choose to report the maximum and minimum temperature values observed in an interval as a coarse-grain representation of the  actual time series. The proxy uses the summary to construct an index; the index is global in that it stores information from all sensors in the  system and it is distributed across the various proxies in the system. Thus, applications see a unified view of distributed data, and can query the index at any proxy to get access to data stored at any sensor. Specifically, each query triggers lookups in this distributed index and the list of matches is then used to retrieve the  corresponding data from the sensors. There are several distributed index and lookup methods which might be used in this system; however, the index structure described in Section 3 is highly suited for the task. Since the index is constructed using a coarse-grain summary, instead of the actual data, index lookups will yield approximate matches. The TSAR summarization mechanism guarantees that  index lookups will never yield false negatives - i.e. it will never miss summaries which include the value being searched for. However, index lookups may yield false positives, where a summary matches the query but when queried the remote sensor finds no matching value, wasting network resources. The more coarse-grained the summary, the lower the update overhead and the greater the  fraction of false positives, while finer summaries incur update overhead while reducing query overhead due to false positives. Remote  sensors may easily distinguish false positives from queries which result in search hits, and calculate the ratio between the two; based on this ratio, TSAR employs a novel adaptive technique that dynamically varies the granularity of sensor summaries to balance the metadata overhead and the overhead of false positives. . Data Structures At the proxy tier, TSAR employs a novel index structure called the Interval Skip Graph, which is an ordered, distributed data  structure for finding all intervals that contain a particular point or range of values. Interval skip graphs combine Interval Trees [5], an interval-based binary search tree, with Skip Graphs [1], a ordered, distributed data structure for peer-to-peer systems [13]. The  resulting data structure has two properties that make it ideal for  sensor networks. First, it has O(log n) search complexity for  accessing the first interval that matches a particular value or range, and constant complexity for accessing each successive interval.  Second, indexing of intervals rather than individual values makes the data structure ideal for indexing summaries over time or value. Such summary-based indexing is a more natural fit for  energyconstrained sensor nodes, since transmitting summaries incurs less energy overhead than transmitting all sensor data. Definitions: We assume that there are Np proxies and Ns  sensors in a two-tier sensor network. Each proxy is responsible for multiple sensor nodes, and no assumption is made about the  number of sensors per proxy. Each sensor transmits interval summaries of data or events regularly to one or more proxies that it is  associated with, where interval i is represented as [lowi, highi]. These intervals can correspond to time or value ranges that are used for indexing sensor data. No assumption is made about the size of an interval or about the amount of overlap between intervals. Range queries on the intervals are posed by users to the network of proxies and sensors; each query q needs to determine all index values that overlap the interval [lowq, highq]. The goal of the  interval skip graph is to index all intervals such that the set that overlaps a query interval can be located efficiently. In the rest of this section, we describe the interval skip graph in greater detail. .1 Skip Graph Overview In order to inform the description of the Interval Skip Graph, we first provide a brief overview of the Skip Graph data structure; for a more extensive description the reader is referred to [1]. Figure 2 shows a skip graph which indexes 8 keys; the keys may be seen along the bottom, and above each key are the pointers associated with that key. Each data element, consisting of a key and its  associated pointers, may reside on a different node in the network, 2  9 13 17 21 25 311 level 0 level 1 level 2 key single skip graph element (each may be on different node) find(21) node-to-node messages Figure 2: Skip Graph of 8 Elements [6,14] [9,12] [14,16] [15,23] [18,19] [20,27] [21,30][2,5]  14 14 16 23 23 27 30 [low,high] max contains(13) match no match halt Figure 3: Interval Skip Graph [6,14] [9,12] [14,16] [15,23] [18,19] [20,27] [21,30] [2,5] Node 1 Node 2 Node 3 level 2 level 1 level 0 Figure 4: Distributed Interval Skip Graph and pointers therefore identify both a remote node as well as a data element on that node. In this figure we may see the following  properties of a skip graph: • Ordered index: The keys are members of an ordered data type, for instance integers. Lookups make use of ordered comparisons between the search key and existing index  entries. In addition, the pointers at the lowest level point  directly to the successor of each item in the index. • In-place indexing: Data elements remain on the nodes where they were inserted, and messages are sent between nodes to establish links between those elements and others in the index. • Log n height: There are log2 n pointers associated with each element, where n is the number of data elements indexed. Each pointer belongs to a level l in [0... log2 n − 1], and together with some other pointers at that level forms a chain of n/2l elements. • Probabilistic balance: Rather than relying on re-balancing operations which may be triggered at insert or delete, skip graphs implement a simple random balancing mechanism which maintains close to perfect balance on average, with an extremely low probability of significant imbalance. • Redundancy and resiliency: Each data element forms an independent search tree root, so searches may begin at any node in the network, eliminating hot spots at a single search root. In addition the index is resilient against node failure; data on the failed node will not be accessible, but remaining data elements will be accessible through search trees rooted on other nodes. In Figure 2 we see the process of searching for a particular value in a skip graph. The pointers reachable from a single data element form a binary tree: a pointer traversal at the highest level skips over n/2 elements, n/4 at the next level, and so on. Search consists of descending the tree from the highest level to level 0, at each level comparing the target key with the next element at that level and deciding whether or not to traverse. In the perfectly balanced case shown here there are log2 n levels of pointers, and search will traverse 0 or 1 pointers at each level. We assume that each data element resides on a different node, and measure search cost by the number messages sent (i.e. the number of pointers traversed); this will clearly be O(log n). Tree update proceeds from the bottom, as in a B-Tree, with the root(s) being promoted in level as the tree grows. In this way, for instance, the two chains at level 1 always contain n/2 entries each, and there is never a need to split chains as the structure grows. The update process then consists of choosing which of the 2l chains to insert an element into at each level l, and inserting it in the proper place in each chain. Maintaining a perfectly balanced skip graph as shown in  Figure 2 would be quite complex; instead, the probabilistic balancing method introduced in Skip Lists [23] is used, which trades off a small amount of overhead in the expected case in return for simple update and deletion. The basis for this method is the observation that any element which belongs to a particular chain at level l can only belong to one of two chains at level l+1. To insert an element we ascend levels starting at 0, randomly choosing one of the two possible chains at each level, an stopping when we reach an empty chain. One means of implementation (e.g. as described in [1]) is to assign each element an arbitrarily long random bit string. Each chain at level l is then constructed from those elements whose bit strings match in the first l bits, thus creating 2l possible chains at each level and ensuring that each chain splits into exactly two chains at the next level. Although the resulting structure is not perfectly balanced, following the analysis in [23] we can show that the probability of it being significantly out of balance is extremely small; in addition, since the structure is determined by the random number stream, input data patterns cannot cause the tree to become imbalanced. .2 Interval Skip Graph A skip graph is designed to store single-valued entries. In this section, we introduce a novel data structure that extends skip graphs to store intervals [lowi, highi] and allows efficient searches for all intervals covering a value v, i.e. {i : lowi ≤ v ≤ highi}. Our data structure can be extended to range searches in a straightforward manner. The interval skip graph is constructed by applying the method of augmented search trees, as described by Cormen, Leiserson, and Rivest [5] and applied to binary search trees to create an Interval Tree. The method is based on the observation that a search structure based on comparison of ordered keys, such as a binary tree, may also be used to search on a secondary key which is non-decreasing in the first key. Given a set of intervals sorted by lower bound - lowi ≤ lowi+1 - we define the secondary key as the cumulative maximum, maxi = maxk=0...i (highk). The set of intervals intersecting a value v may then be found by searching for the first interval (and thus the interval with least lowi) such that maxi ≥ v. We then 3 traverse intervals in increasing order lower bound, until we find the first interval with lowi > v, selecting those intervals which  intersect v. Using this approach we augment the skip graph data structure, as shown in Figure 3, so that each entry stores a range (lower bound and upper bound) and a secondary key (cumulative maximum of upper bound). To efficiently calculate the secondary key maxi for an entry i, we take the greatest of highi and the maximum values reported by each of i"s left-hand neighbors. To search for those intervals containing the value v, we first search for v on the secondary index, maxi, and locate the first entry with maxi ≥ v. (by the definition of maxi, for this data element maxi = highi.) If lowi > v, then this interval does not contain v, and no other intervals will, either, so we are done. Otherwise we traverse the index in increasing order of mini, returning matching intervals, until we reach an entry with mini > v and we are done. Searches for all intervals which overlap a query range, or which completely contain a query range, are straightforward extensions of this mechanism. Lookup Complexity: Lookup for the first interval that matches a given value is performed in a manner very similar to an interval tree. The complexity of search is O(log n). The number of  intervals that match a range query can vary depending on the amount of overlap in the intervals being indexed, as well as the range specified in the query. Insert Complexity: In an interval tree or interval skip list, the maximum value for an entry need only be calculated over the  subtree rooted at that entry, as this value will be examined only when searching within the subtree rooted at that entry. For a simple  interval skip graph, however, this maximum value for an entry must be computed over all entries preceding it in the index, as searches may begin anywhere in the data structure, rather than at a distinguished root element. It may be easily seen that in the worse case the  insertion of a single interval (one that covers all existing intervals in the index) will trigger the update of all entries in the index, for a worst-case insertion cost of O(n). .3 Sparse Interval Skip Graph The final extensions we propose take advantage of the  difference between the number of items indexed in a skip graph and the number of systems on which these items are distributed. The cost in network messages of an operation may be reduced by  arranging the data structure so that most structure traversals occur locally on a single node, and thus incur zero network cost. In addition, since both congestion and failure occur on a per-node basis, we may eliminate links without adverse consequences if those links only contribute to load distribution and/or resiliency within a  single node. These two modifications allow us to achieve reductions in asymptotic complexity of both update and search. As may be in Section 3.2, insert and delete cost on an  interval skip graph has a worst case complexity of O(n), compared to O(log n) for an interval tree. The main reason for the difference is that skip graphs have a full search structure rooted at each  element, in order to distribute load and provide resilience to system failures in a distributed setting. However, in order to provide load distribution and failure resilience it is only necessary to provide a full search structure for each system. If as in TSAR the number of nodes (proxies) is much smaller than the number of data  elements (data summaries indexed), then this will result in significant savings. Implementation: To construct a sparse interval skip graph, we ensure that there is a single distinguished element on each system, the root element for that system; all searches will start at one of these root elements. When adding a new element, rather than  splitting lists at increasing levels l until the element is in a list with no others, we stop when we find that the element would be in a list  containing no root elements, thus ensuring that the element is reachable from all root elements. An example of applying this optimization may be seen in Figure 5. (In practice, rather than designating  existing data elements as roots, as shown, it may be preferable to insert null values at startup.) When using the technique of membership vectors as in [1], this may be done by broadcasting the membership vectors of each root element to all other systems, and stopping insertion of an element at level l when it does not share an l-bit prefix with any of the Np root elements. The expected number of roots sharing a log2Np-bit prefix is 1, giving an expected expected height for each element of log2Np +O(1). An alternate implementation, which distributes  information concerning root elements at pointer establishment time, is omitted due to space constraints; this method eliminates the need for additional messages. Performance: In a (non-interval) sparse skip graph, since the expected height of an inserted element is now log2 Np + O(1), expected insertion complexity is O(log Np), rather than O(log n), where Np is the number of root elements and thus the number of separate systems in the network. (In the degenerate case of a  single system we have a skip list; with splitting probability 0.5 the expected height of an individual element is 1.) Note that since searches are started at root elements of expected height log2 n, search complexity is not improved. For an interval sparse skip graph, update performance is  improved considerably compared to the O(n) worst case for the  nonsparse case. In an augmented search structure such as this, an  element only stores information for nodes which may be reached from that element-e.g. the subtree rooted at that element, in the case of a tree. Thus, when updating the maximum value in an interval tree, the update is only propagated towards the root. In a sparse interval skip graph, updates to a node only propagate towards the Np root elements, for a worst-case cost of Np log2 n. Shortcut search: When beginning a search for a value v, rather than beginning at the root on that proxy, we can find the element that is closest to v (e.g. using a secondary local index), and then begin the search at that element. The expected distance between this element and the search terminus is log2 Np, and the search will now take on average log2 Np + O(1) steps. To illustrate this optimization, in Figure 4 depending on the choice of search root, a search for [21, 30] beginning at node 2 may take 3 network hops, traversing to node 1, then back to node 2, and finally to node 3 where the destination is located, for a cost of 3 messages. The shortcut search, however, locates the intermediate data element on node 2, and then proceeds directly to node 3 for a cost of 1 message. Performance: This technique may be applied to the primary key search which is the first of two insertion steps in an interval skip graph. By combining the short-cut optimization with sparse  interval skip graphs, the expected cost of insertion is now O(log Np), independent of the size of the index or the degree of overlap of the inserted intervals. .4 Alternative Data Structures Thus far we have only compared the sparse interval skip graph with similar structures from which it is derived. A comparison with several other data structures which meet at least some of the  requirements for the TSAR index is shown in Table 2. 4 Table 2: Comparison of Distributed Index Structures Range Query Support Interval Representation Re-balancing Resilience Small Networks Large Networks DHT, GHT no no no yes good good Local index, flood query yes yes no yes good bad P-tree, RP* (distributed B-Trees) yes possible yes no good good DIMS yes no yes yes yes yes Interval Skipgraph yes yes no yes good good [6,14] [9,12] [14,16] [15,23] [18,19] [20,27] [21,30][2,5] Roots Node 1 Node 2 Figure 5: Sparse Interval Skip Graph The hash-based systems, DHT [25] and GHT [26], lack the  ability to perform range queries and are thus not well-suited to indexing spatio-temporal data. Indexing locally using an appropriate  singlenode structure and then flooding queries to all proxies is a  competitive alternative for small networks; for large networks the linear dependence on the number of proxies becomes an issue. Two  distributed B-Trees were examined - P-Trees [6] and RP* [19]. Each of these supports range queries, and in theory could be modified to support indexing of intervals; however, they both require  complex re-balancing, and do not provide the resilience characteristics of the other structures. DIMS [18] provides the ability to perform spatio-temporal range queries, and has the necessary resilience to failures; however, it cannot be used index intervals, which are used by TSAR"s data summarization algorithm. . Data Storage and Summarization Having described the proxy-level index structure, we turn to the mechanisms at the sensor tier. TSAR implements two key  mechanisms at the sensor tier. The first is a local archival store at each sensor node that is optimized for resource-constrained devices. The second is an adaptive summarization technique that enables each sensor to adapt to changing data and query characteristics. The rest of this section describes these mechanisms in detail. .1 Local Storage at Sensors Interval skip graphs provide an efficient mechanism to lookup sensor nodes containing data relevant to a query. These queries are then routed to the sensors, which locate the relevant data records in the local archive and respond back to the proxy. To enable such lookups, each sensor node in TSAR maintains an archival store of sensor data. While the implementation of such an archival store is straightforward on resource-rich devices that can run a database, sensors are often power and resource-constrained. Consequently, the sensor archiving subsystem in TSAR is explicitly designed to exploit characteristics of sensor data in a resource-constrained  setting. Timestamp Calibration Parameters Opaque DataData/Event Attributes size Figure 6: Single storage record Sensor data has very distinct characteristics that inform our  design of the TSAR archival store. Sensors produce time-series data streams, and therefore, temporal ordering of data is a natural and simple way of storing archived sensor data. In addition to  simplicity, a temporally ordered store is often suitable for many sensor data processing tasks since they involve time-series data processing.  Examples include signal processing operations such as FFT, wavelet transforms, clustering, similarity matching, and target detection. Consequently, the local archival store is a collection of records, designed as an append-only circular buffer, where new records are appended to the tail of the buffer. The format of each data record is shown in Figure 6. Each record has a metadata field which includes a timestamp, sensor settings, calibration parameters, etc. Raw  sensor data is stored in the data field of the record. The data field is opaque and application-specific-the storage system does not know or care about interpreting this field. A camera-based sensor, for instance, may store binary images in this data field. In order to support a variety of applications, TSAR supports variable-length data fields; as a result, record sizes can vary from one record to another. Our archival store supports three operations on records: create, read, and delete. Due to the append-only nature of the store,  creation of records is simple and efficient. The create operation simply creates a new record and appends it to the tail of the store. Since records are always written at the tail, the store need not maintain a free space list. All fields of the record need to be specified at creation time; thus, the size of the record is known a priori and the store simply allocates the the corresponding number of bytes at the tail to store the record. Since writes are immutable, the size of a record does not change once it is created. proxy proxy proxy record  record summary local archive in flash memory data summary start,end offset time interval sensor summary sent to proxy Insert summaries into interval skip graph Figure 7: Sensor Summarization 5 The read operation enables stored records to be retrieved in  order to answer queries. In a traditional database system, efficient lookups are enabled by maintaining a structure such as a B-tree that indexes certain keys of the records. However, this can be quite  complex for a small sensor node with limited resources. Consequently, TSAR sensors do not maintain any index for the data stored in their archive. Instead, they rely on the proxies to maintain this metadata index-sensors periodically send the proxy information  summarizing the data contained in a contiguous sequence of records, as well as a handle indicating the location of these records in flash memory. The mechanism works as follows: In addition to the summary of sensor data, each node sends metadata to the proxy containing the time interval corresponding to the summary, as well as the start and end offsets of the flash memory location where the raw data corresponding is stored (as shown in Figure 7). Thus, random  access is enabled at granularity of a summary-the start offset of each chunk of records represented by a summary is known to the proxy. Within this collection, records are accessed sequentially. When a query matches a summary in the index, the sensor uses these offsets to access the relevant records on its local flash by sequentially  reading data from the start address until the end address. Any  queryspecific operation can then be performed on this data. Thus, no index needs to be maintained at the sensor, in line with our goal of simplifying sensor state management. The state of the archive is captured in the metadata associated with the summaries, and is stored and maintained at the proxy. While we anticipate local storage capacity to be large, eventually there might be a need to overwrite older data, especially in high data rate applications. This may be done via techniques such as multi-resolution storage of data [9], or just simply by overwriting older data. When older data is overwritten, a delete operation is performed, where an index entry is deleted from the interval skip graph at the proxy and the corresponding storage space in flash memory at the sensor is freed. .2 Adaptive Summarization The data summaries serve as glue between the storage at the  remote sensor and the index at the proxy. Each update from a sensor to the proxy includes three pieces of information: the summary, a time period corresponding to the summary, and the start and end offsets for the flash archive. In general, the proxy can index the time interval representing a summary or the value range reported in the summary (or both). The former index enables quick lookups on all records seen during a certain interval, while the latter index enables quick lookups on all records matching a certain value. As described in Section 2.4, there is a trade-off between the  energy used in sending summaries (and thus the frequency and  resolution of those summaries) and the cost of false hits during queries. The coarser and less frequent the summary information, the less energy required, while false query hits in turn waste energy on  requests for non-existent data. TSAR employs an adaptive summarization technique that  balances the cost of sending updates against the cost of false positives. The key intuition is that each sensor can independently identify the fraction of false hits and true hits for queries that access its local archive. If most queries result in true hits, then the sensor  determines that the summary can be coarsened further to reduce update costs without adversely impacting the hit ratio. If many queries result in false hits, then the sensor makes the granularity of each summary finer to reduce the number and overhead of false hits. The resolution of the summary depends on two  parametersthe interval over which summaries of the data are constructed and transmitted to the proxy, as well as the size of the  applicationspecific summary. Our focus in this paper is on the interval over which the summary is constructed. Changing the size of the data summary can be performed in an application-specific manner (e.g. using wavelet compression techniques as in [9]) and is beyond the scope of this paper. Currently, TSAR employs a simple  summarization scheme that computes the ratio of false and true hits and  decreases (increases) the interval between summaries whenever this ratio increases (decreases) beyond a threshold. . TSAR Implementation We have implemented a prototype of TSAR on a multi-tier  sensor network testbed. Our prototype employs Crossbow Stargate nodes to implement the proxy tier. Each Stargate node employs a 00MHz Intel XScale processor with 64MB RAM and runs the Linux 2.4.19 kernel and EmStar release 2.1. The proxy nodes are equipped with two wireless radios, a Cisco Aironet 340-based 02.11b radio and a hostmote bridge to the Mica2 sensor nodes using the EmStar transceiver. The 802.11b wireless network is used for inter-proxy communication within the proxy tier, while the wireless bridge enables sensor-proxy communication. The  sensor tier consists of Crossbow Mica2s and Mica2dots, each  consisting of a 915MHz CC1000 radio, a BMAC protocol stack, a 4 Mb on-board flash memory and an ATMega 128L processor. The  sensor nodes run TinyOS 1.1.8. In addition to the on-board flash, the sensor nodes can be equipped with external MMC/SD flash cards using a custom connector. The proxy nodes can be equipped with external storage such as high-capacity compact flash (up to 4GB), GB micro-drives, or up to 60GB 1.8inch mobile disk drives. Since sensor nodes may be several hops away from the nearest proxy, the sensor tier employs multi-hop routing to communicate with the proxy tier. In addition, to reduce the power consumption of the radio while still making the sensor node available for queries, low power listening is enabled, in which the radio receiver is  periodically powered up for a short interval to sense the channel for transmissions, and the packet preamble is extended to account for the latency until the next interval when the receiving radio wakes up. Our prototype employs the MultiHopLEPSM routing protocol with the BMAC layer configured in the low-power mode with a 1% duty cycle (one of the default BMAC [22] parameters) Our TSAR implementation on the Mote involves a data  gathering task that periodically obtains sensor readings and logs these reading to flash memory. The flash memory is assumed to be a circular append-only store and the format of the logged data is  depicted in Figure 6. The Mote sends a report to the proxy every N readings, summarizing the observed data. The report contains: (i) the address of the Mote, (ii) a handle that contains an offset and the length of the region in flash memory containing data referred to by the summary, (iii) an interval (t1, t2) over which this report is  generated, (iv) a tuple (low, high) representing the minimum and the maximum values observed at the sensor in the interval, and (v) a  sequence number. The sensor updates are used to construct a sparse interval skip graph that is distributed across proxies, via network messages between proxies over the 802.11b wireless network. Our current implementation supports queries that request records matching a time interval (t1, t2) or a value range (v1, v2). Spatial constraints are specified using sensor IDs. Given a list of matching intervals from the skip graph, TSAR supports two types of  messages to query the sensor: lookup and fetch. A lookup message triggers a search within the corresponding region in flash memory and returns the number of matching records in that memory region (but does not retrieve data). In contrast, a fetch message not only 6  0 0 0 0 0 0 0 0 28512 1024 2048 4096 NumberofMessages Index size (entries) Insert (skipgraph) Insert (sparse skipgraph) Initial lookup (a) James Reserve Data  0 0 0 0 0 0 0 0 12 1024 2048 4096 NumberofMessages Index size (entries) Insert (skipgraph) Insert (sparse skipgraph) Initial lookup (b) Synthetic Data Figure 8: Skip Graph Insert Performance triggers a search but also returns all matching data records to the proxy. Lookup messages are useful for polling a sensor, for  instance, to determine if a query matches too many records. . Experimental Evaluation In this section, we evaluate the efficacy of TSAR using our  prototype and simulations. The testbed for our experiments consists of four Stargate proxies and twelve Mica2 and Mica2dot sensors; three sensors each are assigned to each proxy. Given the limited size of our testbed, we employ simulations to evaluate the  behavior of TSAR in larger settings. Our simulation employs the EmTOS emulator [10], which enables us to run the same code in simulation and the hardware platform. Rather than using live data from a real sensor, to ensure  repeatable experiments, we seed each sensor node with a dataset (i.e., a trace) that dictates the values reported by that node to the proxy. One section of the flash memory on each sensor node is programmed with data points from the trace; these observations are then replayed during an experiment, logged to the local archive (located in flash memory, as well), and reported to the proxy. The first dataset used to evaluate TSAR is a temperature dataset from James Reserve [27] that includes data from eleven temperature  sensor nodes over a period of 34 days. The second dataset is  synthetically generated; the trace for each sensor is generated using a uniformly distributed random walk though the value space. Our experimental evaluation has four parts. First, we run  EmTOS simulations to evaluate the lookup, update and delete overhead for sparse interval skip graphs using the real and synthetic datasets. Second, we provide summary results from micro-benchmarks of the storage component of TSAR, which include empirical  characterization of the energy costs and latency of reads and writes for the flash memory chip as well as the whole mote platform, and  comparisons to published numbers for other storage and  communication technologies. These micro-benchmarks form the basis for our full-scale evaluation of TSAR on a testbed of four Stargate proxies and twelve Motes. We measure the end-to-end query latency in our multi-hop testbed as well as the query processing overhead at the mote tier. Finally, we demonstrate the adaptive summarization  capability at each sensor node. The remainder of this section presents our experimental results. .1 Sparse Interval Skip Graph Performance This section evaluates the performance of sparse interval skip graphs by quantifying insert, lookup and delete overheads. We assume a proxy tier with 32 proxies and construct sparse  interval skip graphs of various sizes using our datasets. For each skip   0 5 0 5 0 5 09620481024512 NumberofMessages Index size (entries) Initial lookup Traversal (a) James Reserve Data      0 2 4 09620481024512 NumberofMessages Index size (entries) Initial lookup Traversal (b) Synthetic Data Figure 9: Skip Graph Lookup Performance  0 0 0 0 0 0 0  4 8 16 24 32 48 Numberofmessages Number of proxies Skipgraph insert Sparse skipgraph insert Initial lookup (a) Impact of Number of Proxies  0 0 0 0 00 20 12 1024 2048 4096 NumberofMessages Index size (entries) Insert (redundant) Insert (non-redundant) Lookup (redundant) Lookup (non-redundant) (b) Impact of Redundant Summaries Figure 10: Skip Graph Overheads graph, we evaluate the cost of inserting a new value into the index. Each entry was deleted after its insertion, enabling us to quantify the delete overhead as well. Figure 8(a) and (b) quantify the insert overhead for our two datasets: each insert entails an initial traversal that incurs log n messages, followed by neighbor pointer update at increasing levels, incurring a cost of 4 log n messages. Our results demonstrate this behavior, and show as well that performance of delete-which also involves an initial traversal followed by pointer updates at each level-incurs a similar cost. Next, we evaluate the lookup performance of the index  structure. Again, we construct skip graphs of various sizes using our datasets and evaluate the cost of a lookup on the index structure. Figures 9(a) and (b) depict our results. There are two components for each lookup-the lookup of the first interval that matches the query and, in the case of overlapping intervals, the subsequent  linear traversal to identify all matching intervals. The initial lookup can be seen to takes log n messages, as expected. The costs of the subsequent linear traversal, however, are highly data dependent. For instance, temperature values for the James Reserve data exhibit significant spatial correlations, resulting in significant overlap  between different intervals and variable, high traversal cost (see  Figure 9(a)). The synthetic data, however, has less overlap and incurs lower traversal overhead as shown in Figure 9(b). Since the previous experiments assumed 32 proxies, we evaluate the impact of the number of proxies on skip graph performance. We vary the number of proxies from 10 to 48 and distribute a skip graph with 4096 entries among these proxies. We construct regular  interval skip graphs as well as sparse interval skip graphs using these entries and measure the overhead of inserts and lookups. Thus, the experiment also seeks to demonstrate the benefits of sparse skip graphs over regular skip graphs. Figure 10(a) depicts our results. In regular skip graphs, the complexity of insert is O(log2n) in the 7 expected case (and O(n) in the worst case) where n is the number of elements. This complexity is unaffected by changing the  number of proxies, as indicated by the flat line in the figure. Sparse skip graphs require fewer pointer updates; however, their overhead is dependent on the number of proxies, and is O(log2Np) in the expected case, independent of n. This can be seen to result in  significant reduction in overhead when the number of proxies is small, which decreases as the number of proxies increases. Failure handling is an important issue in a multi-tier sensor  architecture since it relies on many components-proxies, sensor nodes and routing nodes can fail, and wireless links can fade. Handling of many of these failure modes is outside the scope of this  paper; however, we consider the case of resilience of skip graphs to proxy failures. In this case, skip graph search (and subsequent repair operations) can follow any one of the other links from a root element. Since a sparse skip graph has search trees rooted at each node, searching can then resume once the lookup request has routed around the failure. Together, these two properties  ensure that even if a proxy fails, the remaining entries in the skip graph will be reachable with high probability-only the entries on the failed proxy and the corresponding data at the sensors becomes inaccessible. To ensure that all data on sensors remains accessible, even in the event of failure of a proxy holding index entries for that data, we  incorporate redundant index entries. TSAR employs a simple  redundancy scheme where additional coarse-grain summaries are used to protect regular summaries. Each sensor sends summary data periodically to its local proxy, but less frequently sends a  lowerresolution summary to a backup proxy-the backup summary  represents all of the data represented by the finer-grained summaries, but in a lossier fashion, thus resulting in higher read overhead (due to false hits) if the backup summary is used. The cost of  implementing this in our system is low - Figure 10(b) shows the overhead of such a redundancy scheme, where a single coarse summary is send to a backup for every two summaries sent to the primary proxy. Since a redundant summary is sent for every two summaries, the insert cost is 1.5 times the cost in the normal case. However, these redundant entries result in only a negligible increase in lookup  overhead, due the logarithmic dependence of lookup cost on the index size, while providing full resilience to any single proxy failure. .2 Storage Microbenchmarks Since sensors are resource-constrained, the energy consumption and the latency at this tier are important measures for evaluating the performance of a storage architecture. Before performing an  endto-end evaluation of our system, we provide more detailed  information on the energy consumption of the storage component used to implement the TSAR local archive, based on empirical  measurements. In addition we compare these figures to those for other  local storage technologies, as well as to the energy consumption of wireless communication, using information from the literature. For empirical measurements we measure energy usage for the storage component itself (i.e. current drawn by the flash chip), as well as for the entire Mica2 mote. The power measurements in Table 3 were performed for the AT45DB041 [15] flash memory on a Mica2 mote, which is an older NOR flash device. The most promising technology for low-energy storage on sensing devices is NAND flash, such as the Samsung K9K4G08U0M device [16]; published power numbers for this  device are provided in the table. Published energy requirements for wireless transmission using the Chipcon [4] CC2420 radio (used in MicaZ and Telos motes) are provided for comparison, assuming Energy Energy/byte Mote flash Read 256 byte page 58µJ* / 36µJ* total .23µJ* Write 256 byte page 926µJ* / 042µJ* total .6µJ* NAND Flash Read 512 byte page 2.7µJ 1.8nJ Write 512 byte page 7.8µJ 15nJ Erase 16K byte sector 60µJ 3.7nJ CC2420 radio Transmit 8 bits (-25dBm) .8µJ 0.8µJ Receive 8 bits 1.9µJ 1.9µJ Mote AVR processor In-memory search, 56 bytes .8µJ 6.9nJ Table 3: Storage and Communication Energy Costs (*measured values)  00 00 00 00 000  2 3 Latency(ms) Number of hops (a) Multi-hop query  performance  00 00 00 00 00  5121024 2048 4096 Latency(ms) Index size (entries) Sensor communication Proxy communication Sensor lookup, processing (b) Query Performance Figure 11: Query Processing Latency zero network and protocol overhead. Comparing the total energy cost for writing flash (erase + write) to the total cost for  communication (transmit + receive), we find that the NAND flash is almost 50 times more efficient than radio communication, even assuming perfect network protocols. .3 Prototype Evaluation This section reports results from an end-to-end evaluation of the TSAR prototype involving both tiers. In our setup, there are four proxies connected via 802.11 links and three sensors per proxy. The multi-hop topology was preconfigured such that sensor nodes were connected in a line to each proxy, forming a minimal tree of depth  00 00 200 600  20 40 60 80 100 120 140 160 Retrievallatency(ms) Archived data retrieved (bytes) (a) Data Query and Fetch Time      0 2 4 8 16 32 Latency(ms) Number of 34-byte records searched (b) Sensor query  processing delay Figure 12: Query Latency Components 8 . Due to resource constraints we were unable to perform  experiments with dozens of sensor nodes, however this topology ensured that the network diameter was as large as for a typical network of significantly larger size. Our evaluation metric is the end-to-end latency of query  processing. A query posed on TSAR first incurs the latency of a sparse skip graph lookup, followed by routing to the appropriate sensor node(s). The sensor node reads the required page(s) from its local archive, processes the query on the page that is read, and transmits the response to the proxy, which then forwards it to the user. We first measure query latency for different sensors in our multi-hop topology. Depending on which of the sensors is queried, the total latency increases almost linearly from about 400ms to 1 second, as the number of hops increases from 1 to 3 (see Figure 11(a)). Figure 11(b) provides a breakdown of the various components of the end-to-end latency. The dominant component of the total latency is the communication over one or more hops. The  typical time to communicate over one hop is approximately 300ms. This large latency is primarily due to the use of a duty-cycled MAC layer; the latency will be larger if the duty cycle is reduced (e.g. the 2% setting as opposed to the 11.5% setting used in this  experiment), and will conversely decrease if the duty cycle is increased. The figure also shows the latency for varying index sizes; as  expected, the latency of inter-proxy communication and skip graph lookups increases logarithmically with index size. Not surprisingly, the overhead seen at the sensor is independent of the index size. The latency also depends on the number of packets transmitted in response to a query-the larger the amount of data retrieved by a query, the greater the latency. This result is shown in Figure 12(a). The step function is due to packetization in TinyOS; TinyOS sends one packet so long as the payload is smaller than 30 bytes and splits the response into multiple packets for larger payloads. As the data retrieved by a query is increased, the latency increases in steps, where each step denotes the overhead of an additional packet. Finally, Figure 12(b) shows the impact of searching and  processing flash memory regions of increasing sizes on a sensor. Each summary represents a collection of records in flash memory, and all of these records need to be retrieved and processed if that  summary matches a query. The coarser the summary, the larger the memory region that needs to be accessed. For the search sizes  examined, amortization of overhead when searching multiple flash pages and archival records, as well as within the flash chip and its associated driver, results in the appearance of sub-linear increase in latency with search size. In addition, the operation can be seen to have very low latency, in part due to the simplicity of our query processing, requiring only a compare operation with each stored element. More complex operations, however, will of course incur greater latency. .4 Adaptive Summarization When data is summarized by the sensor before being reported to the proxy, information is lost. With the interval summarization method we are using, this information loss will never cause the proxy to believe that a sensor node does not hold a value which it in fact does, as all archived values will be contained within the interval reported. However, it does cause the proxy to believe that the sensor may hold values which it does not, and forward query messages to the sensor for these values. These false positives constitute the cost of the summarization mechanism, and need to be balanced against the savings achieved by reducing the number of reports. The goal of adaptive summarization is to dynamically vary the summary size so that these two costs are balanced.  .1 .2 .3 .4 .5  5 10 15 20 25 30 Fractionoftruehits Summary size (number of records) (a) Impact of summary size   0 5 0 5 0 5  5000 10000 15000 20000 25000 30000 Summarizationsize(num.records) Normalized time (units) query rate 0.2 query rate 0.03 query rate 0.1 (b) Adaptation to query rate Figure 13: Impact of Summarization Granularity Figure 13(a) demonstrates the impact of summary granularity on false hits. As the number of records included in a summary is increased, the fraction of queries forwarded to the sensor which match data held on that sensor (true positives) decreases. Next, in Figure 13(b) we run the a EmTOS simulation with our  adaptive summarization algorithm enabled. The adaptive algorithm  increases the summary granularity (defined as the number of records per summary) when Cost(updates) Cost(falsehits) > 1 + and reduces it if Cost(updates) Cost(falsehits) > 1 − , where is a small constant. To  demonstrate the adaptive nature of our technique, we plot a time series of the summarization granularity. We begin with a query rate of 1 query per 5 samples, decrease it to 1 every 30 samples, and then increase it again to 1 query every 10 samples. As shown in  Figure 13(b), the adaptive technique adjusts accordingly by sending more fine-grain summaries at higher query rates (in response to the higher false hit rate), and fewer, coarse-grain summaries at lower query rates. . Related Work In this section, we review prior work on storage and indexing techniques for sensor networks. While our work addresses both problems jointly, much prior work has considered them in isolation. The problem of archival storage of sensor data has received limited attention in sensor network literature. ELF [7] is a  logstructured file system for local storage on flash memory that  provides load leveling and Matchbox is a simple file system that is packaged with the TinyOS distribution [14]. Both these systems focus on local storage, whereas our focus is both on storage at the remote sensors as well as providing a unified view of distributed data across all such local archives. Multi-resolution storage [9] is intended for in-network storage and search in systems where there is significant data in comparison to storage resources. In contrast, TSAR addresses the problem of archival storage in two-tier systems where sufficient resources can be placed at the edge sensors. The RISE platform [21] being developed as part of the NODE project at UCR addresses the issues of hardware platform support for large amounts of storage in remote sensor nodes, but not the indexing and querying of this data. In order to efficiently access a distributed sensor store, an index needs to be constructed of the data. Early work on sensor networks such as Directed Diffusion [17] assumes a system where all useful sensor data was stored locally at each sensor, and spatially scoped queries are routed using geographic co-ordinates to locations where the data is stored. Sources publish the events that they detect, and sinks with interest in specific events can subscribe to these events. The Directed Diffusion substrate routes queries to specific locations 9 if the query has geographic information embedded in it (e.g.: find temperature in the south-west quadrant), and if not, the query is flooded throughout the network. These schemes had the drawback that for queries that are not  geographically scoped, search cost (O(n) for a network of n nodes) may be prohibitive in large networks with frequent queries.  Local storage with in-network indexing approaches address this  issue by constructing indexes using frameworks such as Geographic Hash Tables [24] and Quad Trees [9]. Recent research has seen a growing body of work on data indexing schemes for sensor  networks[26][11][18]. One such scheme is DCS [26], which provides a hash function for mapping from event name to location. DCS constructs a distributed structure that groups events together  spatially by their named type. Distributed Index of Features in  Sensornets (DIFS [11]) and Multi-dimensional Range Queries in Sensor Networks (DIM [18]) extend the data-centric storage approach to provide spatially distributed hierarchies of indexes to data. While these approaches advocate in-network indexing for sensor networks, we believe that indexing is a task that is far too  complicated to be performed at the remote sensor nodes since it involves maintaining significant state and large tables. TSAR provides a  better match between resource requirements of storage and indexing and the availability of resources at different tiers. Thus complex operations such as indexing and managing metadata are performed at the proxies, while storage at the sensor remains simple. In addition to storage and indexing techniques specific to sensor networks, many distributed, peer-to-peer and spatio-temporal index structures are relevant to our work. DHTs [25] can be used for indexing events based on their type, quad-tree variants such as  Rtrees [12] can be used for optimizing spatial searches, and K-D trees [2] can be used for multi-attribute search. While this paper focuses on building an ordered index structure for range queries, we will explore the use of other index structures for alternate queries over sensor data. . Conclusions In this paper, we argued that existing sensor storage systems are designed primarily for flat hierarchies of homogeneous sensor nodes and do not fully exploit the multi-tier nature of emerging  sensor networks. We presented the design of TSAR, a fundamentally different storage architecture that envisions separation of data from metadata by employing local storage at the sensors and distributed indexing at the proxies. At the proxy tier, TSAR employs a novel multi-resolution ordered distributed index structure, the Sparse  Interval Skip Graph, for efficiently supporting spatio-temporal and range queries. At the sensor tier, TSAR supports energy-aware adaptive summarization that can trade-off the energy cost of  transmitting metadata to the proxies against the overhead of false hits  resulting from querying a coarser resolution index structure. We  implemented TSAR in a two-tier sensor testbed comprising  Stargatebased proxies and Mote-based sensors. Our experimental  evaluation of TSAR demonstrated the benefits and feasibility of  employing our energy-efficient low-latency distributed storage architecture in multi-tier sensor networks. . REFERENCES [1] James Aspnes and Gauri Shah. Skip graphs. In Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 384-393, Baltimore, MD, USA, 2-14 January 2003. [2] Jon Louis Bentley. Multidimensional binary search trees used for associative searching. Commun. ACM, 18(9):509-517, 1975. [3] Philippe Bonnet, J. E. Gehrke, and Praveen Seshadri. Towards sensor database systems. In Proceedings of the Second International Conference on Mobile Data Management., January 2001. [4] Chipcon. CC2420 2.4 GHz IEEE 802.15.4 / ZigBee-ready RF transceiver, 2004. [5] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms. The MIT Press and McGraw-Hill, second edition edition, 2001. [6] Adina Crainiceanu, Prakash Linga, Johannes Gehrke, and Jayavel Shanmugasundaram. Querying Peer-to-Peer Networks Using P-Trees. Technical Report TR2004-1926, Cornell University, 2004. [7] Hui Dai, Michael Neufeld, and Richard Han. ELF: an efficient log-structured flash file system for micro sensor nodes. In SenSys "04: Proceedings of the 2nd international conference on Embedded networked sensor systems, pages 76-187, New York, NY, USA, 2004. ACM Press. [8] Peter Desnoyers, Deepak Ganesan, Huan Li, and Prashant Shenoy. PRESTO: A predictive storage architecture for sensor networks. In Tenth Workshop on Hot Topics in Operating Systems (HotOS X)., June 2005. [9] Deepak Ganesan, Ben Greenstein, Denis Perelyubskiy, Deborah Estrin, and John Heidemann. An evaluation of multi-resolution storage in sensor networks. In Proceedings of the First ACM Conference on Embedded Networked Sensor Systems (SenSys)., 2003. [10] L. Girod, T. Stathopoulos, N. Ramanathan, J. Elson, D. Estrin, E. Osterweil, and T. Schoellhammer. A system for simulation, emulation, and deployment of heterogeneous sensor networks. In Proceedings of the Second ACM Conference on Embedded Networked Sensor Systems, Baltimore, MD, 2004. [11] B. Greenstein, D. Estrin, R. Govindan, S. Ratnasamy, and S. Shenker. DIFS: A distributed index for features in sensor networks. Elsevier Journal of ad-hoc Networks, 2003. [12] Antonin Guttman. R-trees: a dynamic index structure for spatial searching. In SIGMOD "84: Proceedings of the 1984 ACM SIGMOD international conference on Management of data, pages 47-57, New York, NY, USA, 1984. ACM Press. [13] Nicholas Harvey, Michael B. Jones, Stefan Saroiu, Marvin Theimer, and Alec Wolman. Skipnet: A scalable overlay network with practical locality properties. In In proceedings of the 4th USENIX Symposium on Internet Technologies and Systems (USITS "03), Seattle, WA, March 2003. [14] Jason Hill, Robert Szewczyk, Alec Woo, Seth Hollar, David Culler, and Kristofer Pister. System architecture directions for networked sensors. In Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IX), pages 93-104, Cambridge, MA, USA, November 2000. ACM. [15] Atmel Inc. 4-megabit 2.5-volt or 2.7-volt DataFlash AT45DB041B, 2005. [16] Samsung Semiconductor Inc. K9W8G08U1M, K9K4G08U0M: 512M x 8 bit / G x 8 bit NAND flash memory, 2003. [17] Chalermek Intanagonwiwat, Ramesh Govindan, and Deborah Estrin. Directed diffusion: A scalable and robust communication paradigm for sensor networks. In Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, pages 56-67, Boston, MA, August 2000. ACM Press. [18] Xin Li, Young-Jin Kim, Ramesh Govindan, and Wei Hong. Multi-dimensional range queries in sensor networks. In Proceedings of the First ACM Conference on Embedded Networked Sensor Systems (SenSys)., 2003. to appear. [19] Witold Litwin, Marie-Anne Neimat, and Donovan A. Schneider. RP*: A family of order preserving scalable distributed data structures. In VLDB "94: Proceedings of the 20th International Conference on Very Large Data Bases, pages 342-353, San Francisco, CA, USA, 1994. [20] Samuel Madden, Michael Franklin, Joseph Hellerstein, and Wei Hong. TAG: a tiny aggregation service for ad-hoc sensor networks. In OSDI, Boston, MA, 002. [21] A. Mitra, A. Banerjee, W. Najjar, D. Zeinalipour-Yazti, D.Gunopulos, and V. Kalogeraki. High performance, low power sensor platforms featuring gigabyte scale storage. In SenMetrics 2005: Third International Workshop on Measurement, Modeling, and Performance Analysis of Wireless Sensor Networks, July 2005. [22] J. Polastre, J. Hill, and D. Culler. Versatile low power media access for wireless sensor networks. In Proceedings of the Second ACM Conference on Embedded Networked Sensor Systems (SenSys), November 2004. [23] William Pugh. Skip lists: a probabilistic alternative to balanced trees. Commun. ACM, 33(6):668-676, 1990. [24] S. Ratnasamy, D. Estrin, R. Govindan, B. Karp, L. Yin S. Shenker, and F. Yu. Data-centric storage in sensornets. In ACM First Workshop on Hot Topics in Networks, 2001. [25] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and S. Shenker. A scalable content addressable network. In Proceedings of the 2001 ACM SIGCOMM Conference, 2001. [26] S. Ratnasamy, B. Karp, L. Yin, F. Yu, D. Estrin, R. Govindan, and S. Shenker. GHT - a geographic hash-table for data-centric storage. In First ACM International Workshop on Wireless Sensor Networks and their Applications, 002. [27] N. Xu, E. Osterweil, M. Hamilton, and D. Estrin. http://www.lecs.cs.ucla.edu/˜nxu/ess/. James Reserve Data. 0
Multi-dimensional Range Queries in Sensor Networks∗ Xin Li † Young Jin Kim † Ramesh Govindan † Wei Hong ‡ ABSTRACT In many sensor networks, data or events are named by  attributes. Many of these attributes have scalar values, so one natural way to query events of interest is to use a  multidimensional range query. An example is: List all events whose temperature lies between 50◦ and 60◦ , and whose light levels lie between 10 and 15. Such queries are useful for correlating events occurring within the network. In this paper, we describe the design of a distributed  index that scalably supports multi-dimensional range queries. Our distributed index for multi-dimensional data (or DIM) uses a novel geographic embedding of a classical index data structure, and is built upon the GPSR geographic routing algorithm. Our analysis reveals that, under reasonable  assumptions about query distributions, DIMs scale quite well with network size (both insertion and query costs scale as O( √ N)). In detailed simulations, we show that in practice, the insertion and query costs of other alternatives are  sometimes an order of magnitude more than the costs of DIMs, even for moderately sized network. Finally, experiments on a small scale testbed validate the feasibility of DIMs. Categories and Subject Descriptors C.2.4 [Computer Communication Networks]: Distributed Systems; C.3 [Special-Purpose and Application-Based Systems]: Embedded Systems General Terms Embedded Systems, Sensor Networks, Storage . INTRODUCTION In wireless sensor networks, data or events will be named by attributes [15] or represented as virtual relations in a distributed database [18, 3]. Many of these attributes will have scalar values: e.g., temperature and light levels, soil moisture conditions, etc. In these systems, we argue, one natural way to query for events of interest will be to use multi-dimensional range queries on these attributes. For example, scientists analyzing the growth of marine  microorganisms might be interested in events that occurred within certain temperature and light conditions: List all events that have temperatures between 50◦ F and 60◦ F, and light levels between 10 and 20. Such range queries can be used in two distinct ways. They can help users efficiently drill-down their search for events of interest. The query described above illustrates this, where the scientist is presumably interested in discovering, and perhaps mapping the combined effect of temperature and light on the growth of marine micro-organisms. More  importantly, they can be used by application software running within a sensor network for correlating events and triggering actions. For example, if in a habitat monitoring application, a bird alighting on its nest is indicated by a certain range of thermopile sensor readings, and a certain range of  microphone readings, a multi-dimensional range query on those attributes enables higher confidence detection of the arrival of a flock of birds, and can trigger a system of cameras. In traditional database systems, such range queries are supported using pre-computed indices. Indices trade-off some initial pre-computation cost to achieve a significantly more efficient querying capability. For sensor networks, we  assert that a centralized index for multi-dimensional range queries may not be feasible for energy-efficiency reasons (as well as the fact that the access bandwidth to this central index will be limited, particularly for queries emanating from within the network). Rather, we believe, there will be situations when it is more appropriate to build an  innetwork distributed data structure for efficiently answering multi-dimensional range queries. In this paper, we present just such a data structure, that we call a DIM1 . DIMs are inspired by classical database  indices, and are essentially embeddings of such indices within the sensor network. DIMs leverage two key ideas: in-network  Distributed Index for Multi-dimensional data. 3 data centric storage, and a novel locality-preserving  geographic hash (Section 3). DIMs trace their lineage to  datacentric storage systems [23]. The underlying mechanism in these systems allows nodes to consistently hash an event to some location within the network, which allows efficient  retrieval of events. Building upon this, DIMs use a technique whereby events whose attribute values are close are likely to be stored at the same or nearby nodes. DIMs then use an underlying geographic routing algorithm (GPSR [16]) to route events and queries to their corresponding nodes in an entirely distributed fashion. We discuss the design of a DIM, presenting algorithms for event insertion and querying, for maintaining a DIM in the event of node failure, and for making DIMs robust to data or packet loss (Section 3). We then extensively evaluate DIMs using analysis (Section 4), simulation (Section 5), and actual implementation (Section 6). Our analysis reveals that,  under reasonable assumptions about query distributions, DIMs scale quite well with network size (both insertion and query costs scale as O( √ N)). In detailed simulations, we show that in practice, the event insertion and querying costs of other alternatives are sometimes an order of magnitude the costs of DIMs, even for moderately sized network.  Experiments on a small scale testbed validate the feasibility of DIMs (Section 6). Much work remains, including efficient support for skewed data distributions, existential queries, and node heterogeneity. We believe that DIMs will be an essential, but perhaps not necessarily the only, distributed data structure  supporting efficient queries in sensor networks. DIMs will be part of a suite of such systems that enable feature extraction [7], simple range querying [10], exact-match queries [23], or  continuous queries [15, 18]. All such systems will likely be integrated to a sensor network database system such as TinyDB [17]. Application designers could then choose the appropriate method of information access. For instance, a fire tracking application would use DIM to detect the hotspots, and would then use mechanisms that enable  continuous queries [15, 18] to track the spatio-temporal progress of the hotspots. Finally, we note that DIMs are applicable not just to sensor networks, but to other deeply distributed systems (embedded networks for home and factory  automation) as well. . RELATED WORK The basic problem that this paper addresses -  multidimensional range queries - is typically solved in database systems using indexing techniques. The database  community has focused mostly on centralized indices, but distributed indexing has received some attention in the literature. Indexing techniques essentially trade-off some data  insertion cost to enable efficient querying. Indexing has, for long, been a classical research problem in the database  community [5, 2]. Our work draws its inspiration from the class of multi-key constant branching index structures,  exemplified by k-d trees [2], where k represents the dimensionality of the data space. Our approach essentially represents a geographic embedding of such structures in a sensor field. There is one important difference. The classical indexing structures are data-dependent (as are some indexing schemes that use locality preserving hashes, and developed in the theory literature [14, 8, 13]). The index structure is decided not only by the data, but also by the order in which data is inserted. Our current design is not data dependent.  Finally, tangentially related to our work is the class of spatial indexing systems [21, 6, 11]. While there has been some work on distributed indexing, the problem has not been extensively explored. There  exist distributed indices of a restricted kind-those that allow exact match or partial prefix match queries. Examples of such systems, of course, are the Internet Domain Name  System, and the class of distributed hash table (DHT) systems exemplified by Freenet[4], Chord[24], and CAN[19]. Our work is superficially similar to CAN in that both construct a zone-based overlay atop of the underlying physical  network. The underlying details make the two systems very different: CAN"s overlay is purely logical while our overlay is consistent with the underlying physical topology. More recent work in the Internet context has addressed support for range queries in DHT systems [1, 12], but it is unclear if these directly translate to the sensor network context. Several research efforts have expressed the vision of a database interface to sensor networks [9, 3, 18], and there are examples of systems that contribute to this vision [18, , 17]. Our work is similar in spirit to this body of  literature. In fact, DIMs could become an important component of a sensor network database system such as TinyDB [17]. Our work departs from prior work in this area in two  significant respects. Unlike these approaches, in our work the data generated at a node are hashed (in general) to different  locations. This hashing is the key to scaling multi-dimensional range searches. In all the other systems described above, queries are flooded throughout the network, and can  dominate the total cost of the system. Our work avoids query flooding by an appropriate choice of hashing. Madden et al. [17] also describe a distributed index, called Semantic Routing Trees (SRT). This index is used to direct queries to nodes that have detected relevant data. Our work  differs from SRT in three key aspects. First, SRT is built on single attributes while DIM supports mulitple attributes. Second, SRT constructs a routing tree based on historical sensor readings, and therefore works well only for  slowlychanging sensor values. Finally, in SRT queries are issued from a fixed node while in DIM queries can be issued from any node. A similar differentiation applies with respect to work on data-centric routing in sensor networks [15, 25], where data generated at a node is assumed to be stored at the node, and queries are either flooded throughout the network [15], or each source sets up a network-wide overlay announcing its presence so that mobile sinks can rendezvous with sources at the nearest node on the overlay [25]. These approaches work well for relatively long-lived queries. Finally, our work is most close related to data-centric storage [23] systems, which include geographic hash-tables (GHTs) [20], DIMENSIONS [7], and DIFS [10].In a GHT, data is hashed by name to a location within the network,  enabling highly efficient rendezvous. GHTs are built upon the GPSR [16] protocol and leverage some interesting properties of that protocol, such as the ability to route to a node nearest to a given location. We also leverage properties in GPSR (as we describe later), but we use a locality-preserving hash to store data, enabling efficient multi-dimensional range queries. DIMENSIONS and DIFS can be thought of as using the same set of primitives as GHT (storage using consistent hashing), but for different ends: DIMENSIONS allows  drill64 down search for features within a sensor network, while DIFS allows range queries on a single key in addition to other operations. . THE DESIGN OF DIMS Most sensor networks are deployed to collect data from the environment. In these networks, nodes (either  individually or collaboratively) will generate events. An event can generally be described as a tuple of attribute values, A1, A2, · · · , Ak , where each attribute Ai represents a  sensor reading, or some value corresponding to a detection (e.g., a confidence level). The focus of this paper is the  design of systems to efficiently answer multi-dimensional range queries of the form: x1 − y1, x2 − y2, · · · , xk − yk . Such a query returns all events whose attribute values fall into the corresponding ranges. Notice that point queries, i.e., queries that ask for events with specified values for each attribute, are a special case of range queries. As we have discussed in Section 1, range queries can  enable efficient correlation and triggering within the network. It is possible to implement range queries by flooding a query within the network. However, as we show in later sections, this alternative can be inefficient, particularly as the system scales, and if nodes within the network issue such queries  relatively frequently. The other alternative, sending all events to an external storage node results in the access link being a bottleneck, especially if nodes within the network issue queries. Shenker et al. [23] also make similar arguments with respect to data-centric storage schemes in general; DIMs are an instance of such schemes. The system we present in this paper, the DIM, relies upon two foundations: a locality-preserving geographic hash, and an underlying geographic routing scheme. The key to resolving range queries efficiently is data  locality: i.e., events with comparable attribute values are stored nearby. The basic insight underlying DIM is that data  locality can be obtained by a locality-preserving geographic hash function. Our geographic hash function finds a  localitypreserving mapping from the multi-dimensional space  (described by the set of attributes) to a 2-d geographic space; this mapping is inspired by k-d trees [2] and is described later. Moreover, each node in the network self-organizes to claim part of the attribute space for itself (we say that each node owns a zone), so events falling into that space are routed to and stored at that node. Having established the mapping, and the zone structure, DIMs use a geographic routing algorithm previously  developed in the literature to route events to their corresponding nodes, or to resolve queries. This algorithm, GPSR [16], essentially enables the delivery of a packet to a node at a specified location. The routing mechanism is simple: when a node receives a packet destined to a node at location X, it forwards the packet to the neighbor closest to X. In GPSR, this is called greedy-mode forwarding. When no such  neighbor exists (as when there exists a void in the network), the node starts the packet on a perimeter mode traversal,  using the well known right-hand rule to circumnavigate voids. GPSR includes efficient techniques for perimeter traversal that are based on graph planarization algorithms amenable to distributed implementation. For all of this to work, DIMs make two assumptions that are consistent with the literature [23]. First, all nodes know the approximate geographic boundaries of the network. These boundaries may either be configured in nodes at the time of deployment, or may be discovered using a simple protocol. Second, each node knows its geographic location. Node  locations can be automatically determined by a localization system or by other means. Although the basic idea of DIMs may seem  straightforward, it is challenging to design a completely distributed data structure that must be robust to packet losses and node failures, yet must support efficient query distribution and deal with communication voids and obstacles. We now describe the complete design of DIMs. .1 Zones The key idea behind DIMs, as we have discussed, is a  geographic locality-preserving hash that maps a multi-attribute event to a geographic zone. Intuitively, a zone is a  subdivision of the geographic extent of a sensor field. A zone is defined by the following constructive procedure. Consider a rectangle R on the x-y plane. Intuitively, R is the bounding rectangle that contains all sensors withing the network. We call a sub-rectangle Z of R a zone, if Z is obtained by dividing R k times, k ≥ 0, using a procedure that satisfies the following property: After the i-th division, 0 ≤ i ≤ k, R is  partitioned into 2i equal sized rectangles. If i is an odd (even) number, the i-th division is parallel to the y-axis (x-axis). That is, the bounding rectangle R is first sub-divided into two zones at level 0 by a vertical line that splits R into two equal pieces, each of these sub-zones can be split into two zones at level 1 by a horizontal line, and so on. We call the non-negative integer k the level of zone Z, i.e. level(Z) = k. A zone can be identified either by a zone code code(Z) or by an address addr(Z). The code code(Z) is a 0-1 bit string of length level(Z), and is defined as follows. If Z lies in the left half of R, the first (from the left) bit of code(Z) is 0, else 1. If Z lies in the bottom half of R, the second bit of code(Z) is 0, else 1. The remaining bits of code(Z) are then recursively defined on each of the four quadrants of R. This definition of the zone code matches the definition of zones given above, encoding divisions of the sensor field geography by bit strings. Thus, in Figure 2, the zone in the top-right corner of the rectangle R has a zone code of 1111. Note that the zone codes collectively define a zone tree such that individual zones are at the leaves of this tree. The address of a zone Z, addr(Z), is defined to be the  centroid of the rectangle defined by Z. The two representations of a zone (its code and its address) can each be computed from the other, assuming the level of the zone is known. Two zones are called sibling zones if their zone codes are the same except for the last bit. For example, if code(Z1) = 1101 and code(Z2) = 01100, then Z1 and Z2 are sibling zones. The sibling subtree of a zone is the subtree rooted at the left or right sibling of the zone in the zone tree. We uniquely define a backup zone for each zone as follows: if the sibling subtree of the zone is on the left, the backup zone is the right-most zone in the sibling subtree;  otherwise, the backup zone is the left-most zone in the sibling subtree. For a zone Z, let p be the first level(Z) − 1 digits of code(Z). Let backup(Z) be the backup zone of zone Z. If code(Z) = p1, code(backup(Z)) = p01∗ with the most number of trailing 1"s (∗ means 0 or 1 occurrences). If 5 code(Z) = p0, code(backup(Z)) = p10∗ with the most  number of trailing 0"s. .2 Associating Zones with Nodes Our definition of a zone is independent of the actual  distribution of nodes in the sensor field, and only depends upon the geographic extent (the bounding rectangle) of the sensor field. Now we describe how zones are mapped to nodes. Conceptually, the sensor field is logically divided into zones and each zone is assigned to a single node. If the sensor  network were deployed in a grid-like (i.e., very regular) fashion, then it is easy to see that there exists a k such that each node maps into a distinct level-k zone. In general, however, the node placements within a sensor field are likely to be less regular than the grid. For some k, some zones may be empty and other zones might have more than one node situated within them. One alternative would have been to choose a fixed k for the overall system, and then associate nodes with the zones they are in (and if a zone is empty, associate the nearest node with it, for some definition of nearest). Because it makes our overall query routing system simpler, we allow nodes in a DIM to map to different-sized zones. To precisely understand the associations between zones and nodes, we define the notion of zone ownership. For any given placement of network nodes, consider a node A. Let ZA to be the largest zone that includes only node A and no other node. Then, we say that A owns ZA. Notice that this definition of ownership may leave some sections of the sensor field un-associated with a node. For example, in Figure 2, the zone 110 does not contain any nodes and would not have an owner. To remedy this, for any empty zone Z, we define the owner to be the owner of backup(Z). In our example, that empty zone"s owner would also be the node that owns 110, its backup zone. Having defined the association between nodes and zones, the next problem we tackle is: given a node placement, does there exist a distributed algorithm that enables each node to determine which zones it owns, knowing only the overall boundary of the sensor network? In principle, this should be relatively straightforward, since each node can simply determine the location of its neighbors, and apply simple geometric methods to determine the largest zone around it such that no other node resides in that zone. In practice, however, communication voids and obstacles make the  algorithm much more challenging. In particular, resolving the ownership of zones that do not contain any nodes is  complicated. Equally complicated is the case where the zone of a node is larger than its communication radius and the node cannot determine the boundaries of its zone by local communication alone. Our distributed zone building algorithm defers the  resolution of such zones until when either a query is initiated, or when an event is inserted. The basic idea behind our  algorithm is that each node tentatively builds up an idea of the zone it resides in just by communicating with its neighbors (remembering which boundaries of the zone are undecided because there is no radio neighbor that can help resolve that boundary). These undecided boundaries are later resolved by a GPSR perimeter traversal when data messages are  actually routed. We now describe the algorithm, and illustrate it using  examples. In our algorithm, each node uses an array bound[0..3] to maintain the four boundaries of the zone it owns  (rememFigure 1: A network, where circles represent sensor nodes and dashed lines mark the network boundary. 111 11 0 10 00 01 110 10 Figure 2: The zone code and boundaries.  1  1 0 0  1 0 0 Figure 3: The Corresponding Zone Tree ber that in this algorithm, the node only tries to determine the zone it resides in, not the other zones it might own because those zones are devoid of nodes). When a node starts up, each node initializes this array to be the network boundary, i.e., initially each node assumes its zone contains the whole network. The zone boundary algorithm now  relies upon GPSR"s beacon messages to learn the locations of neighbors within radio range. Upon hearing of such a  neighbor, the node calls the algorithm in Figure 4 to update its zone boundaries and its code accordingly. In this algorithm, we assume that A is the node at which the algorithm is  executed, ZA is its zone, and a is a newly discovered neighbor of A. (Procedure Contain(ZA, a) is used to decide if node a is located within the current zone boundaries of node A). Using this algorithm, then, each node can independently and asynchronously decide its own tentative zone based on the location of its neighbors. Figure 2 illustrates the results of applying this algorithm for the network in Figure 1. Figure 3 describes the corresponding zone tree. Each zone resides at a leaf node and the code of a zone is the path from the root to the zone if we represent the branch to the left 6 Build-Zone(a)  while Contain(ZA, a)  do if length(code(ZA)) mod 2 = 0  then new bound ← (bound[0] + bound[1])/2  if A.x < new bound  then bound[1] ← new bound  else bound[0] ← new bound  else new bound ← (bound[2] + bound[3])/2  if A.y < new bound  then bound[3] ← new bound 0 else bound[2] ← new bound 1 Update zone code code(ZA) Figure 4: Zone Boundary Determination, where A.x and A.y represent the geographic coordinate of node A. Insert-Event(e)  c ← Encode(e)  if Contain(ZA, c) = true and is Internal() = true  then Store e and exit  Send-Message(c, e) Send-Message(c, m)  if ∃ neighbor Y, Closer(Y, owner(m), m) = true  then addr(m) ← addr(Y )  else if length(c) > length(code(m))  then Update code(m) and addr(m)  source(m) ← caller  if is Owner(msg) = true  then owner(m) ← caller"s code  Send(m) Figure 5: Inserting an event in a DIM. Procedure Closer(A, B, m) returns true if code(A) is closer to code(m) than code(B). source(m) is used to set the source address of message m. child by 0 and the branch to the right child by 1. This binary tree forms the index that we will use in the following event and query processing procedures. We see that the zone sizes are different and depend on the local densities and so are the lengths of zone codes for different nodes. Notice that in Figure 2, there is an empty zone whose code should be 110. In this case, if the node in zone 1111 can only hear the node in zone 1110, it sets its boundary with the empty zone to undecided, because it did not hear from any neighboring nodes from that direction. As we have mentioned before, the undecided boundaries are resolved using GPSR"s perimeter mode when an event is inserted, or a query sent. We describe event insertion in the next step. Finally, this description does not describe how a node"s zone codes are adjusted when neighboring nodes fail, or new nodes come up. We return to this in Section 3.5. .3 Inserting an Event In this section, we describe how events are inserted into a DIM. There are two algorithms of interest: a consistent hashing technique for mapping an event to a zone, and a routing algorithm for storing the event at the appropriate zone. As we shall see, these two algorithms are inter-related. .3.1 Hashing an Event to a Zone In Section 3.1, we described a recursive tessellation of the geographic extent of a sensor field. We now describe a consistent hashing scheme for a DIM that supports range queries on m distinct attributes2 Let us denote these attributes A1 . . . Am. For simplicity, assume for now that the depth of every zone in the network is k, k is a multiple of m, and that this value of k is known to every node. We will relax this assumption shortly.  Furthermore, for ease of discussion, we assume that all attribute values have been normalized to be between 0 and 1. Our hashing scheme assigns a k bit zone code to an event as follows. For i between 1 and m, if Ai < 0.5, the i-th bit of the zone code is assigned 0, else 1. For i between m + 1 and 2m, if Ai−m < 0.25 or Ai−m ∈ [0.5, 0.75), the i-th bit of the zone is assigned 0, else 1, because the next level divisions are at 0.25 and 0.75 which divide the ranges to [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). We repeat this procedure until all k bits have been assigned. As an example, consider event E = 0.3, 0.8 . For this event, the -bit zone code is code(ZA) = 01110. Essentially, our hashing scheme uses the values of the  attributes in round-robin fashion on the zone tree (such as the one in Figure 3), in order to map an m-attribute event to a zone code. This is reminiscent of k-d trees [2], but is quite different from that data structure: zone trees are spatial embeddings and do not incorporate the re-balancing algorithms in k-d trees. In our design of DIMs, we do not require nodes to have zone codes of the same length, nor do we expect a node to know the zone codes of other nodes. Rather, suppose the encoding node is A and its own zone code is of length kA. Then, given an event E, node A only hashes E to a zone code of length kA. We denote the zone code assigned to an event E by code(E). As we describe below, as the event is routed, code(E) is refined by intermediate nodes. This lazy evaluation of zone codes allows different nodes to use  different length zone codes without any explicit coordination. .3.2 Routing an Event to its Owner The aim of hashing an event to a zone code is to store the event at the node within the network node that owns that zone. We call this node the owner of the event. Consider an event E that has just been generated at a node A. After encoding event E, node A compares code(E) with code(A). If the two are identical, node A store event E locally;  otherwise, node A will attempt to route the event to its owner. To do this, note that code(E) corresponds to some zone Z , which is A"s current guess for the zone at which event E should be stored. A now invokes GPSR to send a message to addr(Z ) (the centroid of Z , Section 3.1). The message contains the event E, code(E), and the target geographic location for storing the event. In the message, A also marks itself as the owner of event E. As we will see later, the guessed zone Z , the address addr(Z ), and the owner of E, all of them contained in the message, will be refined by intermediate forwarding nodes. GPSR now delivers this message to the next hop towards addr(Z ) from A. This next hop node (call it B) does not  immediately forward the message. Rather, it attempts to  com2 DIM does not assume that all nodes are homogeneous in terms of the sensors they have. Thus, in an m dimensional DIM, a node that does not possess all m sensors can use NULL values for the corresponding readings. DIM treats NULL as an extreme value for range comparisons. As an aside, a  network may have many DIM instances running concurrently. 7 pute a new zone code for E to get a new code codenew(E). B will update the code contained in the message (and also the geographic destination of the message) if codenew(E) is longer than the event code in the message. In this manner, as the event wends its way to its owner, its zone code gets refined. Now, B compares its own code code(B) against the owner code owner(E) contained in the incoming message. If code(B) has a longer match with code(E) than the  current owner owner(E), then B sets itself to be the current owner of E, meaning that if nobody is eligible to store E, then B will store the event (we shall see how this happens next). If B"s zone code does not exactly match code(E), B will invoke GPSR to deliver E to the next hop. .3.3 Resolving undecided zone boundaries during insertion Suppose that some node, say C, finds itself to be the  destination (or eventual owner) of an event E. It does so by noticing that code code(C) equals code(E) after locally  recomputing a code for E. In that case, C stores E locally, but only if all four of C"s zone boundaries are decided. When this condition holds, C knows for sure that no other nodes have overlapped zones with it. In this case, we call C an internal node. Recall, though, that because the zone discovery algorithm Section 3.2 only uses information from immediate neighbors, one or more of C"s boundaries may be undecided. If so, C assumes that some other nodes have a zone that overlaps with its own, and sets out to resolve this overlap. To do this, C now sets itself to be the owner of E and continues forwarding the message. Here we rely on GPSR"s  perimeter mode routing to probe around the void that causes the undecided boundary. Since the message starts from C and is destined for a geographic location near C, GPSR  guarantees that the message will be delivered back to C if no other nodes will update the information in the message. If the message comes back to C with itself to be the owner, C infers that it must be the true owner of the zone and stores E locally. If this does not happen, there are two possibilities. The first is that as the event traverses the perimeter, some  intermediate node, say B whose zone overlaps with C"s marks itself to be the owner of the event, but otherwise does not change the event"s zone code. This node also recognizes that its own zone overlaps with C"s and initiates a message  exchange which causes each of them to appropriately shrink their zone. Figures 6 through 8 show an example of this data-driven zone shrinking. Initially, both node A and node B have claimed the same zone 0 because they are out of radio range of each other. Suppose that A inserts an event E = 0.4, 0.8, 0.9 . A encodes E to 0 and claims itself to be the owner of E. Since A is not an internal node, it sends out E, looking for other owner candidates of E. Once E gets to node B, B will see in the message"s owner field A"s code that is the same as its own. B then shrinks its zone from 0 to 01 according to A"s location which is also recorded in the message and send a shrink request to A. Upon receiving this request, A also shrinks its zone from 0 to 00. A second possibility is if some intermediate node changes the destination code of E to a more specific value (i.e., longer zone code). Let us label this node D. D now tries to initiate delivery to the centroid of the new zone. This A B   10 00 111 110 01 Figure 6: Nodes A and B have claimed the same zone. A B <0.4,0.8,0.9> Figure 7: An event/query message (filled arrows)  triggers zone shrinking (hollow arrows). A B 1 0 10 00 111 110 01 Figure 8: The zone layout after shrinking. Now node A and B have been mapped to different zones. might result in a new perimeter walk that returns to D (if, for example, D happens to be geographically closest to the centroid of the zone). However, D would not be the owner of the event, which would still be C. In routing to the  centroid of this zone, the message may traverse the perimeter and return to D. Now D notices that C was the original owner, so it encapsulates the event and directs it to C. In case that there indeed is another node, say X, that owns an overlapped zone with C, X will notice this fact by  finding in the message the same prefix of the code of one of its zones, but with a different geographic location from its own. X will shrink its zone to resolve the overlap. If X"s zone is smaller than or equal to C"s zone, X will also send a shrink request to C. Once C receives a shrink request, it will reduce its zone appropriately and fix its undecided boundary. In this manner, the zone formation process is resolved on demand in a data-driven way. 8 There are several interesting effects with respect to  perimeter walking that arise in our algorithm. The first is that there are some cases where an event insertion might cause the entire outer perimeter of the network to be traversed3 . Figure 6 also works as an example where the outer  perimeter is traversed. Event E inserted by A will eventually be stored in node B. Before node B stores event E, if B"s  nominal radio range does not intersect the network boundary, it needs to send out E again as A did, because B in this case is not an internal node. But if B"s nominal radio range  intersects the network boundary, it then has two choices. It can assume that there will not be any nodes outside the network boundary and so B is an internal node. This is an aggressive approach. On the other hand, B can also make a conservative decision assuming that there might be some other nodes it have not heard of yet. B will then force the message walking another perimeter before storing it. In some situations, especially for large zones where the node that owns a zone is far away from the centroid of the owned zone, there might exist a small perimeter around the destination that does not include the owner of the zone. The event will end up being stored at a different node than the real owner. In order to deal with this problem, we add an extra operation in event forwarding, called efficient neighbor discovery. Before invoking GPSR, a node needs to check if there exists a neighbor who is eligible to be the real owner of the event. To do this, a node C, say, needs to know the zone codes of its neighboring nodes. We deploy GPSR"s  beaconing message to piggyback the zone codes for nodes. So by simply comparing the event"s code and neighbor"s code, a node can decide whether there exists a neighbor Y which is more likely to be the owner of event E. C delivers E to Y , which simply follows the decision making procedure discussed above. .3.4 Summary and Pseudo-code In summary, our event insertion procedure is designed to nicely interact with the zone discovery mechanism, and the event hashing mechanism. The latter two mechanisms are kept simple, while the event insertion mechanism uses lazy evaluation at each hop to refine the event"s zone code, and it leverages GPSR"s perimeter walking mechanism to fix  undecided zone boundaries. In Section 3.5, we address robustness of event insertion to packet loss or to node failures. Figure 5 shows the pseudo-code for inserting and  forwarding an event e. In this pseudo code, we have omitted a  description of the zone shrinking procedure. In the pseudo code, procedure is Internal() is used to determine if the caller is an internal node and procedure is Owner() is used to determine if the caller is more eligible to be the owner of the event than is currently claimed owner as recorded in the message. Procedure Send-Message is used to send either an event message or a query message. If the message  destination address has been changed, the packet source address needs also to be changed in order to avoid being dropped by GPSR, since GPSR does not allow a node to see the same packet in greedy mode twice.  This happens less frequently than for GHTs, where  inserting an event to a location outside the actual (but inside the nominal) boundary of the network will always invoke an external perimeter walk. .4 Resolving and Routing Queries DIMs support both point queries4 and range queries.  Routing a point query is identical to routing an event. Thus, the rest of this section details how range queries are routed. The key challenge in routing zone queries is brought out by the following strawman design. If the entire network was divided evenly into zones of depth k (for some pre-defined constant k), then the querier (the node issuing the query) could subdivide a given range query into the relevant  subzones and route individual requests to each of the zones. This can be inefficient for large range queries and also hard to implement in our design where zone sizes are not  predefined. Accordingly, we use a slightly different technique where a range query is initially routed to a zone  corresponding to the entire range, and is then progressively split into smaller subqueries. We describe this algorithm here. The first step of the algorithm is to map a range query to a zone code prefix. Conceptually, this is easy; in a zone tree (Figure 3), there exists some node which contains the entire range query in its sub-tree, and none of its children in the tree do. The initial zone code we choose for the query is the zone code corresponding to that tree node, and is a prefix of the zone codes of all zones (note that these zones may not be geographically contiguous) in the subtree. The querier computes the zone code of Q, denoted by code(Q) and then starts routing a query to addr(code(Q)). Upon receiving a range query Q, a node A (where A is any node on the query propagation path) divides it into multiple smaller sized subqueries if there is an overlap between the zone of A, zone(A) and the zone code associated with Q, code(Q). Our approach to split a query Q into subqueries is as follows. If the range of Q"s first attribute contains the value 0.5, A divides Q into two sub-queries one of whose first attribute ranges from 0 to 0.5, and the other from 0.5 to . Then A decides the half that overlaps with its own zone. Let"s call it QA. If QA does not exist, then A stops splitting; otherwise, it continues splitting (using the second attribute range) and recomputing QA until QA is small enough so that it completely falls into zone(A) and hence A can now resolve it. For example, suppose that node A, whose code is 0110, is to split a range query Q = 0.3 − 0.8, 0.6 − 0.9 . The splitting steps is shown in Figure 2. After splitting, we obtain three smaller queries q0 = 0.3 − 0.5, 0.6 − 0.75 , q1 = 0.3 − 0.5, 0.75 − 0.9 , and q2 = 0.5 − 0.8, 0.6 − 0.9 . This splitting procedure is illustrated in Figure 9 which also shows the codes of each subquery after splitting. A then replies to subquery q0 with data stored locally and sends subqueries q1 and q2 using the procedure outlined above. More generally, if node A finds itself to be inside the zone subtree that maximally covers Q, it will send the subqueries that resulted from the split. Otherwise, if there is no overlap between A and Q, then A forwards Q as is (in this case Q is either the original query, or a product of an earlier split). Figure 10 describes the pseudo-code for the zone splitting algorithm. As shown in the above algorithm, once a  subquery has been recognized as belonging to the caller"s zone, procedure Resolve is invoked to resolve the subquery and send a reply to the querier. Every query message contains  By point queries, we mean the equality condition on all indexed keys. DIM index attributes are not necessarily  primary keys. 9 the geographic location of its initiator, so the corresponding reply message can be delivered directly back to the  initiator. Finally, in the process of query resolution, zones might shrink similar to shrinkage during inserting. We omit this in the pseudo code. .5 Robustness Until now, we have not discussed the impact of node  failures and packet losses, or node arrivals and departures on our algorithms. Packet losses can affect query and event  insertion, and node failures can result in lost data, while node arrivals and departures can impact the zone structure. We now discuss how DIMs can be made robust to these kinds of dynamics. .5.1 Maintaining Zones In previous sections, we described how the zone discovery algorithm could leave zone boundaries undecided. These  undecided boundaries are resolved during insertion or  querying, using the zone shrinking procedure describe above. When a new node joins the network, the zone discovery mechanism (Section 3.2) will cause neighboring zones to  appropriately adjust their zone boundaries. At this time, those zones can also transfer to the new node those events they store but which should belong to the new node. Before a node turns itself off (if this is indeed possible), it knows that its backup node (Section 3.1) will take over its zone, and will simply send all its events to its backup node. Node deletion may also cause zone expansion. In order to keep the mapping between the binary zone tree"s leaf nodes and zones, we allow zone expansion to only occur among sibling zones (Section 3.1). The rule is: if zone(A)"s sibling zone becomes empty, then A can expand its own zone to include its sibling zone. Now, we turn our attention to node failures. Node failures are just like node deletions except that a failed node does not have a chance to move its events to another node. But how does a node decide if its sibling has failed? If the  sibling is within radio range, the absence of GPSR beaconing messages can detect this. Once it detects this, the node can expand its zone. A different approach is needed for  detecting siblings who are not within radio range. These are the cases where two nodes own their zones after exchanging a shrink message; they do not periodically exchange messages thereafter to maintain this zone relationship. In this case, we detect the failure in a data-driven fashion, with obvious efficiency benefits compared to periodic keepalives. Once a node B has failed, an event or query message that previously should have been owned by the failed node will now be  delivered to the node A that owns the empty zone left by node B. A can see this message because A stands right around the empty area left by B and is guaranteed to be visited in a GPSR perimeter traversal. A will set itself to be the owner of the message, and any node which would have dropped this message due to a perimeter loop will redirect the message to A instead. If A"s zone happens to be the sibling of B"s zone, A can safely expand its own zone and notify its expanded zone to its neighbors via GPSR beaconing messages. .5.2 Preventing Data Loss from Node Failure The algorithms described above are robust in terms of zone formation, but node failure can erase data. To avoid this, DIMs can employ two kinds of replication: local  replication to be resilient to random node failures, and mirror replication for resilience to concurrent failure of  geographically contiguous nodes. Mirror replication is conceptually easy. Suppose an event E has a zone code code(E). Then, the node that inserts E would store two copies of E; one at the zone denoted by code(E), and the other at the zone corresponding to the one"s complement of code(E). This technique essentially creates a mirror DIM. A querier would need, in parallel, to query both the original DIM and its mirror since there is no way of knowing if a collection of nodes has failed. Clearly, the trade-off here is an approximate doubling of both  insertion and query costs. There exists a far cheaper technique to ensure resilience to random node failures. Our local replication technique rests on the observation that, for each node A, there exists a unique node which will take over its zone when A fails. This node is defined as the node responsible for A"s zone"s backup zone (see Section 3.1). The basic idea is that A replicates each data item it has in this node. We call this node A"s local replica. Let A"s local replica be B. Often B will be a radio neighbor of A and can be detected from GPSR beacons. Sometimes, however, this is not the case, and B will have to be explicitly discovered. We use an explicit message for discovering the local replica. Discovering the local replica is data-driven, and uses a  mechanism similar to that of event insertion. Node A sends a message whose geographic destination is a random nearby location chosen by A. The location is close enough to A such that GPSR will guarantee that the message will delivered back to A. In addition, the message has three fields, one for the zone code of A, code(A), one for the owner owner(A) of zone(A) which is set to be empty, and one for the geographic location of owner(A). Then the packet will be delivered in GPSR perimeter mode. Each node that receives this  message will compare its zone code and code(A) in the message, and if it is more eligible to be the owner of zone(A) than the current owner(A) recorded in the message, it will  update the field owner(A) and the corresponding geographic location. Once the packet comes back to A, it will know the location of its local replica and can start to send replicas. In a dense sensor network, the local replica of a node is usually very near to the node, either its direct neighbor or 1-2 hops away, so the cost of sending replicas to local replication will not dominate the network traffic. However, a node"s local replica itself may fail. There are two ways to deal with this situation; periodic refreshes, or repeated  datadriven discovery of local replicas. The former has higher overhead, but more quickly discovers failed replicas. .5.3 Robustness to Packet Loss Finally, the mechanisms for querying and event insertion can be easily made resilient to packet loss. For event  insertion, a simple ACK scheme suffices. Of course, queries and responses can be lost as well. In this case, there exists an efficient approach for error  recovery. This rests on the observation that the querier knows which zones fall within its query and should have responded (we assume that a node that has no data matching a query, but whose zone falls within the query, responds with a  negative acknowledgment). After a conservative timeout, the querier can re-issue the queries selectively to these zones. If DIM cannot get any answers (positive or negative) from 0 <0.3-0.8, 0.6-0.9> <0.5-0.8, 0.6-0.9><0.3-0.5, 0.6-0.9> <0.3-0.5, 0.6-0.9> <0.3-0.5, 0.6-0.9> <0.3-0.5, 0.6-0.75> <0.3-0.5, 0.75-0.9>       Figure 9: An example of range query splitting Resolve-Range-Query(Q)  Qsub ← nil  q0, Qsub ← Split-Query(Q)  if q0 = nil  then c ← Encode(Q)  if Contain(c, code(A)) = true  then go to step 12  else Send-Message(c, q0)  else Resolve(q0)  if is Internal() = true 0 then Absorb (q0) 1 else Append q0 to Qsub 2 if Qsub = nil 3 then for each subquery q ∈ Qsub 4 do c ← Encode(q) 5 Send-Message(c, q) Figure 10: Query resolving algorithm certain zones after repeated timeouts, it can at least return the partial query results to the application together with the information about the zones from which data is missing. . DIMS: AN ANALYSIS In this section, we present a simple analytic performance evaluation of DIMs, and compare their performance against other possible approaches for implementing multi-dimensional range queries in sensor networks. In the next section, we  validate these analyses using detailed packet-level simulations. Our primary metrics for the performance of a DIM are: Average Insertion Cost measures the average number of messages required to insert an event into the network. Average Query Delivery Cost measures the average  number of messages required to route a query message to all the relevant nodes in the network. It does not measure the number of messages required to transmit responses to the querier; this latter number  depends upon the precise data distribution and is the same for many of the schemes we compare DIMs against. In DIMs, event insertion essentially uses geographic  routing. In a dense N-node network where the likelihood of traversing perimeters is small, the average event insertion cost proportional to √ N [23]. On the other hand, the query delivery cost depends upon the size of ranges specified in the query. Recall that our query delivery mechanism is careful about splitting a query into sub-queries, doing so only when the query nears the zone that covers the query range. Thus, when the querier is far from the queried zone, there are two components to the query delivery cost. The first, which is proportional to √ N, is the cost to deliver the query near the covering zone. If within this covering zone, there are M nodes, the message delivery cost of splitting the query is proportional to M. The average cost of query delivery depends upon the  distribution of query range sizes. Now, suppose that query sizes follow some density function f(x), then the average cost of resolve a query can be approximated by Ê N  xf(x)dx. To give some intuition for the performance of DIMs, we  consider four different forms for f(x): the uniform distribution where a query range encompassing the entire network is as likely as a point query; a bounded uniform distribution where all sizes up to a bound B are equally likely; an algebraic  distribution in which most queries are small, but large queries are somewhat likely; and an exponential distribution where most queries are small and large queries are unlikely. In all our analyses, we make the simplifying assumption that the size of a query is proportional to the number of nodes that can answer that query. For the uniform distribution P(x) ∝ c for some constant c. If each query size from 1 . . . N is equally likely, the average query delivery cost of uniformly distributed queries is O(N). Thus, for uniformly distributed queries, the performance of DIMs is comparable to that of flooding. However, for the applications we envision, where nodes within the network are trying to correlate events, the uniform distribution is highly unrealistic. Somewhat more realistic is a situation where all query sizes are bounded by a constant B. In this case, the average cost for resolving such a query is approximately Ê B  xf(x)dx = O(B). Recall now that all queries have to pay an  approximate cost of O( √ N) to deliver the query near the covering zone. Thus, if DIM limited queries to a size proportional to√ N, the average query cost would be O( √ N). The algebraic distribution, where f(x) ∝ x−k , for some constant k between 1 and 2, has an average query resolution cost given by Ê N  xf(x)dx = O(N2−k ). In this case, if k > .5, the average cost of query delivery is dominated by the cost to deliver the query to near the covering zone, given by O( √ N). Finally, for the exponential distribution, f(x) = ce−cx for some constant c, and the average cost is just the mean of the corresponding distribution, i.e., O(1) for large N.  Asymptotically, then, the cost of the query for the exponential distribution is dominated by the cost to deliver the query near the covering zone (O( √ N)). Thus, we see that if queries follow either the bounded uniform distribution, the algebraic distribution, or the  exponential distribution, the query cost scales as the insertion cost (for appropriate choice of constants for the bounded uniform and the algebraic distributions). How well does the performance of DIMs compare against alternative choices for implementing multi-dimensional queries? A simple alternative is called external storage [23], where all events are stored centrally in a node outside the sensor  network. This scheme incurs an insertion cost of O( √ N), and a zero query cost. However, as [23] points out, such systems may be impractical in sensor networks since the access link to the external node becomes a hotspot. A second alternative implementation would store events at the node where they are generated. Queries are flooded 1 throughout the network, and nodes that have matching data respond. Examples of systems that can be used for this  (although, to our knowledge, these systems do not implement multi-dimensional range queries) are Directed Diffusion [15] and TinyDB [17]. The flooding scheme incurs a zero  insertion cost, but an O(N) query cost. It is easy to show that DIMs outperform flooding as long as the ratio of the number of insertions to the number of queries is less than √ N. A final alternative would be to use a geographic hash table (GHT [20]). In this approach, attribute values are assumed to be integers (this is actually quite a reasonable  assumption since attribute values are often quantized), and events are hashed on some (say, the first) attribute. A range query is sub-divided into several sub-queries, one for each integer in the range of the first attribute. Each sub-query is then hashed to the appropriate location. The nodes that receive a sub-query only return events that match all other attribute ranges. In this approach, which we call GHT-R (GHT"s for range queries) the insertion cost is O( √ N). Suppose that the range of the first attribute contains r discrete values. Then the cost to deliver queries is O(r √ N). Thus,  asymptotically, GHT-R"s perform similarly to DIMs. In practice, however, the proportionality constants are significantly  different, and DIMs outperform GHT-Rs, as we shall show using detailed simulations. . DIMS: SIMULATION RESULTS Our analysis gives us some insight into the asymptotic behavior of various approaches for multi-dimensional range queries. In this section, we use simulation to compare DIMs against flooding and GHT-R; this comparison gives us a more detailed understanding of these approaches for  moderate size networks, and gives us a nuanced view of the  mechanistic differences between some of these approaches. .1 Simulation Methodology We use ns-2 for our simulations. Since DIMs are  implemented on top of GPSR, we first ported an earlier GPSR implementation to the latest version of ns-2. We modified the GPSR module to call our DIM implementation when it receives any data message in transit or when it is about to drop a message because that message traversed the entire perimeter. This allows a DIM to modify message zone codes in flight (Section 3), and determine the actual owner of an event or query. In addition, to this, we implemented in ns-2 most of the DIM mechanisms described in Section 3. Of those  mechanisms, the only one we did not implement is mirror  replication. We have implemented selective query retransmission for resiliency to packet loss, but have left the evaluation of this mechanism to future work. Our DIM implementation in ns-2 is 2800 lines of code. Finally, we implemented GHT-R, our GHT-based  multidimensional range query mechanism in ns-2. This  implementation was relatively straightforward, given that we had ported GPSR, and modified GPSR to detect the completion of perimeter mode traversals. Using this implementation, we conducted a fairly  extensive evaluation of DIM and two alternatives (flooding, and our GHT-R). For all our experiments, we use uniformly placed sensor nodes with network sizes ranging from 50 nodes to 300 nodes. Each node has a radio range of 40m. For the results presented here, each node has on average 20 nodes within its nominal radio range. We have conducted experiments at other node densities; they are in agreement with the results presented here. In all our experiments, each node first generates 3 events5 on average (more precisely, for a topology of size N, we have N events, and each node is equally likely to generate an event). We have conducted experiments for three different event value distributions. Our uniform event distribution generates 2-dimensional events and, for each dimension,  every attribute value is equally likely. Our normal event  distribution generates 2-dimensional events and, for each  dimension, the attribute value is normally distributed with a mean corresponding to the mid-point of the attribute value range. The normal event distribution represents a skewed data set. Finally, our trace event distribution is a collection of 4-dimensional events obtained from a habitat monitoring network. As we shall see, this represents a fairly skewed data set. Having generated events, for each simulation we  generate queries such that, on average, each node generates 2 queries. The query sizes are determined using the four size distributions we discussed in Section 4: uniform,  boundeduniform, algebraic and exponential. Once a query size has been determined, the location of the query (i.e., the actual boundaries of the zone) are uniformly distributed. For our GHT-R experiments, the dynamic range of the attributes had 100 discrete values, but we restricted the query range for any one attribute to 50 discrete values to allow those simulations to complete in reasonable time. Finally, using one set of simulations we evaluate the  efficacy of local replication by turning off random fractions of nodes and measuring the fidelity of the returned results. The primary metrics for our simulations are the average query and insertion costs, as defined in Section 4. .2 Results Although we have examined almost all the combinations of factors described above, we discuss only the most salient ones here, for lack of space. Figure 11 plots the average insertion costs for DIM and GHT-R (for flooding, of course, the insertion costs are zero). DIM incurs less per event overhead in inserting events  (regardless of the actual event distribution; Figure 11 shows the cost for uniformly distributed events). The reason for this is interesting. In GHT-R, storing almost every event incurs a perimeter traversal, and storing some events require  traversing the outer perimeter of the network [20]. By contrast, in DIM, storing an event incurs a perimeter traversal only when a node"s boundaries are undecided. Furthermore, an  insertion or a query in a DIM can traverse the outer perimeter (Section 3.3), but less frequently than in GHTs. Figure 13 plots the average query cost for a bounded  uniform query size distribution. For this graph (and the next) we use a uniform event distribution, since the event  distribution does not affect the query delivery cost. For this  simulation, our bound was 1  th the size of the largest possible  Our metrics are chosen so that the exact number of events and queries is unimportant for our discussion. Of course, the overall performance of the system will depend on the relative frequency of events and queries, as we discuss in Section 4. Since we don"t have realistic ratios for these, we focus on the microscopic costs, rather than on the overall system costs. 2      0 2 4 6 8 0 0 100 150 200 250 300 AverageCostperInsertion Network Size DIM GHT-R Figure 11: Average insertion cost for DIM and GHT. .4 .5 .6 .7 .8 .9   10 15 20 25 30 Fractionofrepliescomparedwithnon-failurecase Fraction of failed nodes (%) No Replication Local Replication Figure 12: Local replication performance. query (e.g., a query of the form 0 − 0.5, 0 − 0.5 . Even for this generous query size, DIMs perform quite well (almost a third the cost of flooding). Notice, however, that  GHTRs incur high query cost since almost any query requires as many subqueries as the width of the first attribute"s range. Figure 14 plots the average query cost for the exponential distribution (the average query size for this distribution was set to be 1 6 th the largest possible query). The superior scaling of DIMs is evident in these graphs. Clearly, this is the regime in which one might expect DIMs to perform best, when most of the queries are small and large queries are relatively rare. This is also the regime in which one would expect to use multi-dimensional range queries: to perform relatively tight correlations. As with the bounded uniform distribution, GHT query cost is dominated by the cost of sending sub-queries; for DIMs, the query splitting strategy works quite well in keep overall query delivery costs low. Figure 12 describes the efficacy of local replication. To obtain this figure, we conducted the following experiment. On a 100-node network, we inserted a number of events uniformly distributed throughout the network, then issued a query covering the entire network and recorded the  answers. Knowing the expected answers for this query, we then successively removed a fraction f of nodes randomly, and re-issued the same query. The figure plots the fraction of expected responses actually received, with and without replication. As the graph shows, local replication performs well for random failures, returning almost 90% of the  responses when up to 30% of the nodes have failed  simultaneously 6 .In the absence of local replication, of course, when  In practice, the performance of local replication is likely to  00 00 00 00 00 00 00 0 100 150 200 250 300 AverageCostperQueryinBoundedUnifDistribution Network Size DIM flooding GHT-R Figure 13: Average query cost with a bounded uniform query distribution  0 00 50 00 50 00 50 00 50 0 100 150 200 250 300 AverageCostperQueryinExponentialDistribution Network Size DIM flooding GHT-R Figure 14: Average query cost with an exponential query distribution 0% of the nodes fail, the response rate is only 70% as one would expect. We note that DIMs (as currently designed) are not  perfect. When the data is highly skewed-as it was for our trace data set from the habitat monitoring application where most of the event values fell into within 10% of the attribute"s range-a few DIM nodes will clearly become the bottleneck. This is depicted in Figure 15, which shows that for DIMs, and GHT-Rs, the maximum number of transmissions at any network node (the hotspots) is rather high. (For less skewed data distributions, and reasonable query size distributions, the hotspot curves for all three schemes are comparable.) This is a standard problem that the database indices have dealt with by tree re-balancing. In our case, simpler  solutions might be possible (and we discuss this in Section 7). However, our use of the trace data demonstrates that DIMs work for events which have more than two dimensions. Increasing the number of dimensions does not noticeably  degrade DIMs query cost (omitted for lack of space). Also omitted are experiments examining the impact of several other factors, as they do not affect our conclusions in any way. As we expected, DIMs are comparable in  performance to flooding when all sizes of queries are equally likely. For an algebraic distribution of query sizes, the  relative performance is close to that for the exponential  distribution. For normally distributed events, the insertion costs be much better than this. Assuming a node and its replica don"t simultaneously fail often, a node will almost always detect a replica failure and re-replicate, leading to near 100% response rates. 3  000 000 000 000 0000 2000 0 100 150 200 250 300 MaximumHotspotonTraceDataSet Network Size DIM flooding GHT-R Figure 15: Hotspot usage DIM Zone Manager Query Router Query Processor Event Manager Event Router GPSR interface(Event driven/Thread based) update useuse update GPSR Upper interface(Event driven/Thread based) Lower interface(Event driven/Thread based) Greedy Forwarding Perimeter Forwarding Beaconing Neighbor List Manager update use MoteNIC (MicaRadio) IP Socket (802.11b/Ethernet) Figure 16: Software architecture of DIM over GPSR are comparable to that for the uniform distribution. Finally, we note that in all our evaluations we have only used list queries (those that request all events matching the specified range). We expect that for summary queries (those that expect an aggregate over matching events), the overall cost of DIMs could be lower because the matching data are likely to be found in one or a small number of zones. We leave an understanding of this to future work. Also left to future work is a detailed understanding of the impact of location error on DIM"s mechanisms. Recent work [22] has examined the impact of imprecise location information on other data-centric storage mechanisms such as GHTs, and found that there exist relatively simple fixes to GPSR that ameliorate the effects of location error. . IMPLEMENTATION We have implemented DIMs on a Linux platform suitable for experimentation on PDAs and PC-104 class machines. To implement DIMs, we had to develop and test an  independent implementation of GPSR. Our GPSR implementation is full-featured, while our DIM implementation has most of the algorithms discussed in Section 3; some of the robustness extensions have only simpler variants implemented. The software architecture of DIM/GPSR system is shown in Figure 16. The entire system (about 5000 lines of code) is event-driven and multi-threaded. The DIM subsystem consists of six logical components: zone management, event maintenance, event routing, query routing, query  processing, and GPSR interactions. The GPSR system is  implemented as user-level daemon process. Applications are  executed as clients. For the DIM subsystem, the GPSR module      0 2 4 6 .25x0.25 0.50x0.50 0.75x0.75 1.0x1.0 Query size Average#ofreceivedresponses perquery Figure 17: Number of events received for different query sizes      0 2 4 6 .25x0.25 0.50x0.50 0.75x0.75 1.0x1.0 Query sizeTotalnumberofmessages onlyforsendingthequery Figure 18: Query distribution cost provides several extensions: it exports information about neighbors, and provides callbacks during packet forwarding and perimeter-mode termination. We tested our implementation on a testbed consisting of 8 PC-104 class machines. Each of these boxes runs Linux and uses a Mica mote (attached through a serial cable) for  communication. These boxes are laid out in an office building with a total spatial separation of over a hundred feet. We manually measured the locations of these nodes relative to some coordinate system and configured the nodes with their location. The network topology is approximately a chain. On this testbed, we inserted queries and events from a  single designated node. Our events have two attributes which span all combinations of the four values [0, 0.25, 0.75, 1]  (sixteen events in all). Our queries span four sizes, returning 1, , 9 and 16 events respectively. Figure 17 plots the number of events received for different sized queries. It might appear that we received fewer events than expected, but this graph doesn"t count the events that were already stored at the querier. With that adjustment, the number of responses matches our expectation. Finally, Figure 18 shows the total number of messages required for different query sizes on our testbed. While these experiments do not reveal as much about the performance range of DIMs as our simulations do, they  nevertheless serve as proof-of-concept for DIMs. Our next step in the implementation is to port DIMs to the Mica motes, and integrate them into the TinyDB [17] sensor database engine on motes. 4 . CONCLUSIONS In this paper, we have discussed the design and evaluation of a distributed data structure called DIM for efficiently  resolving multi-dimensional range queries in sensor networks. Our design of DIMs relies upon a novel locality-preserving hash inspired by early work in database indexing, and is built upon GPSR. We have a working prototype, both of GPSR and DIM, and plan to conduct larger scale  experiments in the future. There are several interesting future directions that we intend to pursue. One is adaptation to skewed data  distributions, since these can cause storage and transmission hotspots. Unlike traditional database indices that re-balance trees upon data insertion, in sensor networks it might be feasible to re-structure the zones on a much larger timescale after obtaining a rough global estimate of the data  distribution. Another direction is support for node heterogeneity in the zone construction process; nodes with larger storage space assert larger-sized zones for themselves. A third is  support for efficient resolution of existential queries-whether there exists an event matching a multi-dimensional range. Acknowledgments This work benefited greatly from discussions with Fang Bian, Hui Zhang and other ENL lab members, as well as from comments provided by the reviewers and our shepherd Feng Zhao. . REFERENCES [1] J. Aspnes and G. Shah. Skip Graphs. In Proceedings of 4th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Baltimore, MD, January 2003. [2] J. L. Bentley. Multidimensional Binary Search Trees Used for Associative Searching. Communicaions of the ACM, 8(9):475-484, 1975. [3] P. Bonnet, J. E. Gerhke, and P. Seshadri. Towards Sensor Database Systems. In Proceedings of the Second International Conference on Mobile Data Management, Hong Kong, January 2001. [4] I. Clarke, O. Sandberg, B. Wiley, and T. W. Hong. Freenet: A Distributed Anonymous Information Storage and Retrieval System. In Designing Privacy Enhancing Technologies: International Workshop on Design Issues in Anonymity and Unobservability. Springer, New York, 2001. [5] D. Comer. The Ubiquitous B-tree. ACM Computing Surveys, 11(2):121-137, 1979. [6] R. A. Finkel and J. L. Bentley. Quad Trees: A Data Structure for Retrieval on Composite Keys. Acta Informatica, 4:1-9, 1974. [7] D. Ganesan, D. Estrin, and J. Heidemann. DIMENSIONS: Why do we need a new Data Handling architecture for Sensor Networks? In Proceedings of the First Workshop on Hot Topics In Networks (HotNets-I), Princeton, NJ, October 2002. [8] A. Gionis, P. Indyk, and R. Motwani. Similarity Search in High Dimensions via Hashing. In Proceedings of the 25th VLDB conference, Edinburgh, Scotland, September 1999. [9] R. Govindan, J. Hellerstein, W. Hong, S. Madden, M. Franklin, and S. Shenker. The Sensor Network as a Database. Technical Report 02-771, Computer Science Department, University of Southern California, September 002. [10] B. Greenstein, D. Estrin, R. Govindan, S. Ratnasamy, and S. Shenker. DIFS: A Distributed Index for Features in Sensor Networks. In Proceedings of 1st IEEE International Workshop on Sensor Network Protocols and Applications, Anchorage, AK, May 2003. [11] A. Guttman. R-trees: A Dynamic Index Structure for Spatial Searching. In Proceedings of the ACM SIGMOD, Boston, MA, June 1984. [12] M. Harren, J. M. Hellerstein, R. Huebsch, B. T. Loo, S. Shenker, and I. Stoica. Complex Queries in DHT-based Peer-to-Peer Networks. In P. Druschel, F. Kaashoek, and A. Rowstron, editors, Proceedings of 1st International Workshop on Peer-to-Peer Systems (IPTPS"02), volume 429 of LNCS, page 242, Cambridge, MA, March 2002. Springer-Verlag. [13] P. Indyk and R. Motwani. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proceedings of the 30th Annual ACM Symposium on Theory of Computing, Dallas, Texas, May 1998. [14] P. Indyk, R. Motwani, P. Raghavan, and S. Vempala. Locality-preserving Hashing in Multidimensional Spaces. In Proceedings of the 29th Annual ACM symposium on Theory of Computing, pages 618 - 625, El Paso, Texas, May 1997. ACM Press. [15] C. Intanagonwiwat, R. Govindan, and D. Estrin. Directed Diffusion: A Scalable and Robust Communication Paradigm for Sensor Networks. In Proceedings of the Sixth Annual ACM/IEEE International Conference on Mobile Computing and Networking (Mobicom 2000), Boston, MA, August 2000. [16] B. Karp and H. T. Kung. GPSR: Greedy Perimeter Stateless Routing for Wireless Networks. In Proceedings of the Sixth Annual ACM/IEEE International Conference on Mobile Computing and Networking (Mobicom 2000), Boston, MA, August 2000. [17] S. Madden, M. Franklin, J. Hellerstein, and W. Hong. The Design of an Acquisitional Query Processor for Sensor Networks. In Proceedings of ACM SIGCMOD, San Diego, CA, June 2003. [18] S. Madden, M. J. Franklin, J. M. Hellerstein, and W. Hong. TAG: a Tiny AGregation Service for ad-hoc Sensor Networks. In Proceedings of 5th Annual Symposium on Operating Systems Design and Implementation (OSDI), Boston, MA, December 2002. [19] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and S. Shenker. A Scalable Content-Addressable Network. In Proceedings of the ACM SIGCOMM, San Diego, CA, August 2001. [20] S. Ratnasamy, B. Karp, L. Yin, F. Yu, D. Estrin, R. Govindan, and S. Shenker. GHT: A Geographic Hash Table for Data-Centric Storage. In Proceedings of the First ACM International Workshop on Wireless Sensor Networks and Applications, Atlanta, GA, September 2002. [21] H. Samet. Spatial Data Structures. In W. Kim, editor, Modern Database Systems: The Object Model, Interoperability and Beyond, pages 361-385. Addison Wesley/ACM, 1995. [22] K. Sead, A. Helmy, and R. Govindan. On the Effect of Localization Errors on Geographic Face Routing in Sensor Networks. In Under submission, 2003. [23] S. Shenker, S. Ratnasamy, B. Karp, R. Govindan, and D. Estrin. Data-Centric Storage in Sensornets. In Proc. ACM SIGCOMM Workshop on Hot Topics In Networks, Princeton, NJ, 2002. [24] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan. Chord: A Scalable Peer-To-Peer Lookup Service for Internet Applications. In Proceedings of the ACM SIGCOMM, San Diego, CA, August 2001. [25] F. Ye, H. Luo, J. Cheng, S. Lu, and L. Zhang. A Two-Tier Data Dissemination Model for Large-scale Wireless Sensor Networks. In Proceedings of the Eighth Annual ACM/IEEE International Conference on Mobile Computing and Networking (Mobicom"02), Atlanta, GA, September 2002. 5
Evaluating Opportunistic Routing Protocols with Large Realistic Contact Traces Libo Song and David F. Kotz Institute for Security Technology Studies (ISTS) Department of Computer Science, Dartmouth College, Hanover, NH, USA 03755 ABSTRACT Traditional mobile ad-hoc network (MANET) routing protocols  assume that contemporaneous end-to-end communication paths exist between data senders and receivers. In some mobile ad-hoc  networks with a sparse node population, an end-to-end  communication path may break frequently or may not exist at any time. Many routing protocols have been proposed in the literature to address the problem, but few were evaluated in a realistic opportunistic  network setting. We use simulation and contact traces (derived from logs in a production network) to evaluate and compare five  existing protocols: direct-delivery, epidemic, random, PRoPHET, and Link-State, as well as our own proposed routing protocol. We show that the direct delivery and epidemic routing protocols suffer either low delivery ratio or high resource usage, and other protocols make tradeoffs between delivery ratio and resource usage. Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Computer  Communication Networks-Distributed Systems General Terms Performance, Design . INTRODUCTION Mobile opportunistic networks are one kind of delay-tolerant network (DTN) [6]. Delay-tolerant networks provide service  despite long link delays or frequent link breaks. Long link delays  happen in networks with communication between nodes at a great  distance, such as interplanetary networks [2]. Link breaks are caused by nodes moving out of range, environmental changes, interference from other moving objects, radio power-offs, or failed nodes. For us, mobile opportunistic networks are those DTNs with sparse node population and frequent link breaks caused by power-offs and the mobility of the nodes. Mobile opportunistic networks have received increasing interest from researchers. In the literature, these networks include mobile sensor networks [25], wild-animal tracking networks [11],  pocketswitched networks [8], and transportation networks [1, 14]. We expect to see more opportunistic networks when the  one-laptopper-child (OLPC) project [18] starts rolling out inexpensive  laptops with wireless networking capability for children in developing countries, where often no infrastructure exits. Opportunistic  networking is one promising approach for those children to exchange information. One fundamental problem in opportunistic networks is how to route messages from their source to their destination. Mobile  opportunistic networks differ from the Internet in that disconnections are the norm instead of the exception. In mobile opportunistic  networks, communication devices can be carried by people [4],  vehicles [1] or animals [11]. Some devices can form a small mobile ad-hoc network when the nodes move close to each other. But a node may frequently be isolated from other nodes. Note that  traditional Internet routing protocols and ad-hoc routing protocols, such as AODV [20] or DSDV [19], assume that a contemporaneous  endto-end path exists, and thus fail in mobile opportunistic networks. Indeed, there may never exist an end-to-end path between two given devices. In this paper, we study protocols for routing messages between wireless networking devices carried by people. We assume that people send messages to other people occasionally, using their  devices; when no direct link exists between the source and the  destination of the message, other nodes may relay the message to the destination. Each device represents a unique person (it is out of the scope of this paper when a device maybe carried by multiple  people). Each message is destined for a specific person and thus for a specific node carried by that person. Although one person may carry multiple devices, we assume that the sender knows which device is the best to receive the message. We do not consider  multicast or geocast in this paper. Many routing protocols have been proposed in the literature. Few of them were evaluated in realistic network settings, or even in realistic simulations, due to the lack of any realistic people  mobility model. Random walk or random way-point mobility models are often used to evaluate the performance of those routing protocols. Although these synthetic mobility models have received extensive interest by mobile ad-hoc network researchers [3], they do not  reflect people"s mobility patterns [9]. Realising the limitations of  using random mobility models in simulations, a few researchers have studied routing protocols in mobile opportunistic networks with  realistic mobility traces. Chaintreau et al. [5] theoretically analyzed the impact of routing algorithms over a model derived from a  realistic mobility data set. Su et al. [22] simulated a set of routing 5 protocols in a small experimental network. Those studies help  researchers better understand the theoretical limits of opportunistic networks, and the routing protocol performance in a small network (20-30 nodes). Deploying and experimenting large-scale mobile opportunistic networks is difficult, we too resort to simulation. Instead of  using a complex mobility model to mimic people"s mobility patterns, we used mobility traces collected in a production wireless  network at Dartmouth College to drive our simulation. Our  messagegeneration model, however, was synthetic. To the best of our knowledge, we are the first to simulate the effect of routing protocols in a large-scale mobile opportunistic network, using realistic contact traces derived from real traces of a production network with more than 5, 000 users. Using realistic contact traces, we evaluate the performance of three naive routing protocols (direct-delivery, epidemic, and  random) and two prediction-based routing protocols, PRoPHET [16] and Link-State [22]. We also propose a new prediction-based  routing protocol, and compare it to the above in our evaluation. . ROUTING PROTOCOL A routing protocol is designed for forwarding messages from one node (source) to another node (destination). Any node may  generate messages for any other node, and may carry messages destined for other nodes. In this paper, we consider only messages that are unicast (single destination). DTN routing protocols could be described in part by their  transfer probability and replication probability; that is, when one node meets another node, what is the probability that a message should be transfered and if so, whether the sender should retain its copy. Two extremes are the direct-delivery protocol and the epidemic protocol. The former transfers with probability 1 when the node meets the destination, 0 for others, and no replication. The latter uses transfer probability 1 for all nodes and unlimited replication. Both these protocols have their advantages and disadvantages. All other protocols are between the two extremes. First, we define the notion of contact between two nodes. Then we describe five existing protocols before presenting our own  proposal. A contact is defined as a period of time during which two nodes have the opportunity to communicate. Although we are aware that wireless technologies differ, we assume that a node can reliably detect the beginning and end time of a contact with nearby nodes. A node may be in contact with several other nodes at the same time. The contact history of a node is a sequence of contacts with other nodes. Node i has a contact history Hi(j), for each other node j, which denotes the historical contacts between node i and node j. We record the start and end time for each contact; however, the last contacts in the node"s contact history may not have ended. .1 Direct Delivery Protocol In this simple protocol, a message is transmitted only when the source node can directly communicate with the destination node of the message. In mobile opportunistic networks, however, the probability for the sender to meet the destination may be low, or even zero. .2 Epidemic Routing Protocol The epidemic routing protocol [23] floods messages into the  network. The source node sends a copy of the message to every node that it meets. The nodes that receive a copy of the message also send a copy of the message to every node that they meet.  Eventually, a copy of the message arrives at the destination of the message. This protocol is simple, but may use significant resources;  excessive communication may drain each node"s battery quickly.  Moreover, since each node keeps a copy of each message, storage is not used efficiently, and the capacity of the network is limited. At a minimum, each node must expire messages after some amount of time or stop forwarding them after a certain number of hops.  After a message expires, the message will not be transmitted and will be deleted from the storage of any node that holds the message. An optimization to reduce the communication cost is to  transfer index messages before transferring any data message. The  index messages contain IDs of messages that a node currently holds. Thus, by examining the index messages, a node only transfers  messages that are not yet contained on the other nodes. .3 Random Routing An obvious approach between the above two extremes is to  select a transfer probability between 0 and 1 to forward messages at each contact. We use a simple replication strategy that allows only the source node to make replicas, and limits the replication to a specific number of copies. The message has some chance of  being transferred to a highly mobile node, and thus may have a better chance to reach its destination before the message expires. .4 PRoPHET Protocol PRoPHET [16] is a Probabilistic Routing Protocol using History of past Encounters and Transitivity to estimate each node"s delivery probability for each other node. When node i meets node j, the delivery probability of node i for j is updated by pij = (1 − pij)p0 + pij, (1) where p0 is an initial probability, a design parameter for a given network. Lindgren et al. [16] chose 0.75, as did we in our  evaluation. When node i does not meet j for some time, the delivery probability decreases by pij = αk pij, (2) where α is the aging factor (α < 1), and k is the number of time units since the last update. The PRoPHET protocol exchanges index messages as well as  delivery probabilities. When node i receives node j"s delivery  probabilities, node i may compute the transitive delivery probability through j to z with piz = piz + (1 − piz)pijpjzβ, (3) where β is a design parameter for the impact of transitivity; we used β = 0.25 as did Lindgren [16]. .5 Link-State Protocol Su et al. [22] use a link-state approach to estimate the weight of each path from the source of a message to the destination. They use the median inter-contact duration or exponentially aged  intercontact duration as the weight on links. The exponentially aged inter-contact duration of node i and j is computed by wij = αwij + (1 − α)I, (4) where I is the new inter-contact duration and α is the aging factor. Nodes share their link-state weights when they can communicate with each other, and messages are forwarded to the node that have the path with the lowest link-state weight. 6 . TIMELY-CONTACT PROBABILITY We also use historical contact information to estimate the  probability of meeting other nodes in the future. But our method differs in that we estimate the contact probability within a period of time. For example, what is the contact probability in the next hour?  Neither PRoPHET nor Link-State considers time in this way. One way to estimate the timely-contact probability is to use the ratio of the total contact duration to the total time. However, this approach does not capture the frequency of contacts. For example, one node may have a long contact with another node, followed by a long non-contact period. A third node may have a short contact with the first node, followed by a short non-contact period. Using the above estimation approach, both examples would have similar contact probability. In the second example, however, the two nodes have more frequent contacts. We design a method to capture the contact frequency of mobile nodes. For this purpose, we assume that even short contacts are sufficient to exchange messages.1 The probability for node i to meet node j is computed by the following procedure. We divide the contact history Hi(j) into a sequence of n periods of ΔT starting from the start time (t0) of the first contact in history Hi(j) to the current time. We number each of the n periods from 0 to n − 1, then check each period. If node i had any contact with node j during a given period m, which is [t0 + mΔT, t0 + (m + 1)ΔT), we set the contact status Im to be ; otherwise, the contact status Im is 0. The probability p (0) ij that node i meets node j in the next ΔT can be estimated as the average of the contact status in prior intervals: p (0) ij =  n n−1X m=0 Im. (5) To adapt to the change of contact patterns, and reduce the storage space for contact histories, a node may discard old history contacts; in this situation, the estimate would be based on only the retained history. The above probability is the direct contact probability of two nodes. We are also interested in the probability that we may be able to pass a message through a sequence of k nodes. We define the k-order probability inductively, p (k) ij = p (0) ij + X α p (0) iα p (k−1) αj , (6) where α is any node other than i or j. .1 Our Routing Protocol We first consider the case of a two-hop path, that is, with only one relay node. We consider two approaches: either the receiving neighbor decides whether to act as a relay, or the source decides which neighbors to use as relay. .1.1 Receiver Decision Whenever a node meets other nodes, they exchange all their  messages (or as above, index messages). If the destination of a  message is the receiver itself, the message is delivered. Otherwise, if the probability of delivering the message to its destination through this receiver node within ΔT is greater than or equal to a certain threshold, the message is stored in the receiver"s storage to forward  In our simulation, however, we accurately model the  communication costs and some short contacts will not succeed in transfer of all messages. to the destination. If the probability is less than the threshold, the receiver discards the message. Notice that our protocol replicates the message whenever a good-looking relay comes along. .1.2 Sender Decision To make decisions, a sender must have the information about its neighbors" contact probability with a message"s destination.  Therefore, meta-data exchange is necessary. When two nodes meet, they exchange a meta-message,  containing an unordered list of node IDs for which the sender of the  metamessage has a contact probability greater than the threshold. After receiving a meta-message, a node checks whether it has any message that destined to its neighbor, or to a node in the node list of the neighbor"s meta-message. If it has, it sends a copy of the message. When a node receives a message, if the destination of the  message is the receiver itself, the message is delivered. Otherwise, the message is stored in the receiver"s storage for forwarding to the destination. .1.3 Multi-node Relay When we use more than two hops to relay a message, each node needs to know the contact probabilities along all possible paths to the message destination. Every node keeps a contact probability matrix, in which each cell pij is a contact probability between to nodes i and j. Each node i computes its own contact probabilities (row i) with other nodes using Equation (5) whenever the node ends a contact with other nodes. Each row of the contact probability matrix has a version number; the version number for row i is only increased when node i updates the matrix entries in row i. Other matrix entries are updated through exchange with other nodes when they meet. When two nodes i and j meet, they first exchange their contact probability matrices. Node i compares its own contact matrix with node j"s matrix. If node j"s matrix has a row l with a higher version number, then node i replaces its own row l with node j"s row l. Likewise node j updates its matrix. After the exchange, the two nodes will have identical contact probability matrices. Next, if a node has a message to forward, the node estimates its neighboring node"s order-k contact probability to contact the destination of the message using Equation (6). If p (k) ij is above a threshold, or if j is the destination of the message, node i will send a copy of the message to node j. All the above effort serves to determine the transfer probability when two nodes meet. The replication decision is orthogonal to the transfer decision. In our implementation, we always replicate. Although PRoPHET [16] and Link-State [22] do no replication, as described, we added replication to those protocols for better  comparison to our protocol. . EVALUATION RESULTS We evaluate and compare the results of direct delivery, epidemic, random, PRoPHET, Link-State, and timely-contact routing  protocols. .1 Mobility traces We use real mobility data collected at Dartmouth College.  Dartmouth College has collected association and disassociation  messages from devices on its wireless network wireless users since spring 2001 [13]. Each message records the wireless card MAC address, the time of association/disassociation, and the name of the access point. We treat each unique MAC address as a node. For 7 more information about Dartmouth"s network and the data  collection, see previous studies [7, 12]. Our data are not contacts in a mobile ad-hoc network. We can approximate contact traces by assuming that two users can  communicate with each other whenever they are associated with the same access point. Chaintreau et al. [5] used Dartmouth data traces and made the same assumption to theoretically analyze the impact of human mobility on opportunistic forwarding algorithms. This  assumption may not be accurate,2 but it is a good first approximation. In our simulation, we imagine the same clients and same mobility in a network with no access points. Since our campus has full WiFi coverage, we assume that the location of access points had little impact on users" mobility. We simulated one full month of trace data (November 2003) taken from CRAWDAD [13], with 5, 142 users. Although  predictionbased protocols require prior contact history to estimate each node"s delivery probability, our preliminary results show that the  performance improvement of warming-up over one month of trace was marginal. Therefore, for simplicity, we show the results of all  protocols without warming-up. .2 Simulator We developed a custom simulator.3 Since we used contact traces derived from real mobility data, we did not need a mobility model and omitted physical and link-layer details for node discovery. We were aware that the time for neighbor discovery in different  wireless technologies vary from less than one seconds to several  seconds. Furthermore, connection establishment also takes time, such as DHCP. In our simulation, we assumed the nodes could discover and connect each other instantly when they were associated with a same AP. To accurately model communication costs, however, we simulated some MAC-layer behaviors, such as collision. The default settings of the network of our simulator are listed in Table 1, using the values recommended by other papers [22, 16]. The message probability was the probability of generating  messages, as described in Section 4.3. The default transmission  bandwidth was 11 Mb/s. When one node tried to transmit a message, it first checked whether any nearby node was transmitting. If it was, the node backed off a random number of slots. Each slot was 1  millisecond, and the maximum number of backoff slots was 30. The size of messages was uniformly distributed between 80 bytes and 024 bytes. The hop count limit (HCL) was the maximum number of hops before a message should stop forwarding. The time to live (TTL) was the maximum duration that a message may exist before expiring. The storage capacity was the maximum space that a node can use for storing messages. For our routing method, we used a default prediction window ΔT of 10 hours and a probability  threshold of 0.01. The replication factor r was not limited by default, so the source of a message transferred the messages to any other node that had a contact probability with the message destination higher than the probability threshold. .3 Message generation After each contact event in the contact trace, we generated a  message with a given probability; we choose a source node and a  des2 Two nodes may not have been able to directly communicate while they were at two far sides of an access point, or two nodes may have been able to directly communicate if they were between two adjacent access points.  We tried to use a general network simulator (ns2), which was  extremely slow when simulating a large number of mobile nodes (in our case, more than 5000 nodes), and provided unnecessary detail in modeling lower-level network protocols. Table 1: Default Settings of the Simulation Parameter Default value message probability 0.001 bandwidth 11 Mb/s transmission slot 1 millisecond max backoff slots 30 message size 80-1024 bytes hop count limit (HCL) unlimited time to live (TTL) unlimited storage capacity unlimited prediction window ΔT 10 hours probability threshold 0.01 contact history length 20 replication always aging factor α 0.9 (0.98 PRoPHET) initial probability p0 0.75 (PRoPHET) transitivity impact β 0.25 (PRoPHET)  0000 0000 0000 0000 00000 20000  5 10 15 20 Numberofoccurrence hour movements contacts Figure 1: Movements and contacts duration each hour tination node randomly using a uniform distribution across nodes seen in the contact trace up to the current time. When there were more contacts during a certain period, there was a higher likelihood that a new message was generated in that period. This correlation is not unreasonable, since there were more movements during the day than during the night, and so the number of contacts. Figure 1 shows the statistics of the numbers of movements and the numbers of contacts during each hour of the day, summed across all users and all days. The plot shows a clear diurnal activity pattern. The activities reached lowest around 5am and peaked between 4pm and pm. We assume that in some applications, network traffic exhibits similar patterns, that is, people send more messages during the day, too. Messages expire after a TTL. We did not use proactive methods to notify nodes the delivery of messages, so that the messages can be removed from storage. .4 Metrics We define a set of metrics that we use in evaluating routing  protocols in opportunistic networks: • delivery ratio, the ratio of the number of messages delivered to the number of total messages generated. • message transmissions, the total number of messages  transmitted during the simulation across all nodes. 8 • meta-data transmissions, the total number of meta-data units transmitted during the simulation across all nodes. • message duplications, the number of times a message copy occurred, due to replication. • delay, the duration between a message"s generation time and the message"s delivery time. • storage usage, the max and mean of maximum storage (bytes) used across all nodes. .5 Results Here we compare simulation results of the six routing protocols. .001 .01 .1  unlimited 100 24 10 1 Deliveryratio Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Figure 2: Delivery ratio (log scale). The direct and random protocols for one-hour TTL had delivery ratios that were too low to be visible in the plot. Figure 2 shows the delivery ratio of all the protocols, with  different TTLs. (In all the plots in the paper, prediction stands for our method, state stands for the Link-State protocol, and prophet represents PRoPHET.) Although we had 5,142 users in the  network, the direct-delivery and random protocols had low delivery ratios (note the log scale). Even for messages with an unlimited lifetime, only 59 out of 2077 messages were delivered during this one-month simulation. The delivery ratio of epidemic routing was the best. The three prediction-based approaches had low delivery ratio, compared to epidemic routing. Although our method was slightly better than the other two, the advantage was marginal. The high delivery ratio of epidemic routing came with a price: excessive transmissions. Figure 3 shows the number of message data transmissions. The number of message transmissions of  epidemic routing was more than 10 times higher than for the  predictionbased routing protocols. Obviously, the direct delivery protocol had the lowest number of message transmissions - the number of message delivered. Among the three prediction-based methods, the PRoPHET transmitted fewer messages, but had comparable delivery-ratio as seen in Figure 2. Figure 4 shows that epidemic and all prediction-based methods had substantial meta-data transmissions, though epidemic routing had relatively more, with shorter TTLs. Because epidemic  protocol transmitted messages at every contact, in turn, more nodes had messages that required meta-data transmission during contact. The direct-delivery and random protocols had no meta-data  transmissions. In addition to its message transmissions and meta-data  transmissions, the epidemic routing protocol also had excessive message  0 00 000 0000 00000 e+06 e+07 e+08 unlimited 100 24 10 1 Numberofmessagetransmitted Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Figure 3: Message transmissions (log scale)  0 00 000 0000 00000 e+06 e+07 e+08 unlimited 100 24 10 1 Numberofmeta-datatransmissions Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Figure 4: Meta-data transmissions (log scale). Direct and  random protocols had no meta-data transmissions. duplications, spreading replicas of messages over the network.  Figure 5 shows that epidemic routing had one or two orders more  duplication than the prediction-based protocols. Recall that the  directdelivery and random protocols did not replicate, thus had no data duplications. Figure 6 shows both the median and mean delivery delays. All protocols show similar delivery delays in both mean and median measures for medium TTLs, but differ for long and short TTLs. With a 100-hour TTL, or unlimited TTL, epidemic routing had the shortest delays. The direct-delivery had the longest delay for  unlimited TTL, but it had the shortest delay for the one-hour TTL. The results seem contrary to our intuition: the epidemic routing protocol should be the fastest routing protocol since it spreads  messages all over the network. Indeed, the figures show only the delay time for delivered messages. For direct delivery, random, and the probability-based routing protocols, relatively few messages were delivered for short TTLs, so many messages expired before they could reach their destination; those messages had infinite delivery delay and were not included in the median or mean measurements. For longer TTLs, more messages were delivered even for the  directdelivery protocol. The statistics of longer TTLs for comparison are more meaningful than those of short TTLs. Since our message generation rate was low, the storage usage was also low in our simulation. Figure 7 shows the maximum and average of maximum volume (in KBytes) of messages stored 9  0 00 000 0000 00000 e+06 e+07 e+08 unlimited 100 24 10 1 Numberofmessageduplications Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Figure 5: Message duplications (log scale). Direct and random protocols had no message duplications.  0 00 000 0000 unlimited100 24 10 1 unlimited100 24 10 1 Delay(minute) Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Mean delayMedian delay Figure 6: Median and mean delays (log scale). in each node. The epidemic routing had the most storage usage. The message time-to-live parameter was the big factor affecting the storage usage for epidemic and prediction-based routing protocols. We studied the impact of different parameters of our  predictionbased routing protocol. Our prediction-based protocol was  sensitive to several parameters, such as the probability threshold and the prediction window ΔT. Figure 8 shows the delivery ratios when we used different probability thresholds. (The leftmost value 0.01 is the value used for the other plots.) A higher probability threshold limited the transfer probability, so fewer messages were delivered. It also required fewer transmissions as shown in Figure 9. With a larger prediction window, we got a higher contact probability. Thus, for the same probability threshold, we had a slightly higher delivery ratio as shown in Figure 10, and a few more transmissions as shown in Figure 11. . RELATED WORK In addition to the protocols that we evaluated in our simulation, several other opportunistic network routing protocols have been proposed in the literature. We did not implement and evaluate these routing protocols, because either they require domain-specific  information (location information) [14, 15], assume certain mobility patterns [17], present orthogonal approaches [10, 24] to other  routing protocols. .1  0 00 000 0000 unlimited100 24 10 1 unlimited100 24 10 1 Storageusage(KB) Message time-to-live (TTL) (hour) direct random prediction state prophet epidemic Mean of maximumMax of maximum Figure 7: Max and mean of maximum storage usage across all nodes (log scale).  .2 .4 .6 .8   0.2 0.4 0.6 0.8 1 Deliveryratio Probability threshold Figure 8: Probability threshold impact on delivery ratio of timely-contact routing. LeBrun et al. [14] propose a location-based delay-tolerant  network routing protocol. Their algorithm assumes that every node knows its own position, and the destination is stationary at a known location. A node forwards data to a neighbor only if the  neighbor is closer to the destination than its own position. Our protocol does not require knowledge of the nodes" locations, and learns their contact patterns. Leguay et al. [15] use a high-dimensional space to represent a mobility pattern, then routes messages to nodes that are closer to the destination node in the mobility pattern space. Location  information of nodes is required to construct mobility patterns. Musolesi et al. [17] propose an adaptive routing protocol for  intermittently connected mobile ad-hoc networks. They use a Kalman filter to compute the probability that a node delivers messages. This protocol assumes group mobility and cloud connectivity, that is, nodes move as a group, and among this group of nodes a  contemporaneous end-to-end connection exists for every pair of nodes. When two nodes are in the same connected cloud, DSDV [19] routing is used. Network coding also draws much interest from DTN research. Erasure-coding [10, 24] explores coding algorithms to reduce  message replicas. The source node replicates a message m times, then uses a coding scheme to encode them in one big message.  After replicas are encoded, the source divides the big message into k 0  .5  .5  .5  .5  0.2 0.4 0.6 0.8 1 Numberofmessagetransmitted(million) Probability threshold Figure 9: Probability threshold impact on message  transmission of timely-contact routing.  .2 .4 .6 .8  .01 0.1 1 10 100 Deliveryratio Prediction window (hour) Figure 10: Prediction window impact on delivery ratio of timely-contact routing (semi-log scale). blocks of the same size, and transmits a block to each of the first k encountered nodes. If m of the blocks are received at the  destination, the message can be restored, where m < k. In a uniformly distributed mobility scenario, the delivery probability increases  because the probability that the destination node meets m relays is greater than it meets k relays, given m < k. . SUMMARY We propose a prediction-based routing protocol for  opportunistic networks. We evaluate the performance of our protocol using realistic contact traces, and compare to five existing routing  protocols. Our simulation results show that direct delivery had the  lowest delivery ratio, the fewest data transmissions, and no meta-data transmission or data duplication. Direct delivery is suitable for  devices that require an extremely low power consumption. The  random protocol increased the chance of delivery for messages  otherwise stuck at some low mobility nodes. Epidemic routing delivered the most messages. The excessive transmissions, and data  duplication, however, consume more resources than portable devices may be able to provide. None of these protocols (direct-delivery, random and epidemic routing) are practical for real deployment of opportunistic networks,  .5  .5  .5  .5 .01 0.1 1 10 100 Numberofmessagetransmitted(million) Prediction window (hour) Figure 11: Prediction window impact on message transmission of timely-contact routing (semi-log scale). because they either had an extremely low delivery ratio, or had an extremely high resource consumption. The prediction-based  routing protocols had a delivery ratio more than 10 times better than that for direct-delivery and random routing, and fewer  transmissions and less storage usage than epidemic routing. They also had fewer data duplications than epidemic routing. All the prediction-based routing protocols that we have  evaluated had similar performance. Our method had a slightly higher delivery ratio, but more transmissions and higher storage usage. There are many parameters for prediction-based routing protocols, however, and different parameters may produce different results. Indeed, there is an opportunity for some adaptation; for example, high priority messages may be given higher transfer and  replication probabilities to increase the chance of delivery and reduce the delay, or a node with infrequent contact may choose to raise its transfer probability. We only studied the impact of predicting peer-to-peer contact probability for routing in unicast messages. In some applications, context information (such as location) may be available for the peers. One may also consider other messaging models, for  example, where messages are sent to a location, such that every node at that location will receive a copy of the message. Location  prediction [21] may be used to predict nodes" mobility, and to choose as relays those nodes moving toward the destined location. Research on routing in opportunistic networks is still in its early stage. Many other issues of opportunistic networks, such as  security and privacy, are mainly left open. We anticipate studying these issues in future work. . ACKNOWLEDGEMENT This research is a project of the Center for Mobile  Computing and the Institute for Security Technology Studies at Dartmouth College. It was supported by DoCoMo Labs USA, the  CRAWDAD archive at Dartmouth College (funded by NSF CRI Award 454062), NSF Infrastructure Award EIA-9802068, and by Grant number 2005-DD-BX-1091 awarded by the Bureau of Justice  Assistance. Points of view or opinions in this document are those of the authors and do not represent the official position or policies of any sponsor. . REFERENCES [1] John Burgess, Brian Gallagher, David Jensen, and Brian Neil Levine. MaxProp: routing for vehicle-based 1 disruption-tolerant networks. In Proceedings of the 25th IEEE International Conference on Computer Communications (INFOCOM), April 2006. [2] Scott Burleigh, Adrian Hooke, Leigh Torgerson, Kevin Fall, Vint Cerf, Bob Durst, Keith Scott, and Howard Weiss. Delay-tolerant networking: An approach to interplanetary Internet. IEEE Communications Magazine, 41(6):128-136, June 2003. [3] Tracy Camp, Jeff Boleng, and Vanessa Davies. A survey of mobility models for ad-hoc network research. Wireless Communication & Mobile Computing (WCMC): Special issue on Mobile ad-hoc Networking: Research, Trends and Applications, 2(5):483-502, 2002. [4] Andrew Campbell, Shane Eisenman, Nicholas Lane, Emiliano Miluzzo, and Ronald Peterson. People-centric urban sensing. In IEEE Wireless Internet Conference, August 006. [5] Augustin Chaintreau, Pan Hui, Jon Crowcroft, Christophe Diot, Richard Gass, and James Scott. Impact of human mobility on the design of opportunistic forwarding algorithms. In Proceedings of the 25th IEEE International Conference on Computer Communications (INFOCOM), April 2006. [6] Kevin Fall. A delay-tolerant network architecture for challenged internets. In Proceedings of the 2003 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (SIGCOMM), August 2003. [7] Tristan Henderson, David Kotz, and Ilya Abyzov. The changing usage of a mature campus-wide wireless network. In Proceedings of the 10th Annual International Conference on Mobile Computing and Networking (MobiCom), pages 87-201, September 2004. [8] Pan Hui, Augustin Chaintreau, James Scott, Richard Gass, Jon Crowcroft, and Christophe Diot. Pocket switched networks and human mobility in conference environments. In ACM SIGCOMM Workshop on Delay Tolerant Networking, pages 244-251, August 2005. [9] Ravi Jain, Dan Lelescu, and Mahadevan Balakrishnan. Model T: an empirical model for user registration patterns in a campus wireless LAN. In Proceedings of the 11th Annual International Conference on Mobile Computing and Networking (MobiCom), pages 170-184, 2005. [10] Sushant Jain, Mike Demmer, Rabin Patra, and Kevin Fall. Using redundancy to cope with failures in a delay tolerant network. In Proceedings of the 2005 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (SIGCOMM), pages 109-120, August 2005. [11] Philo Juang, Hidekazu Oki, Yong Wang, Margaret Martonosi, Li-Shiuan Peh, and Daniel Rubenstein. Energy-efficient computing for wildlife tracking: Design tradeoffs and early experiences with ZebraNet. In the Tenth International Conference on Architectural Support for Programming Languages and Operating Systems, October 002. [12] David Kotz and Kobby Essien. Analysis of a campus-wide wireless network. Wireless Networks, 11:115-133, 2005. [13] David Kotz, Tristan Henderson, and Ilya Abyzov. CRAWDAD data set dartmouth/campus. http://crawdad.cs.dartmouth.edu/dartmouth/campus, December 2004. [14] Jason LeBrun, Chen-Nee Chuah, Dipak Ghosal, and Michael Zhang. Knowledge-based opportunistic forwarding in vehicular wireless ad-hoc networks. In IEEE Vehicular Technology Conference, pages 2289-2293, May 2005. [15] Jeremie Leguay, Timur Friedman, and Vania Conan. Evaluating mobility pattern space routing for DTNs. In Proceedings of the 25th IEEE International Conference on Computer Communications (INFOCOM), April 2006. [16] Anders Lindgren, Avri Doria, and Olov Schelen. Probabilistic routing in intermittently connected networks. In Workshop on Service Assurance with Partial and Intermittent Resources (SAPIR), pages 239-254, 2004. [17] Mirco Musolesi, Stephen Hailes, and Cecilia Mascolo. Adaptive routing for intermittently connected mobile ad-hoc networks. In IEEE International Symposium on a World of Wireless Mobile and Multimedia Networks, pages 183-189, June 2005. extended version. [18] OLPC. One laptop per child project. http://laptop.org. [19] C. E. Perkins and P. Bhagwat. Highly dynamic destination-sequenced distance-vector routing (DSDV) for mobile computers. Computer Communication Review, pages 34-244, October 1994. [20] C. E. Perkins and E. M. Royer. ad-hoc on-demand distance vector routing. In IEEE Workshop on Mobile Computing Systems and Applications, pages 90-100, February 1999. [21] Libo Song, David Kotz, Ravi Jain, and Xiaoning He. Evaluating next-cell predictors with extensive Wi-Fi mobility data. IEEE Transactions on Mobile Computing, (12):1633-1649, December 2006. [22] Jing Su, Ashvin Goel, and Eyal de Lara. An empirical evaluation of the student-net delay tolerant network. In International Conference on Mobile and Ubiquitous Systems (MobiQuitous), July 2006. [23] Amin Vahdat and David Becker. Epidemic routing for partially-connected ad-hoc networks. Technical Report CS-2000-06, Duke University, July 2000. [24] Yong Wang, Sushant Jain, Margaret Martonosia, and Kevin Fall. Erasure-coding based routing for opportunistic networks. In ACM SIGCOMM Workshop on Delay Tolerant Networking, pages 229-236, August 2005. [25] Yu Wang and Hongyi Wu. DFT-MSN: the delay fault tolerant mobile sensor network for pervasive information gathering. In Proceedings of the 25th IEEE International Conference on Computer Communications (INFOCOM), April 2006. 2
CenWits: A Sensor-Based Loosely Coupled Search and Rescue System Using Witnesses Jyh-How Huang Department of Computer Science University of Colorado, Campus Box 0430 Boulder, CO 80309-0430 huangjh@cs.colorado.edu Saqib Amjad Department of Computer Science University of Colorado, Campus Box 0430 Boulder, CO 80309-0430 Saqib.Amjad@colorado.edu Shivakant Mishra Department of Computer Science University of Colorado, Campus Box 0430 Boulder, CO 80309-0430 mishras@cs.colorado.edu ABSTRACT This paper describes the design, implementation and  evaluation of a search and rescue system called CenWits. CenWits uses several small, commonly-available RF-based sensors, and a small number of storage and processing devices. It is designed for search and rescue of people in emergency  situations in wilderness areas. A key feature of CenWits is that it does not require a continuously connected sensor network for its operation. It is designed for an intermittently  connected network that provides only occasional connectivity. It makes a judicious use of the combined storage capability of sensors to filter, organize and store important  information, combined battery power of sensors to ensure that the system remains operational for longer time periods, and  intermittent network connectivity to propagate information to a processing center. A prototype of CenWits has been implemented using Berkeley Mica2 motes. The paper  describes this implementation and reports on the performance measured from it. Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems General Terms Algorithms, Design, Experimentation . INTRODUCTION Search and rescue of people in emergency situation in a timely manner is an extremely important service. It has been difficult to provide such a service due to lack of timely information needed to determine the current location of a person who may be in an emergency situation. With the emergence of pervasive computing, several systems [12, 19, , 5, 6, 4, 11] have been developed over the last few years that make use of small devices such as cell phones,  sensors, etc. All these systems require a connected network via satellites, GSM base stations, or mobile devices. This requirement severely limits their applicability, particularly in remote wilderness areas where maintaining a connected network is very difficult. For example, a GSM transmitter has to be in the range of a base station to transmit. As a result, it cannot operate in most wilderness areas. While a satellite transmitter is the only viable solution in wilderness areas, it is typically expensive and cumbersome. Furthermore, a line of sight is required to transmit to satellite, and that makes it  infeasible to stay connected in narrow canyons, large cities with skyscrapers, rain forests, or even when there is a roof or some other obstruction above the transmitter, e.g. in a car. An RF transmitter has a relatively smaller range of  transmission. So, while an in-situ sensor is cheap as a single unit, it is expensive to build a large network that can provide  connectivity over a large wilderness area. In a mobile environment where sensors are carried by moving people, power-efficient routing is difficult to implement and maintain over a large wilderness area. In fact, building an adhoc sensor network using only the sensors worn by hikers is nearly impossible due to a relatively small number of sensors spread over a large wilderness area. In this paper, we describe the design, implementation and evaluation of a search and rescue system called  CenWits (Connection-less Sensor-Based Tracking System  Using Witnesses). CenWits is comprised of mobile, in-situ sensors that are worn by subjects (people, wild animals, or in-animate objects), access points (AP) that collect  information from these sensors, and GPS receivers and location points (LP) that provide location information to the  sensors. A subject uses GPS receivers (when it can connect to a satellite) and LPs to determine its current location. The key idea of CenWits is that it uses a concept of witnesses to convey a subject"s movement and location information to the outside world. This averts a need for maintaining a connected network to transmit location information to the outside world. In particular, there is no need for  expensive GSM or satellite transmitters, or maintaining an adhoc network of in-situ sensors in CenWits. 80 CenWits employs several important mechanisms to  address the key problem of resource constraints (low signal strength, low power and limited memory) in sensors. In particular, it makes a judicious use of the combined  storage capability of sensors to filter, organize and store  important information, combined battery power of sensors to ensure that the system remains operational for longer time periods, and intermittent network connectivity to propagate information to a processing center. The problem of low signal strengths (short range RF  communication) is addressed by avoiding a need for maintaining a connected network. Instead, CenWits propagates the  location information of sensors using the concept of witnesses through an intermittently connected network. As a result, this system can be deployed in remote wilderness areas, as well as in large urban areas with skyscrapers and other tall structures. Also, this makes CenWits cost-effective. A  subject only needs to wear light-weight and low-cost sensors that have GPS receivers but no expensive GSM or satellite transmitters. Furthermore, since there is no need for a  connected sensor network, there is no need to deploy sensors in very large numbers. The problem of limited battery life and limited memory of a sensor is addressed by incorporating the concepts of groups and partitions. Groups and partitions allow sensors to stay in sleep or receive modes most of the time. Using groups and partitions, the location information collected by a sensor can be distributed among several sensors, thereby reducing the amount of memory needed in one sensor to store that  information. In fact, CenWits provides an adaptive tradeoff between memory and power consumption of sensors. Each sensor can dynamically adjust its power and memory  consumption based on its remaining power or available memory. It has amply been noted that the strength of sensor  networks comes from the fact that several sensor nodes can be distributed over a relatively large area to construct a multihop network. This paper demonstrates that important large-scale applications can be built using sensors by  judiciously integrating the storage, communication and  computation capabilities of sensors. The paper describes  important techniques to combine memory, transmission and  battery power of many sensors to address resource constraints in the context of a search and rescue application. However, these techniques are quite general. We discuss several other sensor-based applications that can employ these techniques. While CenWits addresses the general location tracking and reporting problem in a wide-area network, there are two important differences from the earlier work done in this area. First, unlike earlier location tracking solutions,  CenWits does not require a connected network. Second, unlike earlier location tracking solutions, CenWits does not aim for a very high accuracy of localization. Instead, the main goal is to provide an approximate, small area where search and rescue efforts can be concentrated. The rest of this paper is organized as follows. In Section , we overview some of the recent projects and technologies related to movement and location tracking, and search and rescue systems. In Section 3, we describe the overall  architecture of CenWits, and provide a high-level description of its functionality. In the next section, Section 4, we discuss power and memory management in CenWits. To simplify our presentation, we will focus on a specific application of tracking lost/injured hikers in all these sections. In  Section 6, we describe a prototype implementation of CenWits and present performance measured from this  implementation. We discuss how the ideas of CenWits can be used to build several other applications in Section 7. Finally, in Section 8, we discuss some related issues and conclude the paper. . RELATED WORK A survey of location systems for ubiquitous computing is provided in [11]. A location tracking system for adhoc sensor networks using anchor sensors as reference to gain location information and spread it out to outer node is  proposed in [17]. Most location tracking systems in adhoc  sensor networks are for benefiting geographic-aware routing. They don"t fit well for our purposes. The well-known  active badge system [19] lets a user carry a badge around. An infrared sensor in the room can detect the presence of a badge and determine the location and identification of the person. This is a useful system for indoor environment, where GPS doesn"t work. Locationing using 802.11 devices is probably the cheapest solution for indoor position  tracking [8]. Because of the popularity and low cost of 802.11 devices, several business solutions based on this technology have been developed[1]. A system that combines two mature technologies and is viable in suburban area where a user can see clear sky and has GSM cellular reception at the same time is currently available[5]. This system receives GPS signal from a  satellite and locates itself, draws location on a map, and sends location information through GSM network to the others who are interested in the user"s location. A very simple system to monitor children consists an RF transmitter and a receiver. The system alarms the holder of the receiver when the transmitter is about to run out of range [6]. Personal Locater Beacons (PLB) has been used for avalanche rescuing for years. A skier carries an RF transmitter that emits beacons periodically, so that a rescue team can find his/her location based on the strength of the RF signal.  Luxury version of PLB combines a GPS receiver and a  COSPASSARSAT satellite transmitter that can transmit user"s  location in latitude and longitude to the rescue team whenever an accident happens [4]. However, the device either is turned on all the time resulting in fast battery drain, or must be turned on after the accident to function. Another related technology in widespread use today is the ONSTAR system [3], typically used in several luxury cars. In this system, a GPS unit provides position information, and a powerful transmitter relays that information via  satellite to a customer service center. Designed for emergencies, the system can be triggered either by the user with the push of a button, or by a catastrophic accident. Once the system has been triggered, a human representative attempts to gain communication with the user via a cell phone built as an  incar device. If contact cannot be made, emergency services are dispatched to the location provided by GPS. Like PLBs, this system has several limitations. First, it is heavy and  expensive. It requires a satellite transmitter and a connected network. If connectivity with either the GPS network or a communication satellite cannot be maintained, the system fails. Unfortunately, these are common obstacles  encountered in deep canyons, narrow streets in large cities, parking garages, and a number of other places. 81 The Lifetch system uses GPS receiver board combined with a GSM/GPRS transmitter and an RF transmitter in one wireless sensor node called Intelligent Communication Unit (ICU). An ICU first attempts to transmit its location to a control center through GSM/GPRS network. If that fails, it connects with other ICUs (adhoc network) to  forward its location information until the information reaches an ICU that has GSM/GPRS reception. This ICU then transmits the location information of the original ICU via the GSM/GPRS network. ZebraNet is a system designed to study the moving  patterns of zebras [13]. It utilizes two protocols: History-based protocol and flooding protocol. History-based protocol is used when the zebras are grazing and not moving around too much. While this might be useful for tracking zebras, it"s not suitable for tracking hikers because two hikers are most likely to meet each other only once on a trail. In the flooding protocol, a node dumps its data to a neighbor whenever it finds one and doesn"t delete its own copy until it finds a base station. Without considering routing loops, packet filtering and grouping, the size of data on a node will grow exponentially and drain the power and memory of a sensor node with in a short time. Instead, Cenwits uses a four-phase hand-shake protocol to ensure that a node  transmits only as much information as the other node is willing to receive. While ZebraNet is designed for a big group of sensors moving together in the same direction with same speed, Cenwits is designed to be used in the scenario where sensors move in different directions at different speeds. Delay tolerant network architecture addresses some  important problems in challenged (resource-constrained)  networks [9]. While this work is mainly concerned with  interoperability of challenged networks, some problems related to occasionally-connected networks are similar to the ones we have addressed in CenWits. Among all these systems, luxury PLB and Lifetch are  designed for location tracking in wilderness areas. However, both of these systems require a connected network. Luxury PLB requires the user to transmit a signal to a satellite, while Lifetch requires connection to GSM/GPRS network. Luxury PLB transmits location information, only when an accident happens. However, if the user is buried in the snow or falls into a deep canyon, there is almost no chance for the signal to go through and be relayed to the rescue team. This is because satellite transmission needs line of sight.  Furthermore, since there is no known history of user"s location, it is not possible for the rescue team to infer the current location of the user. Another disadvantage of luxury PLB is that a satellite transmitter is very expensive, costing in the range of $750. Lifetch attempts to transmit the location  information by GSM/GPRS and adhoc sensor network that uses AODV as the routing protocol. However, having a cellular reception in remote areas in wilderness areas, e.g.  American national parks is unlikely. Furthermore, it is extremely unlikely that ICUs worn by hikers will be able to form an adhoc network in a large wilderness area. This is because the hikers are mobile and it is very unlikely to have several ICUs placed dense enough to forward packets even on a very popular hike route. CenWits is designed to address the limitations of systems such as luxury PLB and Lifetch. It is designed to  provide hikers, skiers, and climbers who have their activities mainly in wilderness areas a much higher chance to convey their location information to a control center. It is not  reliant upon constant connectivity with any communication medium. Rather, it communicates information along from user to user, finally arriving at a control center. Unlike  several of the systems discussed so far, it does not require that a user"s unit is constantly turned on. In fact, it can discover a victim"s location, even if the victim"s sensor was off at the time of accident and has remained off since then. CenWits solves one of the greatest problems plaguing modern search and rescue systems: it has an inherent on-site storage  capability. This means someone within the network will have access to the last-known-location information of a victim, and perhaps his bearing and speed information as well. Figure 1: Hiker A and Hiker B are are not in the range of each other . CENWITS We describe CenWits in the context of locating lost/injured hikers in wilderness areas. Each hiker wears a sensor (MICA2 motes in our prototype) equipped with a GPS receiver and an RF transmitter. Each sensor is assigned a unique ID and maintains its current location based on the signal received by its GPS receiver. It also emits beacons periodically. When any two sensors are in the range of one another, they record the presence of each other (witness information), and also exchange the witness information they recorded earlier. The key idea here is that if two sensors come with in range of each other at any time, they become each other"s witnesses. Later on, if the hiker wearing one of these sensors is lost, the other sensor can convey the last known (witnessed) location of the lost hiker. Furthermore, by exchanging the witness information that each sensor recorded earlier, the witness information is propagated beyond a direct contact between two sensors. To convey witness information to a processing center or to a rescue team, access points are established at well-known locations that the hikers are expected to pass through, e.g. at the trail heads, trail ends, intersection of different trails, scenic view points, resting areas, and so on. Whenever a sensor node is in the vicinity of an access point, all witness information stored in that sensor is automatically dumped to the access point. Access points are connected to a  processing center via satellite or some other network1 . The witness information is downloaded to the processing center from various access points at regular intervals. In case,  connection to an access point is lost, the information from that  A connection is needed only between access points and a processing center. There is no need for any connection  between different access points. 82 access point can be downloaded manually, e.g. by UAVs. To estimate the speed, location and direction of a hiker at any point in time, all witness information of that hiker that has been collected from various access points is processed. Figure 2: Hiker A and Hiker B are in the range of each other. A records the presence of B and B records the presence of A. A and B become each other"s witnesses. Figure 3: Hiker A is in the range of an access point. It uploads its recorded witness information and clears its memory. An example of how CenWits operates is illustrated in  Figures 1, 2 and 3. First, hikers A and B are on two close trails, but out of range of each other (Figure 1). This is a very common scenario during a hike. For example, on a popular four-hour hike, a hiker might run into as many as 0 other hikers. This accounts for one encounter every 12 minutes on average. A slow hiker can go 1 mile (5,280 feet) per hour. Thus in 12 minutes a slow hiker can go as far as 056 feet. This implies that if we were to put 20 hikers on a -hour, one-way hike evenly, the range of each sensor node should be at least 1056 feet for them to communicate with one another continuously. The signal strength starts  dropping rapidly for two Mica2 nodes to communicate with each other when they are 180 feet away, and is completely lost when they are 230 feet away from each other[7]. So, for the sensors to form a sensor network on a 4-hour hiking trail, there should be at least 120 hikers scattered evenly. Clearly, this is extremely unlikely. In fact, in a 4-hour, less-popular hiking trail, one might only run into say five other hikers. CenWits takes advantage of the fact that sensors can  communicate with one another and record their presence. Given a walking speed of one mile per hour (88 feet per minute) and Mica2 range of about 150 feet for non-line-of-sight radio transmission, two hikers have about 150/88 = 1.7 minutes to discover the presence of each other and exchange their  witness information. We therefore design our system to have each sensor emit a beacon every one-and-a-half minute. In Figure 2, hiker B"s sensor emits a beacon when A is in range, this triggers A to exchange data with B. A communicates the following information to B: My ID is A; I saw C at 1:23 PM at (39◦ 9.3277655", 105◦ 9.1126776"), I saw E at 3:09 PM at (40◦ 9.2234879", 105◦ 0.3290168"). B then replies with My ID is B; I saw K at 11:20 AM at (39◦ 1.4531655", 05◦ 1.6776223"). In addition, A records I saw B at 4:17 PM at (41◦ 9.3177354", 105◦ 4.9106211") and B records I saw A at 4:17 PM at (41◦ 9.3177354", 105◦ 4.9106211"). B goes on his way to overnight camping while A heads back to trail head where there is an AP, which emits beacon every 5 seconds to avoid missing any hiker. A dumps all witness information it has collected to the access point. This is shown in Figure 3. .1 Witness Information: Storage A critical concern is that there is limited amount of  memory available on motes (4 KB SDRAM memory, 128 KB flash memory, and 4-512 KB EEPROM). So, it is important to organize witness information efficiently. CenWits stores witness information at each node as a set of witness records (Format is shown in Figure 4.  B Node ID Record Time X, Y Location Time Hop Count  B 3 B 8 B 3 B Figure 4: Format of a witness record. When two nodes i and j encounter each other, each node generates a new witness record. In the witness record  generated by i, Node ID is j, Record Time is the current time in i"s clock, (X,Y) are the coordinates of the location of i that i recorded most recently (either from satellite or an LP), Location Time is the time when the this location was recorded, and Hop Count is 0. Each node is assigned a unique Node Id when it enters a trail. In our current prototype, we have allocated one byte for Node Id, although this can be increased to two or more bytes if a large number of hikers are expected to be present at the same time. We can represent time in 17 bits to a  second precision. So, we have allocated 3 bytes each for Record Time and Location Time. The circumference of the Earth is approximately 40,075 KM. If we use a 32-bit number to represent both longitude and latitude, the precision we get is 40,075,000/232 = 0.0093 meter = 0.37 inches, which is quite precise for our needs. So, we have allocated 4 bytes each for X and Y coordinates of the location of a node. In fact, a foot precision can be achieved by using only 27 bits. .2 Location Point and Location Inference Although a GPS receiver provides an accurate location information, it has it"s limitation. In canyons and rainy forests, a GPS receiver does not work. When there is a heavy cloud cover, GPS users have experienced inaccuracy in the reported location as well. Unfortunately, a lot of  hiking trails are in dense forests and canyons, and it"s not that uncommon to rain after hikers start hiking. To address this, CenWits incorporates the idea of location points (LP). A location point can update a sensor node with its current  location whenever the node is near that LP. LPs are placed at different locations in a wilderness area where GPS receivers don"t work. An LP is a very simple device that emits  prerecorded location information at some regular time interval. It can be placed in difficult-to-reach places such as deep canyons and dense rain forests by simply dropping them from an airplane. LPs allow a sensor node to determine its current location more accurately. However, they are not 83 an essential requirement of CenWits. If an LP runs out of power, the CenWits will continue to work correctly. Figure 5: GPS receiver not working correctly.  Sensors then have to rely on LP to provide coordination In Figure 5, B cannot get GPS reception due to bad weather. It then runs into A on the trail who doesn"t have GPS reception either. Their sensors record the presence of each other. After 10 minutes, A is in range of an LP that provides an accurate location information to A. When A returns to trail head and uploads its data (Figure 6), the system can draw a circle centered at the LP from which A fetched location information for the range of encounter  location of A and B. By Overlapping this circle with the trail map, two or three possible location of encounter can be  inferred. Thus when a rescue is required, the possible location of B can be better inferred (See Figures 7 and 8). Figure 6: A is back to trail head, It reports the time of encounter with B to AP, but no location information to AP Figure 7: B is still missing after sunset. CenWits infers the last contact point and draws the circle of possible current locations based on average hiking speed CenWits requires that the clocks of different sensor nodes be loosely synchronized with one another. Such a  synchronization is trivial when GPS coverage is available. In  addition, sensor nodes in CenWits synchronize their clocks whenever they are in the range of an AP or an LP. The Figure 8: Based on overlapping landscape, B might have hiked to wrong branch and fallen off a cliff. Hot rescue areas can thus be determined synchronization accuracy Cenwits needs is of the order of a second or so. As long as the clocks are synchronized with in one second range, whether A met B at 12:37"45 or 12:37"46 doesn"t matter in the ordering of witness events and  inferring the path. . MEMORY AND POWER MANAGEMENT CenWits employs several important mechanisms to  conserve power and memory. It is important to note while current sensor nodes have limited amount of memory,  future sensor nodes are expected to have much more memory. With this in mind, the main focus in our design is to  provide a tradeoff between the amount of memory available and amount of power consumption. .1 Memory Management The size of witness information stored at a node can get very large. This is because the node may come across several other nodes during a hike, and may end up accumulating a large amount of witness information over time. To address this problem, CenWits allows a node to pro-actively free up some parts of its memory periodically. This raises an  interesting question of when and which witness record should be deleted from the memory of a node? CenWits uses three  criteria to determine this: record count, hop count, and record gap. Record count refers to the number of witness records with same node id that a node has stored in its memory. A node maintains an integer parameter MAX RECORD COUNT. It stores at most MAX RECORD COUNT witness records of any node. Every witness record has a hop count field that stores the number times (hops) this record has been transferred since being created. Initially this field is set to 0. Whenever a node receives a witness record from another node, it  increments the hop count of that record by 1. A node maintains an integer parameter called MAX HOP COUNT. It keeps only those witness records in its memory, whose hop count is less than MAX HOP COUNT. The MAX HOP COUNT parameter provides a balance between two conflicting goals: (1) To ensure that a witness record has been propagated to and thus stored at as many nodes as possible, so that it has a high probability of being dumped at some AP as quickly as possible; and (2) To ensure that a witness record is stored only at a few nodes, so that it does not clog up too much of the combined memory of all sensor nodes. We chose to use hop count instead of time-to-live to decide when to drop a packet. The main reason for this is that the probability of a packet reaching an AP goes up as the hop count adds up. For example, when the hop count if 5 for a specific record, 84 the record is in at least 5 sensor nodes. On the other hand, if we discard old records, without considering hop count, there is no guarantee that the record is present in any other sensor node. Record gap refers to the time difference between the record times of two witness records with the same node id. To save memory, a node n ensures the the record gap between any two witness records with the same node id is at least MIN RECORD GAP. For each node id i, n stores the  witness record with the most recent record time rti, the witness with most recent record time that is at least MIN RECORD GAP time units before rti, and so on until the record count limit (MAX RECORD COUNT) is reached. When a node is tight in memory, it adjusts the three  parameters, MAX RECORD COUNT, MAX HOP COUNT and MIN RECORD GAP to free up some memory. It  decrements MAX RECORD COUNT and MAX HOP COUNT, and increments MIN RECORD GAP. It then first erases all witness records whose hop count exceeds the reduced MAX HOP COUNT value, and then erases witness records to satisfy the record gap criteria. Also, when a node has  extra memory space available, e.g. after dumping its witness information at an access point, it resets MAX RECORD COUNT, MAX HOP COUNT and MIN RECORD GAP to some  predefined values. .2 Power Management An important advantage of using sensors for tracking  purposes is that we can regulate the behavior of a sensor node based on current conditions. For example, we mentioned earlier that a sensor should emit a beacon every 1.7 minute, given a hiking speed of 1 mile/hour. However, if a user is moving 10 feet/sec, a beacon should be emitted every 10 seconds. If a user is not moving at all, a beacon can be emitted every 10 minutes. In the night, a sensor can be put into sleep mode to save energy, when a user is not likely to move at all for a relatively longer period of time. If a user is active for only eight hours in a day, we can put the sensor into sleep mode for the other 16 hours and thus save 2/3rd of the energy. In addition, a sensor node can choose to not send any beacons during some time intervals. For example, suppose hiker A has communicated its witness information to three other hikers in the last five minutes. If it is running low on power, it can go to receive mode or sleep mode for the next ten minutes. It goes to receive mode if it is still willing to receive additional witness information from hikers that it encounters in the next ten minutes. It goes to sleep mode if it is extremely low on power. The bandwidth and energy limitations of sensor nodes require that the amount of data transferred among the nodes be reduced to minimum. It has been observed that in some scenarios 3000 instructions could be executed for the same energy cost of sending a bit 100m by radio [15]. To reduce the amount of data transfer, CenWits employs a handshake protocol that two nodes execute when they encounter one another. The goal of this protocol is to ensure that a node transmits only as much witness information as the other node is willing to receive. This protocol is initiated when a node i receives a beacon containing the node ID of the sender node j and i has not exchanged witness information with j in the last δ time units. Assume that i < j. The protocol consists of four phases (See Figure 9): . Phase I: Node i sends its receive constraints and the number of witness records it has in its memory. . Phase II: On receiving this message from i, j sends its receive constraints and the number of witness records it has in its memory. . Phase III: On receiving the above message from j, i sends its witness information (filtered based on receive constraints received in phase II). . Phase IV: After receiving the witness records from i, j sends its witness information (filtered based on receive constraints received in phase I). j <Constaints, Witness info size> <Constaints, Witness info size> <Filtered Witness info> <Filtered Witness info> i j j j i i i Figure 9: Four-Phase Hand Shake Protocol (i < j) Receive constraints are a function of memory and power. In the most general case, they are comprised of the three parameters (record count, hop count and record gap) used for memory management. If i is low on memory, it specifies the maximum number of records it is willing to accept from j. Similarly, i can ask j to send only those records that have hop count value less than MAX HOP COUNT − 1. Finally, i can include its MIN RECORD GAP value in its receive constraints. Note that the handshake protocol is beneficial to both i and j. They save memory by receiving only as much information as they are willing to accept and conserve energy by sending only as many witness records as needed. It turns out that filtering witness records based on MIN RECORD GAP is complex. It requires that the  witness records of any given node be arranged in an order sorted by their record time values. Maintaining this sorted order is complex in memory, because new witness records with the same node id can arrive later that may have to be inserted in between to preserve the sorted order. For this reason, the receive constraints in the current CenWits prototype do not include record gap. Suppose i specifies a hop count value of 3. In this case, j checks the hop count field of every witness record before sending them. If the hop count value is greater than 3, the record is not transmitted. .3 Groups and Partitions To further reduce communication and increase the  lifetime of our system, we introduce the notion of groups. The idea is based on the concept of abstract regions presented in [20]. A group is a set of n nodes that can be defined in terms of radio connectivity, geographic location, or other properties of nodes. All nodes within a group can  communicate directly with one another and they share information to maintain their view of the external world. At any point in time, a group has exactly one leader that communicates 85 with external nodes on behalf of the entire group. A group can be static, meaning that the group membership does not change over the period of time, or it could be dynamic in which case nodes can leave or join the group. To make our analysis simple and to explain the advantages of group, we first discuss static groups. A static group is formed at the start of a hiking trail or ski slope. Suppose there are five family members who want to go for a hike in the Rocky Mountain National Park. Before these members start their hike, each one of them is given a sensor node and the information is entered in the system that the five nodes form a group. Each group member is given a unique id and every group member knows about other members of the group. The group, as a whole, is also assigned an id to distinguish it from other groups in the system. Figure 10: A group of five people. Node 2 is the group leader and it is communicating on behalf of the group with an external node 17. All other (shown in a lighter shade) are in sleep mode. As the group moves through the trail, it exchanges  information with other nodes or groups that it comes across. At any point in time, only one group member, called the leader, sends and receives information on behalf of the group and all other n − 1 group members are put in the sleep mode (See Figure 10). It is this property of groups that saves us energy. The group leadership is time-multiplexed among the group members. This is done to make sure that a single node does not run out of battery due to continuous exchange of information. Thus after every t seconds, the leadership is passed on to another node, called the successor, and the leader (now an ordinary member) is put to sleep. Since energy is dear, we do not implement an extensive election algorithm for choosing the successor. Instead, we choose the successor on the basis of node id. The node with the next highest id in the group is chosen as the successor. The last node, of course, chooses the node with the lowest id as its successor. We now discuss the data storage schemes for groups.  Memory is a scarce resource in sensor nodes and it is therefore  important that witness information be stored efficiently among group members. Efficient data storage is not a trivial task when it comes to groups. The tradeoff is between simplicity of the scheme and memory savings. A simpler scheme  incurs lesser energy cost as compared to a more sophisticated scheme, but offers lesser memory savings as well. This is because in a more complicated scheme, the group members have to coordinate to update and store information. After considering a number of different schemes, we have come to a conclusion that there is no optimal storage scheme for groups. The system should be able to adapt according to its requirements. If group members are low on battery, then the group can adapt a scheme that is more energy efficient. Similarly, if the group members are running out of memory, they can adapt a scheme that is more memory efficient. We first present a simple scheme that is very energy efficient but does not offer significant memory savings. We then present an alternate scheme that is much more memory efficient. As already mentioned a group can receive information only through the group leader. Whenever the leader comes across an external node e, it receives information from that node and saves it. In our first scheme, when the timeslot for the leader expires, the leader passes this new information it received from e to its successor. This is important because during the next time slot, if the new leader comes across another external node, it should be able to pass  information about all the external nodes this group has witnessed so far. Thus the information is fully replicated on all nodes to maintain the correct view of the world. Our first scheme does not offer any memory savings but is highly energy efficient and may be a good choice when the group members are running low on battery. Except for the time when the leadership is switched, all n − 1 members are asleep at any given time. This means that a single member is up for t seconds once every n∗t seconds and therefore has to spend approximately only 1/nth of its energy. Thus, if there are 5 members in a group, we save 80% energy, which is huge. More energy can be saved by increasing the group size. We now present an alternate data storage scheme that aims at saving memory at the cost of energy. In this scheme we divide the group into what we call partitions. Partitions can be thought of as subgroups within a group. Each  partition must have at least two nodes in it. The nodes within a partition are called peers. Each partition has one peer  designated as partition leader. The partition leader stays in  receive mode at all times, while all others peers a partition stay in the sleep mode. Partition leadership is time-multiplexed among the peers to make sure that a single node does not run out of battery. Like before, a group has exactly one leader and the leadership is time-multiplexed among  partitions. The group leader also serves as the partition leader for the partition it belongs to (See Figure 11). In this scheme, all partition leaders participate in  information exchange. Whenever a group comes across an external node e, every partition leader receives all witness  information, but it only stores a subset of that information after filtering. Information is filtered in such a way that each partition leader has to store only B/K bytes of data, where K is the number of partitions and B is the total number of bytes received from e. Similarly when a group wants to send witness information to e, each partition leader sends only B/K bytes that are stored in the partition it belongs to. However, before a partition leader can send information, it must switch from receive mode to send mode. Also,  partition leaders must coordinate with one another to ensure that they do not send their witness information at the same time, i.e. their message do not collide. All this is achieved by having the group leader send a signal to every partition leader in turn. 86 Figure 11: The figure shows a group of eight nodes divided into four partitions of 2 nodes each. Node  is the group leader whereas nodes 2, 9, and 7 are partition leaders. All other nodes are in the sleep mode. Since the partition leadership is time-multiplexed, it is important that any information received by the partition leader, p1, be passed on to the next leader, p2. This has to be done to make sure that p2 has all the information that it might need to send when it comes across another external node during its timeslot. One way of achieving this is to wake p2 up just before p1"s timeslot expires and then have p1 transfer information only to p2. An alternate is to wake all the peers up at the time of leadership change, and then have p1 broadcast the information to all peers. Each peer saves the information sent by p1 and then goes back to sleep. In both cases, the peers send acknowledgement to the partition leader after receiving the information. In the former method, only one node needs to wake up at the time of leadership change, but the amount of information that has to be transmitted between the nodes increases as time passes. In the latter case, all nodes have to be woken up at the time of leadership change, but small piece of information has to be transmitted each time among the peers. Since communication is much more expensive than bringing the nodes up, we prefer the second method over the first one. A group can be divided into partitions in more than one way. For example, suppose we have a group of six members. We can divide this group into three partitions of two peers each, or two partitions with three peers each. The choice once again depends on the requirements of the system. A few big partitions will make the system more energy efficient. This is because in this configuration, a greater number of nodes will stay in sleep mode at any given point in time. On the other hand, several small partitions will make the system memory efficient, since each node will have to store lesser information (See Figure 12). A group that is divided into partitions must be able to readjust itself when a node leaves or runs out of battery. This is crucial because a partition must have at least two nodes at any point in time to tolerate failure of one node. For example, in figure 3 (a), if node 2 or node 5 dies, the partition is left with only one node. Later on, if that single node in the partition dies, all witness information stored in that partition will be lost. We have devised a very simple protocol to solve this problem. We first explain how  partiFigure 12: The figure shows two different ways of partitioning a group of six nodes. In (a), a group is divided into three partitions of two nodes. Node  is the group leader, nodes 9 and 5 are partition leaders, and nodes 2, 3, and 6 are in sleep mode. In (b) the group is divided into two partitions of three nodes. Node 1 is the group leader, node 9 is the partition leader and nodes 2, 3, 5, and 6 are in sleep mode. tions are adjusted when a peer dies, and then explain what happens if a partition leader dies. Suppose node 2 in figure 3 (a) dies. When node 5, the partition leader, sends information to node 2, it does not  receive an acknowledgement from it and concludes that node  has died2 . At this point, node 5 contacts other partition leaders (nodes 1 ... 9) using a broadcast message and  informs them that one of its peers has died. Upon hearing this, each partition leader informs node 5 (i) the number of nodes in its partition, (ii) a candidate node that node 5 can take if the number of nodes in its partition is greater than , and (iii) the amount of witness information stored in its partition. Upon hearing from every leader, node 5 chooses the candidate node from the partition with maximum  number (must be greater than 2) of peers, and sends a message back to all leaders. Node 5 then sends data to its new peer to make sure that the information is replicated within the partition. However, if all partitions have exactly two nodes, then node 5 must join another partition. It chooses the partition that has the least amount of witness information to join. It sends its witness information to the new partition leader. Witness information and membership update is propagated to all peers during the next partition leadership change. We now consider the case where the partition leader dies. If this happens, then we wait for the partition leadership to change and for the new partition leader to eventually find out that a peer has died. Once the new partition leader finds out that it needs more peers, it proceeds with the protocol explained above. However, in this case, we do lose  information that the previous partition leader might have received just before it died. This problem can be solved by  implementing a more rigorous protocol, but we have decided to give up on accuracy to save energy. Our current design uses time-division multiplexing to  schedule wakeup and sleep modes in the sensor nodes. However, recent work on radio wakeup sensors [10] can be used to do this scheduling more efficiently. we plan to incorporate radio wakeup sensors in CenWits when the hardware is mature.  The algorithm to conclude that a node has died can be made more rigorous by having the partition leader query the suspected node a few times. 87 . SYSTEM EVALUATION A sensor is constrained in the amount of memory and power. In general, the amount of memory needed and power consumption depends on a variety of factors such as node density, number of hiker encounters, and the number of  access points. In this Section, we provide an estimate of how long the power of a MICA2 mote will last under certain assumtions. First, we assume that each sensor node carries about 100 witness records. On encountering another hiker, a sensor node transmits 50 witness records and receives 50 new  witness records. Since, each record is 16 bytes long, it will take .34 seconds to transmit 50 records and another 0.34  seconds to receive 50 records over a 19200 bps link. The power consumption of MICA2 due to CPU processing,  transmission and reception are approximately 8.0 mA, 7.0 mA and .5 mA per hour respectively [18], and the capacity of an alkaline battery is 2500mAh. Since the radio module of Mica2 is half-duplex and  assuming that the CPU is always active when a node is awake, power consumption due to transmission is 8 + 8.5 = 16.5 mA per hour and due to reception is 8 + 7 = 15mA per hour. So, average power consumtion due to transmission and reception is (16.5 + 15)/2 = 15.75 mA per hour. Given that the capacity of an alkaline battery is 2500 mAh, a battery should last for 2500/15.75 = 159 hours of transmission and reception. An encounter between two  hikers results in exchange of about 50 witness records that takes about 0.68 seconds as calculated above. Thus, a single  alkaline battery can last for (159 ∗ 60 ∗ 60)/0.68 = 841764 hiker encounters. Assuming that a node emits a beacon every 90 seconds and a hiker encounter occurs everytime a beacon is emitted (worst-case scenario), a single alkaline battery will last for (841764 ∗ 90)/(30 ∗ 24 ∗ 60 ∗ 60) = 29 days. Since, a Mica2 is equipped with two batteries, a Mica2 sensor can remain operation for about two months. Notice that this  calculation is preliminary, because it assumes that hikers are active 4 hours of the day and a hiker encounter occurs every 90 seconds. In a more realistic scenario, power is expected to last for a much longer time period. Also, this time period will significantly increase when groups of hikers are moving together. Finally, the lifetime of a sensor running on two  batteries can definitely be increased significantly by using energy scavenging techniques and energy harvesting techniques [16, 4]. . PROTOTYPE IMPLEMENTATION We have implemented a prototype of CenWits on MICA2 sensor 900MHz running Mantis OS 0.9.1b. One of the sensor is equipped with MTS420CA GPS module, which is capable of barometric pressure and two-axis acceleration sensing in addition to GPS location tracking. We use SiRF, the serial communication protocol, to control GPS module. SiRF has a rich command set, but we record only X and Y coordinates. A witness record is 16 bytes long. When a node starts up, it stores its current location and emits a beacon  periodicallyin the prototype, a node emits a beacon every minute. We have conducted a number of experiments with this prototype. A detailed report on these experiments with the raw data collected and photographs of hikers, access points etc. is available at http://csel.cs.colorado.edu/∼huangjh/ Cenwits.index.htm. Here we report results from three of them. In all these experiments, there are three access points (A, B and C) where nodes dump their witness information. These access points also provide location information to the nodes that come with in their range. We first show how  CenWits can be used to determine the hiking trail a hiker is most likely on and the speed at which he is hiking, and identify hot search areas in case he is reported missing. Next, we show the results of power and memory management  techniques of CenWits in conserving power and memory of a sensor node in one of our experiments. .1 Locating Lost Hikers The first experiment is called Direct Contact. It is a very simple experiment in which a single hiker starts from A, goes to B and then C, and finally returns to A (See Figure 3). The goal of this experiment is to illustrate that  CenWits can deduce the trail a hiker takes by processing witness information. Figure 13: Direct Contact Experiment Node Id Record (X,Y) Location Hop Time Time Count  15 (12,7) 15 0  33 (31,17) 33 0  46 (12,23) 46 0  10 (12,7) 10 0  48 (12,23) 48 0  16 (12,7) 16 0  34 (31,17) 34 0 Table 1: Witness information collected in the direct contact experiment. The witness information dumped at the three access points was then collected and processed at a control center. Part of the witness information collected at the control center is shown in Table 1. The X,Y locations in this table  correspond to the location information provided by access points A, B, and C. A is located at (12,7), B is located at (31,17) and C is located at (12,23). Three encounter points  (between hiker 1 and the three access points) extracted from 88 this witness information are shown in Figure 13 (shown in rectangular boxes). For example, A,1 at 16 means 1 came in contact with A at time 16. Using this information, we can infer the direction in which hiker 1 was moving and speed at which he was moving. Furthermore, given a map of hiking trails in this area, it is clearly possible to identify the hiking trail that hiker 1 took. The second experiment is called Indirect Inference. This experiment is designed to illustrate that the location,  direction and speed of a hiker can be inferred by CenWits, even if the hiker never comes in the range of any access point. It illustrates the importance of witness information in search and rescue applications. In this experiment, there are three hikers, 1, 2 and 3. Hiker 1 takes a trail that goes along  access points A and B, while hiker 3 takes trail that goes along access points C and B. Hiker 2 takes a trail that does not come in the range of any access points. However, this hiker meets hiker 1 and 3 during his hike. This is illustrated in Figure 14. Figure 14: Indirect Inference Experiment Node Id Record (X,Y) Location Hop Time Time Count  16 (12,7) 6 0  15 (12,7) 6 0  4 (12,7) 4 0  6 (12,7) 6 0  29 (31,17) 29 0  31 (31,17) 31 0 Table 2: Witness information collected from hiker 1 in indirect inference experiment. Part of the witness information collected at the control center from access points A, B and C is shown in Tables  and 3. There are some interesting data in these tables. For example, the location time in some witness records is not the same as the record time. This means that the node that generated that record did not have its most up-to-date location at the encounter time. For example, when hikers  and 2 meet at time 16, the last recorded location time of Node Id Record (X,Y) Location Hop Time Time Count  78 (12,23) 78 0  107 (31,17) 107 0  106 (31,17) 106 0  76 (12,23) 76 0  79 (12,23) 79 0  94 (12,23) 79 0  16 (?,?) ? 1  15 (?,?) ? 1 Table 3: Witness information collected from hiker 3 in indirect inference experiment. hiker 1 is (12,7) recorded at time 6. So, node 1 generates a witness record with record time 16, location (12,7) and location time 6. In fact, the last two records in Table 3 have (?,?) as their location. This has happened because these witness records were generate by hiker 2 during his encounter with 1 at time 15 and 16. Until this time, hiker  hadn"t come in contact with any location points. Interestingly, a more accurate location information of 1 and 2 encounter or 2 and 3 encounter can be computed by process the witness information at the control center. It took 25 units of time for hiker 1 to go from A (12,7) to B (31,17). Assuming a constant hiking speed and a relatively straight-line hike, it can be computed that at time 16, hiker  must have been at location (18,10). Thus (18,10) is a more accurate location of encounter between 1 and 2. Finally, our third experiment called Identifying Hot Search Areas is designed to determine the trail a hiker has taken and identify hot search areas for rescue after he is reported missing. There are six hikers (1, 2, 3, 4, 5 and 6) in this experiment. Figure 15 shows the trails that hikers 1, 2, , 4 and 5 took, along with the encounter points obtained from witness records collected at the control center. For brevity, we have not shown the entire witness information collected at the control center. This information is available at http://csel.cs.colorado.edu/∼huangjh/Cenwits/index.htm. Figure 15: Identifying Hot Search Area Experiment (without hiker 6) 89 Now suppose hiker 6 is reported missing at time 260. To determine the hot search areas, the witness records of hiker  are processed to determine the trail he is most likely on, the speed at which he had been moving, direction in which he had been moving, and his last known location. Based on this information and the hiking trail map, hot search areas are identified. The hiking trail taken by hiker 6 as inferred by CenWits is shown by a dotted line and the hot search areas identified by CenWits are shown by dark lines inside the dotted circle in Figure 16. Figure 16: Identifying Hot Search Area Experiment (with hiker 6) .2 Results of Power and Memory  Management The witness information shown in Tables 1, 2 and 3 has not been filtered using the three criteria described in  Section 4.1. For example, the witness records generated by 3 at record times 76, 78 and 79 (see Table 3) have all been  generated due a single contact between access point C and node . By applying the record gap criteria, two of these three records will be erased. Similarly, the witness records  generated by 1 at record times 10, 15 and 16 (see Table 1) have all been generated due a single contact between access point A and node 1. Again, by applying the record gap criteria, two of these three records will be erased. Our experiments did not generate enough data to test the impact of record count or hop count criteria. To evaluate the impact of these criteria, we simulated  CenWits to generate a significantly large number of records for a given number of hikers and access points. We generated  witness records by having the hikers walk randomly. We applied the three criteria to measure the amount of memory savings in a sensor node. The results are shown in Table 4. The number of hikers in this simulation was 10 and the number of access points was 5. The number of witness records  reported in this table is an average number of witness records a sensor node stored at the time of dump to an access point. These results show that the three memory management criteria significantly reduces the memory consumption of sensor nodes in CenWits. For example, they can reduce MAX MIN MAX # of RECORD RECORD HOP Witness COUNT GAP COUNT Records  5 5 628  5 5 421  5 5 316  10 5 311  20 5 207  5 4 462  5 3 341  20 3 161 Table 4: Impact of memory management techniques. the memory consumption by up to 75%. However, these results are premature at present for two reasons: (1) They are generated via simulation of hikers walking at random; and (2) It is not clear what impact the erasing of witness records has on the accuracy of inferred location/hot search areas of lost hikers. In our future work, we plan to undertake a major study to address these two concerns. . OTHER APPLICATIONS In addition to the hiking in wilderness areas, CenWits can be used in several other applications, e.g. skiing, climbing, wild life monitoring, and person tracking. Since CenWits  relies only on intermittent connectivity, it can take advantage of the existing cheap and mature technologies, and thereby make tracking cheaper and fairly accurate. Since CenWits doesn"t rely on keeping track of a sensor holder all time, but relies on maintaining witnesses, the system is relatively cheaper and widely applicable. For example, there are some dangerous cliffs in most ski resorts. But it is too expensive for a ski resort to deploy a connected wireless sensor network through out the mountain. Using CenWits, we can deploy some sensors at the cliff boundaries. These boundary  sensors emit beacons quite frequently, e.g. every second, and so can record presence of skiers who cross the boundary and fall off the cliff. Ski patrols can cruise the mountains every hour, and automatically query the boundary sensor when in range using PDAs. If a PDA shows that a skier has been close to the boundary sensor, the ski patrol can use a long range walkie-talkie to query control center at the resort base to check the witness record of the skier. If there is no  witness record after the recorded time in the boundary sensor, there is a high chance that a rescue is needed. In wildlife monitoring, a very popular method is to attach a GPS receiver on the animals. To collect data, either a satellite transmitter is used, or the data collector has to wait until the GPS receiver brace falls off (after a year or so) and then search for the GPS receiver. GPS transmitters are very expensive, e.g. the one used in geese tracking is $3,000 each [2]. Also, it is not yet known if continuous radio signal is harmful to the birds. Furthermore, a GPS transmitter is quite bulky and uncomfortable, and as a result, birds always try to get rid of it. Using CenWits, not only can we record the presence of wildlife, we can also record the behavior of wild animals, e.g. lions might follow the migration of deers. CenWits does nor require any bulky and expensive satellite transmitters, nor is there a need to wait for a year and search for the braces. CenWits provides a very simple and cost-effective solution in this case. Also, access points 90 can be strategically located, e.g. near a water source, to increase chances of collecting up-to-date data. In fact, the access points need not be statically located. They can be placed in a low-altitude plane (e.g a UAV) and be flown over a wilderness area to collect data from wildlife. In large cities, CenWits can be used to complement GPS, since GPS doesn"t work indoor and near skyscrapers. If a person A is reported missing, and from the witness records we find that his last contacts were C and D, we can trace an approximate location quickly and quite efficiently. . DISCUSSION AND FUTURE WORK This paper presents a new search and rescue system called CenWits that has several advantages over the current search and rescue systems. These advantages include a  looselycoupled system that relies only on intermittent network  connectivity, power and storage efficiency, and low cost. It solves one of the greatest problems plaguing modern search and rescue systems: it has an inherent on-site storage  capability. This means someone within the network will have access to the last-known-location information of a victim, and perhaps his bearing and speed information as well. It utilizes the concept of witnesses to propagate information, infer current possible location and speed of a subject, and identify hot search and rescue areas in case of emergencies. A large part of CenWits design focuses on addressing the power and memory limitations of current sensor nodes. In fact, power and memory constraints depend on how much weight (of sensor node) a hiker is willing to carry and the cost of these sensors. An important goal of CenWits is build small chips that can be implanted in hiking boots or ski jackets. This goal is similar to the avalanche beacons that are currently implanted in ski jackets. We anticipate that power and memory will continue to be constrained in such an environment. While the paper focuses on the development of a search and rescue system, it also provides some innovative,  systemlevel ideas for information processing in a sensor network system. We have developed and experimented with a basic  prototype of CenWits at present. Future work includes  developing a more mature prototype addressing important issues such as security, privacy, and high availability. There are several pressing concerns regarding security, privacy, and high availability in CenWits. For example, an adversary can sniff the witness information to locate endangered  animals, females, children, etc. He may inject false information in the system. An individual may not be comfortable with providing his/her location and movement information, even though he/she is definitely interested in being located in a timely manner at the time of emergency. In general, people in hiking community are friendly and usually trustworthy. So, a bullet-proof security is not really required. However, when CenWits is used in the context of other applications, security requirements may change. Since the sensor nodes used in CenWits are fragile, they can fail. In fact, the nature and level of security, privacy and high availability support needed in CenWits strongly depends on the application for which it is being used and the individual subjects involved. Accordingly, we plan to design a multi-level support for  security, privacy and high availability in CenWits. So far, we have experimented with CenWits in a very restricted environment with a small number of sensors. Our next goal is to deploy this system in a much larger and more realistic environment. In particular, discussions are currenly underway to deploy CenWits in the Rocky Mountain and Yosemite National Parks. . REFERENCES [1] 802.11-based tracking system. http://www.pangonetworks.com/locator.htm. [2] Brent geese 2002. http://www.wwt.org.uk/brent/. [3] The onstar system. http://www.onstar.com. [4] Personal locator beacons with GPS receiver and satellite transmitter. http://www.aeromedix.com/. [5] Personal tracking using GPS and GSM system. http://www.ulocate.com/trimtrac.html. [6] Rf based kid tracking system. http://www.ion-kids.com/. [7] F. Alessio. Performance measurements with motes technology. MSWiM"04, 2004. [8] P. Bahl and V. N. Padmanabhan. RADAR: An in-building RF-based user location and tracking system. IEEE Infocom, 2000. [9] K. Fall. A delay-tolerant network architecture for challenged internets. In SIGCOMM, 2003. [10] L. Gu and J. Stankovic. Radio triggered wake-up capability for sensor networks. In Real-Time Applications Symposium, 2004. [11] J. Hightower and G. Borriello. Location systems for ubiquitous computing. IEEE Computer, 2001. [12] W. Jaskowski, K. Jedrzejek, B. Nyczkowski, and S. Skowronek. Lifetch life saving system. CSIDC, 2004. [13] P. Juang, H. Oki, Y. Wang, M. Martonosi, L. Peh, and D. Rubenstein. Energy-efficient computing for wildlife tracking: design tradeoffs and early experiences with ZebraNet. In ASPLOS, 2002. [14] K. Kansal and M. Srivastava. Energy harvesting aware power management. In Wireless Sensor Networks: A Systems Perspective, 2005. [15] G. J. Pottie and W. J. Kaiser. Embedding the internet: wireless integrated network sensors. Communications of the ACM, 43(5), May 2000. [16] S. Roundy, P. K. Wright, and J. Rabaey. A study of low-level vibrations as a power source for wireless sensor networks. Computer Communications, 26(11), 003. [17] C. Savarese, J. M. Rabaey, and J. Beutel. Locationing in distributed ad-hoc wireless sensor networks. ICASSP, 2001. [18] V. Shnayder, M. Hempstead, B. Chen, G. Allen, and M. Welsh. Simulating the power consumption of large-scale sensor network applications. In Sensys, 004. [19] R. Want and A. Hopper. Active badges and personal interactive computing objects. IEEE Transactions of Consumer Electronics, 1992. [20] M. Welsh and G. Mainland. Programming sensor networks using abstract regions. First USENIX/ACM Symposium on Networked Systems Design and Implementation (NSDI "04), 2004. 91
Fairness in Dead-Reckoning based Distributed Multi-Player Games Sudhir Aggarwal Hemant Banavar Department of Computer Science Florida State University, Tallahassee, FL Email: {sudhir, banavar}@cs.fsu.edu Sarit Mukherjee Sampath Rangarajan Center for Networking Research Bell Laboratories, Holmdel, NJ Email: {sarit, sampath}@bell-labs.com ABSTRACT In a distributed multi-player game that uses dead-reckoning vectors to exchange movement information among players, there is  inaccuracy in rendering the objects at the receiver due to network delay between the sender and the receiver. The object is placed at the  receiver at the position indicated by the dead-reckoning vector, but by that time, the real position could have changed considerably at the sender. This inaccuracy would be tolerable if it is consistent among all players; that is, at the same physical time, all players see  inaccurate (with respect to the real position of the object) but the same position and trajectory for an object. But due to varying network delays between the sender and different receivers, the inaccuracy is different at different players as well. This leads to unfairness in game playing. In this paper, we first introduce an error  measure for estimating this inaccuracy. Then we develop an algorithm for scheduling the sending of dead-reckoning vectors at a sender that strives to make this error equal at different receivers over time. This algorithm makes the game very fair at the expense of  increasing the overall mean error of all players. To mitigate this effect, we propose a budget based algorithm that provides improved fairness without increasing the mean error thereby maintaining the accuracy of game playing. We have implemented both the scheduling  algorithm and the budget based algorithm as part of BZFlag, a popular distributed multi-player game. We show through experiments that these algorithms provide fairness among players in spite of widely varying network delays. An additional property of the proposed  algorithms is that they require less number of DRs to be exchanged (compared to the current implementation of BZflag) to achieve the same level of accuracy in game playing. Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed  Systems-Distributed applications General Terms Algorithms, Design, Experimentation, Performance . INTRODUCTION In a distributed multi-player game, players are normally  distributed across the Internet and have varying delays to each other or to a central game server. Usually, in such games, the players are part of the game and in addition they may control entities that make up the game. During the course of the game, the players and the entities move within the game space. A player sends information about her movement as well as the movement of the entities she controls to the other players using a Dead-Reckoning (DR) vector. A DR vector contains information about the current position of the player/entity in terms of x, y and z coordinates (at the time the DR vector was sent) as well as the trajectory of the entity in terms of the velocity component in each of the dimensions. Each of the  participating players receives such DR vectors from one another and renders the other players/entities on the local consoles until a new DR vector is received for that player/entity. In a peer-to-peer game, players send DR vectors directly to each other; in a client-server game, these DR vectors may be forwarded through a game server. The idea of DR is used because it is almost impossible for  players/entities to exchange their current positions at every time unit. DR vectors are quantization of the real trajectory (which we refer to as real path) at a player. Normally, a new DR vector is computed and sent whenever the real path deviates from the path extrapolated using the previous DR vector (say, in terms of distance in the x, y, z plane) by some amount specified by a threshold. We refer to the trajectory that can be computed using the sequence of DR vectors as the exported path. Therefore, at the sending player, there is a  deviation between the real path and the exported path. The error due to this deviation can be removed if each movement of player/entity is communicated to the other players at every time unit; that is a DR vector is generated at every time unit thereby making the real and exported paths the same. Given that it is not feasible to  satisfy this due to bandwidth limitations, this error is not of practical interest. Therefore, the receiving players can, at best, follow the exported path. Because of the network delay between the sending and receiving players, when a DR vector is received and rendered at a player, the original trajectory of the player/entity may have  already changed. Thus, in physical time, there is a deviation at the receiving player between the exported path and the rendered  trajectory (which we refer to as placed path). We refer to this error as the export error. Note that the export error, in turn, results in a deviation between the real and the placed paths. The export error manifests itself due to the deviation between the exported path at the sender and the placed path at the receiver (i)  before the DR vector is received at the receiver (referred to as the before export error, and (ii) after the DR vector is received at the  receiver (referred to as the after export error). In an earlier paper [1], we showed that by synchronizing the clocks at all the players and by using a technique based on time-stamping messages that carry the DR vectors, we can guarantee that the after export error is made zero. That is, the placed and the exported paths match after the DR vector is received. We also showed that the before export error can never be eliminated since there is always a non-zero network delay, but can be significantly reduced using our technique [1].  Henceforth we assume that the players use such a technique which results in unavoidable but small overall export error. In this paper we consider the problem of different and varying network delays between each sender-receiver pair of a DR vector, and consequently, the different and varying export errors at the  receivers. Due to the difference in the export errors among the  receivers, the same entity is rendered at different physical time at different receivers. This brings in unfairness in game playing. For instance a player with a large delay would always see an entity late in physical time compared to the other players and,  therefore, her action on the entity would be delayed (in physical time) even if she reacted instantaneously after the entity was rendered. Our goal in this paper is to improve the fairness of these games in spite of the varying network delays by equalizing the export error at the players. We explore whether the time-average of the export errors (which is the cumulative export error over a period of time averaged over the time period) at all the players can be made the same by scheduling the sending of the DR vectors appropriately at the sender. We propose two algorithms to achieve this. Both the algorithms are based on delaying (or dropping) the sending of DR vectors to some players on a continuous basis to try and make the export error the same at all the players. At an abstract level, the algorithm delays sending DR vectors to players whose accumulated error so far in the game is smaller than others; this would mean that the export error due to this DR vector at these players will be larger than that of the other players, thereby making them the same. The goal is to make this error at least approximately equal at every DR vector with the deviation in the error becoming smaller as time progresses. The first algorithm (which we refer to as the scheduling  algorithm) is based on estimating the delay between players and  refining the sending of DR vectors by scheduling them to be sent to different players at different times at every DR generation point. Through an implementation of this algorithm using the open source game BZflag, we show that this algorithm makes the game very fair (we measure fairness in terms of the standard deviation of the  error). The drawback of this algorithm is that it tends to push the error of all the players towards that of the player with the worst error (which is the error at the farthest player, in terms of delay, from the sender of the DR). To alleviate this effect, we propose a budget based algorithm which budgets how the DRs are sent to different players. At a high level, the algorithm is based on the idea of sending more DRs to players who are farther away from the sender compared to those who are closer. Experimental results from BZflag illustrates that the budget based algorithm follows a more balanced approach. It improves the fairness of the game but at the same time does so without pushing up the mean error of the players thereby maintaining the accuracy of the game. In addition, the budget based algorithm is shown to achieve the same level of accuracy of game playing as the current implementation of BZflag using much less number of DR vectors. . PREVIOUS WORK Earlier work on network games to deal with network latency has mostly focussed on compensation techniques for packet delay and loss [2, 3, 4]. These methods are aimed at making large delays and message loss tolerable for players but does not consider the  problems that may be introduced by varying delays from the server to different players or from the players to one another. For example, the concept of local lag has been used in [3] where each player delays every local operation for a certain amount of time so that  remote players can receive information about the local operation and execute the same operation at the about same time, thus reducing state inconsistencies. The online multi-player game MiMaze [2, 5, ], for example, takes a static bucket synchronization approach to compensate for variable network delays. In MiMaze, each player delays all events by 100 ms regardless of whether they are  generated locally or remotely. Players with a network delay larger than 100 ms simply cannot participate in the game. In general, techniques based on bucket synchronization depend on imposing a worst case delay on all the players. There have been a few papers which have studied the problem of fairness in a distributed game by more sophisticated message  delivery mechanisms. But these works [7, 8] assume the existence of a global view of the game where a game server maintains a view (or state) of the game. Players can introduce objects into the game or delete objects that are already part of the game (for example, in a first-person shooter game, by shooting down the object). These additions and deletions are communicated to the game server  using action messages. Based on these action messages, the state of the game is changed at the game server and these changes are communicated to the players using update messages. Fairness is achieved by ordering the delivery of action and update messages at the game server and players respectively based on the notion of a fair-order which takes into account the delays between the game server and the different players. Objects that are part of the game may move but how this information is communicated to the players seems to be beyond the scope of these works. In this sense, these works are very limited in scope and may be applicable only to  firstperson shooter games and that too to only games where players are not part of the game. DR vectors can be exchanged directly among the players  (peerto-peer model) or using a central server as a relay (client-server model). It has been shown in [9] that multi-player games that use DR vectors together with bucket synchronization are not  cheatproof unless additional mechanisms are put in place. Both the scheduling algorithm and the budget-based algorithm described in our paper use DR vectors and hence are not cheat-proof. For  example, a receiver could skew the delay estimate at the sender to make the sender believe that the delay between the sender and the receiver is high thereby gaining undue advantage. We emphasize that the focus of this paper is on fairness without addressing the issue of cheating. In the next section, we describe the game model that we use and illustrate how senders and receivers exchange DR vectors and how entities are rendered at the receivers based on the time-stamp augmented DR vector exchange as described in [1]. In Section 4, we describe the DR vector scheduling algorithm that aims to make the export error equal across the players with varying delays from the sender of a DR vector, followed by experimental results  obtained from instrumentation of the scheduling algorithm on the open source game BZFlag. Section 5, describes the budget based algorithm that achieves improved fairness but without reducing the level accuracy of game playing. Conclusions are presented in  Section 6.  . GAME MODEL The game architecture is based on players distributed across the Internet and exchanging DR vectors to each other. The DR  vectors could either be sent directly from one player to another  (peerto-peer model) or could be sent through a game server which  receives the DR vector from a player and forwards it to other players (client-server model). As mentioned before, we assume  synchronized clocks among the participating players. Each DR vector sent from one player to another specifies the  trajectory of exactly one player/entity. We assume a linear DR vector in that the information contained in the DR vector is only enough at the receiving player to compute the trajectory and render the entity in a straight line path. Such a DR vector contains information about the starting position and velocity of the player/entity where the  velocity is constant1 . Thus, the DR vectors sent by a player specifies the current time at the player when the DR vector is computed (not the time at which this DR vector is sent to the other players as we will explain later), the current position of the player/entity in terms of the x, y, z coordinates and the velocity vector in the direction of x, y and z coordinates. Specifically, the ith DR vector sent by player j about the kth entity is denoted by DRj ik and is represented by the following tuple (Tj ik, xj ik, yj ik, zj ik, vxj ik, vyj ik, vzj ik). Without loss of generality, in the rest of the discussion, we  consider a sequence of DR vectors sent by only one player and for only one entity. For simplicity, we consider a two dimensional game space rather than a three dimensional one. Hence we use DRi to denote the ith such DR vector represented as the tuple (Ti, xi, yi, vxi, vyi). The receiving player computes the starting position for the entity based on xi, yi and the time difference  between when the DR vector is received and the time Ti at which it was computed. Note that the computation of time difference is  feasible since all the clocks are synchronized. The receiving player then uses the velocity components to project and render the  trajectory of the entity. This trajectory is followed until a new DR vector is received which changes the position and/or velocity of the entity. timeT1 Real Exported Placed dt1 A B C D DR1 = (T1, x1, y1, vx1, vy1) computed at time T1 and sent to the receiver DR0 = (T0, x0, y0, vx0, vy0) computed at time T0 and sent to the receiver T0 dt0 Placed E Figure 1: Trajectories and deviations. Based on this model, Figure 1 illustrates the sending and  receiv1 Other type of DR vectors include quadratic DR vectors which specify the acceleration of the entity and cubic spline DR vectors that consider the starting position and velocity and the ending  position and velocity of the entity. ing of DR vectors and the different errors that are encountered. The figure shows the reception of DR vectors at a player (henceforth called the receiver). The horizontal axis shows the time which is synchronized among all the players. The vertical axis tries to  conceptually capture the two-dimensional position of an entity.  Assume that at time T0 a DR vector DR0 is computed by the sender and immediately sent to the receiver. Assume that DR0 is received at the receiver after a delay of dt0 time units. The receiver  computes the initial position of the entity as (x0 + vx0 × dt0, y0 + vy0 × dt0) (shown as point E). The thick line EBD represents the projected and rendered trajectory at the receiver based on the  velocity components vx0 and vy0 (placed path). At time T1 a DR vector DR1 is computed for the same entity and immediately sent to the receiver2 . Assume that DR1 is received at the receiver after a delay of dt1 time units. When this DR vector is received, assume that the entity is at point D. A new position for the entity is computed as (x1 + vx1 × dt1, y1 + vy0 × dt1) and the entity is moved to this position (point C). The velocity components vx1 and vy1 are used to project and render this entity further. Let us now consider the error due to network delay. Although DR1 was computed at time T1 and sent to the receiver, it did not reach the receiver until time T1 + dt1. This means, although the exported path based on DR1 at the sender at time T1 is the  trajectory AC, until time T1 + dt1, at the receiver, this entity was being rendered at trajectory BD based on DR0. Only at time T1 + dt1 did the entity get moved to point C from which point onwards the exported and the placed paths are the same. The deviation between the exported and placed paths creates an error component which we refer to as the export error. A way to represent the export error is to compute the integral of the distance between the two trajectories over the time when they are out of sync. We represent the integral of the distances between the placed and exported paths due to some DR DRi over a time interval [t1, t2] as Err(DRi, t1, t2). In the figure, the export error due to DR1 is computed as the integral of the distance between the trajectories AC and BD over the time interval [T1, T1 + dt1]. Note that there could be other ways of  representing this error as well, but in this paper, we use the integral of the distance between the two trajectories as a measure of the export error. Note that there would have been an export error created due to the reception of DR0 at which time the placed path would have been based on a previous DR vector. This is not shown in the figure but it serves to remind the reader that the export error is cumulative when a sequence of DR vectors are received. Starting from time T1 onwards, there is a deviation between the real and the exported paths. As we discussed earlier, this export error is unavoidable. The above figure and example illustrates one receiver only. But in reality, DR vectors DR0 and DR1 are sent by the sender to all the participating players. Each of these players receives DR0 and DR1 after varying delays thereby creating different export error values at different players. The goal of the DR vector scheduling algorithm to be described in the next section is to make this  (cumulative) export error equal at every player independently for each of the entities that make up the game. . SCHEDULING ALGORITHM  FORSENDING DR VECTORS In Section 3 we showed how delay from the sender of a new DR  Normally, DR vectors are not computed on a periodic basis but on an on-demand basis where the decision to compute a new DR vector is based on some threshold being exceeded on the deviation between the real path and the path exported by the previous DR vector.  vector to the receiver of the DR vector could lead to export error because of the deviation of the placed path from the exported path at the receiver until this new DR vector is received. We also  mentioned that the goal of the DR vector scheduling algorithm is to make the export error equal at all receivers over a period of time. Since the game is played in a distributed environment, it makes sense for the sender of an entity to keep track of all the errors at the receivers and try to make them equal. However, the sender cannot know the actual error at a receiver till it gets some information  regarding the error back from the receiver. Our algorithm estimates the error to compute a schedule to send DR vectors to the receivers and corrects the error when it gets feedbacks from the receivers. In this section we provide motivations for the algorithm and describe the steps it goes through. Throughout this section, we will use the following example to illustrate the algorithm. timeT1 Exported path Placed path at receiver 2 dt1 A B C D E F T0 G2 G1 dt2 DR1 sent to receiver 1 DR1 sent to receiver 2 T1  T1  da1 da2 G H I J K L N M DR1 estimated to be received by receiver 2 DR1 estimated to be received by receiver 1 DR1 actually received by receiver 1 DR1 actually received by receiver 2 DR0 sent to both receivers DR1 computed by sender Placed path at receiver 1 Figure 2: DR vector flow between a sender and two receivers and the evolution of estimated and actual placed paths at the receivers. DR0 = (T0, T0, x0, y0, vx0, vy0), sent at time T0 to both receivers. DR1 = (T1, T1  , x1, y1, vx1, vy1) sent at time T1  = T1+δ1 to receiver 1 and DR1 = (T1, T2  , x1, y1, vx1, vy1) sent at time T2  = T1 + δ2 to receiver 2. Consider the example in Figure 2. The figure shows a single sender sending DR vectors for an entity to two different receivers  and 2. DR0 computed at T0 is sent and received by the receivers sometime between T0 and T1 at which time they move the location of the entity to match the exported path. Thus, the path of the entity is shown only from the point where the placed path matches the exported path for DR0. Now consider DR1. At time T1, DR1 is computed by the sender but assume that it is not immediately sent to the receivers and is only sent after time δ1 to receiver 1 (at time T1  = T1 + δ1) and after time δ2 to receiver 2 (at time T2  = T1 + δ2). Note that the sender includes the sending  timestamp with the DR vector as shown in the figure. Assume that the sender estimates (it will be clear shortly why the sender has to estimate the delay) that after a delay of dt1, receiver 1 will receive it, will use the coordinate and velocity parameters to compute the entity"s current location and move it there (point C) and from this time onwards, the exported and the placed paths will become the same. However, in reality, receiver 1 receives DR1 after a delay of da1 (which is less than sender"s estimates of dt1), and moves the corresponding entity to point H. Similarly, the sender estimates that after a delay of dt2, receiver 2 will receive DR1, will compute the current location of the entity and move it to that point (point E), while in reality it receives DR1 after a delay of da2 > dt2 and moves the entity to point N. The other points shown on the placed and exported paths will be used later in the discussion to describe different error components. .1 Computation of Relative Export Error Referring back to the discussion from Section 3, from the sender"s perspective, the export error at receiver 1 due to DR1 is given by Err(DR1, T1, T1 + δ1 + dt1) (the integral of the distance  between the trajectories AC and DB over the time interval [T1, T1 + δ1 + dt1]) of Figure 2. This is due to the fact that the sender uses the estimated delay dt1 to compute this error. Similarly, the  export error from the sender"s perspective at received 2 due to DR1 is given by Err(DR1, T1, T1 + δ2 + dt2) (the integral of the  distance between the trajectories AE and DF over the time interval [T1, T1 + δ2 + dt2]). Note that the above errors from the sender"s perspective are only estimates. In reality, the export error will be either smaller or larger than the estimated value, based on whether the delay estimate was larger or smaller than the actual delay that DR1 experienced. This difference between the estimated and the actual export error is the relative export error (which could either be positive or negative) which occurs for every DR vector that is sent and is accumulated at the sender. The concept of relative export error is illustrated in Figure 2. Since the actual delay to receiver 1 is da1, the export error  induced by DR1 at receiver 1 is Err(DR1, T1, T1 + δ1 + da1). This means, there is an error in the estimated export error and the sender can compute this error only after it gets a feedback from the receiver about the actual delay for the delivery of DR1, i.e., the value of da1. We propose that once receiver 1 receives DR1, it sends the value of da1 back to the sender. The receiver can  compute this information as it knows the time at which DR1 was sent (T1  = T1 + δ1, which is appended to the DR vector as shown in Figure 2) and the local receiving time (which is synchronized with the sender"s clock). Therefore, the sender computes the relative export error for receiver 1, represented using R1 as R1 = Err(DR1, T1, T1 + δ1 + dt1) − Err(DR1, T1, T1 + δ1 + da1) = Err(DR1, T1 + δ1 + dt1, T1 + δ1 + da1) Similarly the relative export error for receiver 2 is computed as R2 = Err(DR1, T1, T1 + δ2 + dt2) − Err(DR1, T1, T1 + δ2 + da2) = Err(DR1, T1 + δ2 + dt2, T1 + δ2 + da2) Note that R1 > 0 as da1 < dt1, and R2 < 0 as da2 > dt2. Relative export errors are computed by the sender as and when it receives the feedback from the receivers. This example shows the  relative export error values after DR1 is sent and the corresponding feedbacks are received. .2 Equalization of Error Among Receivers We now explain what we mean by making the errors equal at all the receivers and how this can be achieved. As stated  before the sender keeps estimates of the delays to the receivers, dt1 and dt2 in the example of Figure 2. This says that at time T1 when DR1 is computed, the sender already knows how long it may take messages carrying this DR vector to reach the receivers. The sender uses this information to compute the export errors, which are Err(DR1, T1, T1 + δ1 + dt1) and Err(DR1, T1, T1 + δ2 + dt2) for receivers 1 and 2, respectively. Note that the areas of these error components are a function of δ1 and δ2 as well as the network  delays dt1 and dt2. If we are to make the exports errors due to DR1 the same at both receivers, the sender needs to choose δ1 and δ2 such that Err(DR1, T1, T1 + δ1 + dt1) = Err(DR1, T1, T1 + δ2 + dt2). But when T1 was computed there could already have been  accumulated relative export errors due to previous DR vectors (DR0 and the ones before). Let us represent the accumulated relative error up to DRi for receiver j as Ri j. To accommodate these accumulated relative errors, the sender should now choose δ1 and δ2 such that R0  + Err(DR1, T1, T1 + δ1 + dt1) = R0  + Err(DR1, T1, T1 + δ2 + dt2) The δi determines the scheduling instant of the DR vector at the sender for receiver i. This method of computation of δ"s ensures that the accumulated export error (i.e., total actual error) for each receiver equalizes at the transmission of each DR vector. In order to establish this, assume that the feedback for DR vector Di from a receiver comes to the sender before schedule for Di+1 is computed. Let Si m and Ai m denote the estimated error for receiver m used for computing schedule for Di and accumulated error for receiver m computed after receiving feedback for Di, respectively. Then Ri m = Ai m −Si m. In order to compute the schedule instances (i.e., δ"s) for Di, for any pair of receivers m and n, we do Ri−1 m + Si m = Ri−1 n + Si n. The following theorem establishes the fact that the accumulated export error is equalized at every scheduling instant. THEOREM 4.1. When the schedule instances for sending Di are computed for any pair of receivers m and n, the following  condition is satisfied: i−1 k=1 Ak m + Si m = i−1 k=1 Ak n + Si n. Proof: By induction. Assume that the premise holds for some i. We show that it holds for i+1. The base case for i = 1 holds since initially R0 m = R0 n = 0, and the S1 m = S1 n is used to compute the scheduling instances. In order to compute the schedule for Di+1, the we first compute the relative errors as Ri m = Ai m − Si m, and Ri n = Ai n − Si n. Then to compute δ"s we execute Ri m + Si+1 m = Ri n + Si+1 n Ai m − Si m + Si+1 m = Ai n − Si n + Si+1 n . Adding the condition of the premise on both sides we get, i k=1 Ak m + Si+1 m = i k=1 Ak n + Si+1 n . .3 Computation of the Export Error Let us now consider how the export errors can be computed. From the previous section, to find δ1 and δ2 we need to find Err(DR1, T1, T1 +δ1 +dt1) and Err(DR1, T1, T1 +δ2 +dt2). Note that the values of R0  and R0  are already known at the sender. Consider the computation of Err(DR1, T1, T1 +δ1 +dt1). This is the integral of the distance between the trajectories AC due to DR1 and BD due to DR0. From DR0 and DR1, point A is (X1, Y1) = (x1, y1) and point B is (X0, Y0) = (x0 + (T1 − T0) × vx0, y0 + (T1 − T0) × vy0). The trajectory AC can be represented as a function of time as (X1(t), Y1(t) = (X1 + vx1 × t, Y1 + vy1 × t) and the trajectory of BD can be represented as (X0(t), Y0(t) = (X0 + vx0 × t, Y0 + vy0 × t). The distance between the two trajectories as a function of time then becomes, dist(t) = (X1(t) − X0(t))2 + (Y1(t) − Y0(t))2 = ((X1 − X0) + (vx1 − vx0)t)2 +((Y1 − Y0) + (vy1 − vy0)t)2 = ((vx1 − vx0)2 + (vy1 − vy0)2)t2 +2((X1 − X0)(vx1 − vx0) +(Y1 − Y0)(vy1 − vy0))t +(X1 − X0)2 + (Y1 − Y0)2 Let a = (vx1 − vx0)2 + (vy1 − vy0)2 b = 2((X1 − X0)(vx1 − vx0) +(Y1 − Y0)(vy1 − vy0)) c = (X1 − X0)2 + (Y1 − Y0)2 Then dist(t) can be written as dist(t) = a × t2 + b × t + c. Then Err(DR1, t1, t2) for some time interval [t1, t2] becomes t2 t1 dist(t) dt = t2 t1 a × t2 + b × t + c dt. A closed form solution for the indefinite integral a × t2 + b × t + c dt = (2at + b) √ at2 + bt + c a +   ln  b + at √ a + at2 + bt + c c  √ a −   ln  b + at √ a + at2 + bt + c b2 a− 3  Err(DR1, T1, T1 +δ1 +dt1) and Err(DR1, T1, T1 +δ2 +dt2) can then be calculated by applying the appropriate limits to the above solution. In the next section, we consider the computation of the δ"s for N receivers.  .4 Computation of Scheduling Instants We again look at the computation of δ"s by referring to Figure 2. The sender chooses δ1 and δ2 such that R0  + Err(DR1, T1, T1 + δ1 +dt1) = R0  +Err(DR1, T1, T1 +δ2 +dt2). If R0  and R0  both are zero, then δ1 and δ2 should be chosen such that Err(DR1, T1, T1+ δ1 +dt1) = Err(DR1, T1, T1 +δ2 +dt2). This equality will hold if δ1 + dt1 = δ2 + dt2. Thus, if there is no accumulated relative export error, all that the sender needs to do is to choose the δ"s in such a way that they counteract the difference in the delay to the two receivers, so that they receive the DR vector at the same time. As discussed earlier, because the sender is not able to a priori learn the delay, there will always be an accumulated relative export error from a previous DR vector that does have to be taken into account. To delve deeper into this, consider the computation of the  export error as illustrated in the previous section. To compute the δ"s we require that R0  + Err(DR1, T1, T1 + δ1 + dt1) = R0  + Err(DR1, T1, T1 + δ2 + dt2). That is, R0  + T1+δ1+dt1 T1 dist(t) dt = R0  + T1+δ2+dt2 T1 dist(t) dt. That is R0  + T1+dt1 T1 dist(t) dt + T1+dt1+δ1 T1+dt1 dist(t) dt = R0  + T1+dt2 T1 dist(t) dt + T1+dt2+δ2 T1+dt2 dist(t) dt. The components R0 , R0 , are already known to (or estimated by) the sender. Further, the error components T1+dt1 T1 dist(t) dt and T1+dt2 T1 dist(t) dt can be a priori computed by the sender using estimated values of dt1 and dt2. Let us use E1 to denote R0  + T1+dt1 T1 dist(t) dt and E2 to denote R0  + T1+dt2 T1 dist(t) dt. Then, we require that E1 + T1+dt1+δ1 T1+dt1 dist(t) dt = E2 + T1+dt2+δ2 T1+dt2 dist(t) dt. Assume that E1 > E2. Then, for the above equation to hold, we require that T1+dt1+δ1 T1+dt1 dist(t) dt < T1+dt2+δ2 T1+dt2 dist(t) dt. To make the game as fast as possible within this framework, the δ values should be made as small as possible so that DR vectors are sent to the receivers as soon as possible subject to the fairness  requirement. Given this, we would choose δ1 to be zero and compute δ2 from the equation E1 = E2 + T1+dt2+δ2 T1+dt2 dist(t) dt. In general, if there are N receivers 1, . . . , N, when a sender  generates a DR vector and decides to schedule them to be sent, it first computes the Ei values for all of them from the accumulated  relative export errors and estimates of delays. Then, it finds the smallest of these values. Let Ek be the smallest value. The sender makes δk to be zero and computes the rest of the δ"s from the equality Ei + T1+dti+δi T1+dti dist(t) dt = Ek, ∀i 1 ≤ i ≤ N, i = k. (1) The δ"s thus obtained gives the scheduling instants of the DR  vector for the receivers. .5 Steps of the Scheduling Algorithm For the purpose of the discussion below, as before let us denote the accumulated relative export error at a sender for receiver k up until DRi to be Ri k. Let us denote the scheduled delay at the sender before DRi is sent to receiver k as δi k. Given the above discussion, the algorithm steps are as follows: . The sender computes DRi at (say) time Ti and then  computes δi k, and Ri−1 k , ∀k, 1 ≤ k ≤ N based on the estimation of delays dtk, ∀k, 1 ≤ k ≤ N as per Equation (1). It  schedules, DRi to be sent to receiver k at time Ti + δi k. . The DR vectors are sent to the receivers at the scheduled times which are received after a delay of dak, ∀k, 1 ≤ k ≤ N where dak ≤ or > dtk. The receivers send the value of dak back to the sender (the receiver can compute this value based on the time stamps on the DR vector as described  earlier). . The sender computes Ri k as described earlier and illustrated in Figure 2. The sender also recomputes (using exponential averaging method similar to round-trip time estimation by TCP [10]) the estimate of delay dtk from the new value of dak for receiver k. . Go back to Step 1 to compute DRi+1 when it is required and follow the steps of the algorithm to schedule and send this DR vector to the receivers. .6 Handling Cases in Practice So far we implicity assumed that DRi is sent out to all receivers before a decision is made to compute the next DR vector DRi+1, and the receivers send the value of dak corresponding to DRi and this information reaches the sender before it computes DRi+1 so that it can compute Ri+1 k and then use it in the computation of δi+1 k . Two issues need consideration with respect to the above algorithm when it is used in practice. • It may so happen that a new DR vector is computed even before the previous DR vector is sent out to all receivers. How will this situation be handled? • What happens if the feedback does not arrive before DRi+1 is computed and scheduled to be sent? Let us consider the first scenario. We assume that DRi has been scheduled to be sent and the scheduling instants are such that δi  < δi  < · · · < δi N . Assume that DRi+1 is to be computed (because the real path has deviated exceeding a threshold from the path  exported by DRi) at time Ti+1 where Ti + δi k < Ti+1 < Ti + δi k+1. This means, DRi has been sent only to receivers up to k in the scheduled order. In our algorithm, in this case, the scheduled delay ordering queue is flushed which means DRi is not sent to receivers still queued to receive it, but a new scheduling order is computed for all the receivers to send DRi+1. For those receivers who have been sent DRi, assume for now that daj, 1 ≤ j ≤ k has been received from all receivers (the  scenario where daj has not been received will be considered as a part of the second scenario later). For these receivers, Ei j, 1 ≤ j ≤ k can be computed. For those receivers j, k + 1 ≤ j ≤ N to whom DRi was not sent Ei j does not apply. Consider a receiver j, k + 1 ≤ j ≤ N to whom DRi was not sent. Refer to  Figure 3. For such a receiver j, when DRi+1 is to be scheduled and  timeTi Exported path dtj A B C D Ti-1 Gi j DRi+1 computed by sender and DRi for receiver k+1 to N is removed from queue DRi+1 scheduled for receiver k+1 Ti+1 G H E F DRi scheduled for receiver j DRi computed by sender Placed path at receiver k+1 Gi+1 j Figure 3: Schedule computation when DRi is not sent to  receiver j, k + 1 ≤ j ≤ N. δi+1 j needs to be computed, the total export error is the accumulated relative export error at time Ti when schedule for DRi was  computed, plus the integral of the distance between the two trajectories AC and BD of Figure 3 over the time interval [Ti, Ti+1 + δi+1 j + dtj]. Note that this integral is given by Err(DRi, Ti, Ti+1) + Err(DRi+1, Ti+1, Ti+1 + δi+1 j + dtj). Therefore, instead of Ei j of Equation (1), we use the value Ri−1 j + Err(DRi, Ti, Ti+1) + Err(DRi+1, Ti+1, Ti+1 + δi+1 j + dtj) where Ri−1 j is relative  export error used when the schedule for DRi was computed. Now consider the second scenario. Here the feedback dak  corresponding to DRi has not arrived before DRi+1 is computed and scheduled. In this case, Ri k cannot be computed. Thus, in the  computation of δk for DRi+1, this will be assumed to be zero. We do assume that a reliable mechanism is used to send dak back to the sender. When this information arrives at a later time, Ri k will be computed and accumulated to future relative export errors (for example Ri+1 k if dak is received before DRi+2 is computed) and used in the computation of δk when a future DR vector is to be scheduled (for example DRi+2). .7 Experimental Results In order to evaluate the effectiveness and quantify benefits  obtained through the use of the scheduling algorithm, we implemented the proposed algorithm in BZFlag (Battle Zone Flag) [11] game. It is a first-person shooter game where the players in teams drive tanks and move within a battle field. The aim of the players is to navigate and capture flags belonging to the other team and bring them back to their own area. The players shoot each other"s tanks using shooting bullets. The movement of the tanks as well as that of the shots are exchanged among the players using DR vectors. We have modified the implementation of BZFlag to  incorporate synchronized clocks among the players and the server and  exchange time-stamps with the DR vector. We set up a testbed with four players running the instrumented version of BZFlag, with one as a sender and the rest as receivers. The scheduling approach and the base case where each DR vector was sent to all the receivers concurrently at every trigger point were implemented in the same run by tagging the DR vectors according to the type of approach used to send the DR vector. NISTNet [12] was used to introduce delays across the sender and the three receivers. Mean delays of 00ms, 500ms and 200ms were introduced between the sender and first, second and the third receiver, respectively. We introduce a variance of 100 msec (to the mean delay of each receiver) to model variability in delay. The sender logged the errors of each receiver every 100 milliseconds for both the scheduling approach and the base case. The sender also calculated the standard deviation and the mean of the accumulated export error of all the receivers every 00 milliseconds. Figure 4 plots the mean and standard deviation of the accumulated export error of all the receivers in the  scheduling case against the base case. Note that the x-axis of these graphs (and the other graphs that follow) represents the system time when the snapshot of the game was taken. Observe that the standard deviation of the error with scheduling is much lower as compared to the base case. This implies that the accumulated errors of the receivers in the scheduling case are closer to one another. This shows that the scheduling approach achieves fairness among the receivers even if they are at different distances (i.e, latencies) from the sender. Observe that the mean of the accumulated error increased  multifold with scheduling in comparison to the base case. Further  exploration for the reason for the rise in the mean led to the conclusion that every time the DR vectors are scheduled in a way to equalize the total error, it pushes each receivers total error higher. Also, as the accumulated error has an estimated component, the schedule is not accurate to equalize the errors for the receivers, leading to the DR vector reaching earlier or later than the actual schedule. In  either case, the error is not equalized and if the DR vector reaches late, it actually increases the error for a receiver beyond the highest accumulated error. This means that at the next trigger, this receiver will be the one with highest error and every other receiver"s error will be pushed to this error value. This flip-flop effect leads to the increase in the accumulated error for all the receivers. The scheduling for fairness leads to the decrease in standard  deviation (i.e., increases the fairness among different players), but it comes at the cost of higher mean error, which may not be a  desirable feature. This led us to explore different ways of equalizing the accumulated errors. The approach discussed in the following  section is a heuristic approach based on the following idea. Using the same amount of DR vectors over time as in the base case, instead of sending the DR vectors to all the receivers at the same frequency as in the base case, if we can increase the frequency of sending the DR vectors to the receiver with higher accumulated error and decrease the frequency of sending DR vectors to the receiver with lower accumulated error, we can equalize the export error of all receivers over time. At the same time we wish to decrease the  error of the receiver with the highest accumulated error in the base case (of course, this receiver would be sent more DR vectors than in the base case). We refer to such an algorithm as a budget based algorithm. . BUDGET BASED ALGORITHM In a game, the sender of an entity sends DR vectors to all the receivers every time a threshold is crossed by the entity. Lower the threshold, more DR vectors are generated during a given time period. Since the DR vectors are sent to all the receivers and the network delay between the sender-receiver pairs cannot be avoided, the before export error 3 with the most distant player will always  Note that after export error is eliminated by using synchronized clock among the players.   000 000 000 000 000 5950 16000 16050 16100 16150 16200 16250 16300 MeanAccumulatedError Time in Seconds Base Case Scheduling Algorithm #1  0 00 50 00 50 00 50 00 50 00 5950 16000 16050 16100 16150 16200 16250 16300 StandardDeviationofAccumulatedError Time in Seconds Base Case Scheduling Algorithm #1 Figure 4: Mean and standard deviation of error with scheduling and without (i.e., base case). be higher than the rest. In order to mitigate the imbalance in the error, we propose to send DR vectors selectively to different  players based on the accumulated errors of these players. The budget based algorithm is based on this idea and there are two variations of it. One is a probabilistic budget based scheme and the other, a deterministic budget base scheme. .1 Probabilistic budget based scheme The probabilistic budget based scheme has three main steps: a) lower the dead reckoning threshold but at the same time keep the total number of DRs sent the same as the base case, b) at every trigger, probabilistically pick a player to send the DR vector to, and c) send the DR vector to the chosen player. These steps are described below. The lowering of DR threshold is implemented as follows.  Lowering the threshold is equivalent to increasing the number of trigger points where DR vectors are generated. Suppose the threshold is such that the number of triggers caused by it in the base case is t and at each trigger n DR vectors sent by the sender, which results in a total of nt DR vectors. Our goal is to keep the total number of DR vectors sent by the sender fixed at nt, but lower the number of DR vectors sent at each trigger (i.e., do not send the DR vector to all the receivers). Let n and t be the number of DR vectors sent at each trigger and number of triggers respectively in the modified case. We want to ensure n t = nt. Since we want to increase the number of trigger points, i.e, t > t, this would mean that n < n. That is, not all receivers will be sent the DR vector at every trigger. In the probabilistic budget based scheme, at each trigger, a  probability is calculated for each receiver to be sent a DR vector and only one receiver is sent the DR (n = 1). This probability is based on the relative weights of the receivers" accumulated errors. That is, a receiver with a higher accumulated error will have a higher probability of being sent the DR vector. Consider that the  accumulated error for three players are a1, a2 and a3 respectively. Then the probability of player 1 receiving the DR vector would be a1 a1+a2+a3 . Similarly for the other players. Once the player is picked, the DR vector is sent to that player. To compare the probabilistic budget based algorithm with the base case, we needed to lower the threshold for the base case (for fair comparison). As the dead reckoning threshold in the base case was already very fine, it was decided that instead of  lowering the threshold, the probabilistic budget based approach would be compared against a modified base case that would use the  normal threshold as the budget based algorithm but the base case was modified such that every third trigger would be actually used to send out a DR vector to all the three receivers used in our  experiments. This was called as the 1/3 base case as it resulted in 1/3 number of DR vectors being sent as compared to the base case. The budget per trigger for the probability based approach was  calculated as one DR vector at each trigger as compared to three DR vectors at every third trigger in the 1/3 base case; thus the two cases lead to the same number of DR vectors being sent out over time. In order to evaluate the effectiveness of the probabilistic budget based algorithm, we instrumented the BZFlag game to use this  approach. We used the same testbed consisting of one sender and three receivers with delays of 800ms, 500ms and 200ms from the sender and with low delay variance (100ms) and moderate delay variance (180ms). The results are shown in Figures 5 and 6. As mentioned earlier, the x-axis of these graphs represents the system time when the snapshot of the game was taken. Observe from the figures that the standard deviation of the accumulated error among the receivers with the probabilistic budget based algorithm is less than the 1/3 base case and the mean is a little higher than the 1/3 base case. This implies that the game is fairer as compared to the /3 base case at the cost of increasing the mean error by a small amount as compared to the 1/3 base case. The increase in mean error in the probabilistic case compared to the 1/3 base case can be attributed to the fact that the even though the probabilistic approach on average sends the same number of DR vectors as the 1/3 base case, it sometimes sends DR vectors to a receiver less frequently and sometimes more frequently than the /3 base case due to its probabilistic nature. When a receiver does not receive a DR vector for a long time, the receiver"s trajectory is more and more off of the sender"s trajectory and hence the rate of buildup of the error at the receiver is higher. At times when a receiver receives DR vectors more frequently, it builds up error at a lower rate but there is no way of reversing the error that was built up when it did not receive a DR vector for a long time. This leads the receivers to build up more error in the probabilistic case as compared to the 1/3 base case where the receivers receive a DR vector almost periodically.   00 00 00 00 000 5950 16000 16050 16100 16150 16200 16250 16300 MeanAccumulatedError Time in Seconds /3 Base Case Deterministic Algorithm Probabilistic Algorithm  0 00 50 00 50 00 50 00 50 00 5950 16000 16050 16100 16150 16200 16250 16300 StandardDeviationofAccumulatedError Time in Seconds /3 Base Case Deterministic Algorithm Probabilistic Algorithm Figure 5: Mean and standard deviation of error for different algorithms (including budget based algorithms) for low delay variance.  00 00 00 00 000 6960 16980 17000 17020 17040 17060 17080 17100 17120 17140 17160 17180 MeanAccumulatedError Time in Seconds /3 Base Case Deterministic Algorithm Probabilistic Algorithm  0 00 50 00 50 00 6960 16980 17000 17020 17040 17060 17080 17100 17120 17140 17160 17180 StandardDeviationofAccumulatedError Time in Seconds /3 Base Case Deterministic Algorithm Probabilistic Algorithm Figure 6: Mean and standard deviation of error for different algorithms (including budget based algorithms) for moderate delay variance. .2 Deterministic budget based scheme To bound the increase in mean error we decided to modify the budget based algorithm to be deterministic. The first two steps of the algorithm are the same as in the probabilistic algorithm; the trigger points are increased to lower the threshold and accumulated errors are used to compute the probability that a receiver will  receiver a DR vector. Once these steps are completed, a deterministic schedule for the receiver is computed as follows: . If there is any receiver(s) tagged to receive a DR vector at the current trigger, the sender sends out the DR vector to the respective receiver(s). If at least one receiver was sent a DR vector, the sender calculates the probabilities of each receiver receiving a DR vector as explained before and follows steps  to 6, else it does not do anything. . For each receiver, the probability value is multiplied with the budget available at each trigger (which is set to 1 as explained below) to give the frequency of sending the DR vector to each receiver. . If any of the receiver"s frequency after multiplying with the budget goes over 1, the receiver"s frequency is set as 1 and the surplus amount is equally distributed to all the receivers by adding the amount to their existing frequencies. This  process is repeated until all the receivers have a frequency of less than or equal to 1. This is due to the fact that at a trigger we cannot send more than one DR vector to the respective receiver. That will be wastage of DR vectors by sending  redundant information. . (1/frequency) gives us the schedule at which the sender should send DR vectors to the respective receiver. Credit obtained previously (explained in step 5) if any is subtracted from the schedule. Observe that the resulting value of the schedule might not be an integer; hence, the value is rounded off by taking the ceiling of the schedule. For example, if the  frequency is 1/3.5, this implies that we would like to have a DR vector sent every 3.5 triggers. However, we are constrained to send it at the 4th trigger giving us a credit of 0.5. When we do send the DR vector next time, we would be able to send it  on the 3rd trigger because of the 0.5 credit. . The difference between the schedule and the ceiling of the schedule is the credit that the receiver has obtained which is remembered for the future and used at the next time as explained in step 4. . For each of those receivers who were sent a DR vector at the current trigger, the receivers are tagged to receive the next DR vector at the trigger that happens exactly schedule (the ceiling of the schedule) number of times away from the current trigger. Observe that no other receiver"s schedule is modified at this point as they all are running a schedule  calculated at some previous point of time. Those schedules will be automatically modified at the trigger when they are  scheduled to receive the next DR vector. At the first trigger, the sender sends the DR vector to all the receivers and uses a relative probability of 1/n for each receiver and follows the steps 2 to 6 to calculate the next schedule for each receiver in the same way as mentioned for other triggers. This  algorithm ensures that every receiver has a guaranteed schedule of receiving DR vectors and hence there is no irregularity in sending the DR vector to any receiver as was observed in the budget based probabilistic algorithm. We used the testbed described earlier (three receivers with  varying delays) to evaluate the deterministic algorithm using the budget of 1 DR vector per trigger so as to use the same number of DR vectors as in the 1/3 base case. Results from our experiments are shown in Figures 5 and 6. It can be observed that the standard  deviation of error in the deterministic budget based algorithm is less than the 1/3 base case and also has the same mean error as the 1/3 base case. This indicates that the deterministic algorithm is more fair than the 1/3 base case and at the same time does not increase the mean error thereby leading to a better game quality compared to the probabilistic algorithm. In general, when comparing the deterministic approach to the probabilistic approach, we found that the mean accumulated  error was always less in the deterministic approach. With respect to standard deviation of the accumulated error, we found that in the fixed or low variance cases, the deterministic approach was  generally lower, but in higher variance cases, it was harder to draw  conclusions as the probabilistic approach was sometimes better than the deterministic approach. . CONCLUSIONS AND FUTURE WORK In distributed multi-player games played across the Internet,  object and player trajectory within the game space are exchanged in terms of DR vectors. Due to the variable delay between players, these DR vectors reach different players at different times. There is unfair advantage gained by receivers who are closer to the sender of the DR as they are able to render the sender"s position more accurately in real time. In this paper, we first developed a model for estimating the error in rendering player trajectories at the  receivers. We then presented an algorithm based on scheduling the DR vectors to be sent to different players at different times thereby equalizing the error at different players. This algorithm is aimed at making the game fair to all players, but tends to increase the mean error of the players. To counter this effect, we presented budget based algorithms where the DR vectors are still  scheduled to be sent at different players at different times but the  algorithm balances the need for fairness with the requirement that the error of the worst case players (who are furthest from the sender) are not increased compared to the base case (where all DR vectors are sent to all players every time a DR vector is generated). We  presented two variations of the budget based algorithms and through experimentation showed that the algorithms reduce the standard  deviation of the error thereby making the game more fair and at the same time has comparable mean error to the base case. . REFERENCES [1] S.Aggarwal, H. Banavar, A. Khandelwal, S. Mukherjee, and S. Rangarajan, Accuracy in Dead-Reckoning based Distributed Multi-Player Games, Proceedings of ACM SIGCOMM 2004 Workshop on Network and System Support for Games (NetGames 2004), Aug. 2004. [2] L. Gautier and C. Diot, Design and Evaluation of MiMaze, a Multiplayer Game on the Internet, in Proc. of IEEE Multimedia (ICMCS"98), 1998. [3] M. Mauve, Consistency in Replicated Continuous Interactive Media, in Proc. of the ACM Conference on Computer Supported Cooperative Work (CSCW"00), 2000, pp. 181-190. [4] S.K. Singhal and D.R. Cheriton, Exploiting Position History for Efficient Remote Rendering in Networked Virtual Reality, Presence: Teleoperators and Virtual Environments, vol. 4, no. 2, pp. 169-193, 1995. [5] C. Diot and L. Gautier, A Distributed Architecture for Multiplayer Interactive Applications on the Internet, in IEEE Network Magazine, 1999, vol. 13, pp. 6-15. [6] L. Pantel and L.C. Wolf, On the Impact of Delay on Real-Time Multiplayer Games, in Proc. of ACM NOSSDAV"02, May 2002. [7] Y. Lin, K. Guo, and S. Paul, Sync-MS: Synchronized Messaging Service for Real-Time Multi-Player Distributed Games, in Proc. of 10th IEEE International Conference on Network Protocols (ICNP), Nov 2002. [8] K. Guo, S. Mukherjee, S. Rangarajan, and S. Paul, A Fair Message Exchange Framework for Distributed Multi-Player Games, in Proc. of NetGames2003, May 2003. [9] N. E. Baughman and B. N. Levine, Cheat-Proof Playout for Centralized and Distributed Online Games, in Proc. of IEEE INFOCOM"01, April 2001. [10] M. Allman and V. Paxson, On Estimating End-to-End Network Path Properties, in Proc. of ACM SIGCOMM"99, Sept. 1999. [11] BZFlag Forum, BZFlag Game, URL: http://www.bzflag.org. [12] Nation Institute of Standards and Technology, NIST Net, URL: http://snad.ncsl.nist.gov/nistnet/. 0
Globally Synchronized Dead-Reckoning with Local Lag for Continuous Distributed Multiplayer Games Yi Zhang1 , Ling Chen1, 2 , Gencai Chen1 College of Computer Science, Zhejiang University, Hangzhou 310027, P.R. China School of Computer Science and IT, The University of Nottingham, Nottingham NG8 1BB, UK {m05zhangyi, lingchen, chengc}@cs.zju.edu.cn ABSTRACT Dead-Reckoning (DR) is an effective method to maintain consistency for Continuous Distributed Multiplayer Games (CDMG). Since DR can filter most unnecessary state updates and improve the scalability of a system, it is widely used in commercial CDMG. However, DR cannot maintain high consistency, and this constrains its application in highly interactive games. With the help of global synchronization, DR can achieve higher consistency, but it still cannot eliminate before inconsistency. In this paper, a method named Globally Synchronized DR with Local Lag (GS-DR-LL), which combines local lag and Globally Synchronized DR (GS-DR), is presented. Performance evaluation shows that GS-DR-LL can effectively decrease before inconsistency, and the effects increase with the lag. Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems - distributed applications. General Terms Algorithms, Performance, Experimentation. . INTRODUCTION Nowadays, many distributed multiplayer games adopt replicated architectures. In such games, the states of entities are changed not only by the operations of players, but also by the passing of time [1, 2]. These games are referred to as Continuous Distributed Multiplayer Games (CDMG). Like other distributed applications, CDMG also suffer from the consistency problem caused by network transmission delay. Although new network techniques (e.g. QoS) can reduce or at least bound the delay, they can not completely eliminate it, as there exists the physical speed limitation of light, for instance, 100 ms is needed for light to propagate from Europe to Australia [3]. There are many studies about the effects of network transmission delay in different applications [4, 5, 6, 7]. In replication based games, network transmission delay makes the states of local and remote sites to be inconsistent, which can cause serious problems, such as reducing the fairness of a game and leading to paradoxical situations etc. In order to maintain consistency for distributed systems, many different approaches have been proposed, among which local lag and Dead-Reckoning (DR) are two representative approaches. Mauve et al [1] proposed local lag to maintain high consistency for replicated continuous applications. It synchronizes the physical clocks of all sites in a system. After an operation is issued at local site, it delays the execution of the operation for a short time. During this short time period the operation is transmitted to remote sites, and all sites try to execute the operation at a same physical time. In order to tackle the inconsistency caused by exceptional network transmission delay, a time warp based mechanism is proposed to repair the state. Local lag can achieve significant high consistency, but it is based on operation transmission, which forwards every operation on a shared entity to remote sites. Since operation transmission mechanism requests that all operations should be transmitted in a reliable way, message filtering is difficult to be deployed and the scalability of a system is limited. DR is based on state transmission mechanism. In addition to the high fidelity model that maintains the accurate states of its own entities, each site also has a DR model that estimates the states of all entities (including its own entities). After each update of its own entities, a site compares the accurate state with the estimated one. If the difference exceeds a pre-defined threshold, a state update would be transmitted to all sites and all DR models would be corrected. Through state estimation, DR can not only maintain consistency but also decrease the number of transmitted state updates. Compared with aforementioned local lag, DR cannot maintain high consistency. Due to network transmission delay, when a remote site receives a state update of an entity the state of the entity might have changed at the site sending the state update. In order to make DR maintain high consistency, Aggarwal et al [8] proposed Globally Synchronized DR (GS-DR), which synchronizes the physical clocks of all sites in a system and adds time stamps to transmitted state updates. Detailed description of GS-DR can be found in Section 3. When a state update is available, GS-DR immediately updates the state of local site and then transmits the state update to remote sites, which causes the states of local site and remote sites to be inconsistent in the transmission procedure. Thus with the synchronization of physical clocks, GS-DR can eliminate after inconsistency, but it cannot tackle before inconsistency [8]. In this paper, we propose a new method named globally synchronized DR with Local Lag (GS-DR-LL), which combines local lag and GS-DR. By delaying the update to local site, GS-DR-LL can achieve higher consistency than GS-DR. The rest of this paper is organized as follows: Section 2 gives the definition of consistency and corresponding metrics; the cause of the inconsistency of DR is analyzed in Section 3; Section 4 describes how GS-DR-LL works; performance evaluation is presented in Section 5; Section  concludes the paper. . CONSISTENCY DEFINITIONS AND METRICS The consistency of replicated applications has already been well defined in discrete domain [9, 10, 11, 12], but few related work has been done in continuous domain. Mauve et al [1] have given a definition of consistency for replicated applications in continuous domain, but the definition is based on operation transmission and it is difficult for the definition to describe state transmission based methods (e.g. DR). Here, we present an alternative definition of consistency in continuous domain, which suits state transmission based methods well. Given two distinct sites i and j, which have replicated a shared entity e, at a given time t, the states of e at sites i and j are Si(t) and Sj(t). DEFINITION 1: the states of e at sites i and j are consistent at time t, iff: De(i, j, t) = |Si(t) - Sj(t)| = 0 (1) DEFINITION 2: the states of e at sites i and j are consistent between time t1 and t2 (t1 < t2), iff: De(i, j, t1, t2) = dt|)t(S)t(S| t2 t1 ji = 0 (2) In this paper, formulas (1) and (2) are used to determine whether the states of shared entities are consistent between local and remote sites. Due to network transmission delay, it is difficult to maintain the states of shared entities absolutely consistent. Corresponding metrics are needed to measure the consistency of shared entities between local and remote sites. De(i, j, t) can be used as a metric to measure the degree of consistency at a certain time point. If De(i, j, t1) > De(i, j, t2), it can be stated that between sites i and j, the consistency of the states of entity e at time point t1 is lower than that at time point t2. If De(i, j, t) > De(l, k, t), it can be stated that, at time point t, the consistency of the states of entity e between sites i and j is lower than that between sites l and k. Similarly, De(i, j, t1, t2) can been used as a metric to measure the degree of consistency in a certain time period. If De(i, j, t1, t2) > De(i, j, t3, t4) and |t1 - t2| = |t3 - t4|, it can be stated that between sites i and j, the consistency of the states of entity e between time points t1 and t2 is lower than that between time points t3 and t4. If De(i, j, t1, t2) > De(l, k, t1, t2), it can be stated that between time points t1 and t2, the consistency of the states of entity e between sites i and j is lower than that between sites l and k. In DR, the states of entities are composed of the positions and orientations of entities and some prediction related parameters (e.g. the velocities of entities). Given two distinct sites i and j, which have replicated a shared entity e, at a given time point t, the positions of e at sites i and j are (xit, yit, zit) and (xjt, yjt, zjt), De(i, j, t) and D (i, j, t1, t2) could be calculated as: De(i, j, t) = )zz()yy()xx( jtit  jtit  jtit  (3) De(i, j, t1, t2) = dt)zz()yy()xx( t t jtit  jtit  jtit  (4) In this paper, formulas (3) and (4) are used as metrics to measure the consistency of shared entities between local and remote sites. . INCONSISTENCY IN DR The inconsistency in DR can be divided into two sections by the time point when a remote site receives a state update. The inconsistency before a remote site receives a state update is referred to as before inconsistency, and the inconsistency after a remote site receives a state update is referred to as after inconsistency. Before inconsistency and after inconsistency are similar with the terms before export error and after export error [8]. After inconsistency is caused by the lack of synchronization between the physical clocks of all sites in a system. By employing physical clock synchronization, GS-DR can accurately calculate the states of shared entities after receiving state updates, and it can eliminate after inconsistency. Before inconsistency is caused by two reasons. The first reason is the delay of sending state updates, as local site does not send a state update unless the difference between accurate state and the estimated one is larger than a predefined threshold. The second reason is network transmission delay, as a shared entity can be synchronized only after remote sites receiving corresponding state update. Figure 1. The paths of a shared entity by using GS-DR. For example, it is assumed that the velocity of a shared entity is the only parameter to predict the entity"s position, and current position of the entity can be calculated by its last position and current velocity. To simplify the description, it is also assumed that there are only two sites i and j in a game session, site i acts as  The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 local site and site j acts as remote site, and t1 is the time point the local site updates the state of the shared entity. Figure 1 illustrates the paths of the shared entity at local site and remote site in x axis by using GS-DR. At the beginning, the positions of the shared entity are the same at sites i and j and the velocity of the shared entity is 0. Before time point t0, the paths of the shared entity at sites i and j in x coordinate are exactly the same. At time point t0, the player at site i issues an operation, which changes the velocity in x axis to v0. Site i first periodically checks whether the difference between the accurate position of the shared entity and the estimated one, 0 in this case, is larger than a predefined threshold. At time point t1, site i finds that the difference is larger than the threshold and it sends a state update to site j. The state update contains the position and velocity of the shared entity at time point t1 and time point t1 is also attached as a timestamp. At time point t2, the state update reaches site j, and the received state and the time deviation between time points t1 and t2 are used to calculate the current position of the shared entity. Then site j updates its replicated entity"s position and velocity, and the paths of the shared entity at sites i and j overlap again. From Figure 1, it can be seen that the after inconsistency is 0, and the before consistency is composed of two parts, D1 and D2. D1 is De(i, j, t0, t1) and it is caused by the state filtering mechanism of DR. D2 is De(i, j, t1, t2) and it is caused by network transmission delay. . GLOBALLY SYNCHRONIZED DR WITH LOCAL LAG From the analysis in Section 3, It can be seen that GS-DR can eliminate after inconsistency, but it cannot effectively tackle before inconsistency. In order to decrease before inconsistency, we propose GS-DR-LL, which combines GS-DR with local lag and can effectively decrease before inconsistency. In GS-DR-LL, the state of a shared entity at a certain time point t is notated as S = (t, pos, par 1, par 2, ……, par n), in which pos means the position of the entity and par 1 to par n means the parameters to calculate the position of the entity. In order to simplify the description of GS-DR-LL, it is assumed that there are only one shared entity and one remote site. At the beginning of a game session, the states of the shared entity are the same at local and remote sites, with the same position p0 and parameters pars0 (pars represents all the parameters). Local site keeps three states: the real state of the entity Sreal, the predicted state at remote site Sp-remote, and the latest state updated to remote site Slate. Remote site keep only one state Sremote, which is the real state of the entity at remote site. Therefore, at the beginning of a game session Sreal = Sp-remote = Slate = Sremote = (t0, p0, pars0). In GS-DR-LL, it is assumed that the physical clocks of all sites are synchronized with a deviation of less than 50 ms (using NTP or GPS clock). Furthermore, it is necessary to make corrections to a physical clock in a way that does not result in decreasing the value of the clock, for example by slowing down or halting the clock for a period of time. Additionally it is assumed that the game scene is updated at a fixed frequency and T stands for the time interval between two consecutive updates, for example, if the scene update frequency is 50 Hz, T would be 0 ms. n stands for the lag value used by local lag, and t stands for current physical time. After updating the scene, local site waits for a constant amount of time T. During this time period, local site receives the operations of the player and stores them in a list L. All operations in L are sorted by their issue time. At the end of time period T, local site executes all stored operations, whose issue time is between t - T and t, on Slate to get the new Slate, and it also executes all stored operations, whose issue time is between t - (n + T) and t - n, on Sreal to get the new Sreal. Additionally, local site uses Sp-remote and corresponding prediction methods to estimate the new Sp-remote. After new Slate, Sreal, and Sp-remote are calculated, local site compares whether the difference between the new Slate and  Spremote exceeds the predefined threshold. If YES, local site sends new Slate to remote site and Sp-remote is updated with new Slate. Note that the timestamp of the sent state update is t. After that, local site uses Sreal to update local scene and deletes the operations, whose issue time is less than t - n, from L. After updating the scene, remote site waits for a constant amount of time T. During this time period, remote site stores received state update(s) in a list R. All state updates in R are sorted by their timestamps. At the end of time period T, remote site checks whether R contains state updates whose timestamps are less than t - n. Note that t is current physical time and it increases during the transmission of state updates. If YES, it uses these state updates and corresponding prediction methods to calculate the new Sremote, else they use Sremote and corresponding prediction methods to estimate the new Sremote. After that, local site uses Sremote to update local scene and deletes the sate updates, whose timestamps are less than t - n, from R. From the above description, it can been see that the main difference between GS-DR and GS-DR-LL is that GS-DR-LL uses the operations, whose issue time is less than t - n, to calculate Sreal. That means that the scene seen by local player is the results of the operations issued a period of time (i.e. n) ago. Meanwhile, if the results of issued operations make the difference between Slate and Sp-remote exceed a predefined threshold, corresponding state updates are sent to remote sites immediately. The aforementioned is the basic mechanism of GS-DR-LL. In the case with multiple shared entities and remote sites, local site calculates Slate, Sreal, and Sp-remote for different shared entities respectively, if there are multiple Slate need to be transmitted, local site packets them in one state update and then send it to all remote sites. Figure 2 illustrates the paths of a shared entity at local site and remote site while using GS-DR and GS-DR-LL. All conditions are the same with the conditions used in the aforementioned example describing GS-DR. Compared with t1, t2, and n, T (i.e. the time interval between two consecutive updates) is quite small and it is ignored in the following description. At time point t0, the player at site i issues an operation, which changes the velocity of the shared entity form 0 to v0. By using GS-DR-LL, the results of the operation are updated to local scene at time point t0 + n. However the operation is immediately used to calculate Slate, thus in spite of GS-DR or GS-DR-LL, at time point t1 site i finds that the difference between accurate position and the estimated one is larger than the threshold and it sends a state update to site j. At time point t2, the state update is received by remote site j. Assuming that the timestamp of the state update is less than t - n, site j uses it to update local scene immediately. The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 3 With GS-DR, the time period of before inconsistency is (t2 - t1) + (t1 - t0), whereas it decreases to (t2 - t1 - n) + (t1 - t0) with the help of GS-DR-LL. Note that t2 - t1 is caused by network transmission delay and t1 - t0 is caused by the state filtering mechanism of DR. If n is larger than t2 - t1, GS-DR-LL can eliminate the before inconsistency caused by network transmission delay, but it cannot eliminate the before inconsistency caused by the state filtering mechanism of DR (unless the threshold is set to 0). In highly interactive games, which request high consistency and GS-DR-LL might be employed, the results of operations are quite difficult to be estimated and a small threshold must be used. Thus, in practice, most before inconsistency is caused by network transmission delay and GS-DR-LL has the capability to eliminate such before inconsistency. Figure 2. The paths of a shared entity by using GS-DR and GS-DR-LL. To GS-DR-LL, the selection of lag value n is very important, and both network transmission delay and the effects of local lag on interaction should be considered. According to the results of HCI related researches, humans cannot perceive the delay imposed on a system when it is smaller than a specific value, and the specific value depends on both the system and the task. For example, in a graphical user interface a delay of approximately 150 ms cannot be noticed for keyboard interaction and the threshold increases to 95 ms for mouse interaction [13], and a delay of up to 50 ms is uncritical for a car-racing game [5]. Thus if network transmission delay is less than the specific value of a game system, n can be set to the specific value. Else n can be set in terms of the effects of local lag on the interaction of a system [14]. In the case that a large n must be used, some HCI methods (e.g. echo [15]) can be used to relieve the negative effects of the large lag. In the case that n is larger than the network transmission delay, GS-DR-LL can eliminate most before inconsistency. Traditional local lag requests that the lag value must be larger than typical network transmission delay, otherwise state repairs would flood the system. However GS-DR-LL allows n to be smaller than typical network transmission delay. In this case, the before inconsistency caused by network transmission delay still exists, but it can be decreased. . PERFORMANCE EVALUATION In order to evaluate GS-DR-LL and compare it with GS-DR in a real application, we had implemented both two methods in a networked game named spaceship [1]. Spaceship is a very simple networked computer game, in which players can control their spaceships to accelerate, decelerate, turn, and shoot spaceships controlled by remote players with laser beams. If a spaceship is hit by a laser beam, its life points decrease one. If the life points of a spaceship decrease to 0, the spaceship is removed from the game and the player controlling the spaceship loses the game. In our practical implementation, GS-DR-LL and GS-DR coexisted in the game system, and the test bed was composed of two computers connected by 100 M switched Ethernet, with one computer acted as local site and the other acted as remote site. In order to simulate network transmission delay, a specific module was developed to delay all packets transmitted between the two computers in terms of a predefined delay value. The main purpose of performance evaluation is to study the effects of GS-DR-LL on decreasing before inconsistency in a particular game system under different thresholds, lags, and network transmission delays. Two different thresholds were used in the evaluation, one is 10 pixels deviation in position or 15 degrees deviation in orientation, and the other is 4 pixels or 5 degrees. Six different combinations of lag and network transmission delay were used in the evaluation and they could be divided into two categories. In one category, the lag was fixed at 00 ms and three different network transmission delays (100 ms, 00 ms, and 500 ms) were used. In the other category, the network transmission delay was fixed at 800 ms and three different lags (100 ms, 300 ms, and 500 ms) were used. Therefore the total number of settings used in the evaluation was 12 (2 × 6). The procedure of performance evaluation was composed of three steps. In the first step, two participants were employed to play the game, and the operation sequences were recorded. Based on the records, a sub operation sequence, which lasted about one minute and included different operations (e.g. accelerate, decelerate, and turn), was selected. In the second step, the physical clocks of the two computers were synchronized first. Under different settings and consistency maintenance approaches, the selected sub operation sequence was played back on one computer, and it drove the two spaceships, one was local and the other was remote, to move. Meanwhile, the tracks of the spaceships on the two computers were recorded separately and they were called as a track couple. Since there are 12 settings and 2 consistency maintenance approaches, the total number of recorded track couples was 24. In the last step, to each track couple, the inconsistency between them was calculated, and the unit of inconsistency was pixel. Since the physical clocks of the two computers were synchronized, the calculation of inconsistency was quite simple. The inconsistency at a particular time point was the distance between the positions of the two spaceships at that time point (i.e. formula (3)). In order to show the results of inconsistency in a clear way, only parts of the results, which last about 7 seconds, are used in the following figures, and the figures show almost the same parts of the results. Figures 3, 4, and 5 show the results of inconsistency when the lag is fixed at 300 ms and the network transmission delays are 100, 300, and 500 ms. It can been seen that inconsistency does exist, but in most of the time it is 0. Additionally, inconsistency increases with the network transmission delay, but decreases with the threshold. Compared with GS-DR, GS-DR-LL can decrease more inconsistency, and it eliminates most inconsistency when the network transmission delay is 100 ms and the threshold is 4 pixels or 5 degrees.  The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 According to the prediction and state filtering mechanisms of DR, inconsistency cannot be completely eliminated if the threshold is not 0. With the definitions of before inconsistency and after inconsistency, it can be indicated that GS-DR and GS-DR-LL both can eliminate after inconsistency, and GS-DR-LL can effectively decrease before inconsistency. It can be foreseen that with proper lag and threshold (e.g. the lag is larger than the network transmission delay and the threshold is 0), GS-DR-LL even can eliminate before inconsistency.  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 3. Inconsistency when the network transmission delay is 100 ms and the lag is 300 ms.  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 4. Inconsistency when the network transmission delay is 300 ms and the lag is 300 ms.  0 0 0 0 .0 1.5 3.1 4.6 6.2 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 5. Inconsistency when the network transmission delay is 500 ms and the lag is 300 ms. Figures 6, 7, and 8 show the results of inconsistency when the network transmission delay is fixed at 800 ms and the lag are 100, 00, and 500 ms. It can be seen that with GS-DR-LL before inconsistency decreases with the lag. In traditional local lag, the lag must be set to a value larger than typical network transmission delay, otherwise the state repairs would flood the system. From the above results it can be seen that there does not exist any constraint on the selection of the lag, with GS-DR-LL a system would work fine even if the lag is much smaller than the network transmission delay. The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 5 From all above results, it can be indicated that GS-DR and  GSDR-LL both can eliminate after inconsistency, and GS-DR-LL can effectively decrease before inconsistency, and the effects increase with the lag.  0 0 0 0 .0 1.5 3.1 4.7 6.2 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 6. Inconsistency when the network transmission delay is 800 ms and the lag is 100 ms.  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 7. Inconsistency when the network transmission delay is 800 ms and the lag is 300 ms.  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 10 pixels or 15degrees  0 0 0 0 .0 1.5 3.1 4.6 6.1 Time (seconds) Inconsistency(pixels) GS-DR-LL GS-DR The threshold is 4 pixels or 5degrees Figure 8. Inconsistency when the network transmission delay is 800 ms and the lag is 500 ms. . CONCLUSIONS Compared with traditional DR, GS-DR can eliminate after inconsistency through the synchronization of physical clocks, but it cannot tackle before inconsistency, which would significantly influence the usability and fairness of a game. In this paper, we proposed a method named GS-DR-LL, which combines local lag and GS-DR, to decrease before inconsistency through delaying updating the execution results of local operations to local scene. Performance evaluation indicates that GS-DR-LL can effectively decrease before inconsistency, and the effects increase with the lag. GS-DR-LL has significant implications to consistency maintenance approaches. First, GS-DR-LL shows that improved DR can not only eliminate after inconsistency but also decrease  The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 before inconsistency, with proper lag and threshold, it would even eliminate before inconsistency. As a result, the application of DR can be greatly broadened and it could be used in the systems which request high consistency (e.g. highly interactive games). Second, GS-DR-LL shows that by combining local lag and  GSDR, the constraint on selecting lag value is removed and a lag, which is smaller than typical network transmission delay, could be used. As a result, the application of local lag can be greatly broadened and it could be used in the systems which have large typical network transmission delay (e.g. Internet based games). . REFERENCES [1] Mauve, M., Vogel, J., Hilt, V., and Effelsberg, W. Local-Lag and Timewarp: Providing Consistency for Replicated Continuous Applications. IEEE Transactions on Multimedia, Vol. 6, No.1, 2004, 47-57. [2] Li, F.W., Li, L.W., and Lau, R.W. Supporting Continuous Consistency in Multiplayer Online Games. In Proc. of ACM Multimedia, 2004, 388-391. [3] Pantel, L. and Wolf, L. On the Suitability of Dead Reckoning Schemes for Games. In Proc. of NetGames, 2002, 9-84. [4] Alhalabi, M.O., Horiguchi, S., and Kunifuji, S. An Experimental Study on the Effects of Network Delay in Cooperative Shared Haptic Virtual Environment. Computers and Graphics, Vol. 27, No. 2, 2003, 205-213. [5] Pantel, L. and Wolf, L.C. On the Impact of Delay on  RealTime Multiplayer Games. In Proc. of NOSSDAV, 2002,  329. [6] Meehan, M., Razzaque, S., Whitton, M.C., and Brooks, F.P. Effect of Latency on Presence in Stressful Virtual Environments. In Proc. of IEEE VR, 2003, 141-148. [7] Bernier, Y.W. Latency Compensation Methods in Client/Server In-Game Protocol Design and Optimization. In Proc. of Game Developers Conference, 2001. [8] Aggarwal, S., Banavar, H., and Khandelwal, A. Accuracy in Dead-Reckoning based Distributed Multi-Player Games. In Proc. of NetGames, 2004, 161-165. [9] Raynal, M. and Schiper, A. From Causal Consistency to Sequential Consistency in Shared Memory Systems. In Proc. of Conference on Foundations of Software Technology and Theoretical Computer Science, 1995, 180-194. [10] Ahamad, M., Burns, J.E., Hutto, P.W., and Neiger, G. Causal Memory. In Proc. of International Workshop on Distributed Algorithms, 1991, 9-30. [11] Herlihy, M. and Wing, J. Linearizability: a Correctness Condition for Concurrent Objects. ACM Transactions on Programming Languages and Systems, Vol. 12, No. 3, 1990, 63-492. [12] Misra, J. Axioms for Memory Access in Asynchronous Hardware Systems. ACM Transactions on Programming Languages and Systems, Vol. 8, No. 1, 1986, 142-153. [13] Dabrowski, J.R. and Munson, E.V. Is 100 Milliseconds too Fast. In Proc. of SIGCHI Conference on Human Factors in Computing Systems, 2001, 317-318. [14] Chen, H., Chen, L., and Chen, G.C. Effects of Local-Lag Mechanism on Cooperation Performance in a Desktop CVE System. Journal of Computer Science and Technology, Vol. 0, No. 3, 2005, 396-401. [15] Chen, L., Chen, H., and Chen, G.C. Echo: a Method to Improve the Interaction Quality of CVEs. In Proc. of IEEE VR, 2005, 269-270. The 5th Workshop on Network & System Support for Games 2006 - NETGAMES 2006 7
AdaRank: A Boosting Algorithm for Information Retrieval Jun Xu Microsoft Research Asia No. 49 Zhichun Road, Haidian Distinct Beijing, China 100080 junxu@microsoft.com Hang Li Microsoft Research Asia No. 49 Zhichun Road, Haidian Distinct Beijing, China 100080 hangli@microsoft.com ABSTRACT In this paper we address the issue of learning to rank for document retrieval. In the task, a model is automatically created with some training data and then is utilized for ranking of documents. The goodness of a model is usually evaluated with performance  measures such as MAP (Mean Average Precision) and NDCG  (Normalized Discounted Cumulative Gain). Ideally a learning  algorithm would train a ranking model that could directly optimize the performance measures with respect to the training data. Existing methods, however, are only able to train ranking models by  minimizing loss functions loosely related to the performance measures. For example, Ranking SVM and RankBoost train ranking  models by minimizing classification errors on instance pairs. To deal with the problem, we propose a novel learning algorithm within the framework of boosting, which can minimize a loss function directly defined on the performance measures. Our algorithm,  referred to as AdaRank, repeatedly constructs ‘weak rankers" on the basis of re-weighted training data and finally linearly combines the weak rankers for making ranking predictions. We prove that the training process of AdaRank is exactly that of enhancing the  performance measure used. Experimental results on four benchmark datasets show that AdaRank significantly outperforms the baseline methods of BM25, Ranking SVM, and RankBoost. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models General Terms Algorithms, Experimentation, Theory . INTRODUCTION Recently ‘learning to rank" has gained increasing attention in both the fields of information retrieval and machine learning. When applied to document retrieval, learning to rank becomes a task as follows. In training, a ranking model is constructed with data  consisting of queries, their corresponding retrieved documents, and  relevance levels given by humans. In ranking, given a new query, the corresponding retrieved documents are sorted by using the trained ranking model. In document retrieval, usually ranking results are evaluated in terms of performance measures such as MAP (Mean Average Precision) [1] and NDCG (Normalized Discounted  Cumulative Gain) [15]. Ideally, the ranking function is created so that the accuracy of ranking in terms of one of the measures with respect to the training data is maximized. Several methods for learning to rank have been developed and applied to document retrieval. For example, Herbrich et al. [13] propose a learning algorithm for ranking on the basis of Support Vector Machines, called Ranking SVM. Freund et al. [8] take a similar approach and perform the learning by using boosting,  referred to as RankBoost. All the existing methods used for  document retrieval [2, 3, 8, 13, 16, 20] are designed to optimize loss functions loosely related to the IR performance measures, not loss functions directly based on the measures. For example, Ranking SVM and RankBoost train ranking models by minimizing  classification errors on instance pairs. In this paper, we aim to develop a new learning algorithm that can directly optimize any performance measure used in document retrieval. Inspired by the work of AdaBoost for classification [9], we propose to develop a boosting algorithm for information  retrieval, referred to as AdaRank. AdaRank utilizes a linear  combination of ‘weak rankers" as its model. In learning, it repeats the process of re-weighting the training sample, creating a weak ranker, and calculating a weight for the ranker. We show that AdaRank algorithm can iteratively optimize an  exponential loss function based on any of IR performance measures. A lower bound of the performance on training data is given, which indicates that the ranking accuracy in terms of the performance measure can be continuously improved during the training process. AdaRank offers several advantages: ease in implementation,  theoretical soundness, efficiency in training, and high accuracy in ranking. Experimental results indicate that AdaRank can outperform the  baseline methods of BM25, Ranking SVM, and RankBoost, on four benchmark datasets including OHSUMED, WSJ, AP, and .Gov. Tuning ranking models using certain training data and a  performance measure is a common practice in IR [1]. As the number of features in the ranking model gets larger and the amount of  training data gets larger, the tuning becomes harder. From the viewpoint of IR, AdaRank can be viewed as a machine learning method for ranking model tuning. Recently, direct optimization of performance measures in  learning has become a hot research topic. Several methods for  classification [17] and ranking [5, 19] have been proposed. AdaRank can be viewed as a machine learning method for direct optimization of performance measures, based on a different approach. The rest of the paper is organized as follows. After a summary of related work in Section 2, we describe the proposed AdaRank algorithm in details in Section 3. Experimental results and  discussions are given in Section 4. Section 5 concludes this paper and gives future work. . RELATED WORK .1 Information Retrieval The key problem for document retrieval is ranking, specifically, how to create the ranking model (function) that can sort documents based on their relevance to the given query. It is a common practice in IR to tune the parameters of a ranking model using some labeled data and one performance measure [1]. For example, the  state-ofthe-art methods of BM25 [24] and LMIR (Language Models for Information Retrieval) [18, 22] all have parameters to tune. As the ranking models become more sophisticated (more features are used) and more labeled data become available, how to tune or train ranking models turns out to be a challenging issue. Recently methods of ‘learning to rank" have been applied to ranking model construction and some promising results have been obtained. For example, Joachims [16] applies Ranking SVM to document retrieval. He utilizes click-through data to deduce  training data for the model creation. Cao et al. [4] adapt Ranking SVM to document retrieval by modifying the Hinge Loss function to better meet the requirements of IR. Specifically, they introduce a Hinge Loss function that heavily penalizes errors on the tops of ranking lists and errors from queries with fewer retrieved  documents. Burges et al. [3] employ Relative Entropy as a loss function and Gradient Descent as an algorithm to train a Neural Network model for ranking in document retrieval. The method is referred to as ‘RankNet". .2 Machine Learning There are three topics in machine learning which are related to our current work. They are ‘learning to rank", boosting, and direct optimization of performance measures. Learning to rank is to automatically create a ranking function that assigns scores to instances and then rank the instances by  using the scores. Several approaches have been proposed to tackle the problem. One major approach to learning to rank is that of transforming it into binary classification on instance pairs. This ‘pair-wise" approach fits well with information retrieval and thus is widely used in IR. Typical methods of the approach include  Ranking SVM [13], RankBoost [8], and RankNet [3]. For other  approaches to learning to rank, refer to [2, 11, 31]. In the pair-wise approach to ranking, the learning task is  formalized as a problem of classifying instance pairs into two categories (correctly ranked and incorrectly ranked). Actually, it is known that reducing classification errors on instance pairs is equivalent to maximizing a lower bound of MAP [16]. In that sense, the  existing methods of Ranking SVM, RankBoost, and RankNet are only able to minimize loss functions that are loosely related to the IR performance measures. Boosting is a general technique for improving the accuracies of machine learning algorithms. The basic idea of boosting is to  repeatedly construct ‘weak learners" by re-weighting training data and form an ensemble of weak learners such that the total  performance of the ensemble is ‘boosted". Freund and Schapire have proposed the first well-known boosting algorithm called AdaBoost (Adaptive Boosting) [9], which is designed for binary  classification (0-1 prediction). Later, Schapire & Singer have introduced a generalized version of AdaBoost in which weak learners can give confidence scores in their predictions rather than make 0-1  decisions [26]. Extensions have been made to deal with the problems of multi-class classification [10, 26], regression [7], and ranking [8]. In fact, AdaBoost is an algorithm that ingeniously constructs a linear model by minimizing the ‘exponential loss function" with respect to the training data [26]. Our work in this paper can be viewed as a boosting method developed for ranking, particularly for ranking in IR. Recently, a number of authors have proposed conducting direct optimization of multivariate performance measures in learning. For instance, Joachims [17] presents an SVM method to directly  optimize nonlinear multivariate performance measures like the F1  measure for classification. Cossock & Zhang [5] find a way to  approximately optimize the ranking performance measure DCG [15]. Metzler et al. [19] also propose a method of directly maximizing rank-based metrics for ranking on the basis of manifold learning. AdaRank is also one that tries to directly optimize multivariate  performance measures, but is based on a different approach. AdaRank is unique in that it employs an exponential loss function based on IR performance measures and a boosting technique. . OUR METHOD: ADARANK .1 General Framework We first describe the general framework of learning to rank for document retrieval. In retrieval (testing), given a query the system returns a ranking list of documents in descending order of the  relevance scores. The relevance scores are calculated with a ranking function (model). In learning (training), a number of queries and their corresponding retrieved documents are given. Furthermore, the relevance levels of the documents with respect to the queries are also provided. The relevance levels are represented as ranks (i.e., categories in a total order). The objective of learning is to construct a ranking function which achieves the best results in ranking of the training data in the sense of minimization of a loss function. Ideally the loss function is defined on the basis of the performance measure used in testing. Suppose that Y = {r1, r2, · · · , r } is a set of ranks, where denotes the number of ranks. There exists a total order between the ranks r r −1 · · · r1, where ‘ " denotes a preference relationship. In training, a set of queries Q = {q1, q2, · · · , qm} is given. Each query qi is associated with a list of retrieved documents di = {di1, di2, · · · , di,n(qi)} and a list of labels yi = {yi1, yi2, · · · , yi,n(qi)}, where n(qi) denotes the sizes of lists di and yi, dij denotes the jth document in di, and yij ∈ Y denotes the rank of document di j. A feature  vector xij = Ψ(qi, di j) ∈ X is created from each query-document pair (qi, di j), i = 1, 2, · · · , m; j = 1, 2, · · · , n(qi). Thus, the training set can be represented as S = {(qi, di, yi)}m i=1. The objective of learning is to create a ranking function f : X → , such that for each query the elements in its corresponding  document list can be assigned relevance scores using the function and then be ranked according to the scores. Specifically, we create a permutation of integers π(qi, di, f) for query qi, the  corresponding list of documents di, and the ranking function f. Let di = {di1, di2, · · · , di,n(qi)} be identified by the list of integers {1, 2, · · · , n(qi)}, then permutation π(qi, di, f) is defined as a bijection from {1, 2, · · · , n(qi)} to itself. We use π( j) to denote the position of item j (i.e., di j). The learning process turns out to be that of minimizing the loss function which represents the disagreement between the  permutation π(qi, di, f) and the list of ranks yi, for all of the queries. Table 1: Notations and explanations. Notations Explanations qi ∈ Q ith query di = {di1, di2, · · · , di,n(qi)} List of documents for qi yi j ∈ {r1, r2, · · · , r } Rank of di j w.r.t. qi yi = {yi1, yi2, · · · , yi,n(qi)} List of ranks for qi S = {(qi, di, yi)}m i=1 Training set xij = Ψ(qi, dij) ∈ X Feature vector for (qi, di j) f(xij) ∈ Ranking model π(qi, di, f) Permutation for qi, di, and f ht(xi j) ∈ tth weak ranker E(π(qi, di, f), yi) ∈ [−1, +1] Performance measure function In the paper, we define the rank model as a linear combination of weak rankers: f(x) = T t=1 αtht(x), where ht(x) is a weak ranker, αt is its weight, and T is the number of weak rankers. In information retrieval, query-based performance measures are used to evaluate the ‘goodness" of a ranking function. By query based measure, we mean a measure defined over a ranking list of documents with respect to a query. These measures include MAP, NDCG, MRR (Mean Reciprocal Rank), WTA (Winners Take ALL), and Precision@n [1, 15]. We utilize a general function E(π(qi, di, f), yi) ∈ [−1, +1] to represent the performance  measures. The first argument of E is the permutation π created using the ranking function f on di. The second argument is the list of ranks yi given by humans. E measures the agreement between π and yi. Table 1 gives a summary of notations described above. Next, as examples of performance measures, we present the  definitions of MAP and NDCG. Given a query qi, the corresponding list of ranks yi, and a permutation πi on di, average precision for qi is defined as: AvgPi = n(qi) j=1 Pi( j) · yij n(qi) j=1 yij , (1) where yij takes on 1 and 0 as values, representing being relevant or irrelevant and Pi( j) is defined as precision at the position of dij: Pi( j) = k:πi(k)≤πi(j) yik πi(j) , (2) where πi( j) denotes the position of di j. Given a query qi, the list of ranks yi, and a permutation πi on di, NDCG at position m for qi is defined as: Ni = ni · j:πi(j)≤m yi j − 1 log(1 + πi( j)) , (3) where yij takes on ranks as values and ni is a normalization  constant. ni is chosen so that a perfect ranking π∗ i "s NDCG score at position m is 1. .2 Algorithm Inspired by the AdaBoost algorithm for classification, we have devised a novel algorithm which can optimize a loss function based on the IR performance measures. The algorithm is referred to as ‘AdaRank" and is shown in Figure 1. AdaRank takes a training set S = {(qi, di, yi)}m i=1 as input and takes the performance measure function E and the number of  iterations T as parameters. AdaRank runs T rounds and at each round it creates a weak ranker ht(t = 1, · · · , T). Finally, it outputs a ranking model f by linearly combining the weak rankers. At each round, AdaRank maintains a distribution of weights over the queries in the training data. We denote the distribution of weights Input: S = {(qi, di, yi)}m i=1, and parameters E and T Initialize P1(i) = 1/m. For t = 1, · · · , T • Create weak ranker ht with weighted distribution Pt on  training data S . • Choose αt αt =   · ln m i=1 Pt(i){1 + E(π(qi, di, ht), yi)} m i=1 Pt(i){1 − E(π(qi, di, ht), yi)} . • Create ft ft(x) = t k=1 αkhk(x). • Update Pt+1 Pt+1(i) = exp{−E(π(qi, di, ft), yi)} m j=1 exp{−E(π(qj, dj, ft), yj)} . End For Output ranking model: f(x) = fT (x). Figure 1: The AdaRank algorithm. at round t as Pt and the weight on the ith training query qi at round t as Pt(i). Initially, AdaRank sets equal weights to the queries. At each round, it increases the weights of those queries that are not ranked well by ft, the model created so far. As a result, the learning at the next round will be focused on the creation of a weak ranker that can work on the ranking of those ‘hard" queries. At each round, a weak ranker ht is constructed based on training data with weight distribution Pt. The goodness of a weak ranker is measured by the performance measure E weighted by Pt: m i=1 Pt(i)E(π(qi, di, ht), yi). Several methods for weak ranker construction can be considered. For example, a weak ranker can be created by using a subset of queries (together with their document list and label list) sampled according to the distribution Pt. In this paper, we use single features as weak rankers, as will be explained in Section 3.6. Once a weak ranker ht is built, AdaRank chooses a weight αt > 0 for the weak ranker. Intuitively, αt measures the importance of ht. A ranking model ft is created at each round by linearly  combining the weak rankers constructed so far h1, · · · , ht with weights α1, · · · , αt. ft is then used for updating the distribution Pt+1. .3 Theoretical Analysis The existing learning algorithms for ranking attempt to minimize a loss function based on instance pairs (document pairs). In  contrast, AdaRank tries to optimize a loss function based on queries. Furthermore, the loss function in AdaRank is defined on the basis of general IR performance measures. The measures can be MAP, NDCG, WTA, MRR, or any other measures whose range is within [−1, +1]. We next explain why this is the case. Ideally we want to maximize the ranking accuracy in terms of a performance measure on the training data: max f∈F m i=1 E(π(qi, di, f), yi), (4) where F is the set of possible ranking functions. This is equivalent to minimizing the loss on the training data min f∈F m i=1 (1 − E(π(qi, di, f), yi)). (5) It is difficult to directly optimize the loss, because E is a  noncontinuous function and thus may be difficult to handle. We instead attempt to minimize an upper bound of the loss in (5) min f∈F m i=1 exp{−E(π(qi, di, f), yi)}, (6) because e−x ≥ 1 − x holds for any x ∈ . We consider the use of a linear combination of weak rankers as our ranking model: f(x) = T t=1 αtht(x). (7) The minimization in (6) then turns out to be min ht∈H,αt∈ + L(ht, αt) = m i=1 exp{−E(π(qi, di, ft−1 + αtht), yi)}, (8) where H is the set of possible weak rankers, αt is a positive weight, and ( ft−1 + αtht)(x) = ft−1(x) + αtht(x). Several ways of computing coefficients αt and weak rankers ht may be considered. Following the idea of AdaBoost, in AdaRank we take the approach of ‘forward stage-wise additive modeling" [12] and get the algorithm in Figure . It can be proved that there exists a lower bound on the ranking accuracy for AdaRank on training data, as presented in Theorem 1. T 1. The following bound holds on the ranking  accuracy of the AdaRank algorithm on training data:  m m i=1 E(π(qi, di, fT ), yi) ≥ 1 − T t=1 e−δt min 1 − ϕ(t)2, where ϕ(t) = m i=1 Pt(i)E(π(qi, di, ht), yi), δt min = mini=1,··· ,m δt i, and δt i = E(π(qi, di, ft−1 + αtht), yi) − E(π(qi, di, ft−1), yi) −αtE(π(qi, di, ht), yi), for all i = 1, 2, · · · , m and t = 1, 2, · · · , T. A proof of the theorem can be found in appendix. The theorem implies that the ranking accuracy in terms of the performance  measure can be continuously improved, as long as e−δt min 1 − ϕ(t)2 < 1 holds. .4 Advantages AdaRank is a simple yet powerful method. More importantly, it is a method that can be justified from the theoretical viewpoint, as discussed above. In addition AdaRank has several other advantages when compared with the existing learning to rank methods such as Ranking SVM, RankBoost, and RankNet. First, AdaRank can incorporate any performance measure,  provided that the measure is query based and in the range of [−1, +1]. Notice that the major IR measures meet this requirement. In  contrast the existing methods only minimize loss functions that are loosely related to the IR measures [16]. Second, the learning process of AdaRank is more efficient than those of the existing learning algorithms. The time complexity of AdaRank is of order O((k+T)·m·n log n), where k denotes the  number of features, T the number of rounds, m the number of queries in training data, and n is the maximum number of documents for queries in training data. The time complexity of RankBoost, for example, is of order O(T · m · n2 ) [8]. Third, AdaRank employs a more reasonable framework for  performing the ranking task than the existing methods. Specifically in AdaRank the instances correspond to queries, while in the existing methods the instances correspond to document pairs. As a result, AdaRank does not have the following shortcomings that plague the existing methods. (a) The existing methods have to make a strong assumption that the document pairs from the same query are  independently distributed. In reality, this is clearly not the case and this problem does not exist for AdaRank. (b) Ranking the most relevant documents on the tops of document lists is crucial for document  retrieval. The existing methods cannot focus on the training on the tops, as indicated in [4]. Several methods for rectifying the problem have been proposed (e.g., [4]), however, they do not seem to  fundamentally solve the problem. In contrast, AdaRank can naturally focus on training on the tops of document lists, because the  performance measures used favor rankings for which relevant documents are on the tops. (c) In the existing methods, the numbers of  document pairs vary from query to query, resulting in creating models biased toward queries with more document pairs, as pointed out in [4]. AdaRank does not have this drawback, because it treats queries rather than document pairs as basic units in learning. .5 Differences from AdaBoost AdaRank is a boosting algorithm. In that sense, it is similar to AdaBoost, but it also has several striking differences from AdaBoost. First, the types of instances are different. AdaRank makes use of queries and their corresponding document lists as instances. The  labels in training data are lists of ranks (relevance levels). AdaBoost makes use of feature vectors as instances. The labels in training data are simply +1 and −1. Second, the performance measures are different. In AdaRank, the performance measure is a generic measure, defined on the  document list and the rank list of a query. In AdaBoost the  corresponding performance measure is a specific measure for binary  classification, also referred to as ‘margin" [25]. Third, the ways of updating weights are also different. In  AdaBoost, the distribution of weights on training instances is  calculated according to the current distribution and the performance of the current weak learner. In AdaRank, in contrast, it is calculated according to the performance of the ranking model created so far, as shown in Figure 1. Note that AdaBoost can also adopt the weight updating method used in AdaRank. For AdaBoost they are  equivalent (cf., [12] page 305). However, this is not true for AdaRank. .6 Construction of Weak Ranker We consider an efficient implementation for weak ranker  construction, which is also used in our experiments. In the  implementation, as weak ranker we choose the feature that has the optimal weighted performance among all of the features: max k m i=1 Pt(i)E(π(qi, di, xk), yi). Creating weak rankers in this way, the learning process turns out to be that of repeatedly selecting features and linearly combining the selected features. Note that features which are not selected in the training phase will have a weight of zero. . EXPERIMENTAL RESULTS We conducted experiments to test the performances of AdaRank using four benchmark datasets: OHSUMED, WSJ, AP, and .Gov. Table 2: Features used in the experiments on OHSUMED, WSJ, and AP datasets. C(w, d) represents frequency of word w in document d; C represents the entire collection; n denotes number of terms in query; | · | denotes the size function; and id f(·) denotes inverse document frequency.  wi∈q d ln(c(wi, d) + 1) 2 wi∈q d ln( |C| c(wi,C) + 1)  wi∈q d ln(id f(wi)) 4 wi∈q d ln(c(wi,d) |d| + 1)  wi∈q d ln(c(wi,d) |d| · id f(wi) + 1) 6 wi∈q d ln(c(wi,d)·|C| |d|·c(wi,C) + 1)  ln(BM25 score) .2 .3 .4 .5 .6 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RarnkBoost AdaRank.MAP AdaRank.NDCG Figure 2: Ranking accuracies on OHSUMED data. .1 Experiment Setting Ranking SVM [13, 16] and RankBoost [8] were selected as  baselines in the experiments, because they are the state-of-the-art  learning to rank methods. Furthermore, BM25 [24] was used as a  baseline, representing the state-of-the-arts IR method (we actually used the tool Lemur1 ). For AdaRank, the parameter T was determined automatically during each experiment. Specifically, when there is no  improvement in ranking accuracy in terms of the performance measure, the iteration stops (and T is determined). As the measure E, MAP and NDCG@5 were utilized. The results for AdaRank using MAP and NDCG@5 as measures in training are represented as AdaRank.MAP and AdaRank.NDCG, respectively. .2 Experiment with OHSUMED Data In this experiment, we made use of the OHSUMED dataset [14] to test the performances of AdaRank. The OHSUMED dataset  consists of 348,566 documents and 106 queries. There are in total 6,140 query-document pairs upon which relevance judgments are made. The relevance judgments are either ‘d" (definitely relevant), ‘p" (possibly relevant), or ‘n"(not relevant). The data have been used in many experiments in IR, for example [4, 29]. As features, we adopted those used in document retrieval [4]. Table 2 shows the features. For example, tf (term frequency), idf (inverse document frequency), dl (document length), and  combinations of them are defined as features. BM25 score itself is also a feature. Stop words were removed and stemming was conducted in the data. We randomly divided queries into four even subsets and  conducted 4-fold cross-validation experiments. We tuned the  parameters for BM25 during one of the trials and applied them to the other trials. The results reported in Figure 2 are those averaged over four trials. In MAP calculation, we define the rank ‘d" as relevant and  http://www.lemurproject.com Table 3: Statistics on WSJ and AP datasets. Dataset # queries # retrieved docs # docs per query AP 116 24,727 213.16 WSJ 126 40,230 319.29 .40 .45 .50 .55 .60 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figure 3: Ranking accuracies on WSJ dataset. the other two ranks as irrelevant. From Figure 2, we see that both AdaRank.MAP and AdaRank.NDCG outperform BM25, Ranking SVM, and RankBoost in terms of all measures. We conducted  significant tests (t-test) on the improvements of AdaRank.MAP over BM25, Ranking SVM, and RankBoost in terms of MAP. The  results indicate that all the improvements are statistically significant (p-value < 0.05). We also conducted t-test on the improvements of AdaRank.NDCG over BM25, Ranking SVM, and RankBoost in terms of NDCG@5. The improvements are also statistically significant. .3 Experiment with WSJ and AP Data In this experiment, we made use of the WSJ and AP datasets from the TREC ad-hoc retrieval track, to test the performances of AdaRank. WSJ contains 74,520 articles of Wall Street Journals from 1990 to 1992, and AP contains 158,240 articles of  Associated Press in 1988 and 1990. 200 queries are selected from the TREC topics (No.101 ∼ No.300). Each query has a number of  documents associated and they are labeled as ‘relevant" or ‘irrelevant" (to the query). Following the practice in [28], the queries that have less than 10 relevant documents were discarded. Table 3 shows the statistics on the two datasets. In the same way as in section 4.2, we adopted the features listed in Table 2 for ranking. We also conducted 4-fold cross-validation experiments. The results reported in Figure 3 and 4 are those  averaged over four trials on WSJ and AP datasets, respectively. From Figure 3 and 4, we can see that AdaRank.MAP and AdaRank.NDCG outperform BM25, Ranking SVM, and RankBoost in terms of all measures on both WSJ and AP. We conducted t-tests on the  improvements of AdaRank.MAP and AdaRank.NDCG over BM25, Ranking SVM, and RankBoost on WSJ and AP. The results  indicate that all the improvements in terms of MAP are statistically  significant (p-value < 0.05). However only some of the improvements in terms of NDCG@5 are statistically significant, although overall the improvements on NDCG scores are quite high (1-2 points). .4 Experiment with .Gov Data In this experiment, we further made use of the TREC .Gov data to test the performance of AdaRank for the task of web retrieval. The corpus is a crawl from the .gov domain in early 2002, and has been used at TREC Web Track since 2002. There are a total .40 .45 .50 .55 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figure 4: Ranking accuracies on AP dataset. .1 .2 .3 .4 .5 .6 .7 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figure 5: Ranking accuracies on .Gov dataset. Table 4: Features used in the experiments on .Gov dataset.  BM25 [24] 2 MSRA1000 [27]  PageRank [21] 4 HostRank [30]  Relevance Propagation [23] (10 features) of 1,053,110 web pages with 11,164,829 hyperlinks in the data. The 50 queries in the topic distillation task in the Web Track of TREC 2003 [6] were used. The ground truths for the queries are provided by the TREC committee with binary judgment: relevant or irrelevant. The number of relevant pages vary from query to query (from 1 to 86). We extracted 14 features from each query-document pair.  Table 4 gives a list of the features. They are the outputs of some well-known algorithms (systems). These features are different from those in Table 2, because the task is different. Again, we conducted 4-fold cross-validation experiments. The results averaged over four trials are reported in Figure 5. From the results, we can see that AdaRank.MAP and AdaRank.NDCG  outperform all the baselines in terms of all measures. We conducted  ttests on the improvements of AdaRank.MAP and AdaRank.NDCG over BM25, Ranking SVM, and RankBoost. Some of the  improvements are not statistically significant. This is because we have only 0 queries used in the experiments, and the number of queries is too small. .5 Discussions We investigated the reasons that AdaRank outperforms the  baseline methods, using the results of the OHSUMED dataset as examples. First, we examined the reason that AdaRank has higher  performances than Ranking SVM and RankBoost. Specifically we  com0.58 .60 .62 .64 .66 .68 d-n d-p p-n accuracy pair type Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figure 6: Accuracy on ranking document pairs with OHSUMED dataset.      0 2 numberofqueries number of document pairs per query Figure 7: Distribution of queries with different number of  document pairs in training data of trial 1. pared the error rates between different rank pairs made by  Ranking SVM, RankBoost, AdaRank.MAP, and AdaRank.NDCG on the test data. The results averaged over four trials in the 4-fold cross validation are shown in Figure 6. We use ‘d-n" to stand for the pairs between ‘definitely relevant" and ‘not relevant", ‘d-p" the pairs  between ‘definitely relevant" and ‘partially relevant", and ‘p-n" the pairs between ‘partially relevant" and ‘not relevant". From  Figure 6, we can see that AdaRank.MAP and AdaRank.NDCG make fewer errors for ‘d-n" and ‘d-p", which are related to the tops of rankings and are important. This is because AdaRank.MAP and AdaRank.NDCG can naturally focus upon the training on the tops by optimizing MAP and NDCG@5, respectively. We also made statistics on the number of document pairs per query in the training data (for trial 1). The queries are clustered into different groups based on the the number of their associated  document pairs. Figure 7 shows the distribution of the query groups. In the figure, for example, ‘0-1k" is the group of queries whose  number of document pairs are between 0 and 999. We can see that the numbers of document pairs really vary from query to query. Next we evaluated the accuracies of AdaRank.MAP and RankBoost in terms of MAP for each of the query group. The results are reported in Figure 8. We found that the average MAP of AdaRank.MAP over the groups is two points higher than RankBoost. Furthermore, it is interesting to see that AdaRank.MAP performs particularly better than RankBoost for queries with small numbers of document pairs (e.g., ‘0-1k", ‘1k-2k", and ‘2k-3k"). The results indicate that AdaRank.MAP can effectively avoid creating a model biased  towards queries with more document pairs. For AdaRank.NDCG, similar results can be observed. .2 .3 .4 .5 MAP query group RankBoost AdaRank.MAP Figure 8: Differences in MAP for different query groups. .30 .31 .32 .33 .34 trial 1 trial 2 trial 3 trial 4 MAP AdaRank.MAP AdaRank.NDCG Figure 9: MAP on training set when model is trained with MAP or NDCG@5. We further conducted an experiment to see whether AdaRank has the ability to improve the ranking accuracy in terms of a measure by using the measure in training. Specifically, we trained ranking models using AdaRank.MAP and AdaRank.NDCG and evaluated their accuracies on the training dataset in terms of both MAP and NDCG@5. The experiment was conducted for each trial. Figure  and Figure 10 show the results in terms of MAP and NDCG@5, respectively. We can see that, AdaRank.MAP trained with MAP performs better in terms of MAP while AdaRank.NDCG trained with NDCG@5 performs better in terms of NDCG@5. The results indicate that AdaRank can indeed enhance ranking performance in terms of a measure by using the measure in training. Finally, we tried to verify the correctness of Theorem 1. That is, the ranking accuracy in terms of the performance measure can be continuously improved, as long as e−δt min 1 − ϕ(t)2 < 1 holds. As an example, Figure 11 shows the learning curve of AdaRank.MAP in terms of MAP during the training phase in one trial of the cross validation. From the figure, we can see that the ranking accuracy of AdaRank.MAP steadily improves, as the training goes on, until it reaches to the peak. The result agrees well with Theorem 1. . CONCLUSION AND FUTURE WORK In this paper we have proposed a novel algorithm for learning ranking models in document retrieval, referred to as AdaRank. In contrast to existing methods, AdaRank optimizes a loss function that is directly defined on the performance measures. It employs a boosting technique in ranking model learning. AdaRank offers several advantages: ease of implementation, theoretical soundness, efficiency in training, and high accuracy in ranking. Experimental results based on four benchmark datasets show that AdaRank can significantly outperform the baseline methods of BM25, Ranking SVM, and RankBoost. .49 .50 .51 .52 .53 trial 1 trial 2 trial 3 trial 4 NDCG@5 AdaRank.MAP AdaRank.NDCG Figure 10: NDCG@5 on training set when model is trained with MAP or NDCG@5. .29 .30 .31 .32  50 100 150 200 250 300 350 MAP number of rounds Figure 11: Learning curve of AdaRank. Future work includes theoretical analysis on the generalization error and other properties of the AdaRank algorithm, and further empirical evaluations of the algorithm including comparisons with other algorithms that can directly optimize performance measures. . ACKNOWLEDGMENTS We thank Harry Shum, Wei-Ying Ma, Tie-Yan Liu, Gu Xu, Bin Gao, Robert Schapire, and Andrew Arnold for their valuable  comments and suggestions to this paper. . REFERENCES [1] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison Wesley, May 1999. [2] C. Burges, R. Ragno, and Q. Le. Learning to rank with nonsmooth cost functions. In Advances in Neural Information Processing Systems 18, pages 395-402. MIT Press, Cambridge, MA, 2006. [3] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML 22, pages 89-96, 2005. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang, and H.-W. Hon. Adapting ranking SVM to document retrieval. In SIGIR 29, pages 186-193, 2006. [5] D. Cossock and T. Zhang. Subset ranking using regression. In COLT, pages 605-619, 2006. [6] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu. Overview of the TREC 2003 web track. In TREC, pages 8-92, 2003. [7] N. Duffy and D. Helmbold. Boosting methods for regression. Mach. Learn., 47(2-3):153-200, 2002. [8] Y. Freund, R. D. Iyer, R. E. Schapire, and Y. Singer. An efficient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933-969, 2003. [9] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. J. Comput. Syst. Sci., 55(1):119-139, 1997. [10] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: A statistical view of boosting. The Annals of Statistics, 28(2):337-374, 2000. [11] G. Fung, R. Rosales, and B. Krishnapuram. Learning rankings via convex hull separation. In Advances in Neural Information Processing Systems 18, pages 395-402. MIT Press, Cambridge, MA, 2006. [12] T. Hastie, R. Tibshirani, and J. H. Friedman. The Elements of Statistical Learning. Springer, August 2001. [13] R. Herbrich, T. Graepel, and K. Obermayer. Large Margin rank boundaries for ordinal regression. MIT Press, Cambridge, MA, 2000. [14] W. Hersh, C. Buckley, T. J. Leone, and D. Hickam. Ohsumed: an interactive retrieval evaluation and new large test collection for research. In SIGIR, pages 192-201, 1994. [15] K. Jarvelin and J. Kekalainen. IR evaluation methods for retrieving highly relevant documents. In SIGIR 23, pages 1-48, 2000. [16] T. Joachims. Optimizing search engines using clickthrough data. In SIGKDD 8, pages 133-142, 2002. [17] T. Joachims. A support vector method for multivariate performance measures. In ICML 22, pages 377-384, 2005. [18] J. Lafferty and C. Zhai. Document language models, query models, and risk minimization for information retrieval. In SIGIR 24, pages 111-119, 2001. [19] D. A. Metzler, W. B. Croft, and A. McCallum. Direct maximization of rank-based metrics for information retrieval. Technical report, CIIR, 2005. [20] R. Nallapati. Discriminative models for information retrieval. In SIGIR 27, pages 64-71, 2004. [21] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford Digital Library Technologies Project, 1998. [22] J. M. Ponte and W. B. Croft. A language modeling approach to information retrieval. In SIGIR 21, pages 275-281, 1998. [23] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen, and W.-Y. Ma. A study of relevance propagation for web search. In SIGIR 28, pages 408-415, 2005. [24] S. E. Robertson and D. A. Hull. The TREC-9 filtering track final report. In TREC, pages 25-40, 2000. [25] R. E. Schapire, Y. Freund, P. Barlett, and W. S. Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. In ICML 14, pages 322-330, 1997. [26] R. E. Schapire and Y. Singer. Improved boosting algorithms using confidence-rated predictions. Mach. Learn., 7(3):297-336, 1999. [27] R. Song, J. Wen, S. Shi, G. Xin, T. yan Liu, T. Qin, X. Zheng, J. Zhang, G. Xue, and W.-Y. Ma. Microsoft Research Asia at web track and terabyte track of TREC 2004. In TREC, 2004. [28] A. Trotman. Learning to rank. Inf. Retr., 8(3):359-381, 2005. [29] J. Xu, Y. Cao, H. Li, and Y. Huang. Cost-sensitive learning of SVM for ranking. In ECML, pages 833-840, 2006. [30] G.-R. Xue, Q. Yang, H.-J. Zeng, Y. Yu, and Z. Chen. Exploiting the hierarchical structure for link analysis. In SIGIR 28, pages 186-193, 2005. [31] H. Yu. SVM selective sampling for ranking with application to data retrieval. In SIGKDD 11, pages 354-363, 2005. APPENDIX Here we give the proof of Theorem 1. P. Set ZT = m i=1 exp {−E(π(qi, di, fT ), yi)} and φ(t) = 1  (1 + ϕ(t)). According to the definition of αt, we know that eαt = φ(t) −φ(t) . ZT = m i=1 exp {−E(π(qi, di, fT−1 + αT hT ), yi)} = m i=1 exp −E(π(qi, di, fT−1), yi) − αT E(π(qi, di, hT ), yi) − δT i ≤ m i=1 exp {−E(π(qi, di, fT−1), yi)} exp {−αT E(π(qi, di, hT ), yi)} e−δT min = e−δT min ZT−1 m i=1 exp {−E(π(qi, di, fT−1), yi)} ZT−1 exp{−αT E(π(qi, di, hT ), yi)} = e−δT min ZT−1 m i=1 PT (i) exp{−αT E(π(qi, di, hT ), yi)}. Moreover, if E(π(qi, di, hT ), yi) ∈ [−1, +1] then, ZT ≤ e−δT minZT−1 m i=1 PT (i) +E(π(qi, di, hT ), yi)  e−αT + −E(π(qi, di, hT ), yi)  eαT = e−δT min ZT−1  φ(T)  − φ(T) φ(T) + (1 − φ(T)) φ(T)  − φ(T)   = ZT−1e−δT min 4φ(T)(1 − φ(T)) ≤ ZT−2 T t=T−1 e−δt min 4φ(t)(1 − φ(t)) ≤ Z1 T t=2 e−δt min 4φ(t)(1 − φ(t)) = m m i=1  m exp{−E(π(qi, di, α1h1), yi)} T t=2 e−δt min 4φ(t)(1 − φ(t)) = m m i=1  m exp{−α1E(π(qi, di, h1), yi) − δ1 i } T t=2 e−δt min 4φ(t)(1 − φ(t)) ≤ me−δ1 min m i=1  m exp{−α1E(π(qi, di, h1), yi)} T t=2 e−δt min 4φ(t)(1 − φ(t)) ≤ m e−δ1 min 4φ(1)(1 − φ(1)) T t=2 e−δt min 4φ(t)(1 − φ(t)) = m T t=1 e−δt min 1 − ϕ(t)2. ∴  m m i=1 E(π(qi, di, fT ), yi) ≥  m m i=1 {1 − exp(−E(π(qi, di, fT ), yi))} ≥ 1 − T t=1 e−δt min 1 − ϕ(t)2.
Relaxed Online SVMs for Spam Filtering D. Sculley Tufts University Department of Computer Science 61 College Ave., Medford, MA USA dsculleycs.tufts.edu Gabriel M. Wachman Tufts University Department of Computer Science 61 College Ave., Medford, MA USA gwachm01cs.tufts.edu ABSTRACT Spam is a key problem in electronic communication,  including large-scale email systems and the growing number of blogs. Content-based filtering is one reliable method of  combating this threat in its various forms, but some academic researchers and industrial practitioners disagree on how best to filter spam. The former have advocated the use of  Support Vector Machines (SVMs) for content-based filtering, as this machine learning methodology gives state-of-the-art performance for text classification. However, similar  performance gains have yet to be demonstrated for online spam filtering. Additionally, practitioners cite the high cost of SVMs as reason to prefer faster (if less statistically robust) Bayesian methods. In this paper, we offer a resolution to this controversy. First, we show that online SVMs indeed give state-of-the-art classification performance on online spam filtering on large benchmark data sets. Second, we show that nearly equivalent performance may be achieved by a Relaxed Online SVM (ROSVM) at greatly reduced  computational cost. Our results are experimentally verified on email spam, blog spam, and splog detection tasks. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - spam General Terms Measurement, Experimentation, Algorithms . INTRODUCTION Electronic communication is increasingly plagued by  unwanted or harmful content known as spam. The most well known form of spam is email spam, which remains a major problem for large email systems. Other forms of spam are also becoming problematic, including blog spam, in which spammers post unwanted comments in blogs [21], and splogs, which are fake blogs constructed to enable link spam with the hope of boosting the measured importance of a given webpage in the eyes of automated search engines [17]. There are a variety of methods for identifying these many forms of spam, including compiling blacklists of known spammers, and conducting link analysis. The approach of content analysis has shown particular promise and generality for combating spam. In content  analysis, the actual message text (often including hyper-text and meta-text, such as HTML and headers) is analyzed using machine learning techniques for text classification to  determine if the given content is spam. Content analysis has been widely applied in detecting email spam [11], and has also been used for identifying blog spam [21] and splogs [17]. In this paper, we do not explore the related problem of link spam, which is currently best combated by link analysis [13]. .1 An Anti-Spam Controversy The anti-spam community has been divided on the choice of the best machine learning method for content-based spam detection. Academic researchers have tended to favor the use of Support Vector Machines (SVMs), a statistically  robust machine learning method [7] which yields  state-of-theart performance on general text classification [14]. However, SVMs typically require training time that is quadratic in the number of training examples, and are impractical for  largescale email systems. Practitioners requiring content-based spam filtering have typically chosen to use the faster (if less statistically robust) machine learning method of Naive Bayes text classification [11, 12, 20]. This Bayesian method requires only linear training time, and is easily implemented in an online setting with incremental updates. This allows a deployed system to easily adapt to a changing environment over time. Other fast methods for spam filtering include compression models [1] and logistic regression [10]. It has not yet been empirically demonstrated that SVMs give  improved performance over these methods in an online spam detection setting [4]. .2 Contributions In this paper, we address the anti-spam controversy and offer a potential resolution. We first demonstrate that  online SVMs do indeed provide state-of-the-art spam detection through empirical tests on several large benchmark data sets of email spam. We then analyze the effect of the tradeoff parameter in the SVM objective function, which shows that the expensive SVM methodology may, in fact, be overkill for spam detection. We reduce the computational cost of SVM learning by relaxing this requirement on the maximum  margin in online settings, and create a Relaxed Online SVM, ROSVM, appropriate for high performance content-based spam filtering in large-scale settings. . SPAM AND ONLINE SVMS The controversy between academics and practitioners in spam filtering centers on the use of SVMs. The former  advocate their use, but have yet to demonstrate strong  performance with SVMs on online spam filtering. Indeed, the results of [4] show that, when used with default parameters, SVMs actually perform worse than other methods. In this section, we review the basic workings of SVMs and describe a simple Online SVM algorithm. We then show that Online SVMs indeed achieve state-of-the-art performance on  filtering email spam, blog comment spam, and splogs, so long as the tradeoff parameter C is set to a high value. However, the cost of Online SVMs turns out to be prohibitive for  largescale applications. These findings motivate our proposal of Relaxed Online SVMs in the following section. .1 Background: SVMs SVMs are a robust machine learning methodology which has been shown to yield state-of-the-art performance on text classification [14]. by finding a hyperplane that separates two classes of data in data space while maximizing the  margin between them. We use the following notation to describe SVMs, which draws from [23]. A data set X contains n labeled example vectors {(x1, y1) . . . (xn, yn)}, where each xi is a vector  containing features describing example i, and each yi is the class label for that example. In spam detection, the classes spam and ham (i.e., not spam) are assigned the numerical class labels +1 and −1, respectively. The linear SVMs we employ in this paper use a hypothesis vector w and bias term b to classify a new example x, by generating a predicted class label f(x): f(x) = sign(< w, x > +b) SVMs find the hypothesis w, which defines the separating hyperplane, by minimizing the following objective function over all n training examples: τ(w, ξ) =   ||w||2 + C nX i=i ξi under the constraints that ∀i = {1..n} : yi(< w, xi > +b) ≥ 1 − ξi, ξi ≥ 0 In this objective function, each slack variable ξi shows the amount of error that the classifier makes on a given example xi. Minimizing the sum of the slack variables corresponds to minimizing the loss function on the training data, while minimizing the term 1  ||w||2 corresponds to maximizing the margin between the two classes [23]. These two optimization goals are often in conflict; the tradeoff parameter C  determines how much importance to give each of these tasks. Linear SVMs exploit data sparsity to classify a new  instance in O(s) time, where s is the number of non-zero  features. This is the same classification time as other linear Given: data set X = (x1, y1), . . . , (xn, yn), C, m: Initialize w := 0, b := 0, seenData := { } For Each xi ∈ X do: Classify xi using f(xi) = sign(< w, xi > +b) IF yif(xi) < 1 Find w , b using SMO on seenData, using w, b as seed hypothesis. Add xi to seenData done Figure 1: Pseudo code for Online SVM. classifiers, and as Naive Bayesian classification. Training SVMs, however, typically takes O(n2 ) time, for n training examples. A variant for linear SVMs was recently proposed which trains in O(ns) time [15], but because this method has a high constant, we do not explore it here. .2 Online SVMs In many traditional machine learning applications, SVMs are applied in batch mode. That is, an SVM is trained on an entire set of training data, and is then tested on a  separate set of testing data. Spam filtering is typically tested and deployed in an online setting, which proceeds  incrementally. Here, the learner classifies a new example, is told if its prediction is correct, updates its hypothesis accordingly, and then awaits a new example. Online learning allows a deployed system to adapt itself in a changing environment. Re-training an SVM from scratch on the entire set of  previously seen data for each new example is cost prohibitive. However, using an old hypothesis as the starting point for re-training reduces this cost considerably. One method of  incremental and decremental SVM learning was proposed in [2]. Because we are only concerned with incremental  learning, we apply a simpler algorithm for converting a batch SVM learner into an online SVM (see Figure 1 for  pseudocode), which is similar to the approach of [16]. Each time the Online SVM encounters an example that was poorly classified, it retrains using the old hypothesis as a starting point. Note that due to the Karush-Kuhn-Tucker (KKT) conditions, it is not necessary to re-train on  wellclassified examples that are outside the margins [23]. We used Platt"s SMO algorithm [22] as a core SVM solver, because it is an iterative method that is well suited to  converge quickly from a good initial hypothesis. Because  previous work (and our own initial testing) indicates that binary feature values give the best results for spam filtering [20, ], we optimized our implementation of the Online SMO to exploit fast inner-products with binary vectors. 1 .3 Feature Mapping Spam Content Extracting machine learning features from text may be done in a variety of ways, especially when that text may include hyper-content and meta-content such as HTML and header information. However, previous research has shown that simple methods from text classification, such as bag of words vectors, and overlapping character-level n-grams, can achieve strong results [9]. Formally, a bag of words  vector is a vector x with a unique dimension for each possible  Our source code is freely available at www.cs.tufts.edu/∼dsculley/onlineSMO.  .999 .995 .99 .985 .98 .1 1 10 100 1000 ROCArea C -grams -grams -grams words Figure 2: Tuning the Tradeoff Parameter C. Tests were conducted with Online SMO, using binary  feature vectors, on the spamassassin data set of 6034 examples. Graph plots C versus Area under the ROC curve. word, defined as a contiguous substring of non-whitespace characters. An n-gram vector is a vector x with a unique dimension for each possible substring of n total characters. Note that n-grams may include whitespace, and are  overlapping. We use binary feature scoring, which has been shown to be most effective for a variety of spam detection  methods [20, 9]. We normalize the vectors with the Euclidean norm. Furthermore, with email data, we reduce the impact of long messages (for example, with attachments) by  considering only the first 3,000 characters of each string. For blog comments and splogs, we consider the whole text,  including any meta-data such as HTML tags, as given. No other feature selection or domain knowledge was used. .4 Tuning the Tradeoff Parameter, C The SVM tradeoff parameter C must be tuned to balance the (potentially conflicting) goals of maximizing the  margin and minimizing the training error. Early work on SVM based spam detection [9] showed that high values of C give best performance with binary features. Later work has not always followed this lead: a (low) default setting of C was used on splog detection [17], and also on email spam [4]. Following standard machine learning practice, we tuned C on separate tuning data not used for later testing. We used the publicly available spamassassin email spam data set, and created an online learning task by randomly interleaving all 6034 labeled messages to create a single ordered set. For tuning, we performed a coarse parameter search for C using powers of ten from .0001 to 10000. We used the Online SVM described above, and tested both binary bag of words vectors and n-gram vectors with n = {2, 3, 4}. We used the first 3000 characters of each message, which included header information, body of the email, and possibly attachments. Following the recommendation of [6], we use Area under the ROC curve as our evaluation measure. The results (see Figure 2) agree with [9]: there is a plateau of high  performance achieved with all values of C ≥ 10, and performance degrades sharply with C < 1. For the remainder of our  experiments with SVMs in this paper, we set C = 100. We will return to the observation that very high values of C do not degrade performance as support for the intuition that relaxed SVMs should perform well on spam. Table 1: Results for Email Spam filtering with  Online SVM on benchmark data sets. Score reported is (1-ROCA)%, where 0 is optimal. trec05p-1 trec06p OnSVM: words 0.015 (.011-.022) 0.034 (.025-.046) -grams 0.011 (.009-.015) 0.025 (.017-.035) -grams 0.008 (.007-.011) 0.023 (.017-.032) SpamProbe 0.059 (.049-.071) 0.092 (.078-.110) BogoFilter 0.048 (.038-.062) 0.077 (.056-.105) TREC Winners 0.019 (.015-.023) 0.054 (.034-.085) 3-Ensemble 0.007 (.005-.008) 0.020 (.007-.050) Table 2: Results for Blog Comment Spam Detection using SVMs and Leave One Out Cross Validation. We report the same performance measures as in the prior work for meaningful comparison. accuracy precision recall SVM C = 100: words 0.931 0.946 0.954 -grams 0.951 0.963 0.965 -grams 0.949 0.967 0.956 Prior best method 0.83 0.874 0.874 .5 Email Spam and Online SVMs With C tuned on a separate tuning set, we then tested the performance of Online SVMs in spam detection. We used two large benchmark data sets of email spam as our test corpora. These data sets are the 2005 TREC public data set trec05p-1 of 92,189 messages, and the 2006 TREC public data sets, trec06p, containing 37,822 messages in English. (We do not report our strong results on the trec06c corpus of Chinese messages as there have been questions raised over the validity of this test set.) We used the canonical ordering provided with each of these data sets for fair comparison. Results for these experiments, with bag of words vectors and and n-gram vectors appear in Table 1. To compare our results with previous scores on these data sets, we use the same (1-ROCA)% measure described in [6], which is one  minus the area under the ROC curve, expressed as a percent. This measure shows the percent chance of error made by a classifier asserting that one message is more likely to be spam than another. These results show that Online SVMs do give state of the art performance on email spam. The only known system that out-performs the Online SVMs on the trec05p-1 data set is a recent ensemble classifier which combines the results of 53 unique spam filters [19]. To our knowledge, the Online SVM has out-performed every other single filter on these data sets, including those using Bayesian methods [5, 3], compression models [5, 3], logistic regression [10], and perceptron variants [3], the TREC  competition winners [5, 3], and open source email spam filters BogoFilter v1.1.5 and SpamProbe v1.4d. .6 Blog Comment Spam and SVMs Blog comment spam is similar to email spam in many  regards, and content-based methods have been proposed for detecting these spam comments [21]. However, large  benchmark data sets of labeled blog comment spam do not yet  exist. Thus, we run experiments on the only publicly available data set we know of, which was used in content-based blog Table 3: Results for Splog vs. Blog Detection using SVMs and Leave One Out Cross Validation. We report the same evaluation measures as in the prior work for meaningful comparison. features precision recall F1 SVM C = 100: words 0.921 0.870 0.895 -grams 0.904 0.866 0.885 -grams 0.928 0.876 0.901 Prior SVM with: words 0.887 0.864 0.875 -grams 0.867 0.844 0.855 words+urls 0.893 0.869 0.881 comment spam detection experiments by [21]. Because of the small size of the data set, and because prior researchers did not conduct their experiments in an on-line setting, we test the performance of linear SVMs using leave-one-out cross validation, with SVM-Light, a standard open-source SVM implementation [14]. We use the parameter setting C = 100, with the same feature space mappings as above. We report accuracy, precision, and recall to compare these to the results given on the same data set by [21]. These results (see Table 2) show that SVMs give superior performance on this data set to the prior methodology. .7 Splogs and SVMs As with blog comment spam, there is not yet a large,  publicly available benchmark corpus of labeled splog detection test data. However, the authors of [17] kindly provided us with the labeled data set of 1,389 blogs and splogs that they used to test content-based splog detection using SVMs. The only difference between our methodology and that of [17] is that they used default parameters for C, which SVM-Light sets to 1 avg||x||2 . (For normalized vectors, this default value sets C = 1.) They also tested several domain-informed  feature mappings, such as giving special features to url tags. For our experiments, we used the same feature mappings as above, and tested the effect of setting C = 100. As with the methodology of [17], we performed leave one out cross validation for apples-to-apples comparison on this data. The results (see Table 3) show that a high value of C produces higher performance for the same feature space mappings, and even enables the simple 4-gram mapping to out-perform the previous best mapping which incorporated domain  knowledge by using words and urls. .8 Computational Cost The results presented in this section demonstrate that  linfeatures trec06p trec05p-1 words 12196s 66478s -grams 44605s 128924s -grams 87519s 242160s corpus size 32822 92189 Table 4: Execution time for Online SVMs with email spam detection, in CPU seconds. These times do not include the time spent mapping strings to  feature vectors. The number of examples in each data set is given in the last row as corpus size. A B Figure 3: Visualizing the effect of C.  Hyperplane A maximizes the margin while accepting a small amount of training error. This corresponds to setting C to a low value. Hyperplane B  accepts a smaller margin in order to reduce  training error. This corresponds to setting C to a high value. Content-based spam filtering appears to do best with high values of C. ear SVMs give state of the art performance on content-based spam filtering. However, this performance comes at a price. Although the blog comment spam and splog data sets are too small for the quadratic training time of SVMs to  appear problematic, the email data sets are large enough to illustrate the problems of quadratic training cost. Table 4 shows computation time versus data set size for each of the online learning tasks (on same system). The training cost of SVMs are prohibitive for large-scale content based spam detection, or a large blog host. In the  following section, we reduce this cost by relaxing the expensive requirements of SVMs. . RELAXED ONLINE SVMS (ROSVM) One of the main benefits of SVMs is that they find a  decision hyperplane that maximizes the margin between classes in the data space. Maximizing the margin is expensive, typically requiring quadratic training time in the number of training examples. However, as we saw in the previous section, the task of content-based spam detection is best achieved by SVMs with a high value of C. Setting C to a high value for this domain implies that minimizing  training loss is more important than maximizing the margin (see Figure 3). Thus, while SVMs do create high performance spam  filters, applying them in practice is overkill. The full margin maximization feature that they provide is unnecessary, and relaxing this requirement can reduce computational cost. We propose three ways to relax Online SVMs: • Reduce the size of the optimization problem by only optimizing over the last p examples. • Reduce the number of training updates by only  training on actual errors. • Reduce the number of iterations in the iterative SVM Given: dataset X = (x1, y1), . . . , (xn, yn), C, m, p: Initialize w := 0, b := 0, seenData := { } For Each xi ∈ X do: Classify xi using f(xi) = sign(< w, xi > +b) If yif(xi) < m Find w , b with SMO on seenData, using w, b as seed hypothesis. set (w, b) := (w",b") If size(seenData) > p remove oldest example from seenData Add xi to seenData done Figure 4: Pseudo-code for Relaxed Online SVM. solver by allowing an approximate solution to the  optimization problem. As we describe in the remainder of this subsection, all of these methods trade statistical robustness for reduced  computational cost. Experimental results reported in the  following section show that they equal or approach the  performance of full Online SVMs on content-based spam detection. .1 Reducing Problem Size In the full Online SVMs, we re-optimize over the full set of seen data on every update, which becomes expensive as the number of seen data points grows. We can bound this expense by only considering the p most recent examples for optimization (see Figure 4 for pseudo-code). Note that this is not equivalent to training a new SVM classifier from scratch on the p most recent examples,  because each successive optimization problem is seeded with the previous hypothesis w [8]. This hypothesis may contain values for features that do not occur anywhere in the p most recent examples, and these will not be changed. This allows the hypothesis to remember rare (but informative) features that were learned further than p examples in the past. Formally, the optimization problem is now defined most clearly in the dual form [23]. In this case, the original  softmargin SVM is computed by maximizing at example n: W (α) = nX i=1 αi −   nX i,j=1 αiαjyiyj < xi, xj >, subject to the previous constraints [23]: ∀i ∈ {1, . . . , n} : 0 ≤ αi ≤ C and nX i=1 αiyi = 0 To this, we add the additional lookback buffer constraint ∀j ∈ {1, . . . , (n − p)} : αj = cj where cj is a constant, fixed as the last value found for αj while j > (n − p). Thus, the margin found by an  optimization is not guaranteed to be one that maximizes the margin for the global data set of examples {x1, . . . , xn)}, but rather one that satisfies a relaxed requirement that the margin be maximized over the examples { x(n−p+1), . . . , xn}, subject to the fixed constraints on the hyperplane that were found in previous optimizations over examples {x1, . . . , x(n−p)}. (For completeness, when p ≥ n, define (n − p) = 1.) This set of constraints reduces the number of free variables in the optimization problem, reducing computational cost. .2 Reducing Number of Updates As noted before, the KKT conditions show that a well classified example will not change the hypothesis; thus it is not necessary to re-train when we encounter such an  example. Under the KKT conditions, an example xi is considered well-classified when yif(xi) > 1. If we re-train on every example that is not well-classified, our hyperplane will be guaranteed to be optimal at every step. The number of re-training updates can be reduced by  relaxing the definition of well classified. An example xi is now considered well classified when yif(xi) > M, for some  ≤ M ≤ 1. Here, each update still produces an optimal  hyperplane. The learner may encounter an example that lies within the margins, but farther from the margins than M. Such an example means the hypothesis is no longer globally optimal for the data set, but it is considered good enough for continued use without immediate retraining. This update procedure is similar to that used by  variants of the Perceptron algorithm [18]. In the extreme case, we can set M = 0, which creates a mistake driven Online SVM. In the experimental section, we show that this  version of Online SVMs, which updates only on actual errors, does not significantly degrade performance on content-based spam detection, but does significantly reduce cost. .3 Reducing Iterations As an iterative solver, SMO makes repeated passes over the data set to optimize the objective function. SMO has one main loop, which can alternate between passing over the entire data set, or the smaller active set of current  support vectors [22]. Successive iterations of this loop bring the hyperplane closer to an optimal value. However, it is possible that these iterations provide less benefit than their expense justifies. That is, a close first approximation may be good enough. We introduce a parameter T to control the maximum number of iterations we allow. As we will see in the experimental section, this parameter can be set as low as 1 with little impact on the quality of results, providing computational savings. . EXPERIMENTS In Section 2, we argued that the strong performance on content-based spam detection with SVMs with a high value of C show that the maximum margin criteria is overkill,  incurring unnecessary computational cost. In Section 3, we proposed ROSVM to address this issue, as both of these methods trade away guarantees on the maximum margin  hyperplane in return for reduced computational cost. In this section, we test these methods on the same benchmark data sets to see if state of the art performance may be achieved by these less costly methods. We find that ROSVM is capable of achieving these high levels of performance with greatly reduced cost. Our main tests on content-based spam  detection are performed on large benchmark sets of email data. We then apply these methods on the smaller data sets of blog comment spam and blogs, with similar performance. .1 ROSVM Tests In Section 3, we proposed three approaches for reducing the computational cost of Online SMO: reducing the  prob0.005 .01 .025 .05 .1 0 100 1000 10000 100000 (1-ROCA)% Buffer Size trec05p-1 trec06p  0000 00000 50000 00000 50000 0 100 1000 10000 100000 CPUSec. Buffer Size trec05p-1 trec06p Figure 5: Reduced Size Tests. lem size, reducing the number of optimization iterations, and reducing the number of training updates. Each of these approaches relax the maximum margin criteria on the global set of previously seen data. Here we test the effect that each of these methods has on both effectiveness and efficiency. In each of these tests, we use the large benchmark email data sets, trec05p-1 and trec06p. .1.1 Testing Reduced Size For our first ROSVM test, we experiment on the effect of reducing the size of the optimization problem by only considering the p most recent examples, as described in the previous section. For this test, we use the same 4-gram  mappings as for the reference experiments in Section 2, with the same value C = 100. We test a range of values p in a coarse grid search. Figure 5 reports the effect of the buffer size p in relationship to the (1-ROCA)% performance measure (top), and the number of CPU seconds required (bottom). The results show that values of p < 100 do result in  degraded performance, although they evaluate very quickly. However, p values from 500 to 10,000 perform almost as well as the original Online SMO (represented here as p = 00, 000), at dramatically reduced computational cost. These results are important for making state of the art performance on large-scale content-based spam detection practical with online SVMs. Ordinarily, the training time would grow quadratically with the number of seen examples. However, fixing a value of p ensures that the training time is independent of the size of the data set. Furthermore, a lookback buffer allows the filter to adjust to concept drift. .005 .01 .025 .05 .1 0521 (1-ROCA)% Max Iters. trec06p trec05p-1 0000 00000 50000 00000 50000 0521 CPUSec. Max Iters. trec06p trec05p-1 Figure 6: Reduced Iterations Tests. .1.2 Testing Reduced Iterations In the second ROSVM test, we experiment with reducing the number of iterations. Our initial tests showed that the maximum number of iterations used by Online SMO was rarely much larger than 10 on content-based spam detection; thus we tested values of T = {1, 2, 5, ∞}. Other parameters were identical to the original Online SVM tests. The results on this test were surprisingly stable (see  Figure 6). Reducing the maximum number of SMO iterations per update had essentially no impact on classification  performance, but did result in a moderate increase in speed. This suggests that any additional iterations are spent attempting to find improvements to a hyperplane that is already very close to optimal. These results show that for content-based spam detection, we can reduce computational cost by  allowing only a single SMO iteration (that is, T = 1) with effectively equivalent performance. .1.3 Testing Reduced Updates For our third ROSVM experiment, we evaluate the impact of adjusting the parameter M to reduce the total number of updates. As noted before, when M = 1, the hyperplane is globally optimal at every step. Reducing M allows a slightly inconsistent hyperplane to persist until it encounters an  example for which it is too inconsistent. We tested values of M from 0 to 1, at increments of 0.1. (Note that we used p = 10000 to decrease the cost of evaluating these tests.) The results for these tests are appear in Figure 7, and show that there is a slight degradation in performance with reduced values of M, and that this degradation in  performance is accompanied by an increase in efficiency. Values of .005 .01 .025 .05 .1  0.2 0.4 0.6 0.8 1 (1-ROCA)% M trec05p-1 trec06p 000 0000 5000 0000 5000 0000 5000 0000  0.2 0.4 0.6 0.8 1 CPUSec. M trec05p-1 trec06p Figure 7: Reduced Updates Tests. M > 0.7 give effectively equivalent performance as M = 1, and still reduce cost. .2 Online SVMs and ROSVM We now compare ROSVM against Online SVMs on the email spam, blog comment spam, and splog detection tasks. These experiments show comparable performance on these tasks, at radically different costs. In the previous section, the effect of the different relaxation methods was tested separately. Here, we tested these methods together to  create a full implementation of ROSVM. We chose the values p = 10000, T = 1, M = 0.8 for the email spam detection tasks. Note that these parameter values were selected as those allowing ROSVM to achieve comparable performance results with Online SVMs, in order to test total difference in computational cost. The splog and blog data sets were much smaller, so we set p = 100 for these tasks to allow meaningful comparisons between the reduced size and full size optimization problems. Because these values were not hand-tuned, both generalization performance and runtime results are meaningful in these experiments. .2.1 Experimental Setup We compared Online SVMs and ROSVM on email spam, blog comment spam, and splog detection. For the email spam, we used the two large benchmark corpora, trec05p-1 and trec06p, in the standard online ordering. We randomly ordered both the blog comment spam corpus and the splog corpus to create online learning tasks. Note that this is a different setting than the leave-one-out cross validation task presented on these corpora in Section 2 - the results are not directly comparable. However, this experimental design Table 5: Email Spam Benchmark Data. These  results compare Online SVM and ROSVM on email spam detection, using binary 4-gram feature space. Score reported is (1-ROCA)%, where 0 is optimal. trec05p-1 trec05p-1 trec06p trec06p (1-ROC)% CPUs (1-ROC)% CPUs OnSVM 0.0084 242,160 0.0232 87,519 ROSVM 0.0090 24,720 0.0240 18,541 Table 6: Blog Comment Spam. These results  comparing Online SVM and ROSVM on blog comment spam detection using binary 4-gram feature space. Acc. Prec. Recall F1 CPUs OnSVM 0.926 0.930 0.962 0.946 139 ROSVM 0.923 0.925 0.965 0.945 11 does allow meaningful comparison between our two online methods on these content-based spam detection tasks. We ran each method on each task, and report the results in Tables 5, 6, and 7. Note that the CPU time reported for each method was generated on the same computing system. This time reflects only the time needed to complete online learning on tokenized data. We do not report the time taken to tokenize the data into binary 4-grams, as this is the same additive constant for all methods on each task. In all cases, ROSVM was significantly less expensive computationally. .3 Discussion The comparison results shown in Tables 5, 6, and 7 are striking in two ways. First, they show that the performance of Online SVMs can be matched and even exceeded by  relaxed margin methods. Second, they show a dramatic  disparity in computational cost. ROSVM is an order of  magnitude more efficient than the normal Online SVM, and gives comparable results. Furthermore, the fixed lookback buffer ensures that the cost of each update does not depend on the size of the data set already seen, unlike Online SVMs. Note the blog and splog data sets are relatively small, and results on these data sets must be considered preliminary. Overall, these results show that there is no need to pay the high cost of SVMs to achieve this level of performance on  contentbased detection of spam. ROSVMs offer a far cheaper  alternative with little or no performance loss. . CONCLUSIONS In the past, academic researchers and industrial  practitioners have disagreed on the best method for online  contentbased detection of spam on the web. We have presented one resolution to this debate. Online SVMs do, indeed,  proTable 7: Splog Data Set. These results compare Online SVM and ROSVM on splog detection using binary 4-gram feature space. Acc. Prec. Recall F1 CPUs OnSVM 0.880 0.910 0.842 0.874 29353 ROSVM 0.878 0.902 0.849 0.875 1251 duce state-of-the-art performance on this task with proper adjustment of the tradeoff parameter C, but with cost that grows quadratically with the size of the data set. The high values of C required for best performance with SVMs show that the margin maximization of Online SVMs is overkill for this task. Thus, we have proposed a less expensive  alternative, ROSVM, that relaxes this maximum margin  requirement, and produces nearly equivalent results. These  methods are efficient enough for large-scale filtering of  contentbased spam in its many forms. It is natural to ask why the task of content-based spam  detection gets strong performance from ROSVM. After all, not all data allows the relaxation of SVM requirements. We  conjecture that email spam, blog comment spam, and splogs all share the characteristic that a subset of features are  particularly indicative of content being either spam or not spam. These indicative features may be sparsely represented in the data set, because of spam methods such as word obfuscation, in which common spam words are intentionally misspelled in an attempt to reduce the effectiveness of word-based spam detection. Maximizing the margin may cause these sparsely represented features to be ignored, creating an overall  reduction in performance. It appears that spam data is highly separable, allowing ROSVM to be successful with high  values of C and little effort given to maximizing the margin. Future work will determine how applicable relaxed SVMs are to the general problem of text classification. Finally, we note that the success of relaxed SVM methods for content-based spam detection is a result that depends on the nature of spam data, which is potentially subject to change. Although it is currently true that ham and spam are linearly separable given an appropriate feature space, this assumption may be subject to attack. While our current methods appear robust against primitive attacks along these lines, such as the good word attack [24], we must explore the feasibility of more sophisticated attacks. . REFERENCES [1] A. Bratko and B. Filipic. Spam filtering using compression models. Technical Report IJS-DP-9227, Department of Intelligent Systems, Jozef Stefan Institute, L jubljana, Slovenia, 2005. [2] G. Cauwenberghs and T. Poggio. Incremental and decremental support vector machine learning. In NIPS, pages 409-415, 2000. [3] G. V. Cormack. TREC 2006 spam track overview. In To appear in: The Fifteenth Text REtrieval Conference (TREC 2006) Proceedings, 2006. [4] G. V. Cormack and A. Bratko. Batch and on-line spam filter comparison. In Proceedings of the Third Conference on Email and Anti-Spam (CEAS), 2006. [5] G. V. Cormack and T. R. Lynam. TREC 2005 spam track overview. In The Fourteenth Text REtrieval Conference (TREC 2005) Proceedings, 2005. [6] G. V. Cormack and T. R. Lynam. On-line supervised spam filter evaluation. Technical report, David R. Cheriton School of Computer Science, University of Waterloo, Canada, February 2006. [7] N. Cristianini and J. Shawe-Taylor. An introduction to support vector machines. Cambridge University Press, 000. [8] D. DeCoste and K. Wagstaff. Alpha seeding for support vector machines. In KDD "00: Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 345-349, 000. [9] H. Drucker, V. Vapnik, and D. Wu. Support vector machines for spam categorization. IEEE Transactions on Neural Networks, 10(5):1048-1054, 1999. [10] J. Goodman and W. Yin. Online discriminative spam filter training. In Proceedings of the Third Conference on Email and Anti-Spam (CEAS), 2006. [11] P. Graham. A plan for spam. 2002. [12] P. Graham. Better bayesian filtering. 2003. [13] Z. Gyongi and H. Garcia-Molina. Spam: It"s not just for inboxes anymore. Computer, 38(10):28-34, 2005. [14] T. Joachims. Text categorization with suport vector machines: Learning with many relevant features. In ECML "98: Proceedings of the 10th European Conference on Machine Learning, pages 137-142, 998. [15] T. Joachims. Training linear svms in linear time. In KDD "06: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 217-226, 2006. [16] J. Kivinen, A. Smola, and R. Williamson. Online learning with kernels. In Advances in Neural Information Processing Systems 14, pages 785-793. MIT Press, 2002. [17] P. Kolari, T. Finin, and A. Joshi. SVMs for the blogosphere: Blog identification and splog detection. AAAI Spring Symposium on Computational Approaches to Analyzing Weblogs, 2006. [18] W. Krauth and M. M´ezard. Learning algorithms with optimal stability in neural networks. Journal of Physics A, 20(11):745-752, 1987. [19] T. Lynam, G. Cormack, and D. Cheriton. On-line spam filter fusion. In SIGIR "06: Proceedings of the 9th annual international ACM SIGIR conference on Research and development in information retrieval, pages 123-130, 2006. [20] V. Metsis, I. Androutsopoulos, and G. Paliouras. Spam filtering with naive bayes - which naive bayes? Third Conference on Email and Anti-Spam (CEAS), 006. [21] G. Mishne, D. Carmel, and R. Lempel. Blocking blog spam with language model disagreement. Proceedings of the 1st International Workshop on Adversarial Information Retrieval on the Web (AIRWeb), May 005. [22] J. Platt. Sequenital minimal optimization: A fast algorithm for training support vector machines. In B. Scholkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press, 1998. [23] B. Scholkopf and A. Smola. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. MIT Press, 2001. [24] G. L. Wittel and S. F. Wu. On attacking statistical spam filters. CEAS: First Conference on Email and Anti-Spam, 2004.
DiffusionRank: A Possible Penicillin for Web Spamming Haixuan Yang, Irwin King, and Michael R. Lyu Dept. of Computer Science and Engineering The Chinese University of Hong Kong Shatin, NT, Hong Kong {hxyang,king,lyu}@cse.cuhk.edu.hk ABSTRACT While the PageRank algorithm has proven to be very  effective for ranking Web pages, the rank scores of Web pages can be manipulated. To handle the manipulation problem and to cast a new insight on the Web structure, we propose a ranking algorithm called DiffusionRank. DiffusionRank is motivated by the heat diffusion phenomena, which can be connected to Web ranking because the activities flow on the Web can be imagined as heat flow, the link from a page to another can be treated as the pipe of an air-conditioner, and heat flow can embody the structure of the underlying Web graph. Theoretically we show that DiffusionRank can serve as a generalization of PageRank when the heat diffusion  coefficient γ tends to infinity. In such a case 1/γ = 0,  DiffusionRank (PageRank) has low ability of anti-manipulation. When γ = 0, DiffusionRank obtains the highest ability of anti-manipulation, but in such a case, the web structure is completely ignored. Consequently, γ is an interesting factor that can control the balance between the ability of  preserving the original Web and the ability of reducing the effect of manipulation. It is found empirically that, when γ = 1, DiffusionRank has a Penicillin-like effect on the link  manipulation. Moreover, DiffusionRank can be employed to find group-to-group relations on the Web, to divide the Web graph into several parts, and to find link communities.  Experimental results show that the DiffusionRank algorithm achieves the above mentioned advantages as expected. Categories and Subject Descriptors: H.3.3  [Information Systems]: Information Search and Retrieval; G2.2 [Discrete Mathematics]: Graph Theory General Terms: Algorithms. . INTRODUCTION While the PageRank algorithm [13] has proven to be very effective for ranking Web pages, inaccurate PageRank  results are induced because of web page manipulations by  people for commercial interests. The manipulation problem is also called the Web spam, which refers to hyperlinked pages on the World Wide Web that are created with the intention of misleading search engines [7]. It is reported that  approximately 70% of all pages in the .biz domain and about 35% of the pages in the .us domain belong to the spam category [12]. The reason for the increasing amount of Web spam is explained in [12]: some web site operators try to influence the positioning of their pages within search results because of the large fraction of web traffic originating from searches and the high potential monetary value of this traffic. From the viewpoint of the Web site operators who want to increase the ranking value of a particular page for search engines, Keyword Stuffing and Link Stuffing are being used widely [7, 12]. From the viewpoint of the search engine  managers, the Web spam is very harmful to the users" evaluations and thus their preference to choosing search engines because people believe that a good search engine should not return irrelevant or low-quality results. There are two methods  being employed to combat the Web spam problem. Machine learning methods are employed to handle the keyword  stuffing. To successfully apply machine learning methods, we need to dig out some useful textual features for Web pages, to mark part of the Web pages as either spam or non-spam, then to apply supervised learning techniques to mark other pages. For example, see [5, 12]. Link analysis methods are also employed to handle the link stuffing problem. One  example is the TrustRank [7], a link-based method, in which the link structure is utilized so that human labelled trusted pages can propagate their trust scores trough their links. This paper focuses on the link-based method. The rest of the materials are organized as follows. In the next section, we give a brief literature review on various related ranking techniques. We establish the Heat Diffusion Model (HDM) on various cases in Section 3, and propose DiffusionRank in Section 4. In Section 5, we describe the data sets that we worked on and the experimental results. Finally, we draw conclusions in Section 6. . LITERATURE REVIEW The importance of a Web page is determined by either the textual content of pages or the hyperlink structure or both. As in previous work [7, 13], we focus on ranking methods solely determined by hyperlink structure of the Web graph. All the mentioned ranking algorithms are  established on a graph. For our convenience, we first give some notations. Denote a static graph by G = (V, E), where V = {v1, v2, . . . , vn}, E = {(vi, vj) | there is an edge from vi to vj}. Ii and di denote the in-degree and the out-degree of page i respectively. .1 PageRank The importance of a Web page is an inherently subjective matter, which depends on the reader"s interests, knowledge and attitudes [13]. However, the average importance of all readers can be considered as an objective matter. PageRank tries to find such average importance based on the Web link structure, which is considered to contain a large amount of statistical data. The Web is modelled by a directed graph G in the PageRank algorithms, and the rank or importance xi for page vi ∈ V is defined recursively in terms of pages which point to it: xi = (j,i)∈E aijxj, where aij is assumed to be 1/dj if there is a link from j to i, and 0 otherwise. Or in matrix terms, x = Ax. When the concept of random jump is introduced, the matrix form is changed to x = [(1 − α)g1T + αA]x, (1) where α is the probability of following the actual link from a page, (1 − α) is the probability of taking a random jump, and g is a stochastic vector, i.e., 1T g = 1. Typically, α = .85, and g = 1 n  is one of the standard settings, where 1 is the vector of all ones [6, 13]. .2 TrustRank TrustRank [7] is composed of two parts. The first part is the seed selection algorithm, in which the inverse  PageRank was proposed to help an expert of determining a good node. The second part is to utilize the biased PageRank, in which the stochastic distribution g is set to be shared by all the trusted pages found in the first part. Moreover, the initial input of x is also set to be g. The justification for the inverse PageRank and the solid experiments support its advantage in combating the Web spam. Although there are many variations of PageRank, e.g., a family of link-based ranking algorithms in [2], TrustRank is especially chosen for comparisons for three reasonss: (1) it is designed for  combatting spamming; (2) its fixed parameters make a  comparison easy; and (3) it has a strong theoretical relations with PageRank and DiffusionRank. .3 Manifold Ranking In [17], the idea of ranking on the data manifolds was  proposed. The data points represented as vectors in Euclidean space are considered to be drawn from a manifold. From the data points on such a manifold, an undirected weighted graph is created, then the weight matrix is given by the Gaussian Kernel smoothing. While the manifold ranking algorithm achieves an impressive result on ranking images, the biased vector g and the parameter k in the general  personalized PageRank in [17] are unknown in the Web graph setting; therefore we do not include it in the comparisons. .4 Heat Diffusion Heat diffusion is a physical phenomena. In a medium, heat always flow from position with high temperature to position with low temperature. Heat kernel is used to  describe the amount of heat that one point receives from  another point. Recently, the idea of heat kernel on a manifold is borrowed in applications such as dimension reduction [3] and classification [9, 10, 14]. In these work, the input data is considered to lie in a special structure. All the above topics are related to our work. The readers can find that our model is a generalization of PageRank in order to resist Web manipulation, that we inherit the first part of TrustRank, that we borrow the concept of ranking on the manifold to introduce our model, and that heat diffusion is a main scheme in this paper. . HEAT DIFFUSION MODEL Heat diffusion provides us with another perspective about how we can view the Web and also a way to calculate  ranking values. In this paper, the Web pages are considered to be drawn from an unknown manifold, and the link structure forms a directed graph, which is considered as an  approximation to the unknown manifold. The heat kernel established on the Web graph is considered as the representation of the relationship between Web pages. The temperature  distribution after a fixed time period, induced by a special initial temperature distribution, is considered as the rank scores on the Web pages. Before establishing the proposed models, we first show our motivations. .1 Motivations There are two points to explain that PageRank is  susceptible to web spam. • Over-democratic. There is a belief behind  PageRank-all pages are born equal. This can be seen from the equal voting ability of one page: the sum of each column is equal to one. This equal voting ability of all pages gives the chance for a Web site operator to  increase a manipulated page by creating a large number of new pages pointing to this page since all the newly created pages can obtain an equal voting right. • Input-independent. For any given non-zero initial input, the iteration will converge to the same stable distribution corresponding to the maximum eigenvalue  of the transition matrix. This input-independent property makes it impossible to set a special initial  input (larger values for trusted pages and less values even negative values for spam pages) to avoid web spam. The input-independent feature of PageRank can be further explained as follows. P = [(1 − α)g1T + αA] is a positive stochastic matrix if g is set to be a positive stochastic vector (the uniform distribution is one of such settings), and so the largest eigenvalue is 1 and no other eigenvalue whose  absolute value is equal to 1, which is guaranteed by the Perron Theorem [11]. Let y be the eigenvector corresponding to 1, then we have Py = y. Let {xk} be the sequence generated from the iterations xk+1 = Pxk, and x0 is the initial input. If {xk} converges to x, then xk+1 = Pxk implies that x must satisfy Px = x. Since the only maximum eigenvalue is 1, we have x = cy where c is a constant, and if both x and y are normalized by their sums, then c = 1. The above discussions show that PageRank is independent of the initial input x0. In our opinion, g and α are objective parameters  determined by the users" behaviors and preferences. A, α and g are the true web structure. While A is obtained by a crawler and the setting α = 0.85 is accepted by the people, we think that g should be determined by a user behavior investigation, something like [1]. Without any prior  knowledge, g has to be set as g = 1 n . TrustRank model does not follow the true web structure by setting a biased g, but the effects of combatting  spamming are achieved in [7]; PageRank is on the contrary in some ways. We expect a ranking algorithm that has an  effect of anti-manipulation as TrustRank while respecting the true web structure as PageRank. We observe that the heat diffusion model is a natural way to avoid the over-democratic and input-independent feature of PageRank. Since heat always flows from a position with higher temperatures to one with lower temperatures, points are not equal as some points are born with high  temperatures while others are born with low temperatures. On the other hand, different initial temperature distributions will give rise to different temperature distributions after a fixed time period. Based on these considerations, we propose the novel DiffusionRank. This ranking algorithm is also  motivated by the viewpoint for the Web structure. We view all the Web pages as points drawn from a highly complex geometric structure, like a manifold in a high dimensional space. On a manifold, heat can flow from one point to  another through the underlying geometric structure in a given time period. Different geometric structures determine  different heat diffusion behaviors, and conversely the diffusion behavior can reflect the geometric structure. More  specifically, on the manifold, the heat flows from one point to another point, and in a given time period, if one point x receives a large amount of heat from another point y, we can say x and y are well connected, and thus x and y have a high similarity in the sense of a high mutual connection. We note that on a point with unit mass, the temperature and the heat of this point are equivalent, and these two terms are interchangeable in this paper. In the following, we first show the HDM on a manifold, which is the origin of HDM, but cannot be employed to the World Wide Web directly, and so is considered as the ideal case. To connect the ideal case and the practical case, we then establish HDM on a graph as an intermediate case. To model the real world problem, we further build HDM on a random graph as a practical case. Finally we demonstrate the DiffusionRank which is derived from the HDM on a random graph. .2 Heat Flow On a Known Manifold If the underlying manifold is known, the heat flow  throughout a geometric manifold with initial conditions can be  described by the following second order differential equation: ∂f(x,t) ∂t − ∆f(x, t) = 0, where f(x, t) is the heat at location x at time t, and ∆f is the Laplace-Beltrami operator on a  function f. The heat diffusion kernel Kt(x, y) is a special  solution to the heat equation with a special initial condition-a unit heat source at position y when there is no heat in other positions. Based on this, the heat kernel Kt(x, y) describes the heat distribution at time t diffusing from the initial unit heat source at position y, and thus describes the  connectivity (which is considered as a kind of similarity) between x and y. However, it is very difficult to represent the World Wide Web as a regular geometry with a known dimension; even the underlying is known, it is very difficult to find the heat kernel Kt(x, y), which involves solving the heat  equation with the delta function as the initial condition. This motivates us to investigate the heat flow on a graph. The graph is considered as an approximation to the underlying manifold, and so the heat flow on the graph is considered as an approximation to the heat flow on the manifold. .3 On an Undirected Graph On an undirected graph G, the edge (vi, vj) is considered as a pipe that connects nodes vi and vj. The value fi(t) describes the heat at node vi at time t, beginning from an initial distribution of heat given by fi(0) at time zero. f(t) (f(0)) denotes the vector consisting of fi(t) (fi(0)). We construct our model as follows. Suppose, at time t, each node i receives M(i, j, t, ∆t) amount of heat from its neighbor j during a period of ∆t. The heat M(i, j, t, ∆t) should be proportional to the time period ∆t and the heat difference fj(t) − fi(t). Moreover, the heat flows from node j to node i through the pipe that connects nodes i and j. Based on this consideration, we assume that M(i, j, t, ∆t) = γ(fj(t) − fi(t))∆t. As a result, the heat difference at node i between time t + ∆t and time t will be equal to the sum of the heat that it receives from all its neighbors. This is formulated as fi(t + ∆t) − fi(t) = j:(j,i)∈E γ(fj(t) − fi(t))∆t, (2) where E is the set of edges. To find a closed form solution to Eq. (2), we express it in a matrix form: (f(t + ∆t) − f(t))/∆t = γHf(t), where d(v) denotes the degree of the node v. In the limit ∆t → 0, it becomes d dt f(t) = γHf(t). Solving it, we obtain f(t) = eγtH f(0), especially we have f(1) = eγH f(0), Hij =    −d(vj), j = i, , (vj, vi) ∈ E, , otherwise, (3) where eγH is defined as eγH = I+γH+ γ2 ! H2 + γ3 ! H3 +· · · . .4 On a Directed Graph The above heat diffusion model must be modified to fit the situation where the links between Web pages are directed. On one Web page, when the page-maker creates a link (a, b) to another page b, he actually forces the energy flow, for example, people"s click-through activities, to that page, and so there is added energy imposed on the link. As a result, heat flows in a one-way manner, only from a to b, not from b to a. Based on such consideration, we modified the heat diffusion model on an undirected graph as follows. On a directed graph G, the pipe (vi, vj) is forced by added energy such that heat flows only from vi to vj. Suppose, at time t, each node vi receives RH = RH(i, j, t, ∆t) amount of heat from vj during a period of ∆t. We have three  assumptions: (1) RH should be proportional to the time period ∆t; (2) RH should be proportional to the the heat at node vj; and (3) RH is zero if there is no link from vj to vi. As a result, vi will receive j:(vj ,vi)∈E σjfj(t)∆t amount of heat from all its neighbors that points to it. On the other hand, node vi diffuses DH(i, t, ∆t) amount of heat to its subsequent nodes. We assume that: (1) The heat DH(i, t, ∆t) should be proportional to the time period ∆t. (2) The heat DH(i, t, ∆t) should be proportional to the the heat at node vi. (3) Each node has the same ability of diffusing heat. This fits the intuition that a Web surfer only has one choice to find the next page that he wants to browse. (4) The heat DH(i, t, ∆t) should be uniformly distributed to its subsequent nodes. The real situation is more complex than what we assume, but we have to make this simple  assumption in order to make our model concise. As a result, node vi will diffuse γfi(t)∆t/di amount of heat to any of its subsequent nodes, and each of its subsequent node should receive γfi(t)∆t/di amount of heat. Therefore σj = γ/dj. To sum up, the heat difference at node vi between time t+∆t and time t will be equal to the sum of the heat that it receives, deducted by what it diffuses. This is formulated as fi(t + ∆t) − fi(t) = −γfi(t)∆t + j:(vj ,vi)∈E γ/djfj(t)∆t. Similarly, we obtain f(1) = eγH f(0), Hij =    −1, j = i, /dj, (vj, vi) ∈ E, , otherwise. (4) .5 On a Random Directed Graph For real world applications, we have to consider random edges. This can be seen in two viewpoints. The first one is that in Eq. (1), the Web graph is actually modelled as a random graph, there is an edge from node vi to node vj with a probability of (1 − α)gj (see the item (1 − α)g1T ), and that the Web graph is predicted by a random graph [15, 16]. The second one is that the Web structure is a random graph in essence if we consider the content similarity between two pages, though this is not done in this paper. For these reasons, the model would become more flexible if we extend it to random graphs. The definition of a random graph is given below. Definition 1. A random graph RG = (V, P = (pij)) is defined as a graph with a vertex set V in which the edges are chosen independently, and for 1 ≤ i, j ≤ |V | the probability of (vi, vj) being an edge is exactly pij. The original definition of random graphs in [4], is changed slightly to consider the situation of directed graphs. Note that every static graph can be considered as a special  random graph in the sense that pij can only be 0 or 1. On a random graph RG = (V, P), where P = (pij) is the probability of the edge (vi, vj) exists. In such a random graph, the expected heat difference at node i between time t + ∆t and time t will be equal to the sum of the expected heat that it receives from all its antecedents, deducted by the expected heat that it diffuses. Since the probability of the link (vj, vi) is pji, the  expected heat flow from node j to node i should be multiplied by pji, and so we have fi(t + ∆t) − fi(t) = −γ fi(t) ∆t + j:(vj ,vi)∈E γpjifj(t)∆t/RD+ (vj), where RD+ (vi) is the  expected out-degree of node vi, it is defined as k pik.  Similarly we have f(1) = eγR f(0), Rij =    −1, j = i; pji/RD+ (vj), j = i. (5) When the graph is large, a direct computation of eγR is time-consuming, and we adopt its discrete approximation: f(1) = (I + γ N R)N f(0). (6) The matrix (I+ γ N R)N in Eq. (6) and matrix eγR in Eq. (5) are called Discrete Diffusion Kernel and the Continuous Diffusion Kernel respectively. Based on the Heat Diffusion Models and their solutions, DiffusionRank can be  established on undirected graphs, directed graphs, and random graphs. In the next section, we mainly focus on  DiffusionRank in the random graph setting. . DIFFUSIONRANK For a random graph, the matrix (I + γ N R)N or eγR can measure the similarity relationship between nodes. Let fi(0)= , fj(0) = 0 if j = i, then the vector f(0) represent the unit heat at node vi while all other nodes has zero heat. For such f(0) in a random graph, we can find the heat distribution at time 1 by using Eq. (5) or Eq. (6). The heat  distribution is exactly the i−th row of the matrix of (I + γ N R)N or eγR . So the ith-row jth-column element hij in the matrix (I + γ∆tR)N or eγR means the amount of heat that vi can receive from vj from time 0 to 1. Thus the value hij can be used to measure the similarity from vj to vi. For a static graph, similarly the matrix (I + γ N H)N or eγH can measure the similarity relationship between nodes. The intuition behind is that the amount h(i, j) of heat that a page vi receives from a unit heat in a page vj in a unit time embodies the extent of the link connections from page vj to page vi. Roughly speaking, when there are more uncrossed paths from vj to vi, vi will receive more heat from vj; when the path length from vj to vi is shorter, vi will receive more heat from vj; and when the pipe connecting vj and vi is wide, the heat will flow quickly. The final heat that vi receives will depend on various paths from vj to vi, their length, and the width of the pipes. Algorithm 1 DiffusionRank Function Input: The transition matrix A; the inverse transition  matrix U; the decay factor αI for the inverse PageRank; the decay factor αB for PageRank; number of iterations MI for the inverse PageRank; the number of trusted pages L; the thermal conductivity coefficient γ. Output: DiffusionRank score vector h. : s = 1 : for i = 1 TO MI do : s = αI · U · s + (1 − αI ) · 1 n · 1 : end for : Sort s in a decreasing order: π = Rank({1, . . . , n}, s) : d = 0, Count = 0, i = 0 : while Count ≤ L do : if π(i) is evaluated as a trusted page then : d(π(i)) = 1, Count + + 0: end if 1: i + + 2: end while 3: d = d/|d| 4: h = d 5: Find the iteration number MB according to λ 6: for i = 1 TO MB do 7: h = (1 − γ MB )h + γ MB (αB · A · h + (1 − αB) · 1 n · 1) 8: end for 9: RETURN h .1 Algorithm For the ranking task, we adopt the heat kernel on a  random graph. Formally the DiffusionRank is described in  Algorithm 1, in which,the element Uij in the inverse transition matrix U is defined to be 1/Ij if there is a link from i to j, and 0 otherwise. This trusted pages selection procedure by inverse PageRank is completely borrowed from TrustRank [7] except for a fix number of the size of the trusted set. Although the inverse PageRank is not perfect in its  ability of determining the maximum coverage, it is appealing because of its polynomial execution time and its  reasonable intuition-we actually inverse the original link when we try to build the seed set from those pages that point to many pages that in turn point to many pages and so on. In the algorithm, the underlying random graph is set as P = αB · A + (1 − αB) · 1 n · 1n×n, which is induced by the Web graph. As a result, R = −I + P. In fact, the more general setting for DiffusionRank is P = αB ·A+(1−αB)· 1 n ·g·1T . By such a setting, DiffusionRank is a generalization of TrustRank when γ tends to infinity and when g is set in the same way as TrustRank. However, the second part of TrustRank is not adopted by us. In our model, g should be the true teleportation determined by the user"s browse habits, popularity distribution over all the Web pages, and so on; P should be the true model of the random nature of the World Wide Web. Setting g according to the trusted pages will not be consistent with the basic idea of Heat Diffusion on a random graph. We simply set g = 1 only because we cannot find it without any priori knowledge. Remark. In a social network interpretation,  DiffusionRank first recognizes a group of trusted people, who may not be highly ranked, but they know many other people. The initially trusted people are endowed with the power to decide who can be further trusted, but cannot decide the final voting results, and so they are not dictators. .2 Advantages Next we show the four advantages for DiffusionRank. .2.1 Two closed forms First, its solutions have two forms, both of which are closed form. One takes the discrete form, and has the  advantage of fast computing while the other takes the continuous form, and has the advantage of being easily analyzed in  theoretical aspects. The theoretical advantage has been shown in the proof of theorem in the next section. (a) Group to Group Relations (b) An undirected graph Figure 1: Two graphs .2.2 Group-group relations Second, it can be naturally employed to detect the  groupgroup relation. For example, let G2 and G1 denote two groups, containing pages (j1, j2, . . . , js) and (i1, i2, . . . , it), respectively. Then u,v hiu,jv is the total amounts of heat that G1 receives from G2, where hiu,jv is the iu−th row jv−th column element of the heat kernel. More specifically, we need to first set f(0) for such an application as follows. In f(0) = (f1(0), f2(0), . . . , fn(0))T , if i ∈ {j1, j2, . . . , js}, then fi(0) = 1, and 0 otherwise. Then we employ Eq. (5) to calculate f(1) = (f1(1), f2(1), . . . , fn(1))T , finally we sum those fj(1) where j ∈ {i1, i2, . . . , it}. Fig. 1 (a) shows the results generated by the DiffusionRank. We consider five groups-five departments in our Engineering Faculty: CSE, MAE, EE, IE, and SE. γ is set to be 1, the numbers in Fig. 1 (a) are the amount of heat that they diffuse to each other. These results are normalized by the total number of each group, and the edges are ignored if the values are less than 0.000001. The group-to-group relations are therefore detected, for example, we can see that the most strong  overall tie is from EE to IE. While it is a natural application for DiffusionRank because of the easy interpretation by the amount heat from one group to another group, it is difficult to apply other ranking techniques to such an application because they lack such a physical meaning. .2.3 Graph cut Third, it can be used to partition the Web graph into several parts. A quick example is shown below. The graph in Fig. 1 (b) is an undirected graph, and so we employ the Eq. (3). If we know that node 1 belongs to one  community and that node 12 belongs to another community, then we can put one unit positive heat source on node 1 and one unit negative heat source on node 12. After time 1, if we set γ = 0.5, the heat distribution is [0.25, 0.16, 0.17, .16, 0.15, 0.09, 0.01, -0.04, -0.18 -0.21, -0.21, -0.34], and if we set γ = 1, it will be [0.17, 0.16, 0.17, 0.16, 0.16, 0.12, .02, -0.07, -0.18, -0.22, -0.24, -0.24]. In both settings, we can easily divide the graph into two parts: {1, 2, 3, 4, 5, 6, 7} with positive temperatures and {8, 9, 10, 11, 12} with  negative temperatures. For directed graphs and random graphs, similarly we can cut them by employing corresponding heat solution. .2.4 Anti-manipulation Fourth, it can be used to combat manipulation. Let G2 contain trusted Web pages (j1, j2, . . . , js), then for each page i, v hi,jv is the heat that page i receives from G2, and can be computed by the discrete approximation of Eq. (4) in the case of a static graph or Eq. (6) in the case of a random graph, in which f(0) is set to be a special initial heat  distribution so that the trusted Web pages have unit heat while all the others have zero heat. In doing so, manipulated Web page will get a lower rank unless it has strong in-links from the trusted Web pages directly or indirectly. The situation is quite different for PageRank because PageRank is  inputindependent as we have shown in Section 3.1. Based on the fact that the connection from a trusted page to a bad page should be weak-less uncross paths, longer distance and  narrower pipe, we can say DiffusionRank can resist web spam if we can select trusted pages. It is fortunate that the trusted pages selection method in [7]-the first part of TrustRank can help us to fulfill this task. For such an application of  DiffusionRank, the computation complexity for Discrete  Diffusion Kernel is the same as that for PageRank in cases of both a static graph and a random graph. This can be seen in Eq. (6), by which we need N iterations and for each  iteration we need a multiplication operation between a matrix and a vector, while in Eq. (1) we also need a multiplication operation between a matrix and a vector for each iteration. .3 The Physical Meaning of γ γ plays an important role in the anti-manipulation effect of DiffusionRank. γ is the thermal conductivity-the heat diffusion coefficient. If it has a high value, heat will  diffuse very quickly. Conversely, if it is small, heat will diffuse slowly. In the extreme case, if it is infinitely large, then heat will diffuse from one node to other nodes immediately, and this is exactly the case corresponding to PageRank. Next, we will interpret it mathematically. Theorem 1. When γ tends to infinity and f(0) is not the zero vector, eγR f(0) is proportional to the stable distribution produced by PageRank. Let g = 1 n . By the Perron Theorem [11], we have shown that 1 is the largest eigenvalue of P = [(1 − α)g1T + αA], and that no other eigenvalue whose absolute value is equal to 1. Let x be the stable distribution, and so Px = x. x is the eigenvector corresponding to the eigenvalue 1. Assume the n − 1 other eigenvalues of P are |λ2| < 1, . . . , |λn| < 1, we can find an invertible matrix S = ( x S1 ) such that S−1 PS =       ∗ ∗ ∗  λ2 ∗ ∗  0 ... ∗  0 0 λn      . (7) Since eγR = eγ(−I+P) = S−1       ∗ ∗ ∗  eγ(λ2−1) ∗ ∗  0 ... ∗  0 0 eγ(λn−1)      S, (8) all eigenvalues of the matrix eγR are 1, eγ(λ2−1) , . . . , eγ(λn−1) . When γ → ∞, they become 1, 0, . . . , 0, which means that 1 is the only nonzero eigenvalue of eγR when γ → ∞. We can see that when γ → ∞, eγR eγR f(0) = eγR f(0), and so eγR f(0) is an eigenvector of eγR when γ → ∞. On the other hand, eγR x = (I+γR+γ2 ! R2 +γ3 ! R3 +. . .)x = Ix+γRx+γ2 ! R2 x+ γ3 ! R3 x + . . . = x since Rx = (−I + P)x = −x + x = 0, and hence x is the eigenvector of eγR for any γ. Therefore both x and eγR f(0) are the eigenvectors corresponding the unique eigenvalue 1 of eγR when γ → ∞, and consequently x = ceγR f(0). By this theorem, we see that DiffusionRank is a  generalization of PageRank. When γ = 0, the ranking value is most robust to manipulation since no heat is diffused and the system is unchangeable, but the Web structure is  completely ignored since eγR f(0) = e0R f(0) = If(0) = f(0); when γ = ∞, DiffusionRank becomes PageRank, it can be manipulated easily. We expect an appropriate setting of γ that can balance both. For this, we have no theoretical result, but in practice we find that γ = 1 works well in  Section 5. Next we discuss how to determine the number of iterations if we employ the discrete heat kernel. .4 The Number of Iterations While we enjoy the advantage of the concise form of the exponential heat kernel, it is better for us to calculate  DiffusionRank by employing Eq. (6) in an iterative way. Then the problem about determining N-the number of iterations arises: For a given threshold , find N such that ||((I + γ N R)N − eγR )f(0)|| < for any f(0) whose sum is one. Since it is difficult to solve this problem, we propose a heuristic motivated by the following observations. When R = −I+P, by Eq. (7), we have (I+ γ N R)N = (I+ γ N (−I+ P))N = S−1       ∗ ∗ ∗  (1 + γ(λ2−1) N )N ∗ ∗  0 ... ∗  0 0 (1 + γ(λn−1) N )N      S. (9) Comparing Eq. (8) and Eq. (9), we observe that the  eigenvalues of (I + γ N R)N − eγR are (1 + γ(λn−1) N )N − eγ(λn−1) . We propose a heuristic method to determine N so that the difference between the eigenvalues are less than a threshold for only positive λs. We also observe that if γ = 1, λ < 1, then |(1+ γ(λ−1) N )N − eγ(λ−1) | < 0.005 if N ≥ 100, and |(1+ γ(λ−1) N )N −eγ(λ−1) | < .01 if N ≥ 30. So we can set N = 30, or N = 100, or others according to different accuracy requirements. In this paper, we use the relatively accurate setting N = 100 to make the real eigenvalues in (I + γ N R)N − eγR less than 0.005. . EXPERIMENTS In this section, we show the experimental data, the  methodology, the setting, and the results. .1 Data Preparation Our input data consist of a toy graph, a middle-size  realworld graph, and a large-size real-world graph. The toy graph is shown in Fig. 2 (a). The graph below it shows node  is being manipulated by adding new nodes A, B, C, . . . such that they all point to node 1, and node 1 points to them all. The data of two real Web graph were obtained from the domain in our institute in October, 2004. The total number of pages found are 18,542 in the middle-size graph, and 607,170 in the large-size graph respectively. The middle-size graph is a subgraph of the large-size graph, and they were obtained by the same crawler: one is recorded by the crawler in its earlier time, and the other is obtained when the crawler stopped. .2 Methodology The algorithms we run include PageRank, TrustRank and DiffusionRank. All the rank values are multiplied by the number of nodes so that the sum of the rank values is equal to the number of nodes. By this normalization, we can  compare the results on graphs with different sizes since the  average rank value is one for any graph after such normalization. We will need value difference and pairwise order difference as comparison measures. Their definitions are listed as follows. Value Difference. The value difference between A = {Ai}n i=1 and B = {Bi}n i=1 is measured as n i=1 |Ai − Bi|. Pairwise Order Difference. The order difference between A and B is measured as the number of significant order differences between A and B. The pair (A[i], A[j]) and (B[i], B[j]) is considered as a significant order difference if one of the following cases happens: both A[i] > [ <]A[j]+0.1 and B[i] ≤ [ ≥]A[j]; both A[i] ≤ [ ≥]A[j] and B[i] > [ < ]A[j] + 0.1. A  B C ...    3    5  3 4  1 2 3 4 5 6      0 2 Gamma ValueDifference Trust set={1} Trust set={2} Trust set={3} Trust set={4} Trust set={5} Trust set={6} (a) (b) Figure 2: (a) The toy graph consisting of six nodes, and node 1 is being manipulated by adding new nodes A, B, C, . . . (b) The approximation tendency to PageRank by DiffusionRank .3 Experimental Set-up The experiments on the middle-size graph and the  largesize graphs are conducted on the workstation, whose  hardware model is Nix Dual Intel Xeon 2.2GHz with 1GB RAM and a Linux Kernel 2.4.18-27smp (RedHat7.3). In  calculating DiffusionRank, we employ Eq. (6) and the discrete approximation of Eq. (4) for such graphs. The related tasks are implemented using C language. While in the toy graph, we employ the continuous diffusion kernel in Eq. (4) and Eq. (5), and implement related tasks using Matlab. For nodes that have zero out-degree (dangling nodes), we employ the method in the modified PageRank algorithm [8], in which dangling nodes of are considered to have random links uniformly to each node. We set α = αI = αB = 0.85 in all algorithms. We also set g to be the uniform distribution in both PageRank and DiffusionRank. For DiffusionRank, we set γ = 1. According to the discussions in Section 4.3 and Section 4.4, we set the iteration number to be MB = 100 in DiffusionRank, and for accuracy consideration, the iteration number in all the algorithms is set to be 100. .4 Approximation of PageRank We show that when γ tends to infinity, the value  differences between DiffusionRank and PageRank tend to zero. Fig. 2 (b) shows the approximation property of  DiffusionRank, as proved in Theorem 1, on the toy graph. The  horizontal axis of Fig. 2 (b) marks the γ value, and vertical axis corresponds to the value difference between DiffusionRank and PageRank. All the possible trusted sets with L = 1 are considered. For L > 1, the results should be the linear combination of some of these curves because of the  linearity of the solutions to heat equations. On other graphs, the situations are similar. .5 Results of Anti-manipulation In this section, we show how the rank values change as the intensity of manipulation increases. We measure the  intensity of manipulation by the number of newly added points that point to the manipulated point. The horizontal axes of Fig. 3 stand for the numbers of newly added points, and vertical axes show the corresponding rank values of the  manipulated nodes. To be clear, we consider all six situations. Every node in Fig. 2 (a) is manipulated respectively, and its  50 100  0 0 0 0 0 RankoftheManipulatdNode−1 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4  50 100  0 0 0 0 0 RankoftheManipulatdNode−2 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4  50 100  0 0 0 0 0 RankoftheManipulatdNode−3 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4  50 100  0 0 0 0 0 Number of New Added Nodes RankoftheManipulatdNode−4 DiffusionRank−Trust 3 PageRank TrustRanl−Trust 3  50 100  0 0 0 0 0 Number of New Added Nodes RankoftheManipulatdNode−5 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4  50 100  0 0 0 0 0 Number of New Added Nodes RankoftheManipulatdNode−6 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4 Figure 3: The rank values of the manipulated nodes on the toy graph 00040006000800010000  000 000 000 000 000 000 000 000 Number of New Added Points RankoftheManipulatdNode PageRank DiffusionRank−uniform DiffusionRank0 DiffusionRank1 DiffusionRank2 DiffusionRank3 TrustRank0 TrustRank1 TrustRank2 TrustRank3 000 4000 6000 8000 10000  0 0 0 0 00 20 40 60 80 Number of New Added Points RankoftheManipulatdNode PageRank DiffusionRank TrustRank DiffusionRank−uniform (a) (b) Figure 4: (a) The rank values of the manipulated nodes on the middle-size graph; (b) The rank values of the manipulated nodes on the large-size graph corresponding values for PageRank, TrustRank (TR),  DiffusionRank (DR) are shown in the one of six sub-figures in Fig. 3. The vertical axes show which node is being  manipulated. In each sub-figure, the trusted sets are  computed below. Since the inverse PageRank yields the results [1.26, 0.85, 1.31, 1.36, 0.51, 0.71]. Let L = 1. If the  manipulated node is not 4, then the trusted set is {4}, and  otherwise {3}. We observe that in all the cases, rank values of the manipulated node for DiffusionRank grow slowest as the number of the newly added nodes increases. On the middle-size graph and the large-size graph, this conclusion is also true, see Fig. 4. Note that, in Fig. 4 (a), we choose four trusted sets (L = 1), on which we test DiffusionRank and TrustRank, the results are denoted by DiffusionRanki and TrustRanki (i = 0, 1, 2, 3 denotes the four trusted set); in Fig. 4 (b), we choose one trusted set (L = 1). Moreover, in both Fig. 4 (a) and Fig. 4 (b), we show the results for DiffusionRank when we have no trusted set, and we trust all the pages before some of them are manipulated. We also test the order difference between the ranking  order A before the page is manipulated and the ranking order PA after the page is manipulated. Because after  manipulation, the number of pages changes, we only compare the common part of A and PA. This experiment is used to test the stability of all these algorithms. The less the order  difference, the stabler the algorithm, in the sense that only a smaller part of the order relations is affected by the  manipulation. Figure 5 (a) shows that the order difference values change when we add new nodes that point to the  manipulated node. We give several γ settings. We find that when γ = 1, the least order difference is achieved by  DiffusionRank. It is interesting to point out that as γ increases, the order difference will increase first; after reaching a maximum value, it will decrease, and finally it tends to the PageRank results. We show this tendency in Fig. 5 (b), in which we choose three different settings-the number of manipulated nodes are 2,000, 5,000, and 10,000 respectively. From these figures, we can see that when γ < 2, the values are less than those for PageRank, and that when γ > 20, the difference between PageRank and DiffusionRank is very small.  After these investigations, we find that in all the graphs we tested, DiffusionRank (when γ = 1) is most robust to  manipulation both in value difference and order difference. The trust set selection algorithm proposed in [7] is effective for both TrustRank and DiffusionRank.  1000 2000 3000 4000 5000 6000 7000 8000 9000 10000  .5  .5  .5  x 10  Number of New Added Points PairwiseOrderDifference PageRank DiffusionRank−Gamma=1 DiffusionRank−Gamma=2 DiffusionRank−Gamma=3 DiffusionRank−Gamma=4 DiffusionRank−Gamma=5 DiffusionRank−Gamma=15 TrustRank  5 10 15 20  .5  .5  .5 x 10  Gamma PairwiseOrderDifference DiffusionRank: when added 2000 nodes DiffusionRank: when added 5000 nodes DiffusionRank: when added 10000 nodes PageRank (a) (b) Figure 5: (a) Pairwise order difference on the middle-size graph, the least it is, the more stable the algorithm; (b) The tendency of varying γ . CONCLUSIONS We conclude that DiffusionRank is a generalization of PageRank, which is interesting in that the heat diffusion  coefficient γ can balance the extent that we want to model the original Web graph and the extent that we want to reduce the effect of link manipulations. The experimental results show that we can actually achieve such a balance by  setting γ = 1, although the best setting including varying γi is still under further investigation. This anti-manipulation feature enables DiffusionRank to be a candidate as a  penicillin for Web spamming. Moreover, DiffusionRank can be employed to find group-group relations and to partition Web graph into small communities. All these advantages can be achieved in the same computational complexity as  PageRank. For the special application of anti-manipulation,  DiffusionRank performs best both in reduction effects and in its stability among all the three algorithms. . ACKNOWLEDGMENTS We thank Patrick Lau, Zhenjiang Lin and Zenglin Xu for their help. This work is fully supported by two grants from the Research Grants Council of the Hong Kong Special administrative Region, China (Project No. CUHK4205/04E and Project No. CUHK4235/04E). . REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais. Improving web search ranking by incorporating user behavior information. In E. N. Efthimiadis, S. T. Dumais, D. Hawking, and K. J¨arvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 19-26, 2006. [2] R. A. Baeza-Yates, P. Boldi, and C. Castillo. Generalizing pagerank: damping functions for link-based ranking algorithms. In E. N. Efthimiadis, S. T. Dumais, D. Hawking, and K. J¨arvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 08-315, 2006. [3] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373-1396, Jun 2003. [4] B. Bollob´as. Random Graphs. Academic Press Inc. (London), 985. [5] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning (ICML), pages 89-96, 2005. [6] N. Eiron, K. S. McCurley, and J. A. Tomlin. Ranking the web frontier. In Proceeding of the 13th World Wide Web Conference (WWW), pages 309-318, 2004. [7] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with trustrank. In M. A. Nascimento, M. T. ¨Ozsu, D. Kossmann, R. J. Miller, J. A. Blakeley, and K. B. Schiefer, editors, Proceedings of the Thirtieth International Conference on Very Large Data Bases (VLDB), pages 576-587, 2004. [8] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub. Exploiting the block structure of the web for computing pagerank. Technical report, Stanford University, 2003. [9] R. I. Kondor and J. D. Lafferty. Diffusion kernels on graphs and other discrete input spaces. In C. Sammut and A. G. Hoffmann, editors, Proceedings of the Nineteenth International Conference on Machine Learning (ICML), pages 315-322, 2002. [10] J. Lafferty and G. Lebanon. Diffusion kernels on statistical manifolds. Journal of Machine Learning Research, 6:129-163, Jan 2005. [11] C. R. MacCluer. The many proofs and applications of perron"s theorem. SIAM Review, 42(3):487-498, 2000. [12] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting spam web pages through content analysis. In Proceedings of the 15th international conference on World Wide Web (WWW), pages 83-92, 2006. [13] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical Report Paper SIDL-WP-1999-0120 (version of 11/11/1999), Stanford Digital Library Technologies Project, 1999. [14] H. Yang, I. King, and M. R. Lyu. NHDC and PHDC: Non-propagating and propagating heat diffusion classifiers. In Proceedings of the 12th International Conference on Neural Information Processing (ICONIP), pages 394-399, 2005. [15] H. Yang, I. King, and M. R. Lyu. Predictive ranking: a novel page ranking approach by estimating the web structure. In Proceedings of the 14th international conference on World Wide Web (WWW) - Special interest tracks and posters, pages 944-945, 2005. [16] H. Yang, I. King, and M. R. Lyu. Predictive random graph ranking on the web. In Proceedings of the IEEE World Congress on Computational Intelligence (WCCI), pages 491-3498, 2006. [17] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and B. Sch¨olkopf. Ranking on data manifolds. In S. Thrun, L. Saul, and B. Sch¨olkopf, editors, Advances in Neural Information Processing Systems 16 (NIPS 2003), 2004.
Cross-Lingual Query Suggestion Using Query Logs of Different Languages Wei Gao1* , Cheng Niu2 , Jian-Yun Nie3 , Ming Zhou2 , Jian Hu2 , Kam-Fai Wong1 , Hsiao-Wuen Hon2  The Chinese University of Hong Kong, Hong Kong, China {wgao, kfwong}@se.cuhk.edu.hk  Microsoft Research Asia, Beijing, China {chengniu, mingzhou, jianh, hon}@microsoft.com  Université de Montréal, Montréal, QC, Canada nie@iro.umontreal.ca ABSTRACT Query suggestion aims to suggest relevant queries for a given query, which help users better specify their information needs. Previously, the suggested terms are mostly in the same language of the input query. In this paper, we extend it to cross-lingual query suggestion (CLQS): for a query in one language, we suggest similar or relevant queries in other languages. This is very important to scenarios of cross-language information retrieval (CLIR) and cross-lingual keyword bidding for search engine advertisement. Instead of relying on existing query translation technologies for CLQS, we present an effective means to map the input query of one language to queries of the other language in the query log. Important monolingual and cross-lingual information such as word translation relations and word co-occurrence statistics, etc. are used to estimate the cross-lingual query similarity with a discriminative model. Benchmarks show that the resulting CLQS system significantly outperforms a baseline system based on dictionary-based query translation. Besides, the resulting CLQS is tested with French to English CLIR tasks on TREC collections. The results demonstrate higher effectiveness than the traditional query translation methods. Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information Search and Retrieval - Query formulation General Terms Algorithms, Performance, Experimentation, Theory. . INTRODUCTION Query suggestion is a functionality to help users of a search engine to better specify their information need, by narrowing down or expanding the scope of the search with synonymous queries and relevant queries, or by suggesting related queries that have been frequently used by other users. Search engines, such as Google, Yahoo!, MSN, Ask Jeeves, all have implemented query suggestion functionality as a valuable addition to their core search method. In addition, the same technology has been leveraged to recommend bidding terms to online advertiser in the  pay-forperformance search market [12]. Query suggestion is closely related to query expansion which extends the original query with new search terms to narrow the scope of the search. But different from query expansion, query suggestion aims to suggest full queries that have been formulated by users so that the query integrity and coherence are preserved in the suggested queries. Typical methods for query suggestion exploit query logs and document collections, by assuming that in the same period of time, many users share the same or similar interests, which can be expressed in different manners [12, 14, 26]. By suggesting the related and frequently used formulations, it is hoped that the new query can cover more relevant documents. However, all of the existing studies dealt with monolingual query suggestion and to our knowledge, there is no published study on cross-lingual query suggestion (CLQS). CLQS aims to suggest related queries but in a different language. It has wide applications on World Wide Web: for cross-language search or for suggesting relevant bidding terms in a different language. 1 CLQS can be approached as a query translation problem, i.e., to suggest the queries that are translations of the original query. Dictionaries, large size of parallel corpora and existing commercial machine translation systems can be used for translation. However, these kinds of approaches usually rely on static knowledge and data. It cannot effectively reflect the quickly shifting interests of Web users. Moreover, there are some problems with translated queries in target language. For instance, the translated terms can be reasonable translations, but they are not popularly used in the target language. For example, the French query aliment biologique is translated into biologic food by Google translation tool2 , yet the correct formulation nowadays should be organic food. Therefore, there exist many mismatch cases between the translated terms and the really used terms in target language. This mismatch makes the suggested terms in the target language ineffective. A natural thinking of solving this mismatch is to map the queries in the source language and the queries in the target language, by using the query log of a search engine. We exploit the fact that the users of search engines in the same period of time have similar interests, and they submit queries on similar topics in different languages. As a result, a query written in a source language likely has an equivalent in a query log in the target language. In particular, if the user intends to perform CLIR, then original query is even more likely to have its correspondent included in the target language query log. Therefore, if a candidate for CLQS appears often in the query log, then it is more likely the appropriate one to be suggested. In this paper, we propose a method of calculating the similarity between source language query and the target language query by exploiting, in addition to the translation information, a wide spectrum of bilingual and monolingual information, such as term co-occurrences, query logs with click-through data, etc. A discriminative model is used to learn the cross-lingual query similarity based on a set of manually translated queries. The model is trained by optimizing the cross-lingual similarity to best fit the monolingual similarity between one query and the other query"s translation. Besides being benchmarked as an independent module, the resulting CLQS system is tested as a new means of query translation in CLIR task on TREC collections. The results show that this new translation method is more effective than the traditional query translation method. The remainder of this paper is organized as follows: Section 2 introduces the related work; Section 3 describes in detail the discriminative model for estimating cross-lingual query similarity; Section 4 presents a new CLIR approach using cross-lingual query suggestion as a bridge across language boundaries. Section 5 discusses the experiments and benchmarks; finally, the paper is concluded in Section 6. . RELATED WORK Most approaches to CLIR perform a query translation followed by a monolingual IR. Typically, queries are translated either using a bilingual dictionary [22], a machine translation software [9] or a parallel corpus [20]. Despite the various types of resources used, out-of-vocabulary (OOV) words and translation disambiguation are the two major bottlenecks for CLIR [20]. In [7, 27], OOV term translations are mined from the Web using a search engine. In [17], bilingual knowledge is acquired based on anchor text analysis. In addition, word co-occurrence statistics in the target language has been leveraged for translation disambiguation [3, 10, 11, 19].  http://www.google.com/language_tools Nevertheless, it is arguable that accurate query translation may not be necessary for CLIR. Indeed, in many cases, it is helpful to introduce words even if they are not direct translations of any query word, but are closely related to the meaning of the query. This observation has led to the development of cross-lingual query expansion (CLQE) techniques [2, 16, 18]. [2] reports the enhancement on CLIR by post-translation expansion. [16] develops a cross-lingual relevancy model by leveraging the  crosslingual co-occurrence statistics in parallel texts. [18] makes performance comparison on multiple CLQE techniques, including pre-translation expansion and post-translation expansion. However, there is lack of a unified framework to combine the wide spectrum of resources and recent advances of mining techniques for CLQE. CLQS is different from CLQE in that it aims to suggest full queries that have been formulated by users in another language. As CLQS exploits up-to-date query logs, it is expected that for most user queries, we can find common formulations on these topics in the query log in the target language. Therefore, CLQS also plays a role of adapting the original query formulation to the common formulations of similar topics in the target language. Query logs have been successfully used for monolingual IR [8, 2, 15, 26], especially in monolingual query suggestions [12] and relating the semantically relevant terms for query expansion [8, 5]. In [1], the target language query log has been exploited to help query translation in CLIR. . ESTIMATING CROSS-LINGUAL QUERY SIMILARITY A search engine has a query log containing user queries in different languages within a certain period of time. In addition to query terms, click-through information is also recorded. Therefore, we know which documents have been selected by users for each query. Given a query in the source language, our CLQS task is to determine one or several similar queries in the target language from the query log. The key problem with cross-lingual query suggestion is how to learn a similarity measure between two queries in different languages. Although various statistical similarity measures have been studied for monolingual terms [8, 26], most of them are based on term co-occurrence statistics, and can hardly be applied directly in cross-lingual settings. In order to define a similarity measure across languages, one has to use at least one translation tool or resource. So the measure is based on both translation relation and monolingual similarity. In this paper, as our purpose is to provide up-to-date query similarity measure, it may not be sufficient to use only a static translation resource. Therefore, we also integrate a method to mine possible translations on the Web. This method is particularly useful for dealing with OOV terms. Given a set of resources of different natures, the next question is how to integrate them in a principled manner. In this paper, we propose a discriminative model to learn the appropriate similarity measure. The principle is as follows: we assume that we have a reasonable monolingual query similarity measure. For any training query example for which a translation exists, its similarity measure (with any other query) is transposed to its translation. Therefore, we have the desired cross-language similarity value for this example. Then we use a discriminative model to learn the cross-language similarity function which fits the best these examples. In the following sections, let us first describe the detail of the discriminative model for cross-lingual query similarity estimation. Then we introduce all the features (monolingual and cross-lingual information) that we will use in the discriminative model. .1 Discriminative Model for Estimating Cross-Lingual Query Similarity In this section, we propose a discriminative model to learn  crosslingual query similarities in a principled manner. The principle is as follows: for a reasonable monolingual query similarity between two queries, a cross-lingual correspondent can be deduced between one query and another query"s translation. In other words, for a pair of queries in different languages, their  crosslingual similarity should fit the monolingual similarity between one query and the other query"s translation. For example, the similarity between French query pages jaunes (i.e., yellow page in English) and English query telephone directory should be equal to the monolingual similarity between the translation of the French query yellow page and telephone directory. There are many ways to obtain a monolingual similarity measure between terms, e.g., term co-occurrence based mutual information and 2 χ . Any of them can be used as the target for the cross-lingual similarity function to fit. In this way, cross-lingual query similarity estimation is formulated as a regression task as follows: Given a source language query fq , a target language query eq , and a monolingual query similarity MLsim , the corresponding cross-lingual query similarity CLsim is defined as follows: ),(),( eqMLefCL qTsimqqsim f = (1) where fqT is the translation of fq in the target language. Based on Equation (1), it would be relatively easy to create a training corpus. All it requires is a list of query translations. Then an existing monolingual query suggestion system can be used to automatically produce similar query to each translation, and create the training corpus for cross-lingual similarity estimation. Another advantage is that it is fairly easy to make use of arbitrary information sources within a discriminative modeling framework to achieve optimal performance. In this paper, support vector machine (SVM) regression algorithm [25] is used to learn the cross-lingual term similarity function. Given a vector of feature functions f between fq and eq , ),( efCL ttsim is represented as an inner product between a weight vector and the feature vector in a kernel space as follows: )),((),( efefCL ttfwttsim φ•= (2) where φ is the mapping from the input feature space onto the kernel space, and wis the weight vector in the kernel space which will be learned by the SVM regression training. Once the weight vector is learned, the Equation (2) can be used to estimate the similarity between queries of different languages. We want to point out that instead of regression, one can definitely simplify the task as a binary or ordinal classification, in which case CLQS can be categorized according to discontinuous class labels, e.g., relevant and irrelevant, or a series of levels of relevancies, e.g., strongly relevant, weakly relevant, and irrelevant. In either case, one can resort to discriminative classification approaches, such as an SVM or maximum entropy model, in a straightforward way. However, the regression formalism enables us to fully rank the suggested queries based on the similarity score given by Equation (1). The Equations (1) and (2) construct a regression model for cross-lingual query similarity estimation. In the following sections, the monolingual query similarity measure (see Section .2) and the feature functions used for SVM regression (see Section 3.3) will be presented. .2 Monolingual Query Similarity Measure Based on Click-through Information Any monolingual term similarity measure can be used as the regression target. In this paper, we select the monolingual query similarity measure presented in [26] which reports good performance by using search users" click-through information in query logs. The reason to choose this monolingual similarity is that it is defined in a similar context as ours − according to a user log that reflects users" intention and behavior. Therefore, we can expect that the cross-language term similarity learned from it can also reflect users" intention and expectation. Following [26], our monolingual query similarity is defined by combining both query content-based similarity and click-through commonality in the query log. First the content similarity between two queries p and q is defined as follows: ))(),(( ),( ),( qknpknMax qpKN qpsimilarity content = (3) where )( xkn is the number of keywords in a query x, ),( qpKN is the number of common keywords in the two queries. Secondly, the click-through based similarity is defined as follows, ))(),(( ),( ),( qrdprdMax qpRD qpsimilarity throughclick =− (4) where )(xrd is the number of clicked URLs for a query x, and ),( qpRD is the number of common URLs clicked for two queries. Finally, the similarity between two queries is a linear combination of the content-based and click-through-based similarities, and is presented as follows: ),(* ),(*),( qpsimilarity qpsimilarityqpsimilarity throughclick content − += β α (5) where α and β are the relative importance of the two similarity measures. In this paper, we set ,4.0=α and 6.0=β following the practice in [26]. Queries with similarity measure higher than a threshold with another query will be regarded as relevant monolingual query suggestions (MLQS) for the latter. In this paper, the threshold is set as 0.9 empirically. .3 Features Used for Learning Cross-Lingual Query Similarity Measure This section presents the extraction of candidate relevant queries from the log with the assistance of various monolingual and bilingual resources. Meanwhile, feature functions over source query and the cross-lingual relevant candidates are defined. Some of the resources being used here, such as bilingual lexicon and parallel corpora, were for query translation in previous work. But note that we employ them here as an assistant means for finding relevant candidates in the log rather than for acquiring accurate translations. .3.1 Bilingual Dictionary In this subsection, a built-in-house bilingual dictionary containing 20,000 unique entries is used to retrieve candidate queries. Since multiple translations may be associated with each source word, co-occurrence based translation disambiguation is performed [3, 0]. The process is presented as follows: Given an input query }{ ,2,1 fnfff wwwq K= in the source language, for each query term fiw , a set of unique translations are provided by the bilingual dictionary D : },,{)( ,2,1 imiifi tttwD K= . Then the cohesion between the translations of two query terms is measured using mutual information which is computed as follows: )()( ),( log),()( , klij klij klijklij tPtP ttP ttPttMI = (6) where . )( )(, ),( ),( N tC tP N ttC ttP klij klij == Here ),( yxC is the number of queries in the log containing both x and y , )(xC is the number of queries containing term x , and N is the total number of queries in the log. Based on the term-term cohesion defined in Equation (6), all the possible query translations are ranked using the summation of the term-term cohesion ∑≠ = kiki klijqdict ttMITS f ,, ),()( . The set of top-4 query translations is denoted as )( fqTS . For each possible query translation )( fqTST∈ , we retrieve all the queries containing the same keywords as T from the target language log. The retrieved queries are candidate target queries, and are assigned )(TSdict as the value of the feature Dictionary-based Translation Score. .3.2 Parallel Corpora Parallel corpora are precious resources for bilingual knowledge acquisition. Different from the bilingual dictionary, the bilingual knowledge learned from parallel corpora assigns probability for each translation candidate which is useful in acquiring dominant query translations. In this paper, the Europarl corpus (a set of parallel French and English texts from the proceedings of the European Parliament) is used. The corpus is first sentence aligned. Then word alignments are derived by training an IBM translation model 1 [4] using GIZA++ [21]. The learned bilingual knowledge is used to extract candidate queries from the query log. The process is presented as follows: Given a pair of queries, fq in the source language and eq in the target language, the Bi-Directional Translation Score is defined as follows: )|()|(),( 111 feIBMefIBMefIBM qqpqqpqqS = (7) where )|(1 xypIBM is the word sequence translation probability given by IBM model 1 which has the following form: ∏∑= =+ = ||  ||  ||1 )|( )1|(|  )|( y j x i ijyIBM xyp x xyp (8) where )|( ij xyp is the word to word translation probability derived from the word-aligned corpora. The reason to use bidirectional translation probability is to deal with the fact that common words can be considered as possible translations of many words. By using bidirectional translation, we test whether the translation words can be translated back to the source words. This is helpful to focus on the translation probability onto the most specific translation candidates. Now, given an input query fq , the top 10 queries }{ eq with the highest bidirectional translation scores with fq are retrieved from the query log, and ),(1 efIBM qqS in Equation (7) is assigned as the value for the feature Bi-Directional Translation Score. .3.3 Online Mining for Related Queries OOV word translation is a major knowledge bottleneck for query translation and CLIR. To overcome this knowledge bottleneck, web mining has been exploited in [7, 27] to acquire  EnglishChinese term translations based on the observation that Chinese terms may co-occur with their English translations in the same web page. In this section, this web mining approach is adapted to acquire not only translations but semantically related queries in the target language. It is assumed that if a query in the target language co-occurs with the source query in many web pages, they are probably semantically related. Therefore, a simple method is to send the source query to a search engine (Google in our case) for Web pages in the target language in order to find related queries in the target language. For instance, by sending a French query pages jaunes to search for English pages, the English snippets containing the key words yellow pages or telephone directory will be returned. However, this simple approach may induce significant amount of noise due to the non-relevant returns from the search engine. In order to improve the relevancy of the bilingual snippets, we extend the simple approach by the following query modification: the original query is used to search with the dictionary-based query keyword translations, which are unified by the ∧ (and) ∨ (OR) operators into a single Boolean query. For example, for a given query abcq = where the set of translation entries in the dictionary of for a is },,{ 321 aaa , b is },{ 21 bb and c is }{ 1c , we issue 121321 )()( cbbaaaq ∧∨∧∨∨∧ as one web query. From the returned top 700 snippets, the most frequent 10 target queries are identified, and are associated with the feature Frequency in the Snippets. Furthermore, we use Co-Occurrence Double-Check (CODC) Measure to weight the association between the source and target queries. CODC Measure is proposed in [6] as an association measure based on snippet analysis, named Web Search with Double Checking (WSDC) model. In WSDC model, two objects a and b are considered to have an association if b can be found by using a as query (forward process), and a can be found by using b as query (backward process) by web search. The forward process counts the frequency of b in the top N snippets of query a, denoted as )@( abfreq . Similarly, the backward process count the frequency of a in the top N snippets of query b, denoted as )@( bafreq . Then the CODC association score is defined as follows: ⎪ ⎩ ⎪ ⎨ ⎧ =× = ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎣ ⎡ × otherwise, )@()@(if,0 ),( )( )@( )( )@( log α e ef f fe qfreq qqfreq qfreq qqfreq effe efCODC e qqfreqqqfreq qqS (9) CODC measures the association of two terms in the range between 0 and 1, where under the two extreme cases, eq and fq are of no association when 0)@( =fe qqfreq or 0)@( =ef qqfreq , and are of the strongest association when )()@( ffe qfreqqqfreq = and )()@( eef qfreqqqfreq = . In our experiment, α is set at 0.15 following the practice in [6]. Any query eq mined from the Web will be associated with a feature CODC Measure with ),( efCODC qqS as its value. .3.4 Monolingual Query Suggestion For all the candidate queries 0Q being retrieved using dictionary (see Section 3.3.1), parallel data (see Section 3.3.2) and web mining (see Section 3.3.3), monolingual query suggestion system (described in Section 3.1) is called to produce more related queries in the target language. For each target query eq , its monolingual source query )( eML qSQ is defined as the query in Q with the highest monolingual similarity with eq , i.e., ),(maxarg)( 0 eeMLQqeML qqsimqSQ e ′= ∈′ (10) Then the monolingual similarity between eq and )( eML qSQ is used as the value of the eq "s Monolingual Query Suggestion Feature. For any target query 0Qq∈ , its Monolingual Query Suggestion Feature is set as 1. For any query 0Qqe ∉ , its values of Dictionary-based Translation Score, Bi-Directional Translation Score, Frequency in the Snippet, and CODC Measure are set to be equal to the feature values of )( eML qSQ . .4 Estimating Cross-lingual Query Similarity In summary, four categories of features are used to learn the  crosslingual query similarity. SVM regression algorithm [25] is used to learn the weights in Equation (2). In this paper, LibSVM toolkit [5] is used for the regression training. In the prediction stage, the candidate queries will be ranked using the cross-lingual query similarity score computed in terms of )),((),( efefCL ttfwttsim φ•= , and the queries with similarity score lower than a threshold will be regarded as  nonrelevant. The threshold is learned using a development data set by fitting MLQS"s output. . CLIR BASED ON CROSS-LINGUAL QUERY SUGGESTION In Section 3, we presented a discriminative model for cross lingual query suggestion. However, objectively benchmarking a query suggestion system is not a trivial task. In this paper, we propose to use CLQS as an alternative to query translation, and test its effectiveness in CLIR tasks. The resulting good performance of CLIR corresponds to the high quality of the suggested queries. Given a source query fq , a set of relevant queries }{ eq in the target language are recommended using the cross-lingual query suggestion system. Then a monolingual IR system based on the BM25 model [23] is called using each }{ eqq∈ as queries to retrieve documents. Then the retrieved documents are re-ranked based on the sum of the BM25 scores associated with each monolingual retrieval. . PERFORMACNCE EVALUATION In this section, we will benchmark the cross-lingual query suggestion system, comparing its performance with monolingual query suggestion, studying the contribution of various information sources, and testing its effectiveness when being used in CLIR tasks. .1 Data Resources In our experiments, French and English are selected as the source and target language respectively. Such selection is due to the fact that large scale query logs are readily available for these two languages. A one-month English query log (containing 7 million unique English queries with occurrence frequency more than 5) of MSN search engine is used as the target language log. And a monolingual query suggestion system is built based on it. In addition, 5,000 French queries are selected randomly from a French query log (containing around 3 million queries), and are manually translated into English by professional French-English translators. Among the 5,000 French queries, 4,171 queries have their translations in the English query log, and are used for CLQS training and testing. Furthermore, among the 4,171 French queries, 70% are used for cross-lingual query similarity training, 0% are used as the development data to determine the relevancy threshold, and 20% are used for testing. To retrieve the  crosslingual related queries, a built-in-house French-English bilingual lexicon (containing 120,000 unique entries) and the Europarl corpus are used. Besides benchmarking CLQS as an independent system, the CLQS is also tested as a query translation system for CLIR tasks. Based on the observation that the CLIR performance heavily relies on the quality of the suggested queries, this benchmark measures the quality of CLQS in terms of its effectiveness in helping CLIR. To perform such benchmark, we use the documents of TREC6 CLIR data (AP88-90 newswire, 50MB) with officially provided 25 short French-English queries pairs (CL1-CL25). The selection of this data set is due to the fact that the average length of the queries are 3.3 words long, which matches the web query logs we use to train CLQS. .2 Performance of Cross-lingual Query Suggestion Mean-square-error (MSE) is used to measure the regression error and it is defined as follows: ( )2 ),(),(  ∑ −= i eiqMLeifiCL qTsimqqsim l MSE fi where l is the total number of cross-lingual query pairs in the testing data. As described in Section 3.4, a relevancy threshold is learned using the development data, and only CLQS with similarity value above the threshold is regarded as truly relevant to the input query. In this way, CLQS can also be benchmarked as a classification task using precision (P) and recall (R) which are defined as follows: CLQS MLQSCLQS P S SS I = , MLQS MLQSCLQS R S SS I = where CLQSS is the set of relevant queries suggested by CLQS, MLQSS is the set of relevant queries suggested by MLQS (see Section 3.2). The benchmarking results with various feature configurations are shown in Table 1. Regression Classification Features MSE P R DD 0.274 0.723 0.098 DD+PC 0.224 0.713 0.125 DD+PC+ Web .115 0.808 0.192 DD+PC+ Web+ML QS .174 0.796 0.421 Table 1. CLQS performance with different feature settings (DD: dictionary only; DD+PC: dictionary and parallel corpora; DD+PC+Web: dictionary, parallel corpora, and web mining; DD+PC+Web+MLQS: dictionary, parallel corpora, web mining and monolingual query suggestion) Table 1 reports the performance comparison with various feature settings. The baseline system (DD) uses a conventional query translation approach, i.e., a bilingual dictionary with  cooccurrence-based translation disambiguation. The baseline system only covers less than 10% of the suggestions made by MLQS. Using additional features obviously enables CLQS to generate more relevant queries. The most significant improvement on recall is achieved by exploiting MLQS. The final CLQS system is able to generate 42% of the queries suggested by MLQS. Among all the feature combinations, there is no significant change in precision. This indicates that our methods can improve the recall by effectively leveraging various information sources without losing the accuracy of the suggestions. Besides benchmarking CLQS by comparing its output with MLQS output, 200 French queries are randomly selected from the French query log. These queries are double-checked to make sure that they are not in the CLQS training corpus. Then CLQS system is used to suggest relevant English queries for them. On average, for each French query, 8.7 relevant English queries are suggested. Then the total 1,740 suggested English queries are manually checked by two professional English/French translators with cross-validation. Among the 1,747 suggested queries, 1,407 queries are recognized as relevant to the original ones, hence the accuracy is 80.9%. Figure 1 shows an example of CLQS of the French query terrorisme international (international terrorism in English). .3 CLIR Performance In this section, CLQS is tested with French to English CLIR tasks. We conduct CLIR experiments using the TREC 6 CLIR dataset described in Section 5.1. The CLIR is performed using a query translation system followed by a BM25-based [23] monolingual IR module. The following three different systems have been used to perform query translation: (1) CLQS: our CLQS system; (2) MT: Google French to English machine translation system; (3) DT: a dictionary based query translation system using  cooccurrence statistics for translation disambiguation. The translation disambiguation algorithm is presented in Section 3.3.1. Besides, the monolingual IR performance is also reported as a reference. The average precision of the four IR systems are reported in Table 2, and the 11-point precision-recall curves are shown in Figure 2. Table 2. Average precision of CLIR on TREC 6 Dataset (Monolingual: monolingual IR system; MT: CLIR based on machine translation; DT: CLIR based on dictionary translation; CLQS: CLQS-based CLIR) IR System Average Precision % of Monolingual IR Monolingual 0.266 100% MT 0.217 81.6% DT 0.186 69.9% CLQS 0.233 87.6% Figure 1. An example of CLQS of the French query terrorisme international international terrorism (0.991); what is terrorism (0.943); counter terrorism (0.920); terrorist (0.911); terrorist attacks (0.898); international terrorist (0.853); world terrorism (0.845); global terrorism (0.833); transnational terrorism (0.821); human rights (0.811); terrorist groups (0. 777); patterns of global terrorism (0.762) september 11 (0.734) 1-point P-R curves (TREC6)  .1 .2 .3 .4 .5 .6 .7  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precison Monolingual MT DT CLQS The benchmark shows that using CLQS as a query translation tool outperforms CLIR based on machine translation by 7.4%, outperforms CLIR based on dictionary translation by 25.2%, and achieves 87.6% of the monolingual IR performance. The effectiveness of CLQS lies in its ability in suggesting closely related queries besides accurate translations. For example, for the query CL14 terrorisme international (international terrorism), although the machine translation tool translates the query correctly, CLQS system still achieves higher score by recommending many additional related terms such as global terrorism, world terrorism, etc. (as shown in Figure 1). Another example is the query La pollution causée par l'automobile (air pollution due to automobile) of CL6. The MT tool provides the translation the pollution caused by the car, while CLQS system enumerates all the possible synonyms of car, and suggest the following queries car pollution, auto pollution, automobile pollution. Besides, other related queries such as global warming are also suggested. For the query CL12 La culture écologique (organic farming), the MT tool fails to generate the correct translation. Although the correct translation is neither in our French-English dictionary, CLQS system generates organic farm as a relevant query due to successful web mining. The above experiment demonstrates the effectiveness of using CLQS to suggest relevant queries for CLIR enhancement. A related research is to perform query expansion to enhance CLIR [2, 18]. So it is very interesting to compare the CLQS approach with the conventional query expansion approaches. Following [18], post-translation expansion is performed based on  pseudorelevance feedback (PRF) techniques. We first perform CLIR in the same way as before. Then we use the traditional PRF algorithm described in [24] to select expansion terms. In our experiments, the top 10 terms are selected to expand the original query, and the new query is used to search the collection for the second time. The new CLIR performance in terms of average precision is shown in Table 3. The 11-point P-R curves are drawn in Figure 3. Although being enhanced by pseudo-relevance feedback, the CLIR using either machine translation or dictionary-based query translation still does not perform as well as CLQS-based approach. Statistical t-test [13] is conducted to indicate whether the CLQS-based CLIR performs significantly better. Pair-wise  pvalues are shown in Table 4. Clearly, CLQS significantly outperforms MT and DT without PRF as well as DT+PRF, but its superiority over MT+PRF is not significant. However, when combined with PRF, CLQS significant outperforms all the other methods. This indicates the higher effectiveness of CLQS in related term identification by leveraging a wide spectrum of resources. Furthermore, post-translation expansion is capable of improving CLQS-based CLIR. This is due to the fact that CLQS and pseudo-relevance feedback are leveraging different categories of resources, and both approaches can be complementary. IR System AP without PRF AP with PRF Monolingual 0.266 (100%) 0.288 (100%) MT 0.217 (81.6%) 0.222 (77.1%) DT 0.186 (69.9%) 0.220 (76.4%) CLQS 0.233 (87.6%) 0.259 (89.9%) 1-point P-R curves with pseudo relevance feedback (TREC6)  .1 .2 .3 .4 .5 .6 .7 .8  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precison Monolingual MT DT CLQS MT DT MT+PRF DT+PRF CLQS 0.0298 3.84e-05 0.1472 0.0282 CLQS+PR F .0026 2.63e-05 0.0094 0.0016 . CONCLUSIONS In this paper, we proposed a new approach to cross-lingual query suggestion by mining relevant queries in different languages from query logs. The key solution to this problem is to learn a  crosslingual query similarity measure by a discriminative model exploiting multiple monolingual and bilingual resources. The model is trained based on the principle that cross-lingual similarity should best fit the monolingual similarity between one query and the other query"s translation. Figure 2. 11 points precision-recall on TREC6 CLIR data set Figure 3. 11 points precision-recall on TREC6 CLIR dataset with pseudo relevance feedback Table 3. Comparison of average precision (AP) on TREC 6 without and with post-translation expansion. (%) are the relative percentages over the monolingual IR performance Table 4. The results of pair-wise significance t-test. Here  pvalue < 0.05 is considered statistically significant The baseline CLQS system applies a typical query translation approach, using a bilingual dictionary with co-occurrence-based translation disambiguation. This approach only covers 10% of the relevant queries suggested by an MLQS system (when the exact translation of the original query is given). By leveraging additional resources such as parallel corpora, web mining and  logbased monolingual query expansion, the final system is able to cover 42% of the relevant queries suggested by an MLQS system with precision as high as 79.6%. To further test the quality of the suggested queries, CLQS system is used as a query translation system in CLIR tasks. Benchmarked using TREC 6 French to English CLIR task, CLQS demonstrates higher effectiveness than the traditional query translation methods using either bilingual dictionary or commercial machine translation tools. The improvement on TREC French to English CLIR task by using CLQS demonstrates the high quality of the suggested queries. This also shows the strong correspondence between the input French queries and English queries in the log. In the future, we will build CLQS system between languages which may be more loosely correlated, e.g., English and Chinese, and study the CLQS performance change due to the less strong correspondence among queries in such languages. . REFERENCES [1] Ambati, V. and Rohini., U. Using Monolingual Clickthrough Data to Build Cross-lingual Search Systems. In Proceedings of New Directions in Multilingual Information Access Workshop of SIGIR 2006. [2] Ballestors, L. A. and Croft, W. B. Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval. In Proc. SIGIR 1997, pp. 84-91. [3] Ballestors, L. A. and Croft, W. B. Resolving Ambiguity for Cross-Language Retrieval. In Proc. SIGIR 1998, pp. 64-71. [4] Brown, P. F., Pietra, D. S. A., Pietra, D. V. J., and Mercer, R. L. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,  9(2):263311, 1993. [5] Chang, C. C. and Lin, C. LIBSVM: a Library for Support Vector Machines (Version 2.3). 2001. http://citeseer.ist.psu.edu/chang01libsvm.html [6] Chen, H.-H., Lin, M.-S., and Wei, Y.-C. Novel Association Measures Using Web Search with Double Checking. In Proc. COLING/ACL 2006, pp. 1009-1016. [7] Cheng, P.-J., Teng, J.-W., Chen, R.-C., Wang, J.-H., Lu,  W.H., and Chien, L.-F. Translating Unknown Queries with Web Corpora for Cross-Language Information Retrieval. In Proc. SIGIR 2004, pp. 146-153. [8] Cui, H., Wen, J. R., Nie, J.-Y., and Ma, W. Y. Query Expansion by Mining User Logs. IEEE Trans. on Knowledge and Data Engineering, 15(4):829-839, 2003. [9] Fujii A. and Ishikawa, T. Applying Machine Translation to Two-Stage Cross-Language Information Retrieval. In Proceedings of 4th Conference of the Association for Machine Translation in the Americas, pp. 13-24, 2000. [10] Gao, J. F., Nie, J.-Y., Xun, E., Zhang, J., Zhou, M., and Huang, C. Improving query translation for CLIR using statistical Models. In Proc. SIGIR 2001, pp. 96-104. [11] Gao, J. F., Nie, J.-Y., He, H., Chen, W., and Zhou, M. Resolving Query Translation Ambiguity using a Decaying Co-occurrence Model and Syntactic Dependence Relations. In Proc. SIGIR 2002, pp. 183-190. [12] Gleich, D., and Zhukov, L. SVD Subspace Projections for Term Suggestion Ranking and Clustering. In Technical Report, Yahoo! Research Labs, 2004. [13] Hull, D. Using Statistical Testing in the Evaluation of Retrieval Experiments. In Proc. SIGIR 1993, pp. 329-338. [14] Jeon, J., Croft, W. B., and Lee, J. Finding Similar Questions in Large Question and Answer Archives. In Proc. CIKM 005, pp. 84-90. [15] Joachims, T. Optimizing Search Engines Using Clickthrough Data. In Proc. SIGKDD 2002, pp. 133-142. [16] Lavrenko, V., Choquette, M., and Croft, W. B. Cross-Lingual Relevance Models. In Proc. SIGIR 2002, pp. 175-182. [17] Lu, W.-H., Chien, L.-F., and Lee, H.-J. Anchor Text Mining for Translation Extraction of Query Terms. In Proc. SIGIR 001, pp. 388-389. [18] McNamee, P. and Mayfield, J. Comparing Cross-Language Query Expansion Techniques by Degrading Translation Resources. In Proc. SIGIR 2002, pp. 159-166. [19] Monz, C. and Dorr, B. J. Iterative Translation Disambiguation for Cross-Language Information Retrieval. In Proc. SIGIR 2005, pp. 520-527. [20] Nie, J.-Y., Simard, M., Isabelle, P., and Durand, R.  CrossLanguage Information Retrieval based on Parallel Text and Automatic Mining of Parallel Text from the Web. In Proc. SIGIR 1999, pp. 74-81. [21] Och, F. J. and Ney, H. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 9(1):19-51, 2003. [22] Pirkola, A., Hedlund, T., Keshusalo, H., and Järvelin, K. Dictionary-Based Cross-Language Information Retrieval: Problems, Methods, and Research Findings. Information Retrieval, 4(3/4):209-230, 2001. [23] Robertson, S. E., Walker, S., Hancock-Beaulieu, M. M., and Gatford, M. OKAPI at TREC-3. In Proc.TREC-3, pp.  00225, 1995. [24] Robertson, S. E. and Jones, K. S. Relevance Weighting of Search Terms. Journal of the American Society of Information Science, 27(3):129-146, 1976. [25] Smola, A. J. and Schölkopf, B. A. Tutorial on Support Vector Regression. Statistics and Computing, 14(3):199-222, 2004. [26] Wen, J. R., Nie, J.-Y., and Zhang, H. J. Query Clustering Using User Logs. ACM Trans. Information Systems, 0(1):59-81, 2002. [27] Zhang, Y. and Vines, P. Using the Web for Automated Translation Extraction in Cross-Language Information Retrieval. In Proc. SIGIR 2004, pp. 162-169.
HITS on the Web: How does it Compare? Marc Najork Microsoft Research 065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research  J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the  effectiveness of HITS in comparison with other link-based  ranking algorithms, when used in combination with a  state-ofthe-art text retrieval algorithm exploiting anchor text. We quantified their effectiveness using three common  performance measures: the mean reciprocal rank, the mean  average precision, and the normalized discounted cumulative gain measurements. The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383  results, about 17 of which were labeled by judges. We found that HITS outperforms PageRank, but is about as  effective as web-page in-degree. The same holds true when any of the link-based features are combined with the text  retrieval algorithm. Finally, we studied the relationship  between query specificity and the effectiveness of selected  features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation . INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web. The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query. However, it remains unclear today whether there are  practical benefits of HITS over other link graph measures. This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the document"s anchor text, i.e. the text of incoming links. This, at least to some degree, takes the link graph into account, in a query-dependent manner. Comparing HITS to PageRank or in-degree empirically is no easy task. There are two main difficulties: scale and  relevance. Scale is important because link-based features are known to improve in quality as the document graph grows. If we carry out a small experiment, our conclusions won"t carry over to large graphs such as the web. However,  computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult. Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse. To our knowledge, this paper is the first attempt to  evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment. Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text. This is reassuring: in the absence of a theoretical model capable of tying these  measures with relevance, the only way to validate our intuitions is to carry out realistic experiments. However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most  simpleminded query-independent link-based feature. This  continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text. The remainder of this paper is structured as follows:  Section 2 surveys related work. Section 3 describes the data sets we used in our study. Section 4 reviews the  performance measures we used. Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments. Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. . RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms. The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research. There are numerous attempts at improving the  effectiveness of HITS and PageRank. Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few. Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others. Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank. For  example, Borodin et al. [3] investigated various theoretical  properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2]  studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as  existence and uniqueness of an eigenvector and convergence of power iteration [18]. Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough  studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their  effectiveness have been published. We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank. Amento et al. [1] employed  quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query. A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a  neighborhood graph derived by retrieving 50 in-links per result from Google. By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. . OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges. Our web graph is based on a web crawl that was  conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages. These pages contain 7,672,011,890 hyperlinks (after eliminating duplicate  hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs. Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet  downloaded. The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10. Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links. As we will see, this property affects the computational cost of HITS. Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 6,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average. It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs. In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 85,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).  Results were selected for judgment based on their commercial search engine placement; in other words, the subset of  labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms. Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines. This is so  because no document features have been found yet that can effectively estimate the relevance of a document to a user query. Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features. Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community. A good  performance measure should correlate with user satisfaction,  taking into account that users will dislike having to delve deep in the results to find relevant documents. For this reason, standard correlation measures (such as the correlation  coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. . MEASURING PERFORMANCE In this study, we quantify the effectiveness of various  ranking algorithms using three measures: NDCG, MRR, and MAP. The normalized discounted cumulative gains (NDCG)  measure [13] discounts the contribution of a document to the overall score as the document"s rank increases (assuming that the best document has the lowest rank). Such a  measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12]. NDCG values are  normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges. The discounted  cumulative gain at a particular rank-threshold T (DCG@T) is  defined to be PT j=1  log(1+j)  r(j) − 1  , where r(j) is the  rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j. The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query. Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG. The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set. The RR at rank-threshold T is defined to be 0 if none of the  highestranking T documents is relevant. The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set. Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise. The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results. The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) . The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set. The above definitions of MRR and MAP rely on the notion of a relevant result. We investigated two definitions of  relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant. For reasons of space, we only report MAP and MRR values computed using the  latter definition; using the former definition does not change the qualitative nature of our findings. Similarly, we  computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different  conclusions. Recall that over 99% of documents are unlabeled. We chose to treat all these documents as irrelevant to the query. For some queries, however, not all relevant documents have been judged. This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized. This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment. On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. . COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the  importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page B"s content by page A"s author. The following recursive definition captures this notion of  endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u. However, this definition suffers from a severe shortcoming: In the  fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score. In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2. Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability  distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it. In the limit, the random walker is at node v with probability R(v). One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links. One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph. We chose the alternative approach of introducing a single phantom node. Each sink node has an edge to the phantom node, and the phantom node has an edge to itself. In practice, PageRank scores can be computed using power iteration. Since PageRank is query-independent, the  computation can be performed off-line ahead of query time. This property has been key to PageRank"s success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time. In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed  version of PageRank. The computation consists of two distinct phases. In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and  converted into a more compact format along the way.  Specifically, URLs are partitioned across the machines in the  cluster based on a hash of the URLs" host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer. The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores. The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit  integers. Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster. Since over 80% of all  hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation. The second phase performs the actual PageRank power iteration. Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory. We represent PageRank scores as 64-bit floating point  numbers. PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection. We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph. We used a damping factor of 0.15, and performed 200 power iterations. Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. .07 .08 .09 .10 .11  10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id .01 .02 .03 .04  10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id .07 .08 .09 .10 .11 .12 .13 .14  10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS. A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log. As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs. These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. . HITS HITS, unlike PageRank, is a query-dependent ranking  algorithm. HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First,  hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence. Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain  topically relevant links. But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous. For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set. Moreover,  Kleinberg suggests considering only links that cross host  boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant. Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B. In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a  linkselection predicate. Given a set A, the notation Sn[A] draws n elements  uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u. So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links. The outlinked-set OP of the root set R w.r.t. a  linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t. P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s . For each node u in the neighborhood graph, HITS  computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages. This is done using the following algorithm: . For all u ∈ B do H(u) := q  |B| , A(u) := q  |B| . . Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in  euclidean space, i.e. the squares of its elements sum up to 1. In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one  second) is a major engineering challenge. Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 .00 .05 .10 .15 .20 .25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 .00 .02 .04 .06 .08 .10 .12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 .00 .05 .10 .15 .20 .25 .30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques. In order to experiment with HITS and other  query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short. SHS is a special-purpose database,  distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges. On our  hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS). The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request. We implemented the HITS algorithm using the SHS  infrastructure. We compiled three SHS databases, one  containing all 17.6 billion links in our web graph (all), one  containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id). We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to  determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts  belonging to the same domain). Using each of these databases, we computed HITS authority and hub scores for various  parameterizations of the sampling operator S, sampling  between 1 and 100 back-links of each page in the root set. Result URLs that were not covered by our web graph  automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements. We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value. For each combination, we loaded one of the three databases into an SHS system  running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time. The longest-running combination (using the all database and sampling 100 back-links of each root set  vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. . EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q). Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set. We are specifically interested in evaluating the  usefulness of HITS and other link-based features. In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs. We call this ranking with isolated features. Let us first examine the relative performance of the  different parameterizations of the HITS algorithm we  examined. Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100. Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores. Each graph is  associated with one performance measure. The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the  appropriate measure, and each curve depicts a link selection scheme. The id scheme slightly outperforms ih, and both vastly  outperform the all scheme - eliminating nepotistic links pays off. The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines,  depending on the performance measure. Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other  isolated features: PageRank, in-degree and out-degree  counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24]. BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated  anchor texts. BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text. This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24]. BM25F has a number of free  parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 .22 .24 .26 .28 .30 .32 .34 .36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 .09 .10 .11 .12 .13 .14 .15 .16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 .25 .30 .35 .40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F. Figure 2 shows the NDCG, MRR, and MAP measures of these features. Again all performance measures (and for all rank-thresholds we explored) agree. As expected, BM25F outperforms all link-based features by a large  margin. The link-based features are divided into two groups, with a noticeable performance drop between the groups. The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links  (outdegree and HITS hub scores). In the group of features based on incoming links, features that ignore nepotistic links  perform better than their counterparts using all links.  Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links. The fact that features based on outgoing links  underperform those based on incoming links matches our  expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all. On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising. A possible  explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set. Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores. However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons. First, features based on the textual  content of documents (as opposed to link-based features) are the best predictors of relevance. Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and  numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches. Therefore, one must consider the effect of link-based  features in combination with textual features. Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance. For this reason, we have studied the combination of the link-based features above with BM25F. All feature  combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or  documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned. We chose transform functions that we empirically determined to be well-suited. Table 1 shows the chosen transform functions. This type of linear combination is appropriate if we  assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8]. We tuned the weights by selecting a random  subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the  remaining 23,043 queries to measure the performance of the thus derived scoring functions. We explored the pairwise combination of BM25F with  every link-based scoring function. Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the  feature combinations. Regardless of the performance measure applied, we can make the following general observations: . Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. . The combination of BM25F with features based on  incoming links (PageRank, in-degree, and HITS  authority scores) performs substantially better than the  combination with features based on outgoing links (HITS hub scores and out-degree). . The performance differences between the various  combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the  .00 .02 .04 .06 .08 .10 .12 .14  2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 6 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected  isolated features, broken down by query specificity. ferent performance measures used. However, the  combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster. Finally, we investigated whether certain features are  better for some queries than for others. Particularly, we are  interested in the relationship between the specificity of a query and the performance of different ranking features. The most straightforward measure of the specificity of a query Q would be the number of documents in a search engine"s corpus that satisfy Q. Unfortunately, the query set available to us did not contain this information. Therefore, we chose to  approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms  comprising Q. The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed)  assumption that the individual query terms are independent of each other. However, while not perfect, this approximation is at least directionally correct. We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we  computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket. In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F. Figure 4 shows the MAP@10 for all 13 query specificity buckets. Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries. The figures on the  upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries). BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14). By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. . CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the  effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text  retrieval algorithm exploiting anchor text (BM25F).  Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of  effectiveness: NDCG, MRR, and MAP. Evaluating link-based features in isolation, we found that web page in-degree  outperforms PageRank, and is about as effwective as HITS  authority scores. HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering. A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between  combining BM25F with a feature based on incoming links  (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little. We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes. There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road. Future work includes evaluation of different parameterizations of PageRank and HITS. In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the  impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not. Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA. Finally, we are planning to experiment with more complex feature combinations. . REFERENCES [1] B. Amento, L. Terveen, and W. Hill. Does authority mean quality? Predicting expert quality ratings of web documents. In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 96-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli. Inside PageRank. ACM Transactions on Internet Technology, (1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal. Finding authorities and hubs from link structures on the World Wide Web. In Proc. of the 10th International World Wide Web Conference, pages 15-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas. Link analysis ranking: algorithms, theory, and experiments. ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page. The anatomy of a large-scale hypertextual Web search engine. Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proc. of the 22nd International Conference on Machine Learning, pages 9-96, New York, NY, USA, 2005. ACM Press. [7] D. Cohn and H. Chang. Learning to probabilistically identify authoritative documents. In Proc. of the 17th International Conference on Machine Learning, pages 67-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor. Relevance weighting for query independent evidence. In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 005. [9] E. Garfield. Citation analysis as a tool in journal evaluation. Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina. Web spam taxonomy. In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with TrustRank. In Proc. of the 0th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic. Real life information retrieval: a study of user queries on the web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub. Extrapolation methods for accelerating PageRank computations. In Proc. of the 12th International World Wide Web Conference, pages 61-270, 2003. [15] M. M. Kessler. Bibliographic coupling between scientific papers. American Documentation, 4(1):10-25, 1963. [16] J. M. Kleinberg. Authoritative sources in a hyperlinked environment. In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 68-677, 1998. [17] J. M. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 6(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer. Deeper inside PageRank. Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran. The stochastic approach for link-structure analysis (SALSA) and the TKC effect. Computer Networks and ISDN Systems, 3(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan. Stable algorithms for link analysis. In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the web. Technical report, Stanford Digital Library Technologies Project, 1998. [22] J. A. Tomlin. A new paradigm for ranking pages on the World Wide Web. In Proc. of the 12th International World Wide Web Conference, pages 50-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking. Predicting fame and fortune: Pagerank or indegree? In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson. Microsoft Cambridge at TREC-13: Web and HARD tracks. In Proc. of the 13th Text Retrieval Conference, 2004.
HITS Hits  TRECExploring IR Evaluation Results with Network Analysis Stefano Mizzaro Dept. of Mathematics and Computer Science University of Udine Via delle Scienze, 206 - 33100 Udine, Italy mizzaro@dimi.uniud.it Stephen Robertson Microsoft Research  JJ Thomson Avenue Cambridge CB3 0FB, UK ser@microsoft.com ABSTRACT We propose a novel method of analysing data gathered from TREC or similar information retrieval evaluation  experiments. We define two normalized versions of average  precision, that we use to construct a weighted bipartite graph of TREC systems and topics. We analyze the meaning of well known - and somewhat generalized - indicators from social network analysis on the Systems-Topics graph. We apply this method to an analysis of TREC 8 data; among the results, we find that authority measures systems  performance, that hubness of topics reveals that some topics are better than others at distinguishing more or less effective systems, that with current measures a system that wants to be effective in TREC needs to be effective on easy topics, and that by using different effectiveness measures this is no longer the case. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Measurement, Experimentation . INTRODUCTION Evaluation is a primary concern in the Information  Retrieval (IR) field. TREC (Text REtrieval Conference) [12, 5] is an annual benchmarking exercise that has become a de facto standard in IR evaluation: before the actual  conference, TREC provides to participants a collection of  documents and a set of topics (representations of information needs). Participants use their systems to retrieve, and  submit to TREC, a list of documents for each topic. After the lists have been submitted and pooled, the TREC organizers employ human assessors to provide relevance judgements on the pooled set. This defines a set of relevant documents for each topic. System effectiveness is then measured by well  established metrics (Mean Average Precision being the most used). Other conferences such as NTCIR, INEX, CLEF  provide comparable data. Network analysis is a discipline that studies features and properties of (usually large) networks, or graphs. Of  particular importance is Social Network Analysis [16], that studies networks made up by links among humans (friendship,  acquaintance, co-authorship, bibliographic citation, etc.). Network analysis and IR fruitfully meet in Web Search Engine implementation, as is already described in textbooks [3,6]. Current search engines use link analysis techniques to help rank the retrieved documents. Some indicators (and the corresponding algorithms that compute them) have been found useful in this respect, and are nowadays well known: Inlinks (the number of links to a Web page), PageRank [7], and HITS (Hyperlink-Induced Topic Search) [5]. Several extensions to these algorithms have been and are being  proposed. These indicators and algorithms might be quite  general in nature, and can be used for applications which are very different from search result ranking. One example is using HITS for stemming, as described by Agosti et al. [1]. In this paper, we propose and demonstrate a method for constructing a network, specifically a weighted complete bidirectional directed bipartite graph, on a set of TREC  topics and participating systems. Links represent effectiveness measurements on system-topic pairs. We then apply  analysis methods originally developed for search applications to the resulting network. This reveals phenomena previously hidden in TREC data. In passing, we also provide a small generalization to Kleinberg"s HITS algorithm, as well as to Inlinks and PageRank. The paper is organized as follows: Sect. 2 gives some  motivations for the work. Sect. 3 presents the basic ideas of normalizing average precision and of constructing a  systemstopics graph, whose properties are analyzed in Sect. 4; Sect. 5 presents some experiments on TREC 8 data; Sect. 6  discusses some issues and Sect. 7 closes the paper. . MOTIVATIONS We are interested in the following hypotheses: . Some systems are more effective than others; t1 · · · tn MAP s1 AP(s1, t1) · · · AP(s1, tn) MAP(s1) ... ... ... sm AP(sm, t1) · · · AP(sm, tn) MAP(sm) AAP AAP(t1) · · · AAP(tn) (a) t1 t2 · · · MAP s1 0.5 0.4 · · · 0.6 s2 0.4 · · · · · · 0.3 ... ... ... ... AAP 0.6 0.3 · · · (b) Table 1: AP, MAP and AAP . Some topics are easier than others; . Some systems are better than others at distinguishing easy and difficult topics; . Some topics are better than others at distinguishing more or less effective systems. The first of these hypotheses needs no further justification - every reported significant difference between any two  systems supports it. There is now also quite a lot of evidence for the second, centered on the TREC Robust Track [14]. Our primary interest is in the third and fourth. The third might be regarded as being of purely academic interest;  however, the fourth has the potential for being of major  practical importance in evaluation studies. If we could identify a relatively small number of topics which were really good at distinguishing effective and ineffective systems, we could save considerable effort in evaluating systems. One possible direction from this point would be to attempt direct identification of such small sets of topics. However, in the present paper, we seek instead to explore the  relationships suggested by the hypotheses, between what different topics tell us about systems and what different systems tell us about topics. We seek methods of building and analysing a matrix of system-topic normalised performances, with a view to giving insight into the issue and confirming or  refuting the third and fourth hypotheses. It turns out that the obvious symmetry implied by the above formulation of the hypotheses is a property worth investigating, and the investigation does indeed give us valuable insights. . THE IDEA .1 1st step: average precision table From TREC results, one can produce an Average  Precision (AP) table (see Tab. 1a): each AP(si, tj) value  measures the AP of system si on topic tj. Besides AP values, the table shows Mean Average  Precision (MAP) values i.e., the mean of the AP values for a single system over all topics, and what we call Average  Average Precision (AAP) values i.e., the average of the AP values for a single topic over all systems: MAP(si) =  n nX j=1 AP(si, tj), (1) AAP(tj) =  m mX i=1 AP(si, tj). (2) MAPs are indicators of systems performance: higher MAP means good system. AAP are indicators of the performance on a topic: higher AAP means easy topic - a topic on which all or most systems have good performance. .2 Critique of pure AP MAP is a standard, well known, and widely used IR  effectiveness measure. Single AP values are used too (e.g., in AP histograms). Topic difficulty is often discussed (e.g., in TREC Robust track [14]), although AAP values are not used and, to the best of our knowledge, have never been proposed (the median, not the average, of AP on a topic is used to produce TREC AP histograms [11]). However, the AP values in Tab. 1 present two limitations, which are symmetric in some respect: • Problem 1. They are not reliable to compare the effectiveness of a system on different topics, relative to the other systems. If, for example, AP(s1, t1) > AP(s1, t2), can we infer that s1 is a good system (i.e., has a good performance) on t1 and a bad system on t2? The answer is no: t1 might be an easy topic (with high AAP) and t2 a difficult one (low AAP). See an example in Tab. 1b: s1 is outperformed (on average) by the other systems on t1, and it outperforms the other systems on t2. • Problem 2. Conversely, if, for example, AP(s1, t1) > AP(s2, t1), can we infer that t1 is considered easier by s1 than by s2? No, we cannot: s1 might be a good system (with high MAP) and s2 a bad one (low MAP); see an example in Tab. 1b. These two problems are a sort of breakdown of the well known high influence of topics on IR evaluation; again, our formulation makes explicit the topics / systems symmetry. .3 2nd step: normalizations To avoid these two problems, we can normalize the AP table in two ways. The first normalization removes the  influence of the single topic ease on system performance. Each AP(si, tj) value in the table depends on both system  goodness and topic ease (the value will increase if a system is good and/or the topic is easy). By subtracting from each AP(si, tj) the AAP(tj) value, we obtain normalized AP values (APA(si, tj), Normalized AP according to AAP): APA(si, tj) = AP(si, tj) − AAP(tj), (3) that depend on system performance only (the value will  increase only if system performance is good). See Tab. 2a. The second normalization removes the influence of the  single system effectiveness on topic ease: by subtracting from each AP(si, tj) the MAP(si) value, we obtain normalized AP values (APM(si, tj), Normalized AP according to MAP): APM(si, tj) = AP(si, tj) − MAP(si), (4) that depend on topic ease only (the value will increase only if the topic is easy, i.e., all systems perform well on that topic). See Tab. 2b. In other words, APA avoids Problem 1: APA(s, t) values measure the performance of system s on topic t normalized t1 · · · tn MAP s1 APA(s1, t1) · · · APA(s1, tn) MAP(s1) ... ... ... sm APA(sm, t1) · · · APA(sm, tn) MAP(sm)  · · · 0 0 (a) t1 · · · tn s1 APM(s1, t1) · · · APM(s1, tn) 0 ... ... ... sm APM(sm, t1) · · · APM(sm, tn) 0 AAP AAP(t1) · · · AAP(tn) 0 (b) t1 t2 · · · MAP s1 −0.1 0.1 · · · . . . s2 0.2 · · · · · · . . . ... ... ...  0 · · · t1 t2 · · · s1 −0.1 −0.2 · · · 0 s2 0.1 · · · · · · 0 ... ... ... AAP . . . . . . · · · (c) (d) Table 2: Normalizations: APA and MAP: normalized AP (APA) and MAP (MAP) (a); normalized AP (APM) and AAP (AAP) (b); a numeric example (c) and (d) according to the ease of the topic (easy topics will not have higher APA values). Now, if, for example, APA(s1, t2) > APA(s1, t1), we can infer that s1 is a good system on t2 and a bad system on t1 (see Tab. 2c). Vice versa, APM avoids Problem 2: APM(s, t) values measure the ease of topic t according to system s, normalized according to goodness of the system (good systems will not lead to higher APM values). If, for example, APM(s2, t1) > APM(s1, t1), we can infer that t1 is considered easier by s2 than by s1 (see Tab. 2d). On the basis of Tables 2a and 2b, we can also define two new measures of system effectiveness and topic ease, i.e., a Normalized MAP (MAP), obtained by averaging the APA values on one row in Tab. 2a, and a Normalized AAP (AAP), obtained by averaging the APM values on one column in Tab. 2b: MAP(si) =  n nX j=1 APA(si, tj) (5) AAP(tj) =  m mX i=1 APM(si, tj). (6) Thus, overall system performance can be measured,  besides by means of MAP, also by means of MAP. Moreover, MAP is equivalent to MAP, as can be immediately proved by using Eqs. (5), (3), and (1): MAP(si) =  n nX j=1 (AP(si, tj) − AAP(tj)) = = MAP(si) −  n nX j=1 AAP(tj) (and 1 n Pn j=1 AAP(tj) is the same for all systems). And, conversely, overall topic ease can be measured, besides by t1 · · · tn s1 ... APM sm t1 · · · tn s1 ... APA sm s1 · · · sm t1 · · · tn s1 ... 0 APM 0 sm t1 ... APA T  0 tn MAP AAP 0 Figure 1: Construction of the adjacency matrix. APA T is the transpose of APA. means of AAP, also by means of AAP, and this is equivalent (the proof is analogous, and relies on Eqs. (6), (4), and (2)). The two Tables 2a and 2b are interesting per se, and can be analyzed in several different ways. In the following we propose an analysis based on network analysis techniques, mainly Kleinberg"s HITS algorithm. There is a little further discussion of these normalizations in Sect. 6. .4 3rd step: Systems-Topics Graph The two tables 2a and 2b can be merged into a single one with the procedure shown in Fig. 1. The obtained matrix can be interpreted as the adjacency matrix of a complete weighted bipartite graph, that we call Systems-Topics graph. Arcs and weights in the graph can be interpreted as follows: • (weight on) arc s → t: how much the system s thinks that the topic t is easy - assuming that a system has no knowledge of the other systems (or in other words, how easy we might think the topic is, knowing only the results for this one system). This corresponds to APM values, i.e., to normalized topic ease (Fig. 2a). • (weight on) arc s ← t: how much the topic t thinks that the system s is good - assuming that a topic has no knowledge of the other topics (or in other words, how good we might think the system is, knowing only the results for this one topic). This corresponds to APA (normalized system effectiveness, Fig. 2b). Figs. 2c and 2d show the Systems-Topics complete weighted bipartite graph, on a toy example with 4 systems and 2  topics; the graph is split in two parts to have an understandable graphical representation: arcs in Fig. 2c are labeled with APM values; arcs in Fig. 2d are labeled with APA values. . ANALYSIS OF THE GRAPH .1 Weighted Inlinks, Outlinks, PageRank The sum of weighted outlinks, i.e., the sum of the weights on the outgoing arcs from each node, is always zero: • The outlinks on each node corresponding to a system s (Fig. 2c) is the sum of all the corresponding APM values on one row of the matrix in Tab. 2b. • The outlinks on each node corresponding to a topic t (Fig. 2d) is the sum of all the corresponding APA (a) (b) (c) (d) Figure 2: The relationships between systems and topics (a) and (b); and the Systems-Topics graph for a toy example (c) and (d). Dashed arcs correspond to negative values. h (a) s1 ... sm t1 ... tn = s1 · · · sm t1 · · · tn s1 ... 0 APM (APA) sm t1 ... APA T  tn (APM T ) · a (h) s1 ... sm t1 ... tn Figure 3: Hub and Authority computation values on one row of the transpose of the matrix in Tab. 2a. The average1 of weighted inlinks is: • MAP for each node corresponding to a system s; this corresponds to the average of all the corresponding APA values on one column of the APA T part of the adjacency matrix (see Fig. 1). • AAP for each node corresponding to a topic t; this corresponds to the average of all the corresponding APM values on one column of the APM part of the adjacency matrix (see Fig. 1). Therefore, weighted inlinks measure either system  effectiveness or topic ease; weighted outlinks are not meaningful. We could also apply the PageRank algorithm to the network; the meaning of the PageRank of a node is not quite so  obvious as Inlinks and Outlinks, but it also seems a sensible measure of either system effectiveness or topic ease: if a  system is effective, it will have several incoming links with high  Usually, the sum of the weights on the incoming arcs to each node is used in place of the average; since the graph is complete, it makes no difference. weights (APA); if a topic is easy it will have high weights (APM) on the incoming links too. We will see experimental confirmation in the following. .2 Hubs and Authorities Let us now turn to more sophisticated indicators.  Kleinberg"s HITS algorithm defines, for a directed graph, two indicators: hubness and authority; we reiterate here some of the basic details of the HITS algorithm in order to  emphasize both the nature of our generalization and the  interpretation of the HITS concepts in this context. Usually, hubness and authority are defined as h(x) = P x→y a(y) and a(x) = P y→x h(y), and described intuitively as a good hub links many good authorities; a good authority is linked from many good hubs. As it is well known, an equivalent formulation in linear algebra terms is (see also Fig. 3): h = Aa and a = AT h (7) (where h is the hubness vector, with the hub values for all the nodes; a is the authority vector; A is the adjacency  matrix of the graph; and AT its transpose). Usually, A  contains 0s and 1s only, corresponding to presence and absence of unweighted directed arcs, but Eq. (7) can be immediately generalized to (in fact, it is already valid for) A containing any real value, i.e., to weighted graphs. Therefore we can have a generalized version (or rather a generalized interpretation, since the formulation is still the original one) of hubness and authority for all nodes in a graph. An intuitive formulation of this generalized HITS is still available, although slightly more complex: a good hub links, by means of arcs having high weights, many good authorities; a good authority is linked, by means of arcs  having high weights, from many good hubs. Since arc weights can be, in general, negative, hub and authority values can be negative, and one could speak of unhubness and unauthority; the intuitive formulation could be completed by adding that a good hub links good unauthorities by means of links with highly negative weights; a good authority is linked by good unhubs by means of links with highly negative weights. And, also, a good unhub links positively good  unauthorities and negatively good authorities; a good unauthority is linked positively from good unhubs and negatively from good hubs. Let us now apply generalized HITS to our Systems-Topics graph. We compute a(s), h(s), a(t), and h(t). Intuitively, we expect that a(s) is somehow similar to Inlinks, so it should be a measure of either systems effectiveness or topic ease. Similarly, hubness should be more similar to Outlinks, thus less meaningful, although the interplay between hub and authority might lead to the discovery of something  different. Let us start by remarking that authority of topics and hubness of systems depend only on each other; similarly hubness of topics and authority of systems depend only on each other: see Figs. 2c, 2d and 3. Thus the two graphs in Figs. 2c and 2d can be analyzed independently. In fact the entire HITS analysis could be done in one direction only, with just APM(s, t) values or alternatively with just APA(s, t). As discussed below,  probably most interest resides in the hubness of topics and the authority of systems, so the latter makes sense. However, in this paper, we pursue both analyses together, because the symmetry itself is interesting. Considering Fig. 2c we can state that: • Authority a(t) of a topic node t increases when: - if h(si) > 0, APM(si, t) increases (or if APM(si, t) > 0, h(si) increases); - if h(si) < 0, APM(si, t) decreases (or if APM(si, t) < 0, h(si) decreases). • Hubness h(s) of a system node s increases when: - if a(tj) > 0, APM(s, tj) increases (or, if APM(s, tj) > 0, a(tj) increases); - if a(tj) < 0, APM(s, tj) decreases (or, if APM(s, tj) < 0, a(tj) decreases). We can summarize this as: a(t) is high if APM(s, t) is high for those systems with high h(s); h(s) is high if APM(s, t) is high for those topics with high a(t). Intuitively, authority a(t) of a topic measures topic ease; hubness h(s) of a system measures system"s capability to recognize easy topics. A system with high unhubness (negative hubness) would tend to regard easy topics as hard and hard ones as easy. The situation for Fig. 2d, i.e., for a(s) and h(t), is  analogous. Authority a(s) of a system node s measures system effectiveness: it increases with the weight on the arc (i.e., APA(s, tj)) and the hubness of the incoming topic nodes tj. Hubness h(t) of a topic node t measures topic capability to recognize effective systems: if h(t) > 0, it increases further if APA(s, tj) increases; if h(t) < 0, it increases if APA(s, tj) decreases. Intuitively, we can state that A system has a higher  authority if it is more effective on topics with high hubness; and A topic has a higher hubness if it is easier for those systems which are more effective in general. Conversely for system hubness and topic authority: A topic has a higher authority if it is easier on systems with high hubness; and A system has a higher hubness if it is more effective for those topics which are easier in general. Therefore, for each system we have two indicators:  authority (a(s)), measuring system effectiveness, and hubness (h(s)), measuring system capability to estimate topic ease. And for each topic, we have two indicators: authority (a(t)), measuring topic ease, and hubness (h(t)), measuring topic capability to estimate systems effectiveness. We can define them formally as a(s) = X t h(t) · APA(s, t), h(t) = X s a(s) · APA(s, t), a(t) = X s h(s) · APM(s, t), h(s) = X t a(t) · APM(s, t). We observe that the hubness of topics may be of particular interest for evaluation studies. It may be that we can  evaluate the effectiveness of systems efficiently by using relatively few high-hubness topics. . EXPERIMENTS We now turn to discuss if these indicators are meaningful and useful in practice, and how they correlate with standard measures used in TREC. We have built the Systems-Topics graph for TREC 8 data (featuring 1282 systems - actually,  Actually, TREC 8 data features 129 systems; due to some bug in our scripts, we did not include one system (8manexT3D1N0), but the results should not be affected.  .1 .2 .3 -1 -0.5 0 0.5 1 NAPM NAPA AP Figure 4: Distributions of AP, APA, and APM values in TREC 8 data MAP In PR H A MAP 1 1.0 1.0 .80 .99 Inlinks 1 1.0 .80 .99 PageRank 1 .80 .99 Hub 1 .87 (a) AAP In PR H A AAP 1 1.0 1.0 .92 1.0 Inlinks 1 1.0 .92 1.0 PageRank 1 .92 1.0 Hub 1 .93 (b) Table 3: Correlations between network analysis measures and MAP (a) and AAP (b) runs - on 50 topics). This section illustrates the results  obtained mining these data according to the method presented in previous sections. Fig. 4 shows the distributions of AP, APA, and APM: whereas AP is very skewed, both APA and APM are much more symmetric (as it should be, since they are constructed by subtracting the mean). Tables 3a and 3b show the  Pearson"s correlation values between Inlinks, PageRank, Hub, Authority and, respectively, MAP or AAP (Outlinks  values are not shown since they are always zero, as seen in Sect. 4). As expected, Inlinks and PageRank have a perfect correlation with MAP and AAP. Authority has a very high correlation too with MAP and AAP; Hub assumes slightly lower values. Let us analyze the correlations more in detail. The  correlations chart in Figs. 5a and 5b demonstrate the high  correlation between Authority and MAP or AAP. Hubness presents interesting phenomena: both Fig. 5c (correlation with MAP) and Fig. 5d (correlation with AAP) show that correlation is not exact, but neither is it random. This, given the meaning of hubness (capability in estimating topic ease and system effectiveness), means two things: (i) more  effective systems are better at estimating topic ease; and (ii) easier topics are better at estimating system effectiveness. Whereas the first statement is fine (there is nothing against it), the second is a bit worrying. It means that system  effectiveness in TREC is affected more by easy topics than by difficult topics, which is rather undesirable for quite obvious reasons: a system capable of performing well on a difficult topic, i.e., on a topic on which the other systems perform badly, would be an important result for IR effectiveness;  con-8E-5 -6E-5 -4E-5 -2E-5 E+0 E-5 E-5 E-5 .0 0.1 0.2 0.3 0.4 0.5 -3E-1 -2E-1 -1E-1 E+0 E-1 E-1 E-1 E-1 E-1 .0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 (a) (b) E+0 E-2 E-2 E-2 E-2 E-1 E-1 E-1 .0 0.1 0.2 0.3 0.4 0.5 E+0 E-5 E-5 E-5 E-5 E-5 E-5 E-5 .0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 (c) (d) Figure 5: Correlations: MAP (x axis) and authority (y axis) of systems (a); AAP and authority of topics (b); MAP and hub of systems (c) and AAP and hub of topics (d) versely, a system capable of performing well on easy topics is just a confirmation of the state of the art. Indeed, the  correlation between hubness and AAP (statement (i) above) is higher than the correlation between hubness and MAP  (corresponding to statement (ii)): 0.92 vs. 0.80. However, this phenomenon is quite strong. This is also confirmed by the work being done on the TREC Robust Track [14]. In this respect, it is interesting to see what happens if we use a different measure from MAP (and AAP). The GMAP (Geometric MAP) metric is defined as the geometric mean of AP values, or equivalently as the arithmetic mean of the  logarithms of AP values [8]. GMAP has the property of giving more weight to the low end of the AP scale (i.e., to low AP values), and this seems reasonable, since, intuitively, a  performance increase in MAP values from 0.01 to 0.02 should be more important than an increase from 0.81 to 0.82. To use GMAP in place of MAP and AAP, we only need to take the logarithms of initial AP values, i.e., those in Tab. 1a (zero values are modified into ε = 0.00001). We then repeat the same normalization process (with GMAP and GAAP - Geometric AAP - replacing MAP and AAP): whereas authority values still perfectly correlate with GMAP (0.99) and GAAP (1.00), the correlation with hubness largely  disappears (values are −0.16 and −0.09 - slightly negative but not enough to concern us). This is yet another confirmation that TREC effectiveness as measured by MAP depends mainly on easy topics; GMAP appears to be a more balanced measure. Note that,  perhaps surprisingly, GMAP is indeed fairly well balanced, not biased in the opposite direction - that is, it does not  overemphasize the difficult topics. In Sect. 6.3 below, we discuss another transformation,  replacing the log function used in GMAP with logit. This has a similar effect: the correlation of mean logitAP and average logitAP with hubness are now small positive numbers (0.23 and 0.15 respectively), still comfortably away from the high correlations with regular MAP and AAP, i.e., not presenting the problematic phenomenon (ii) above (over-dependency on easy topics). We also observe that hub values are positive, whereas  authority assumes, as predicted, both positive and negative values. An intuitive justification is that negative hubness would indicate a node which disagrees with the other nodes, e.g., a system which does better on difficult topics, or a topic on which bad systems do better; such systems and topics would be quite strange, and probably do not appear in TREC. Finally, although one might think that topics with several relevant documents are more important and difficult, this is not the case: there is no correlation between hub (or any other indicator) and the number of documents relevant to a topic. . DISCUSSION .1 Related work There has been considerable interest in recent years in questions of statistical significance of effectiveness  comparisons between systems (e.g. [2, 9]), and related questions of how many topics might be needed to establish differences (e.g. [13]). We regard some results of the present study as in some way complementary to this work, in that we make a step towards answering the question Which topics are best for establishing differences?. The results on evaluation without relevance judgements such as [10] show that, to some extent, good systems agree on which are the good documents. We have not addressed the question of individual documents in the present analysis, but this effect is certainly analogous to our results. .2 Are normalizations necessary? At this point it is also worthwhile to analyze what would happen without the MAP- and AAP-normalizations defined in Sect. 3.3. Indeed, the process of graph construction (Sect. 3.4) is still valid: both the APM and APA matrices are replaced by the AP one, and then everything goes on as above. Therefore, one might think that the normalizations are unuseful in this setting. This is not the case. From the theoretical point of view, the AP-only graph does not present the interesting  properties above discussed: since the AP-only graph is  symmetrical (the weight on each incoming link is equal to the weight on the corresponding outgoing link), Inlinks and Outlinks assume the same values. There is symmetry also in  computing hub and authority, that assume the same value for each node since the weights on the incoming and outgoing arcs are the same. This could be stated in more precise and  formal terms, but one might still wonder if on the overall graph there are some sort of counterbalancing effects. It is  therefore easier to look at experimental data, which confirm that the normalizations are needed: the correlations between AP, Inlinks, Outlinks, Hub, and/or Authority are all very close to one (none of them is below 0.98). .3 Are these normalizations sufficient? It might be argued that (in the case of APA, for example) the amount we have subtracted from each AP value is  topicdependent, therefore the range of the resulting APA value is also topic-dependent (e.g. the maximum is 1 − AAP(tj) and the minimum is − AAP(tj)). This suggests that the cross-topic comparisons of these values suggested in Sect. 3.3 may not be reliable. A similar issue arises for APM and comparisons across systems. One possible way to overcome this would be to use an unconstrained measure whose range is the full real line. Note that in applying the method to GMAP by using log AP, we avoid the problem with the lower limit but retain it for the upper limit. One way to achieve an unconstrainted range would be to use the logit function rather than the log [4,8]. We have also run this variant (as already reported in Sect. 5 above), and it appears to provide very similar  results to the GMAP results already given. This is not  surprising, since in practice the two functions are very similar over most of the operative range. The normalizations thus seem reliable. .4 On AAT and AT A It is well known that h and a vectors are the principal left eigenvectors of AAT and AT A, respectively (this can be easily derived from Eqs. (7)), and that, in the case of  citation graphs, AAT and AT A represent, respectively,  bibliographic coupling and co-citations. What is the meaning, if any, of AAT and AT A in our Systems-Topics graph? It is easy to derive that: AAT [i, j] =  >< >:   if i ∈ S ∧ j ∈ T or i ∈ T ∧ j ∈ S P k A[i, k] · A[j, k] otherwise AT A[i, j] =  >< >:   if i ∈ S ∧ j ∈ T or i ∈ T ∧ j ∈ S P k A[k, i] · A[k, j] otherwise (where S is the set of indices corresponding to systems and T the set of indices corresponding to topics). Thus AAT and AT A are block diagonal matrices, with two blocks each, one relative to systems and one relative to topics: (a) if i, j ∈ S, then AAT [i, j] = P k∈T APM(i, k)·APM(j, k) measures how much the two systems i and j agree in estimating topics ease (APM): high values mean that the two systems agree on topics ease. (b) if i, j ∈ T, then AAT [i, j] = P k∈S APA(k, i)·APA(k, j) measures how much the two topics i and j agree in  estimating systems effectiveness (APA): high values mean that the two topics agree on systems effectiveness (and that TREC results would not change by leaving out one of the two topics). (c) if i, j ∈ S, then AT A[i, j] = P k∈T APA(i, k) · APA(j, k) measures how much agreement on the effectiveness of two systems i and j there is over all topics: high  values mean that many topics quite agree on the two  systems effectiveness; low values single out systems that are somehow controversial, and that need several topics to have a correct effectiveness assessment. (d) if i, j ∈ T, then AT A[i, j] = P k∈S APM(k, i)·APM(k, j) measures how much agreement on the ease of the two topics i and j there is over all systems: high values mean that many systems quite agree on the two topics ease. Therefore, these matrices are meaningful and somehow interesting. For instance, the submatrix (b) corresponds to a weighted undirected complete graph, whose nodes are the topics and whose arc weights are a measure of how much two topics agree on systems effectiveness. Two topics that are very close on this graph give the same information, and therefore one of them could be discarded without changes in TREC results. It would be interesting to cluster the topics on this graph. Furthermore, the matrix/graph (a) could be useful in TREC pool formation: systems that do not agree on topic ease would probably find different relevant  documents, and should therefore be complementary in pool  formation. Note that no notion of single documents is involved in the above analysis. .5 Insights As indicated, the primary contribution of this paper has been a method of analysis. However, in the course of  applying this method to one set of TREC results, we have achieved some insights relating to the hypotheses formulated in Sect. 2: • We confirm Hypothesis 2 above, that some topics are easier than others. • Differences in the hubness of systems reveal that some systems are better than others at distinguishing easy and difficult topics; thus we have some confirmation of Hypothesis 3. • There are some relatively idiosyncratic systems which do badly on some topics generally considered easy but well on some hard topics. However, on the whole, the more effective systems are better at distinguishing easy and difficult topics. This is to be expected: a really bad system will do badly on everything, while even a good system may have difficulty with some topics. • Differences in the hubness of topics reveal that some topics are better than others at distinguising more or less effective systems; thus we have some confirmation of Hypothesis 4. • If we use MAP as the measure of effectiveness, it is also true that the easiest topics are better at  distinguishing more or less effective systems. As argued in Sect. 5, this is an undesirable property. GMAP is more balanced. Clearly these ideas need to be tested on other data sets. However, they reveal that the method of analysis proposed in this paper can provide valuable information. .6 Selecting topics The confirmation of Hypothesis 4 leads, as indicated, to the idea that we could do reliable system evaluation on a much smaller set of topics, provided we could select such an appropriate set. This selection may not be straightforward, however. It is possible that simply selecting the high  hubness topics will achieve this end; however, it is also possible that there are significant interactions between topics which would render such a simple rule ineffective. This  investigation would therefore require serious experimentation. For this reason we have not attempted in this paper to point to the specific high hubness topics as being good for evaluation. This is left for future work. . CONCLUSIONS AND FUTURE DEVELOPMENTS The contribution of this paper is threefold: • we propose a novel way of normalizing AP values; • we propose a novel method to analyse TREC data; • the method applied on TREC data does indeed reveal some hidden properties. More particularly, we propose Average Average Precision (AAP), a measure of topic ease, and a novel way of  normalizing the average precision measure in TREC, on the basis of both MAP (Mean Average Precision) and AAP. The normalized measures (APM and APA) are used to build a bipartite weighted Systems-Topics graph, that is then  analyzed by means of network analysis indicators widely known in the (social) network analysis field, but somewhat  generalised. We note that no such approach to TREC data analysis has been proposed so far. The analysis shows that, with current measures, a system that wants to be effective in TREC needs to be effective on easy topics. Also, it is  suggested that a cluster analysis on topic similarity can lead to relying on a lower number of topics. Our method of analysis, as described in this paper, can be applied only a posteriori, i.e., once we have all the  topics and all the systems available. Adding (removing) a new system / topic would mean re-computing hubness and  authority indicators. Moreover, we are not explicitly proposing a change to current TREC methodology, although this could be a by-product of these - and further - analyses. This is an initial work, and further analyses could be  performed. For instance, other effectiveness metrics could be used, in place of AP. Other centrality indicators, widely used in social network analysis, could be computed, although probably with similar results to PageRank. It would be  interesting to compute the higher-order eigenvectors of AT A and AAT . The same kind of analysis could be performed at the document level, measuring document ease. Hopefully, further analyses of the graph defined in this paper,  according to the approach described, can be insightful for a better understanding of TREC or similar data. Acknowledgments We would like to thank Nick Craswell for insightful  discussions and the anonymous referees for useful remarks. Part of this research has been carried on while the first author was visiting Microsoft Research Cambridge, whose financial support is acknowledged. . REFERENCES [1] M. Agosti, M. Bacchin, N. Ferro, and M. Melucci. Improving the automatic retrieval of text documents. In Proceedings of the 3rd CLEF Workshop, volume 785 of LNCS, pages 279-290, 2003. [2] C. Buckley and E. Voorhees. Evaluating evaluation measure stability. In 23rd SIGIR, pages 33-40, 2000. [3] S. Chakrabarti. Mining the Web. Morgan Kaufmann, 003. [4] G. V. Cormack and T. R. Lynam. Statistical precision of information retrieval evaluation. In 29th SIGIR, pages 533-540, 2006. [5] J. Kleinberg. Authoritative sources in a hyperlinked environment. J. of the ACM, 46(5):604-632, 1999. [6] M. Levene. An Introduction to Search Engines and Web Navigation. Addison Wesley, 2006. [7] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank Citation Ranking: Bringing Order to the Web, 1998. http://dbpubs.stanford.edu:8090/pub/1999-66. [8] S. Robertson. On GMAP - and other transformations. In 13th CIKM, pages 78-83, 2006. [9] M. Sanderson and J. Zobel. Information retrieval system evaluation: effort, sensitivity, and reliability. In 8th SIGIR, pages 162-169, 2005. http://doi.acm.org/10.1145/1076034.1076064. [10] I. Soboroff, C. Nicholas, and P. Cahan. Ranking retrieval systems without relevance judgments. In 24th SIGIR, pages 66-73, 2001. [11] TREC Common Evaluation Measures, 2005. http://trec.nist.gov/pubs/trec14/appendices/ CE.MEASURES05.pdf (Last visit: Jan. 2007). [12] Text REtrieval Conference (TREC). http://trec.nist.gov/ (Last visit: Jan. 2007). [13] E. Voorhees and C. Buckley. The effect of topic set size on retrieval experiment error. In 25th SIGIR, pages 316-323, 2002. [14] E. M. Voorhees. Overview of the TREC 2005 Robust Retrieval Track. In TREC 2005 Proceedings, 2005. [15] E. M. Voorhees and D. K. Harman.  TRECExperiment and Evaluation in Information Retrieval. MIT Press, 2005. [16] S. Wasserman and K. Faust. Social Network Analysis. Cambridge University Press, Cambridge, UK, 1994.
Combining Content and Link for Classification using Matrix Factorization Shenghuo Zhu Kai Yu Yun Chi Yihong Gong {zsh,kyu,ychi,ygong}@sv.nec-labs.com NEC Laboratories America, Inc. 0080 North Wolfe Road SW3-350 Cupertino, CA 95014, USA ABSTRACT The world wide web contains rich textual contents that are  interconnected via complex hyperlinks. This huge database violates the  assumption held by most of conventional statistical methods that each web page is considered as an independent and identical sample. It is thus difficult to apply traditional mining or learning methods for solving web mining problems, e.g., web page classification, by  exploiting both the content and the link structure. The research in this direction has recently received considerable attention but are still in an early stage. Though a few methods exploit both the link  structure or the content information, some of them combine the only authority information with the content information, and the others first decompose the link structure into hub and authority features, then apply them as additional document features. Being practically attractive for its great simplicity, this paper aims to design an  algorithm that exploits both the content and linkage information, by  carrying out a joint factorization on both the linkage adjacency matrix and the document-term matrix, and derives a new representation for web pages in a low-dimensional factor space, without explicitly separating them as content, hub or authority factors. Further  analysis can be performed based on the compact representation of web pages. In the experiments, the proposed method is compared with state-of-the-art methods and demonstrates an excellent accuracy in hypertext classification on the WebKB and Cora benchmarks. Categories and Subject Descriptors: H.3.3 [Information  Systems]: Information Search and Retrieval General Terms: Algorithms, Experimentation . INTRODUCTION With the advance of the World Wide Web, more and more  hypertext documents become available on the Web. Some examples of such data include organizational and personal web pages (e.g, the WebKB benchmark data set, which contains university web pages), research papers (e.g., data in CiteSeer), online news articles, and customer-generated media (e.g., blogs). Comparing to data in  traditional information management, in addition to content, these data on the Web also contain links: e.g., hyperlinks from a student"s homepage pointing to the homepage of her advisor, paper citations, sources of a news article, comments of one blogger on posts from another blogger, and so on. Performing information management tasks on such structured data raises many new research challenges. In the following discussion, we use the task of web page  classification as an illustrating example, while the techniques we develop in later sections are applicable equally well to many other tasks in information retrieval and data mining. For the classification problem of web pages, a simple approach is to treat web pages as independent documents. The advantage of this approach is that many off-the-shelf classification tools can be directly applied to the problem. However, this approach  relies only on the content of web pages and ignores the structure of links among them. Link structures provide invaluable information about properties of the documents as well as relationships among them. For example, in the WebKB dataset, the link structure  provides additional insights about the relationship among documents (e.g., links often pointing from a student to her advisor or from a faculty member to his projects). Since some links among these documents imply the inter-dependence among the documents, the usual i.i.d. (independent and identical distributed) assumption of documents does not hold any more. From this point of view, the traditional classification methods that ignore the link structure may not be suitable. On the other hand, a few studies, for example [25], rely solely on link structures. It is however a very rare case that content  information can be ignorable. For example, in the Cora dataset, the content of a research article abstract largely determines the category of the article. To improve the performance of web page classification,  therefore, both link structure and content information should be taken into consideration. To achieve this goal, a simple approach is to convert one type of information to the other. For example, in spam blog classification, Kolari et al. [13] concatenate outlink features with the content features of the blog. In document classification, Kurland and Lee [14] convert content similarity among documents into weights of links. However, link and content information have different properties. For example, a link is an actual piece of  evidence that represents an asymmetric relationship whereas the  content similarity is usually defined conceptually for every pair of  documents in a symmetric way. Therefore, directly converting one type of information to the other usually degrades the quality of  information. On the other hand, there exist some studies, as we will discuss in detail in related work, that consider link information and content information separately and then combine them. We argue that such an approach ignores the inherent consistency between link and  content information and therefore fails to combine the two seamlessly. Some work, such as [3], incorporates link information using  cocitation similarity, but this may not fully capture the global link structure. In Figure 1, for example, web pages v6 and v7 co-cite web page v8, implying that v6 and v7 are similar to each other. In turns, v4 and v5 should be similar to each other, since v4 and v5 cite similar web pages v6 and v7, respectively. But using  cocitation similarity, the similarity between v4 and v5 is zero without considering other information. v1 v2 v3 v4 v5 v6 v7 v8 Figure 1: An example of link structure In this paper, we propose a simple technique for analyzing inter-connected documents, such as web pages, using factor  analysis[18]. In the proposed technique, both content information and link structures are seamlessly combined through a single set of  latent factors. Our model contains two components. The first  component captures the content information. This component has a form similar to that of the latent topics in the Latent Semantic Indexing (LSI) [8] in traditional information retrieval. That is, documents are decomposed into latent topics/factors, which in turn are  represented as term vectors. The second component captures the  information contained in the underlying link structure, such as links from homepages of students to those of faculty members. A  factor can be loosely considered as a type of documents (e.g., those homepages belonging to students). It is worth noting that we do not explicitly define the semantic of a factor a priori. Instead,  similar to LSI, the factors are learned from the data. Traditional factor analysis models the variables associated with entities through the factors. However, in analysis of link structures, we need to model the relationship of two ends of links, i.e., edges between vertex pairs. Therefore, the model should involve factors of both vertices of the edge. This is a key difference between traditional factor analysis and our model. In our model, we connect two  components through a set of shared factors, that is, the latent factors in the second component (for contents) are tied to the factors in the first component (for links). By doing this, we search for a unified set of latent factors that best explains both content and link structures simultaneously and seamlessly. In the formulation, we perform factor analysis based on matrix factorization: solution to the first component is based on  factorizing the term-document matrix derived from content features;  solution to the second component is based on factorizing the adjacency matrix derived from links. Because the two factorizations share a common base, the discovered bases (latent factors) explain both content information and link structures, and are then used in further information management tasks such as classification. This paper is organized as follows. Section 2 reviews related work. Section 3 presents the proposed approach to analyze the web page based on the combined information of links and content.  Section 4 extends the basic framework and a few variants for fine tune. Section 5 shows the experiment results. Section 6 discusses the details of this approach and Section 7 concludes. . RELATED WORK In the content analysis part, our approach is closely related to Latent Semantic Indexing (LSI) [8]. LSI maps documents into a lower dimensional latent space. The latent space implicitly  captures a large portion of information of documents, therefore it is called the latent semantic space. The similarity between documents could be defined by the dot products of the corresponding vectors of documents in the latent space. Analysis tasks, such as  classification, could be performed on the latent space. The commonly used singular value decomposition (SVD) method ensures that the data points in the latent space can optimally reconstruct the original documents. Though our approach also uses latent space to  represent web pages (documents), we consider the link structure as well as the content of web pages. In the link analysis approach, the framework of hubs and  authorities (HITS) [12] puts web page into two categories, hubs and authorities. Using recursive notion, a hub is a web page with many outgoing links to authorities, while an authority is a web page with many incoming links from hubs. Instead of using two categories, PageRank [17] uses a single category for the recursive notion, an authority is a web page with many incoming links from authorities. He et al. [9] propose a clustering algorithm for web document  clustering. The algorithm incorporates link structure and the co-citation patterns. In the algorithm, all links are treated as undirected edge of the link graph. The content information is only used for weighing the links by the textual similarity of both ends of the links. Zhang et al. [23] uses the undirected graph regularization framework for document classification. Achlioptas et al[2] decompose the web into hub and authority attributes then combine them with content. Zhou et al. [25] and [24] propose a directed graph regularization framework for semi-supervised learning. The framework combines the hub and authority information of web pages. But it is difficult to combine the content information into that framework. Our  approach consider the content and the directed linkage between topics of source and destination web pages in one step, which implies the topic combines the information of web page as authorities and as hubs in a single set of factors. Cohn and Hofmann [6] construct the latent space from both  content and link information, using content analysis based on  probabilistic LSI (PLSI) [10] and link analysis based on PHITS [5]. The major difference between the approach of [6] (PLSI+PHITS) and our approach is in the part of link analysis. In PLSI+PHITS, the link is constructed with the linkage from the topic of the source web page to the destination web page. In the model, the outgoing links of the destination web page have no effect on the source web page. In other words, the overall link structure is not utilized in PHITS. In our approach, the link is constructed with the linkage between the factor of the source web page and the factor of the  destination web page, instead of the destination web page itself. The factor of the destination web page contains information of its  outgoing links. In turn, such information is passed to the factor of the source web page. As the result of matrix factorization, the factor forms a factor graph, a miniature of the original graph, preserving the major structure of the original graph. Taskar et al. [19] propose relational Markov networks (RMNs) for entity classification, by describing a conditional distribution of entity classes given entity attributes and relationships. The model was applied to web page classification, where web pages are  entities and hyperlinks are treated as relationships. RMNs apply  conditional random fields to define a set of potential functions on cliques of random variables, where the link structure provides hints to form the cliques. However the model does not give an off-the-shelf  solution, because the success highly depends on the arts of designing the potential functions. On the other hand, the inference for RMNs is intractable and requires belief propagation. The following are some work on combining documents and links, but the methods are loosely related to our approach. The experiments of [21] show that using terms from the linked  document improves the classification accuracy. Chakrabarti et al.[3] use co-citation information in their classification model. Joachims et al.[11] combine text kernels and co-citation kernels for  classification. Oh et al [16] use the Naive Bayesian frame to combine link information with content. . OUR APPROACH In this section we will first introduce a novel matrix  factorization method, which is more suitable than conventional matrix  factorization methods for link analysis. Then we will introduce our approach that jointly factorizes the document-term matrix and link matrix and obtains compact and highly indicative factors for  representing documents or web pages. .1 Link Matrix Factorization Suppose we have a directed graph G = (V, E), where the vertex set V = {vi}n i=1 represents the web pages and the edge set E  represents the hyperlinks between web pages. Let A = {asd} denotes the n×n adjacency matrix of G, which is also called the link matrix in this paper. For a pair of vertices, vs and vd, let asd = 1 when there is an edge from vs to vd, and asd = 0, otherwise. Note that A is an asymmetric matrix, because hyperlinks are directed. Most machine learning algorithms assume a feature-vector  representation of instances. For web page classification, however, the link graph does not readily give such a vector representation for web pages. If one directly uses each row or column of A for the job, she will suffer a very high computational cost because the  dimensionality equals to the number of web pages. On the other hand, it will produces a poor classification accuracy (see our experiments in Section 5), because A is extremely sparse1 . The idea of link matrix factorization is to derive a high-quality feature representation Z of web pages based on analyzing the link matrix A, where Z is an n × l matrix, with each row being the  ldimensional feature vector of a web page. The new representation of web pages captures the principal factors of the link structure and makes further processing more efficient. One may use a method similar to LSI, to apply the well-known principal component analysis (PCA) for deriving Z from A. The corresponding optimization problem 2 is min Z,U A − ZU 2 F + γ U 2 F (1) where γ is a small positive number, U is an l ×n matrix, and · F is the Frobenius norm. The optimization aims to approximate A by ZU , a product of two low-rank matrices, with a regularization on U. In the end, the i-th row vector of Z can be thought as the hub feature vector of vertex vi, and the row vector of U can be thought as the authority features. A link generation model proposed in [2] is similar to the PCA approach. Since A is a nonnegative matrix here, one can also consider to put nonnegative constraints on U and Z, which produces an algorithm similar to PLSA [10] and NMF [20].  Due to the sparsity of A, links from two similar pages may not share any common target pages, which makes them to appear  dissimilar. However the two pages may be indirectly linked to many common pages via their neighbors.  Another equivalent form is minZ,U A − ZU 2 F , s. t. U U = I. The solution Z is identical subject to a scaling factor. However, despite its popularity in matrix analysis, PCA (or other similar methods like PLSA) is restrictive for link matrix  factorization. The major problem is that, PCA ignores the fact that the rows and columns of A are indexed by exactly the same set of objects (i.e., web pages). The approximating matrix ˜A = ZU shows no evidence that links are within the same set of objects. To see the drawback, let"s consider a link transitivity situation vi → vs → vj, where page i is linked to page s which itself is linked to page j. Since ˜A = ZU treats A as links from web pages {vi} to a  different set of objects, let it be denoted by {oi}, ˜A = ZU actually splits an linked object os from vs and breaks down the link path into two parts vi → os and vs → oj. This is obviously a miss interpretation to the original link path. To overcome the problem of PCA, in this paper we suggest to use a different factorization: min Z,U A − ZUZ 2 F + γ U 2 F (2) where U is an l × l full matrix. Note that U is not symmetric, thus ZUZ produces an asymmetric matrix, which is the case of A. Again, each row vector of Z corresponds to a feature vector of a web pages. The new approximating form ˜A = ZUZ puts a clear meaning that the links are between the same set of objects,  represented by features Z. The factor model actually maps each vertex, vi, into a vector zi = {zi,k; 1 ≤ k ≤ l} in the Rl space. We call the Rl space the factor space. Then, {zi} encodes the information of incoming and outgoing connectivity of vertices {vi}. The  factor loadings, U, explain how these observed connections happened based on {zi}. Once we have the vector zi, we can use many  traditional classification methods (such as SVMs) or clustering tools (such as K-Means) to perform the analysis. Illustration Based on a Synthetic Problem To further illustrate the advantages of the proposed link matrix  factorization Eq. (2), let us consider the graph in Figure 1. Given v1 v2 v3 v4 v5 v6 v7 v8 Figure 2: Summarize Figure 1 with a factor graph these observations, we can summarize the graph by grouping as factor graph depicted in Figure 2. In the next we preform the two factorization methods Eq. (2) and Eq. (1) on this link matrix. A good low-rank representation should reveal the structure of the  factor graph. First we try PCA-like decomposition, solving Eq. (1) and obtaining Z = U =                   . 1. 0 0 0  0 −.6 −.7 .1  0 .0 .6 −.0  0 .8 −.4 .3  0 .2 −.2 −.9 .7 .7 0 0 0 .7 .7 0 0 0  0 0 0 0                                      0 0 0 0 .5 −.5 0 0 0 .5 −.5 0 0 0  0 −0.6 −.7 .1  0 .0 .6 −.0  0 .8 −.4 .3  0 .2 −.2 −.9 .7 .7 0 0 0                   We can see that the row vectors of v6 and v7 are the same in Z, indicating that v6 and v7 have the same hub attributes. The row vectors of v2 and v3 are the same in U, indicating that v2 and v3 have the same authority attributes. It is not clear to see the similarity between v4 and v5, because their inlinks (and outlinks) are different. Then, we factorize A by ZUZ via solving Eq. (2), and obtain the results Z = U =                   −.8 −.5 .3 −.1 −.0 −.0 .4 .6 −.1 −.4 −.0 .4 .6 −.1 −.4 .3 −.2 .3 −.4 .3 .3 −.2 .3 −.4 .3 −.4 .5 .0 −.2 .6 −.4 .5 .0 −.2 .6 −.1 .1 −.4 −.8 −.4                             −.1 −.2 −.4 .6 .7 .2 −.5 −.5 −.5 .0 .1 .1 .4 −.4 .3 .1 −.2 −.0 .3 −.1 −.3 .3 −.5 −.4 −.2           The resultant Z is very consistent with the clustering structure of vertices: the row vectors of v2 and v3 are the same, those of v4 and v5 are the same, those of v6 and v7 are the same. Even interestingly, if we add constraints to ensure Z and U be nonnegative, we have Z = U =                   . 0 0 0 0  .9 0 0 0  .9 0 0 0  0 .7 0 0  0 .7 0 0  0 0 .9 0  0 0 .9 0  0 0 0 1.                              1. 0 0 0  0 .7 0 0  0 0 .7 0  0 0 0 1.  0 0 0 0           which clearly tells the assignment of vertices to clusters from Z and the links of factor graph from U. When the interpretability is not critical in some tasks, for example, classification, we found that it achieves better accuracies without the nonnegative constraints. Given our above analysis, it is clear that the factorization ZUZ is more expressive than ZU in representing the link matrix A. .2 Content Matrix Factorization Now let us consider the content information on the vertices. To combine the link information and content information, we want to use the same latent space to approximate the content as the latent space for the links. Using the bag-of-words approach, we denote the content of web pages by an n×m matrix C, each of whose rows represents a document, each column represents a keyword, where m is the number of keywords. Like the latent semantic indexing (LSI) [8], the l-dimensional latent space for words is denoted by an m × l matrix V . Therefore, we use ZV to approximate matrix C, min V,Z C − ZV 2 F + β V 2 F , (3) where β is a small positive number, β V 2 F serves as a  regularization term to improve the robustness. .3 Joint Link-Content Matrix Factorization There are many ways to employ both the content and link  information for web page classification. Our idea in this paper is not to simply combine them, but rather to fuse them into a single,  consistent, and compact feature representation. To achieve this goal, we solve the following problem, min U,V,Z n J (U, V, Z) def = A − ZUZ 2 F + α C − ZV 2 F + γ U 2 F + β V 2 F o . (4) Eq. (4) is the joined matrix factorization of A and C with  regularization. The new representation Z is ensured to capture both the structures of the link matrix A and the content matrix C. Once we find the optimal Z, we can apply the traditional classification or clustering methods on vectorial data Z. The relationship among these matrices can be depicted as Figure 3. A Y C U Z V Figure 3: Relationship among the matrices. Node Y is the  target of classification. Eq. (4) can be solved using gradient methods, such as the  conjugate gradient method and quasi-Newton methods. Then main  computation of gradient methods is evaluating the object function J and its gradients against variables, ∂J ∂U =  Z ZUZ Z − Z AZ  + γU, ∂J ∂V =α  V Z Z − C Z  + βV, ∂J ∂Z =  ZU Z ZU + ZUZ ZU − A ZU − AZU  + α  ZV V − CV  . Because of the sparsity of A, the computational complexity of multiplication of A and Z is O(µAl), where µA is the number of nonzero entries in A. Similarly, the computational complexity of C Z and CV is O(µC l), where µC is the number of nonzero entries in C. The computational complexity of the rest  multiplications in the gradient computation is O(nl2 ). Therefore, the total computational complexity in one iteration is O(µAl + µC l + nl2 ). The number of links and the number of words in a web page are relatively small comparing to the number of web pages, and are  almost constant as the number of web pages/documents increases, i.e. µA = O(n) and µC = O(n). Therefore, theoretically the  computation time is almost linear to the number of web pages/documents, n. . SUPERVISED MATRIX  FACTORIZATION Consider a web page classification problem. We can solve Eq. (4) to obtain Z as Section 3, then use a traditional classifier to perform classification. However, this approach does not take data labels into account in the first step. Believing that using data labels improves the accuracy by obtaining a better Z for the  classification, we consider to use the data labels to guide the matrix factorization, called supervised matrix factorization [22]. Because some data used in the matrix factorization have no label  information, the supervised matrix factorization falls into the category of semi-supervised learning. Let C be the set of classes. For simplicity, we first consider  binary class problem, i.e. C = {−1, 1}. Assume we know the  labels {yi} for vertices in T ⊂ V. We want to find a hypothesis h : V → R, such that we assign vi to 1 when h(vi) ≥ 0, −1  otherwise. We assume a transform from the latent space to R is linear, i.e. h(vi) = w φ(vi) + b = w zi + b, (5) School course dept. faculty other project staff student total Cornell 44 1 34 581 18 21 128 827 Texas 36 1 46 561 20 2 148 814 Washington 77 1 30 907 18 10 123 1166 Wisconsin 85 0 38 894 25 12 156 1210 Table 1: Dataset of WebKB where w and b are parameters to estimate. Here, w is the norm of the decision boundary. Similar to Support Vector Machines (SVMs) [7], we can use the hinge loss to measure the loss, X i:vi∈T [1 − yih(vi)]+ , where [x]+ is x if x ≥ 0, 0 if x < 0. However, the hinge loss is not smooth at the hinge point, which makes it difficult to apply gradient methods on the problem. To overcome the difficulty, we use a smoothed version of hinge loss for each data point, g(yih(vi)), (6) where g(x) =  >< >:  when x ≥ 2,  − x when x ≤ 0,   (x − 2)2 when 0 < x < 2. We reduce a multiclass problem into multiple binary ones. One simple scheme of reduction is the one-against-rest coding scheme. In the one-against-rest scheme, we assign a label vector for each class label. The element of a label vector is 1 if the data point  belongs the corresponding class, −1, if the data point does not belong the corresponding class, 0, if the data point is not labeled. Let Y be the label matrix, each column of which is a label vector. Therefore, Y is a matrix of n × c, where c is the number of classes, |C|. Then the values of Eq. (5) form a matrix H = ZW + 1b , (7) where 1 is a vector of size n, whose elements are all one, W is a c × l parameter matrix, and b is a parameter vector of size c. The total loss is proportional to the sum of Eq. (6) over all labeled data points and the classes, LY (W, b, Z) = λ X i:vi∈T ,j∈C g(YijHij), where λ is the parameter to scale the term. To derive a robust solution, we also use Tikhonov regularization for W, ΩW (W) = ν  W 2 F , where ν is the parameter to scale the term. Then the supervised matrix factorization problem becomes min U,V,Z,W,b Js(U, V, Z, W, b) (8) where Js(U, V, Z, W, b) = J (U, V, Z) + LY (W, b, Z) + ΩW (W). We can also use gradient methods to solve the problem of Eq. (8). The gradients are ∂Js ∂U = ∂J ∂U , ∂Js ∂V = ∂J ∂V , ∂Js ∂Z = ∂J ∂Z + λGW, ∂Js ∂W =λG Z + νW, ∂Js ∂b =λG 1, where G is an n×c matrix, whose ik-th element is Yikg (YikHik), and g (x) =  >< >:  when x ≥ 2, −1 when x ≤ 0,   (x − 2) when 0 < x < 2. Once we obtain w, b, and Z, we can apply h on the vertices with unknown class labels, or apply traditional classification algorithms on Z to get the classification results. . EXPERIMENTS .1 Data Description In this section, we perform classification on two datasets, to demonstrate the our approach. The two datasets are the WebKB data set[1] and the Cora data set [15]. The WebKB data set  consists of about 6000 web pages from computer science departments of four schools (Cornell, Texas, Washington, and Wisconsin). The web pages are classified into seven categories. The numbers of pages in each category are shown in Table 1. The Cora data set consists of the abstracts and references of about 34,000 computer science research papers. We use part of them to categorize into one of subfields of data structure (DS), hardware and architecture (HA), machine learning (ML), and programing language (PL). We remove those articles without reference to other articles in the set. The number of papers and the number of subfields in each area are shown in Table 2. area # of papers # of subfields Data structure (DS) 751 9 Hardware and architecture (HA) 400 7 Machine learning (ML) 1617 7 Programing language (PL) 1575 9 Table 2: Dataset of Cora .2 Methods The task of the experiments is to classify the data based on their content information and/or link structure. We use the following methods: 5 0 5 0 5 0 5 00 WisconsinWashingtonTexasCornell accuracy(%) dataset SVM on content SVM on link SVM on link-content Directed graph reg. PLSI+PHITS link-content MF link-content sup. MF method Cornell Texas Washington Wisconsin SVM on content 81.00 ± 0.90 77.00 ± 0.60 85.20 ± 0.90 84.30 ± 0.80 SVM on links 70.10 ± 0.80 75.80 ± 1.20 80.50 ± 0.30 74.90 ± 1.00 SVM on link-content 80.00 ± 0.80 78.30 ± 1.00 85.20 ± 0.70 84.00 ± 0.90 Directed graph regularization 89.47 ± 1.41 91.28 ± 0.75 91.08 ± 0.51 89.26 ± 0.45 PLSI+PHITS 80.74 ± 0.88 76.15 ± 1.29 85.12 ± 0.37 83.75 ± 0.87 link-content MF 93.50 ± 0.80 96.20 ± 0.50 93.60 ± 0.50 92.60 ± 0.60 link-content sup. MF 93.80 ± 0.70 97.07 ± 1.11 93.70 ± 0.60 93.00 ± 0.30 Table 3: Classification accuracy (mean ± std-err %) on WebKB data set • SVM on content We apply support vector machines (SVM) on the content of documents. The features are the  bag-ofwords and all word are stemmed. This method ignores link structure in the data. Linear SVM is used. The  regularization parameter of SVM is selected using the cross-validation method. The implementation of SVM used in the  experiments is libSVM[4]. • SVM on links We treat links as the features of each  document, i.e. the i-th feature is link-to-pagei. We apply SVM on link features. This method uses link information, but not the link structure. • SVM on link-content We combine the features of the above two methods. We use different weights for these two set of features. The weights are also selected using  crossvalidation. • Directed graph regularization This method is described in [25] and [24]. This method is solely based on link structure. • PLSI+PHITS This method is described in [6]. This method combines text content information and link structure for analysis. The PHITS algorithm is in spirit similar to Eq.1, with an additional nonnegative constraint. It models the  outgoing and in-coming structures separately. • Link-content MF This is our approach of matrix  factorization described in Section 3. We use 50 latent factors for Z. After we compute Z, we train a linear SVM using Z as the feature vectors, then apply SVM on testing portion of Z to obtain the final result, because of the multiclass output. • Link-content sup. MF This method is our approach of the supervised matrix factorization in Section 4. We use 50 latent factors for Z. After we compute Z, we train a linear SVM on the training portion of Z, then apply SVM on testing  portion of Z to obtain the final result, because of the multiclass output. We randomly split data into five folds and repeat the experiment for five times, for each time we use one fold for test, four other folds for training. During the training process, we use the  crossvalidation to select all model parameters. We measure the results by the classification accuracy, i.e., the percentage of the number of correct classified documents in the entire data set. The results are shown as the average classification accuracies and it standard deviation over the five repeats. .3 Results The average classification accuracies for the WebKB data set are shown in Table 3. For this task, the accuracies of SVM on links are worse than that of SVM on content. But the directed graph regularization, which is also based on link alone, achieves a much higher accuracy. This implies that the link structure plays an  important role in the classification of this dataset, but individual links in a web page give little information. The combination of link and content using SVM achieves similar accuracy as that of SVM on content alone, which confirms individual links in a web page give little information. Since our approach consider the link structure as well as the content information, our two methods give results a highest accuracies among these approaches. The difference  between the results of our two methods is not significant. However in the experiments below, we show the difference between them. The classification accuracies for the Cora data set are shown in Table 4. In this experiment, the accuracies of SVM on the  combination of links and content are higher than either SVM on content or SVM on links. This indicates both content and links are  infor45 0 5 0 5 0 5 0 PLMLHADS accuracy(%) dataset SVM on content SVM on link SVM on link-content Directed graph reg. PLSI+PHITS link-content MF link-content sup. MF method DS HA ML PL SVM on content 53.70 ± 0.50 67.50 ± 1.70 68.30 ± 1.60 56.40 ± 0.70 SVM on links 48.90 ± 1.70 65.80 ± 1.40 60.70 ± 1.10 58.20 ± 0.70 SVM on link-content 63.70 ± 1.50 70.50 ± 2.20 70.56 ± 0.80 62.35 ± 1.00 Directed graph regularization 46.07 ± 0.82 65.50 ± 2.30 59.37 ± 0.96 56.06 ± 0.84 PLSI+PHITS 53.60 ± 1.78 67.40 ± 1.48 67.51 ± 1.13 57.45 ± 0.68 link-content MF 61.00 ± 0.70 74.20 ± 1.20 77.50 ± 0.80 62.50 ± 0.80 link-content sup. MF 69.38 ± 1.80 74.20 ± 0.70 78.70 ± 0.90 68.76 ± 1.32 Table 4: Classification accuracy (mean ± std-err %) on Cora data set mative for classifying the articles into subfields. The method of directed graph regularization does not perform as good as SVM on link-content, which confirms the importance of the article content in this task. Though our method of link-content matrix  factorization perform slightly better than other methods, our method of  linkcontent supervised matrix factorization outperform significantly. .4 The Number of Factors As we discussed in Section 3, the computational complexity of each iteration for solving the optimization problem is quadratic to the number of factors. We perform experiments to study how the number of factors affects the accuracy of predication. We use  different numbers of factors for the Cornell data of WebKB data set and the machine learning (ML) data of Cora data set. The result shown in Figure 4(a) and 4(b). The figures show that the accuracy 8 9 0 1 2 3 4 5  10 20 30 40 50 accuracy(%) number of factors link-content sup. MF link-content MF (a) Cornell data 2 4 6 8 0 2 4 6 8 0  10 20 30 40 50 accuracy(%) number of factors link-content sup. MF link-content MF (b) ML data Figure 4: Accuracy vs number of factors increases as the number of factors increases. It is a different  concept from choosing the optimal number of clusters in clustering application. It is how much information to represent in the latent variables. We have considered the regularization over the factors, which avoids the overfit problem for a large number of factors. To choose of the number of factors, we need to consider the trade-off between the accuracy and the computation time, which is quadratic to the number of factors. The difference between the method of matrix factorization and that of supervised one decreases as the number of factors increases. This indicates that the usefulness of supervised matrix factorization at lower number of factors. . DISCUSSIONS The loss functions LA in Eq. (2) and LC in Eq. (3) use squared loss due to computationally convenience. Actually, squared loss does not precisely describe the underlying noise model, because the weights of adjacency matrix can only take nonnegative  values, in our case, zero or one only, and the components of  content matrix C can only take nonnegative integers. Therefore, we can apply other types of loss, such as hinge loss or smoothed hinge loss, e.g. LA(U, Z) = µh(A, ZUZ ), where h(A, B) =P i,j [1 − AijBij]+ . In our paper, we mainly discuss the application of classification. A entry of matrix Z means the relationship of a web page and a factor. The values of the entries are the weights of linear model, instead of the probabilities of web pages belonging to latent  topics. Therefore, we allow the components take any possible real  values. When we come to the clustering application, we can use this model to find Z, then apply K-means to partition the web pages into clusters. Actually, we can use the idea of nonnegative matrix factorization for clustering [20] to directly cluster web pages. As the example with nonnegative constraints shown in Section 3, we represent each cluster by a latent topic, i.e. the dimensionality of the latent space is set to the number of clusters we want. Then the problem of Eq. (4) becomes min U,V,Z J (U, V, Z), s.t.Z ≥ 0. (9) Solving Eq. (9), we can obtain more interpretable results, which could be used for clustering. . CONCLUSIONS In this paper, we study the problem of how to combine the  information of content and links for web page analysis, mainly on  classification application. We propose a simple approach using factors to model the text content and link structure of web pages/documents. The directed links are generated from the linear combination of linkage of between source and destination factors. By sharing  factors between text content and link structure, it is easy to combine both the content information and link structure. Our experiments show our approach is effective for classification. We also discuss an extension for clustering application. Acknowledgment We would like to thank Dr. Dengyong Zhou for sharing his code of his algorithm. Also, thanks to the reviewers for constructive comments. . REFERENCES [1] CMU world wide knowledge base (WebKB) project. Available at http://www.cs.cmu.edu/∼WebKB/. [2] D. Achlioptas, A. Fiat, A. R. Karlin, and F. McSherry. Web search via hub synthesis. In IEEE Symposium on Foundations of Computer Science, pages 500-509, 2001. [3] S. Chakrabarti, B. E. Dom, and P. Indyk. Enhanced hypertext categorization using hyperlinks. In L. M. Haas and A. Tiwary, editors, Proceedings of SIGMOD-98, ACM International Conference on Management of Data, pages 07-318, Seattle, US, 1998. ACM Press, New York, US. [4] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm. [5] D. Cohn and H. Chang. Learning to probabilistically identify authoritative documents. Proc. ICML 2000. pp.167-174., 000. [6] D. Cohn and T. Hofmann. The missing link - a probabilistic model of document content and hypertext connectivity. In T. K. Leen, T. G. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems 13, pages 30-436. MIT Press, 2001. [7] C. Cortes and V. Vapnik. Support-vector networks. Machine Learning, 20:273, 1995. [8] S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. Indexing by latent semantic analysis. Journal of the American Society of Information Science, 41(6):391-407, 1990. [9] X. He, H. Zha, C. Ding, and H. Simon. Web document clustering using hyperlink structures. Computational Statistics and Data Analysis, 41(1):19-45, 2002. [10] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of the Twenty-Second Annual International SIGIR Conference, 1999. [11] T. Joachims, N. Cristianini, and J. Shawe-Taylor. Composite kernels for hypertext categorisation. In C. Brodley and A. Danyluk, editors, Proceedings of ICML-01, 18th International Conference on Machine Learning, pages 50-257, Williams College, US, 2001. Morgan Kaufmann Publishers, San Francisco, US. [12] J. M. Kleinberg. Authoritative sources in a hyperlinked environment. J. ACM, 48:604-632, 1999. [13] P. Kolari, T. Finin, and A. Joshi. SVMs for the Blogosphere: Blog Identification and Splog Detection. In AAAI Spring Symposium on Computational Approaches to Analysing Weblogs, March 2006. [14] O. Kurland and L. Lee. Pagerank without hyperlinks: structural re-ranking using links induced by language models. In SIGIR "05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 306-313, New York, NY, USA, 2005. ACM Press. [15] A. McCallum, K. Nigam, J. Rennie, and K. Seymore. Automating the contruction of internet portals with machine learning. Information Retrieval Journal, 3(127-163), 2000. [16] H.-J. Oh, S. H. Myaeng, and M.-H. Lee. A practical hypertext catergorization method using links and incrementally available class information. In SIGIR "00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 264-271, New York, NY, USA, 2000. ACM Press. [17] L. Page, S. Brin, R. Motowani, and T. Winograd. PageRank citation ranking: bring order to the web. Stanford Digital Library working paper 1997-0072, 1997. [18] C. Spearman. General Intelligence, objectively determined and measured. The American Journal of Psychology, 5(2):201-292, Apr 1904. [19] B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In Proceedings of 8th International UAI Conference, 2002. [20] W. Xu, X. Liu, and Y. Gong. Document clustering based on non-negative matrix factorization. In SIGIR "03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 267-273. ACM Press, 2003. [21] Y. Yang, S. Slattery, and R. Ghani. A study of approaches to hypertext categorization. Journal of Intelligent Information Systems, 18(2-3):219-241, 2002. [22] K. Yu, S. Yu, and V. Tresp. Multi-label informed latent semantic indexing. In SIGIR "05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 258-265, New York, NY, USA, 2005. ACM Press. [23] T. Zhang, A. Popescul, and B. Dom. Linear prediction models with graph regularization for web-page categorization. In KDD "06: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 821-826, New York, NY, USA, 006. ACM Press. [24] D. Zhou, J. Huang, and B. Sch¨olkopf. Learning from labeled and unlabeled data on a directed graph. In Proceedings of the 2nd International Conference on Machine Learning, Bonn, Germany, 2005. [25] D. Zhou, B. Sch¨olkopf, and T. Hofmann. Semi-supervised learning on directed graphs. Proc. Neural Info. Processing Systems, 2004.
A Time Machine for Text Search Klaus Berberich Srikanta Bedathur Thomas Neumann Gerhard Weikum Max-Planck Institute for Informatics Saarbr¨ucken, Germany {kberberi, bedathur, neumann, weikum}@mpi-inf.mpg.de ABSTRACT Text search over temporally versioned document collections such as web archives has received little attention as a  research problem. As a consequence, there is no scalable and principled solution to search such a collection as of a  specified time t. In this work, we address this shortcoming and propose an efficient solution for time-travel text search by extending the inverted file index to make it ready for  temporal search. We introduce approximate temporal coalescing as a tunable method to reduce the index size without  significantly affecting the quality of results. In order to further improve the performance of time-travel queries, we  introduce two principled techniques to trade off index size for its performance. These techniques can be formulated as  optimization problems that can be solved to near-optimality. Finally, our approach is evaluated in a comprehensive  series of experiments on two large-scale real-world datasets. Results unequivocally show that our methods make it  possible to build an efficient time machine scalable to large versioned text collections. Categories and Subject Descriptors H.3.1 [Content Analysis and Indexing]: Indexing  methods; H.3.3 [Information Search and Retrieval]:  Retrieval models, Search process General Terms Algorithms, Experimentation, Performance . INTRODUCTION In this work we address time-travel text search over  temporally versioned document collections. Given a keyword query q and a time t our goal is to identify and rank  relevant documents as if the collection was in its state as of time t. An increasing number of such versioned document  collections is available today including web archives,  collaborative authoring environments like Wikis, or timestamped information feeds. Text search on these collections,  however, is mostly time-ignorant: while the searched collection changes over time, often only the most recent version of a documents is indexed, or, versions are indexed  independently and treated as separate documents. Even worse, for some collections, in particular web archives like the  Internet Archive [18], a comprehensive text-search functionality is often completely missing. Time-travel text search, as we develop it in this paper, is a crucial tool to explore these collections and to unfold their full potential as the following example demonstrates. For a documentary about a past political scandal, a  journalist needs to research early opinions and statements made by the involved politicians. Sending an appropriate query to a major web search-engine, the majority of returned  results contains only recent coverage, since many of the early web pages have disappeared and are only preserved in web archives. If the query could be enriched with a time point, say August 20th 2003 as the day after the scandal got  revealed, and be issued against a web archive, only pages that existed specifically at that time could be retrieved thus better satisfying the journalist"s information need. Document collections like the Web or Wikipedia [32], as we target them here, are already large if only a single  snapshot is considered. Looking at their evolutionary history, we are faced with even larger data volumes. As a consequence, na¨ıve approaches to time-travel text search fail, and viable approaches must scale-up well to such large data volumes. This paper presents an efficient solution to time-travel text search by making the following key contributions: . The popular well-studied inverted file index [35] is  transparently extended to enable time-travel text search. . Temporal coalescing is introduced to avoid an  indexsize explosion while keeping results highly accurate. . We develop two sublist materialization techniques to improve index performance that allow trading off space vs. performance. . In a comprehensive experimental evaluation our  approach is evaluated on the English Wikipedia and parts of the Internet Archive as two large-scale real-world datasets with versioned documents. The remainder of this paper is organized as follows. The presented work is put in context with related work in  Section 2. We delineate our model of a temporally versioned document collection in Section 3. We present our time-travel inverted index in Section 4. Building on it, temporal  coalescing is described in Section 5. In Section 6 we describe principled techniques to improve index performance, before presenting the results of our experimental evaluation in  Section 7. . RELATED WORK We can classify the related work mainly into the following two categories: (i) methods that deal explicitly with  collections of versioned documents or temporal databases, and (ii) methods for reducing the index size by exploiting either the document-content overlap or by pruning portions of the index. We briefly review work under these categories here. To the best of our knowledge, there is very little prior work dealing with historical search over temporally versioned  documents. Anick and Flynn [3], while pioneering this research, describe a help-desk system that supports historical queries. Access costs are optimized for accesses to the most recent versions and increase as one moves farther into the past. Burrows and Hisgen [10], in a patent description, delineate a method for indexing range-based values and mention its potential use for searching based on dates associated with documents. Recent work by Nørv˚ag and Nybø [25] and their earlier proposals concentrate on the relatively simpler problem of supporting text-containment queries only and neglect the relevance scoring of results. Stack [29] reports practical experiences made when adapting the open source search-engine Nutch to search web archives. This  adaptation, however, does not provide the intended time-travel text search functionality. In contrast, research in temporal databases has produced several index structures tailored for time-evolving databases; a comprehensive overview of the state-of-art is available in [28]. Unlike the inverted file  index, their applicability to text search is not well understood. Moving on to the second category of related work, Broder et al. [8] describe a technique that exploits large content overlaps between documents to achieve a reduction in index size. Their technique makes strong assumptions about the structure of document overlaps rendering it inapplicable to our context. More recent approaches by Hersovici et al. [17] and Zhang and Suel [34] exploit arbitrary content overlaps between documents to reduce index size. None of the  approaches, however, considers time explicitly or provides the desired time-travel text search functionality. Static  indexpruning techniques [11, 12] aim to reduce the effective index size, by removing portions of the index that are expected to have low impact on the query result. They also do not consider temporal aspects of documents, and thus are  technically quite different from our proposal despite having a shared goal of index-size reduction. It should be noted that index-pruning techniques can be adapted to work along with the temporal text index we propose here. . MODEL In the present work, we deal with a temporally versioned document collection D that is modeled as described in the following. Each document d ∈ D is a sequence of its versions d = dt1 , dt2 , . . . . Each version dti has an associated timestamp ti reflecting when the version was created. Each version is a vector of searchable terms or features. Any modification to a  document version results in the insertion of a new version with corresponding timestamp. We employ a discrete definition of time, so that timestamps are non-negative integers. The deletion of a document at time ti, i.e., its disappearance from the current state of the collection, is modeled as the insertion of a special tombstone version ⊥. The validity time-interval val(dti ) of a version dti is [ti, ti+1), if a newer version with associated timestamp ti+1 exists, and [ti, now) otherwise where now points to the greatest possible value of a timestamp (i.e., ∀t : t < now). Putting all this together, we define the state Dt of the collection at time t (i.e., the set of versions valid at t that are not deletions) as Dt = [ d∈D {dti ∈ d | t ∈ val(dti ) ∧ dti = ⊥} . As mentioned earlier, we want to enrich a keyword query q with a timestamp t, so that q be evaluated over Dt , i.e., the state of the collection at time t. The enriched time-travel query is written as q t for brevity. As a retrieval model in this work we adopt Okapi BM25 [27], but note that the proposed techniques are not dependent on this choice and are applicable to other retrieval models like tf-idf [4] or language models [26] as well. For our considered setting, we slightly adapt Okapi BM25 as w(q t , dti ) = X v∈q wtf (v, dti ) · widf (v, t) . In the above formula, the relevance w(q t , dti ) of a  document version dti to the time-travel query q t is defined. We reiterate that q t is evaluated over Dt so that only the version dti valid at time t is considered. The first factor wtf (v, dti ) in the summation, further referred to as the  tfscore is defined as wtf (v, dti ) = (k1 + 1) · tf(v, dti ) k1 · ((1 − b) + b · dl(d ti ) avdl(ti) ) + tf(v, dti ) . It considers the plain term frequency tf(v, dti ) of term v in version dti normalizing it, taking into account both the length dl(dti ) of the version and the average document length avdl(ti) in the collection at time ti. The length-normalization parameter b and the tf-saturation parameter k1 are inherited from the original Okapi BM25 and are commonly set to  values 1.2 and 0.75 respectively. The second factor widf (v, t), which we refer to as the idf-score in the remainder, conveys the inverse document frequency of term v in the collection at time t and is defined as widf (v, t) = log N(t) − df(v, t) + 0.5 df(v, t) + 0.5 where N(t) = |Dt | is the collection size at time t and df(v, t) gives the number of documents in the collection that contain the term v at time t. While the idf-score depends on the whole corpus as of the query time t, the tf-score is specific to each version. . TIME-TRAVELINVERTEDFILEINDEX The inverted file index is a standard technique for text indexing, deployed in many systems. In this section, we briefly review this technique and present our extensions to the inverted file index that make it ready for time-travel text search. .1 Inverted File Index An inverted file index consists of a vocabulary, commonly organized as a B+-Tree, that maps each term to its  idfscore and inverted list. The index list Lv belonging to term v contains postings of the form ( d, p ) where d is a document-identifier and p is the so-called  payload. The payload p contains information about the term frequency of v in d, but may also include positional  information about where the term appears in the document. The sort-order of index lists depends on which queries are to be supported efficiently. For Boolean queries it is  favorable to sort index lists in document-order.  Frequencyorder and impact-order sorted index lists are beneficial for ranked queries and enable optimized query processing that stops early after having identified the k most relevant  documents [1, 2, 9, 15, 31]. A variety of compression techniques, such as encoding document identifiers more compactly, have been proposed [33, 35] to reduce the size of index lists. For an excellent recent survey about inverted file indexes we  refer to [35]. .2 Time-Travel Inverted File Index In order to prepare an inverted file index for time travel we extend both inverted lists and the vocabulary structure by explicitly incorporating temporal information. The main idea for inverted lists is that we include a validity  timeinterval [tb, te) in postings to denote when the payload  information was valid. The postings in our time-travel inverted file index are thus of the form ( d, p, [tb, te) ) where d and p are defined as in the standard inverted file index above and [tb, te) is the validity time-interval. As a concrete example, in our implementation, for a  version dti having the Okapi BM25 tf-score wtf (v, dti ) for term v, the index list Lv contains the posting ( d, wtf (v, dti ), [ti, ti+1) ) . Similarly, the extended vocabulary structure maintains for each term a time-series of idf-scores organized as a  B+Tree. Unlike the tf-score, the idf-score of every term could vary with every change in the corpus. Therefore, we take a simplified approach to idf-score maintenance, by  computing idf-scores for all terms in the corpus at specific (possibly periodic) times. .3 Query Processing During processing of a time-travel query q t , for each query term the corresponding idf-score valid at time t is retrieved from the extended vocabulary. Then, index lists are  sequentially read from disk, thereby accumulating the information contained in the postings. We transparently extend the  sequential reading, which is - to the best of our  knowledgecommon to all query processing techniques on inverted file indexes, thus making them suitable for time-travel  queryprocessing. To this end, sequential reading is extended by skipping all postings whose validity time-interval does not contain t (i.e., t ∈ [tb, te)). Whether a posting can be skipped can only be decided after the posting has been  transferred from disk into memory and therefore still incurs  significant I/O cost. As a remedy, we propose index organization techniques in Section 6 that aim to reduce the I/O overhead significantly. We note that our proposed extension of the inverted file index makes no assumptions about the sort-order of  index lists. As a consequence, existing query-processing  techniques and most optimizations (e.g., compression techniques) remain equally applicable. . TEMPORAL COALESCING If we employ the time-travel inverted index, as described in the previous section, to a versioned document collection, we obtain one posting per term per document version. For frequent terms and large highly-dynamic collections, this time score non-coalesced coalesced Figure 1: Approximate Temporal Coalescing leads to extremely long index lists with very poor  queryprocessing performance. The approximate temporal coalescing technique that we propose in this section counters this blowup in index-list size. It builds on the observation that most changes in a versioned document collection are minor, leaving large parts of the document untouched. As a consequence, the payload of many postings belonging to temporally adjacent versions will differ only slightly or not at all. Approximate temporal coalescing reduces the number of postings in an index list by merging such a sequence of postings that have almost equal payloads, while keeping the maximal error bounded. This idea is illustrated in Figure 1, which plots non-coalesced and coalesced scores of postings belonging to a single document. Approximate temporal coalescing is greatly effective given such fluctuating payloads and reduces the number of  postings from 9 to 3 in the example. The notion of temporal coalescing was originally introduced in temporal database research by B¨ohlen et al. [6], where the simpler problem of coalescing only equal information was considered. We next formally state the problem dealt with in  approximate temporal coalescing, and discuss the computation of optimal and approximate solutions. Note that the technique is applied to each index list separately, so that the following explanations assume a fixed term v and index list Lv. As an input we are given a sequence of temporally  adjacent postings I = ( d, pi, [ti, ti+1) ), . . . , ( d, pn−1, [tn−1, tn)) ) . Each sequence represents a contiguous time period during which the term was present in a single document d. If a term disappears from d but reappears later, we obtain multiple input sequences that are dealt with separately. We seek to generate the minimal length output sequence of postings O = ( d, pj, [tj, tj+1) ), . . . , ( d, pm−1, [tm−1, tm)) ) , that adheres to the following constraints: First, O and I must cover the same time-range, i.e., ti = tj and tn = tm. Second, when coalescing a subsequence of postings of the  input into a single posting of the output, we want the  approximation error to be below a threshold . In other words, if (d, pi, [ti, ti+1)) and (d, pj, [tj, tj+1)) are postings of I and O respectively, then the following must hold for a chosen error function and a threshold : tj ≤ ti ∧ ti+1 ≤ tj+1 ⇒ error(pi, pj) ≤ . In this paper, as an error function we employ the relative error between payloads (i.e., tf-scores) of a document in I and O, defined as: errrel(pi, pj) = |pi − pj| / |pi| . Finding an optimal output sequence of postings can be cast into finding a piecewise-constant representation for the points (ti, pi) that uses a minimal number of segments while retaining the above approximation guarantee. Similar  problems occur in time-series segmentation [21, 30] and histogram construction [19, 20]. Typically dynamic programming is applied to obtain an optimal solution in O(n2 m∗ ) [20, 30] time with m∗ being the number of segments in an optimal sequence. In our setting, as a key difference, only a  guarantee on the local error is retained - in contrast to a guarantee on the global error in the aforementioned settings.  Exploiting this fact, an optimal solution is computable by means of induction [24] in O(n2 ) time. Details of the optimal  algorithm are omitted here but can be found in the  accompanying technical report [5]. The quadratic complexity of the optimal algorithm makes it inappropriate for the large datasets encountered in this work. As an alternative, we introduce a linear-time  approximate algorithm that is based on the sliding-window  algorithm given in [21]. This algorithm produces nearly-optimal output sequences that retain the bound on the relative error, but possibly require a few additional segments more than an optimal solution. Algorithm 1 Temporal Coalescing (Approximate) : I = ( d, pi, [ti, ti+1) ), . . . O = : pmin = pi pmax = pi p = pi tb = ti te = ti+1 : for ( d, pj, [tj, tj+1) ) ∈ I do : pmin = min( pmin, pj ) pmax = max( pmax, pj ) : p = optrep(pmin, pmax) : if errrel(pmin, p ) ≤ ∧ errrel(pmax, p ) ≤ then : pmin = pmin pmax = pmax p = p te = tj+1 : else : O = O ∪ ( d, p, [tb, te) ) 0: pmin = pj pmax = pj p = pj tb = tj te = tj+1 1: end if 2: end for 3: O = O ∪ ( d, p, [tb, te) ) Algorithm 1 makes one pass over the input sequence I. While doing so, it coalesces sequences of postings having maximal length. The optimal representative for a sequence of postings depends only on their minimal and maximal  payload (pmin and pmax) and can be looked up using optrep in O(1) (see [16] for details). When reading the next  posting, the algorithm tries to add it to the current sequence of postings. It computes the hypothetical new representative p and checks whether it would retain the approximation guarantee. If this test fails, a coalesced posting bearing the old representative is added to the output sequence O and, following that, the bookkeeping is reinitialized. The time complexity of the algorithm is in O(n). Note that, since we make no assumptions about the sort order of index lists, temporal-coalescing algorithms have an additional preprocessing cost in O(|Lv| log |Lv|) for sorting the index list and chopping it up into subsequences for each document. . SUBLIST MATERIALIZATION Efficiency of processing a query q t on our time-travel  inverted index is influenced adversely by the wasted I/O due to read but skipped postings. Temporal coalescing  implicitly addresses this problem by reducing the overall index list size, but still a significant overhead remains. In this section, we tackle this problem by proposing the idea of materializing sublists each of which corresponds to a contiguous  subinterval of time spanned by the full index. Each of these sublists contains all coalesced postings that overlap with the  corresponding time interval of the sublist. Note that all those postings whose validity time-interval spans across the  temporal boundaries of several sublists are replicated in each of the spanned sublists. Thus, in order to process the query q t time t1 t2 t3 t4 t5 t6 t7 t8 t9 t10 d1 d2 d3 document  2 3 4  6 7  9 10 Figure 2: Sublist Materialization it is sufficient to scan any materialized sublist whose  timeinterval contains t. We illustrate the idea of sublist materialization using an example shown in Figure 2. The index list Lv visualized in the figure contains a total of 10 postings from three  documents d1, d2, and d3. For ease of description, we have numbered boundaries of validity time-intervals, in increasing time-order, as t1, . . . , t10 and numbered the postings  themselves as 1, . . . , 10. Now, consider the processing of a query q t with t ∈ [t1, t2) using this inverted list. Although only three postings (postings 1, 5 and 8) are valid at time t, the whole inverted list has to be read in the worst case. Suppose that we split the time axis of the list at time t2, forming two sublists with postings {1, 5, 8} and {2, 3, 4, 5, 6, 7, 8, 9, 0} respectively. Then, we can process the above query with optimal cost by reading only those postings that existed at this t. At a first glance, it may seem counterintuitive to reduce index size in the first step (using temporal coalescing), and then to increase it again using the sublist materialization techniques presented in this section. However, we reiterate that our main objective is to improve the efficiency of  processing queries, not to reduce the index size alone. The use of temporal coalescing improves the performance by  reducing the index size, while the sublist materialization improves performance by judiciously replicating entries. Further, the two techniques, can be applied separately and are  independent. If applied in conjunction, though, there is a synergetic effect - sublists that are materialized from a temporally  coalesced index are generally smaller. We employ the notation Lv : [ti, tj) to refer to the  materialized sublist for the time interval [ti, tj), that is formally defined as, Lv : [ti, tj) = {( d, p, [tb, te) ) ∈ Lv | tb < tj ∧ te > ti} . To aid the presentation in the rest of the paper, we first provide some definitions. Let T = t1 . . . tn be the sorted sequence of all unique time-interval boundaries of an  inverted list Lv. Then we define E = { [ti, ti+1) | 1 ≤ i < n} to be the set of elementary time intervals. We refer to the set of time intervals for which sublists are materialized as M ⊆ { [ti, tj) | 1 ≤ i < j ≤ n } , and demand ∀ t ∈ [t1, tn) ∃ m ∈ M : t ∈ m , i.e., the time intervals in M must completely cover the time interval [t1, tn), so that time-travel queries q t for all t ∈ [t1, tn) can be processed. We also assume that  intervals in M are disjoint. We can make this assumption  without ruling out any optimal solution with regard to space or performance defined below. The space required for the materialization of sublists in a set M is defined as S( M ) = X m∈M |Lv : m| , i.e., the total length of all lists in M. Given a set M, we let π( [ti, ti+1) ) = [tj, tk) ∈ M : [ti, ti+1) ⊆ [tj, tk) denote the time interval that is used to process queries q t with t ∈ [ti, ti+1). The performance of processing queries q t for t ∈ [ti, ti+1) inversely depends on its processing cost PC( [ti, ti+1) ) = |Lv : π( [ti, ti+1) )| , which is assumed to be proportional to the length of the list Lv : π( [ti, ti+1) ). Thus, in order to optimize the  performance of processing queries we minimize their processing costs. .1 Performance/Space-Optimal Approaches One strategy to eliminate the problem of skipped  postings is to eagerly materialize sublists for all elementary time intervals, i.e., to choose M = E. In doing so, for every query q t only postings valid at time t are read and thus the best possible performance is achieved. Therefore, we will refer to this approach as Popt in the remainder. The initial approach described above that keeps only the full list Lv and thus picks M = { [t1, tn) } is referred to as Sopt in the remainder. This approach requires minimal space, since it keeps each posting exactly once. Popt and Sopt are extremes: the former provides the best possible performance but is not space-efficient, the latter requires minimal space but does not provide good  performance. The two approaches presented in the rest of this section allow mutually trading off space and performance and can thus be thought of as means to explore the  configuration spectrum between the Popt and the Sopt approach. .2 Performance-Guarantee Approach The Popt approach clearly wastes a lot of space  materializing many nearly-identical sublists. In the example  illustrated in Figure 2 materialized sublists for [t1, t2) and [t2, t3) differ only by one posting. If the sublist for [t1, t3) was materialized instead, one could save significant space while incurring only an overhead of one skipped posting for all t ∈ [t1, t3). The technique presented next is driven by the idea that significant space savings over Popt are  achievable, if an upper-bounded loss on the performance can be tolerated, or to put it differently, if a performance  guarantee relative to the optimum is to be retained. In detail, the technique, which we refer to as PG (Performance  Guarantee) in the remainder, finds a set M that has minimal required space, but guarantees for any elementary time  interval [ti, ti+1) (and thus for any query q t with t ∈ [ti, ti+1)) that performance is worse than optimal by at most a factor of γ ≥ 1. Formally, this problem can be stated as argmin M S( M ) s.t. ∀ [ti, ti+1) ∈ E : PC( [ti, ti+1) ) ≤ γ · |Lv : [ti, ti+1)| . An optimal solution to the problem can be computed by means of induction using the recurrence C( [t1, tk+1) ) = min {C( [t1, tj) ) + |Lv : [tj, tk+1)| | 1 ≤ j ≤ k ∧ condition} , where C( [t1, tj) ) is the optimal cost (i.e., the space  required) for the prefix subproblem { [ti, ti+1) ∈ E | [ti, ti+1) ⊆ [t1, tj) } and condition stands for ∀ [ti, ti+1) ∈ E : [ti, ti+1) ⊆ [tj, tk+1) ⇒ |Lv : [tj, tk+1)| ≤ γ · |Lv : [ti, ti+1)| . Intuitively, the recurrence states that an optimal solution for [t1, tk+1) be combined from an optimal solution to a prefix subproblem C( [t1, tj) ) and a time interval [tj, tk+1) that can be materialized without violating the performance guarantee. Pseudocode of the algorithm is omitted for space reasons, but can be found in the accompanying technical report [5]. The time complexity of the algorithm is in O(n2 ) - for each prefix subproblem the above recurrence must be evaluated, which is possible in linear time if list sizes |L : [ti, tj)| are precomputed. The space complexity is in O(n2 ) - the cost of keeping the precomputed sublist lengths and memoizing optimal solutions to prefix subproblems. .3 Space-Bound Approach So far we considered the problem of materializing sublists that give a guarantee on performance while requiring  minimal space. In many situations, though, the storage space is at a premium and the aim would be to materialize a set of sublists that optimizes expected performance while not  exceeding a given space limit. The technique presented next, which is named SB, tackles this very problem. The space restriction is modeled by means of a user-specified  parameter κ ≥ 1 that limits the maximum allowed blowup in index size from the space-optimal solution provided by Sopt. The SB technique seeks to find a set M that adheres to this space limit but minimizes the expected processing cost (and thus optimizes the expected performance). In the definition of the expected processing cost, P( [ti, ti+1) ) denotes the probability of a query time-point being in [ti, ti+1).  Formally, this space-bound sublist-materialization problem can be stated as argmin M X [ti, ti+1) ∈ E P( [ti, ti+1) ) · PC( [ti, ti+1) ) s.t. X m∈M |Lv : m| ≤ κ |Lv| . The problem can be solved by using dynamic  programming over an increasing number of time intervals: At each time interval in E the algorithms decides whether to start a new materialization time-interval, using the known best  materialization decision from the previous time intervals, and keeping track of the required space consumption for  materialization. A detailed description of the algorithm is omitted here, but can be found in the accompanying technical  report [5]. Unfortunately, the algorithm has time complexity in O(n3 |Lv|) and its space complexity is in O(n2 |Lv|), which is not practical for large data sets. We obtain an approximate solution to the problem  using simulated annealing [22, 23]. Simulated annealing takes a fixed number R of rounds to explore the solution space. In each round a random successor of the current solution is looked at. If the successor does not adhere to the space limit, it is always rejected (i.e., the current solution is kept). A successor adhering to the space limit is always accepted if it achieves lower expected processing cost than the current solution. If it achieves higher expected processing cost, it is randomly accepted with probability e−∆/r where ∆ is the increase in expected processing cost and R ≥ r ≥ 1 denotes the number of remaining rounds. In addition, throughout all rounds, the method keeps track of the best solution seen so far. The solution space for the problem at hand can be efficiently explored. As we argued above, we solely have to look at sets M that completely cover the time interval [t1, tn) and do not contain overlapping time intervals. We represent such a set M as an array of n boolean variables b1 . . . bn that convey the boundaries of time intervals in the set. Note that b1 and bn are always set to true. Initially, all n − 2 intermediate variables assume false, which  corresponds to the set M = { [t1, tn) }. A random successor can now be easily generated by switching the value of one of the n − 2 intermediate variables. The time complexity of the method is in O(n2 ) - the expected processing cost must be computed in each round. Its space complexity is in O(n) - for keeping the n boolean variables. As a side remark note that for κ = 1.0 the SB method does not necessarily produce the solution that is obtained from Sopt, but may produce a solution that requires the same amount of space while achieving better expected  performance. . EXPERIMENTAL EVALUATION We conducted a comprehensive series of experiments on two real-world datasets to evaluate the techniques proposed in this paper. .1 Setup and Datasets The techniques described in this paper were implemented in a prototype system using Java JDK 1.5. All  experiments described below were run on a single SUN V40z  machine having four AMD Opteron CPUs, 16GB RAM, a large network-attached RAID-5 disk array, and running Microsoft Windows Server 2003. All data and indexes are kept in an Oracle 10g database that runs on the same machine. For our experiments we used two different datasets. The English Wikipedia revision history (referred to as WIKI in the remainder) is available for free download as a single XML file. This large dataset, totaling 0.7 TBytes, contains the full editing history of the English Wikipedia from January 2001 to December 2005 (the time of our  download). We indexed all encyclopedia articles excluding  versions that were marked as the result of a minor edit (e.g., the correction of spelling errors etc.). This yielded a total of 92,255 documents with 13,976,915 versions having a mean (µ) of 15.67 versions per document at standard deviation (σ) of 59.18. We built a time-travel query workload using the query log temporarily made available recently by AOL  Research as follows - we first extracted the 300 most frequent keyword queries that yielded a result click on a Wikipedia  article (for e.g., french revolution, hurricane season 2005, da vinci code etc.). The thus extracted queries contained a total of 422 distinct terms. For each extracted query, we randomly picked a time point for each month covered by the dataset. This resulted in a total of 18, 000 (= 300 × 60) time-travel queries. The second dataset used in our experiments was based on a subset of the European Archive [13], containing weekly crawls of 11 .gov.uk websites throughout the years 2004 and 005 amounting close to 2 TBytes of raw data. We filtered out documents not belonging to MIME-types text/plain and text/html, to obtain a dataset that totals 0.4 TBytes and which we refer to as UKGOV in rest of the paper. This included a total of 502,617 documents with 8,687,108  versions (µ = 17.28 and σ = 13.79). We built a corresponding query workload as mentioned before, this time choosing  keyword queries that led to a site in the .gov.uk domain (e.g., minimum wage, inheritance tax , citizenship ceremony dates etc.), and randomly sampling a time point for every month within the two year period spanned by the dataset. Thus, we obtained a total of 7,200 (= 300 × 24) time-travel queries for the UKGOV dataset. In total 522 terms appear in the extracted queries. The collection statistics (i.e., N and avdl) and term  statistics (i.e., DF) were computed at monthly granularity for both datasets. .2 Impact of Temporal Coalescing Our first set of experiments is aimed at evaluating the  approximate temporal coalescing technique, described in  Section 5, in terms of index-size reduction and its effect on the result quality. For both the WIKI and UKGOV datasets, we compare temporally coalesced indexes for different values of the error threshold computed using Algorithm 1 with the non-coalesced index as a baseline. WIKI UKGOV # Postings Ratio # Postings Ratio - 8,647,996,223 100.00% 7,888,560,482 100.00% .00 7,769,776,831 89.84% 2,926,731,708 37.10% .01 1,616,014,825 18.69% 744,438,831 9.44% .05 556,204,068 6.43% 259,947,199 3.30% .10 379,962,802 4.39% 187,387,342 2.38% .25 252,581,230 2.92% 158,107,198 2.00% .50 203,269,464 2.35% 155,434,617 1.97% Table 1: Index sizes for non-coalesced index (-) and coalesced indexes for different values of Table 1 summarizes the index sizes measured as the total number of postings. As these results demonstrate,  approximate temporal coalescing is highly effective in reducing  index size. Even a small threshold value, e.g. = 0.01, has a considerable effect by reducing the index size almost by an order of magnitude. Note that on the UKGOV dataset, even accurate coalescing ( = 0) manages to reduce the index size to less than 38% of the original size. Index size continues to reduce on both datasets, as we increase the value of . How does the reduction in index size affect the query  results? In order to evaluate this aspect, we compared the top-k results computed using a coalesced index against the ground-truth result obtained from the original index, for  different cutoff levels k. Let Gk and Ck be the top-k documents from the ground-truth result and from the coalesced index respectively. We used the following two measures for  comparison: (i) Relative Recall at cutoff level k (RR@k), that measures the overlap between Gk and Ck, which ranges in [0, 1] and is defined as RR@k = |Gk ∩ Ck|/k . (ii) Kendall"s τ (see [7, 14] for a detailed definition) at  cutoff level k (KT@k), measuring the agreement between two results in the relative order of items in Gk ∩ Ck, with value  (or -1) indicating total agreement (or disagreement). Figure 3 plots, for cutoff levels 10 and 100, the mean of RR@k and KT@k along with 5% and 95% percentiles, for different values of the threshold starting from 0.01. Note that for = 0, results coincide with those obtained by the original index, and hence are omitted from the graph. It is reassuring to see from these results that approximate temporal coalescing induces minimal disruption to the query results, since RR@k and KT@k are within reasonable limits. For = 0.01, the smallest value of in our experiments, RR@100 for WIKI is 0.98 indicating that the results are -1 -0.5  .5  ε .01 0.05 0.10 0.25 0.50 Relative Recall @ 10 (WIKI) Kendall's τ @ 10 (WIKI) Relative Recall @ 10 (UKGOV) Kendall's τ @ 10 (UKGOV) (a) @10 -1 -0.5  .5  ε .01 0.05 0.10 0.25 0.50 Relative Recall @ 100 (WIKI) Kendall's τ @ 100 (WIKI) Relative Recall @ 100 (UKGOV) Kendall's τ @ 100 (UKGOV) (b) @100 Figure 3: Relative recall and Kendall"s τ observed on coalesced indexes for different values of almost indistinguishable from those obtained through the original index. Even the relative order of these common results is quite high, as the mean KT@100 is close to 0.95. For the extreme value of = 0.5, which results in an index size of just 2.35% of the original, the RR@100 and KT@100 are about 0.8 and 0.6 respectively. On the relatively less dynamic UKGOV dataset (as can be seen from the σ values above), results were even better, with high values of RR and KT seen throughout the spectrum of values for both cutoff values. .3 Sublist Materialization We now turn our attention towards evaluating the  sublist materialization techniques introduced in Section 6. For both datasets, we started with the coalesced index produced by a moderate threshold setting of = 0.10. In order to reduce the computational effort, boundaries of elementary time intervals were rounded to day granularity before  computing the sublist materializations. However, note that the postings in the materialized sublists still retain their  original timestamps. For a comparative evaluation of the four approaches - Popt, Sopt, PG, and SB - we measure space and performance as follows. The required space S(M), as defined earlier, is equal to the total number of postings in the materialized sublists. To assess performance we  compute the expected processing cost (EPC) for all terms in the respective query workload assuming a uniform  probability distribution among query time-points. We report the mean EPC, as well as the 5%- and 95%-percentile. In other words, the mean EPC reflects the expected length of the  index list (in terms of index postings) that needs to be scanned for a random time point and a random term from the query workload. The Sopt and Popt approaches are, by their definition, parameter-free. For the PG approach, we varied its  parameter γ, which limits the maximal performance degradation, between 1.0 and 3.0. Analogously, for the SB approach the parameter κ, as an upper-bound on the allowed space blowup, was varied between 1.0 and 3.0. Solutions for the SB approach were obtained running simulated annealing for R = 50, 000 rounds. Table 2 lists the obtained space and performance figures. Note that EPC values are smaller on WIKI than on  UKGOV, since terms in the query workload employed for WIKI are relatively rarer in the corpus. Based on the depicted results, we make the following key observations. i) As  expected, Popt achieves optimal performance at the cost of an enormous space consumption. Sopt, to the contrary, while consuming an optimal amount of space, provides only poor expected processing cost. The PG and SB methods, for different values of their respective parameter, produce  solutions whose space and performance lie in between the  extremes that Popt and Sopt represent. ii) For the PG method we see that for an acceptable performance degradation of only 10% (i.e., γ = 1.10) the required space drops by more than one order of magnitude in comparison to Popt on both datasets. iii) The SB approach achieves close-to-optimal performance on both datasets, if allowed to consume at most three times the optimal amount of space (i.e., κ = 3.0), which on our datasets still corresponds to a space reduction over Popt by more than one order of magnitude. We also measured wall-clock times on a sample of the queries with results indicating improvements in execution time by up to a factor of 12. . CONCLUSIONS In this work we have developed an efficient solution for time-travel text search over temporally versioned document collections. Experiments on two real-world datasets showed that a combination of the proposed techniques can reduce index size by up to an order of magnitude while achieving nearly optimal performance and highly accurate results. The present work opens up many interesting questions for future research, e.g.: How can we even further improve performance by applying (and possibly extending) encoding, compression, and skipping techniques [35]?. How can we extend the approach for queries q [tb, te] specifying a time interval instead of a time point? How can the described time-travel text search functionality enable or speed up text mining along the time axis (e.g., tracking sentiment changes in customer opinions)? . ACKNOWLEDGMENTS We are grateful to the anonymous reviewers for their  valuable comments - in particular to the reviewer who pointed out the opportunity for algorithmic improvements in  Section 5 and Section 6.2. 0. REFERENCES [1] V. N. Anh and A. Moffat. Pruned Query Evaluation Using Pre-Computed Impacts. In SIGIR, 2006. [2] V. N. Anh and A. Moffat. Pruning Strategies for Mixed-Mode Querying. In CIKM, 2006. WIKI UKGOV S(M) EPC S(M) EPC % Mean 95% 5% Mean 95% Popt 54,821,634,137 11.22 3,132.29 15,658.42 21,372,607,052 39.93 15,593.60 66,938.86 Sopt 379,962,802 114.05 30,186.52 149,820.1 187,387,342 63.15 22,852.67 102,923.85 PG γ = 1.10 3,814,444,654 11.30 3,306.71 16,512.88 1,155,833,516 40.66 16,105.61 71,134.99 PG γ = 1.25 1,827,163,576 12.37 3,629.05 18,120.86 649,884,260 43.62 17,059.47 75,749.00 PG γ = 1.50 1,121,661,751 13.96 4,128.03 20,558.60 436,578,665 46.68 18,379.69 78,115.89 PG γ = 1.75 878,959,582 15.48 4,560.99 22,476.77 345,422,898 51.26 19,150.06 82,028.48 PG γ = 2.00 744,381,287 16.79 4,992.53 24,637.62 306,944,062 51.48 19,499.78 87,136.31 PG γ = 2.50 614,258,576 18.28 5,801.66 28,849.02 269,178,107 53.36 20,279.62 87,897.95 PG γ = 3.00 552,796,130 21.04 6,485.44 32,361.93 247,666,812 55.95 20,800.35 89,591.94 SB κ = 1.10 412,383,387 38.97 12,723.68 60,350.60 194,287,671 63.09 22,574.54 102,208.58 SB κ = 1.25 467,537,173 26.87 9,011.81 45,119.08 204,454,800 57.42 22,036.39 95,337.33 SB κ = 1.50 557,341,140 19.84 6,699.36 32,810.85 246,323,383 53.24 20,566.68 91,691.38 SB κ = 1.75 647,187,522 16.59 5,769.40 28,272.89 296,345,976 49.56 19,065.99 84,377.44 SB κ = 2.00 737,819,354 15.86 5,358.99 27,112.01 336,445,773 47.58 18,569.08 81,386.02 SB κ = 2.50 916,308,766 13.99 4,639.77 23,037.59 427,122,038 44.89 17,153.94 74,449.28 SB κ = 3.00 1,094,973,140 13.01 4,343.72 22,708.37 511,470,192 42.15 16,772.65 72,307.43 Table 2: Required space and expected processing cost (in # postings) observed on coalesced indexes ( = 0.10) [3] P. G. Anick and R. A. Flynn. Versioning a Full-Text Information Retrieval System. In SIGIR, 1992. [4] R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley, 1999. [5] K. Berberich, S. Bedathur, T. Neumann, and G. Weikum. A Time Machine for Text search. Technical Report MPI-I-2007-5-002, Max-Planck Institute for Informatics, 2007. [6] M. H. B¨ohlen, R. T. Snodgrass, and M. D. Soo. Coalescing in Temporal Databases. In VLDB, 1996. [7] P. Boldi, M. Santini, and S. Vigna. Do Your Worst to Make the Best: Paradoxical Effects in PageRank Incremental Computations. In WAW, 2004. [8] A. Z. Broder, N. Eiron, M. Fontoura, M. Herscovici, R. Lempel, J. McPherson, R. Qi, and E. J. Shekita. Indexing Shared Content in Information Retrieval Systems. In EDBT, 2006. [9] C. Buckley and A. F. Lewit. Optimization of Inverted Vector Searches. In SIGIR, 1985. [10] M. Burrows and A. L. Hisgen. Method and Apparatus for Generating and Searching Range-Based Index of Word Locations. U.S. Patent 5,915,251, 1999. [11] S. B¨uttcher and C. L. A. Clarke. A Document-Centric Approach to Static Index Pruning in Text Retrieval Systems. In CIKM, 2006. [12] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer. Static Index Pruning for Information Retrieval Systems. In SIGIR, 2001. [13] http://www.europarchive.org. [14] R. Fagin, R. Kumar, and D. Sivakumar. Comparing Top k Lists. SIAM J. Discrete Math., 17(1):134-160, 003. [15] R. Fagin, A. Lotem, and M. Naor. Optimal Aggregation Algorithms for Middleware. J. Comput. Syst. Sci., 66(4):614-656, 2003. [16] S. Guha, K. Shim, and J. Woo. REHIST: Relative Error Histogram Construction Algorithms. In VLDB, 004. [17] M. Hersovici, R. Lempel, and S. Yogev. Efficient Indexing of Versioned Document Sequences. In ECIR, 007. [18] http://www.archive.org. [19] Y. E. Ioannidis and V. Poosala. Balancing Histogram Optimality and Practicality for Query Result Size Estimation. In SIGMOD, 1995. [20] H. V. Jagadish, N. Koudas, S. Muthukrishnan, V. Poosala, K. C. Sevcik, and T. Suel. Optimal Histograms with Quality Guarantees. In VLDB, 1998. [21] E. J. Keogh, S. Chu, D. Hart, and M. J. Pazzani. An Online Algorithm for Segmenting Time Series. In ICDM, 2001. [22] S. Kirkpatrick, D. G. Jr., and M. P. Vecchi. Optimization by Simulated Annealing. Science, 20(4598):671-680, 1983. [23] J. Kleinberg and E. Tardos. Algorithm Design. Addison-Wesley, 2005. [24] U. Manber. Introduction to Algorithms: A Creative Approach. Addison-Wesley, 1989. [25] K. Nørv˚ag and A. O. N. Nybø. DyST: Dynamic and Scalable Temporal Text Indexing. In TIME, 2006. [26] J. M. Ponte and W. B. Croft. A Language Modeling Approach to Information Retrieval. In SIGIR, 1998. [27] S. E. Robertson and S. Walker. Okapi/Keenbow at TREC-8. In TREC, 1999. [28] B. Salzberg and V. J. Tsotras. Comparison of Access Methods for Time-Evolving Data. ACM Comput. Surv., 31(2):158-221, 1999. [29] M. Stack. Full Text Search of Web Archive Collections. In IWAW, 2006. [30] E. Terzi and P. Tsaparas. Efficient Algorithms for Sequence Segmentation. In SIAM-DM, 2006. [31] M. Theobald, G. Weikum, and R. Schenkel. Top-k Query Evaluation with Probabilistic Guarantees. In VLDB, 2004. [32] http://www.wikipedia.org. [33] I. H. Witten, A. Moffat, and T. C. Bell. Managing Gigabytes: Compressing and Indexing Documents and Images. Morgan Kaufmann publishers Inc., 1999. [34] J. Zhang and T. Suel. Efficient Search in Large Textual Collections with Redundancy. In WWW, 007. [35] J. Zobel and A. Moffat. Inverted Files for Text Search Engines. ACM Comput. Surv., 38(2):6, 2006.
Query Performance Prediction in Web Search Environments Yun Zhou and W. Bruce Croft Department of Computer Science University of Massachusetts, Amherst {yzhou, croft}@cs.umass.edu ABSTRACT Current prediction techniques, which are generally designed for content-based queries and are typically evaluated on relatively homogenous test collections of small sizes, face serious challenges in web search environments where collections are significantly more heterogeneous and different types of retrieval tasks exist. In this paper, we present three techniques to address these challenges. We focus on performance prediction for two types of queries in web search environments: content-based and Named-Page finding. Our evaluation is mainly performed on the GOV2 collection. In addition to evaluating our models for the two types of queries separately, we consider a more challenging and realistic situation that the two types of queries are mixed together without prior information on query types. To assist prediction under the mixed-query situation, a novel query classifier is adopted. Results show that our prediction of web query performance is substantially more accurate than the current  stateof-the-art prediction techniques. Consequently, our paper provides a practical approach to performance prediction in  realworld web settings. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval -Query formulation General Terms Algorithms, Experimentation, Theory . INTRODUCTION Query performance prediction has many applications in a variety of information retrieval (IR) areas such as improving retrieval consistency, query refinement, and distributed IR. The importance of this problem has been recognized by IR researchers and a number of new methods have been proposed for prediction recently [1, 2, 17]. Most work on prediction has focused on the traditional ad-hoc retrieval task where query performance is measured according to topical relevance. These prediction models are evaluated on TREC document collections which typically consist of no more than one million relatively homogenous newswire articles. With the popularity and influence of the Web, prediction techniques that will work well for web-style queries are highly preferable. However, web search environments pose significant challenges to current prediction models that are mainly designed for traditional TREC settings. Here we outline some of these challenges. First, web collections, which are much larger than conventional TREC collections, include a variety of documents that are different in many aspects such as quality and style. Current prediction techniques can be vulnerable to these characteristics of web collections. For example, the reported prediction accuracy of the ranking robustness technique and the clarity technique on the GOV2 collection (a large web collection) is significantly worse compared to the other TREC collections [1]. Similar prediction accuracy on the GOV2 collection using another technique is reported in [2], confirming the difficult of predicting query performance on a large web collection. Furthermore, web search goes beyond the scope of the ad-hoc retrieval task based on topical relevance. For example, the Named-Page (NP) finding task, which is a navigational task, is also popular in web retrieval. Query performance prediction for the NP task is still necessary since NP retrieval performance is far from perfect. In fact, according to the report on the NP task of the 005 Terabyte Track [3], about 40% of the test queries perform poorly (no correct answer in the first 10 search results) even in the best run from the top group. To our knowledge, little research has explicitly addressed the problem of NP-query performance prediction. Current prediction models devised for content-based queries will be less effective for NP queries considering the fundamental differences between the two. Third, in real-world web search environments, user queries are usually a mixture of different types and prior knowledge about the type of each query is generally unavailable. The mixed-query situation raises new problems for query performance prediction. For instance, we may need to incorporate a query classifier into prediction models. Despite these problems, the ability to handle this situation is a crucial step towards turning query performance prediction from an interesting research topic into a practical tool for web retrieval. In this paper, we present three techniques to address the above challenges that current prediction models face in Web search environments. Our work focuses on query performance prediction for the content-based (ad-hoc) retrieval task and the name-page finding task in the context of web retrieval. Our first technique, called weighted information gain (WIG), makes use of both single term and term proximity features to estimate the quality of top retrieved documents for prediction. We find that WIG offers consistent prediction accuracy across various test collections and query types. Moreover, we demonstrate that good prediction accuracy can be achieved for the mixed-query situation by using WIG with the help of a query type classifier. Query feedback and first rank change, which are our second and third prediction techniques, perform well for content-based queries and NP queries respectively. Our main contributions include: (1) considerably improved prediction accuracy for web content-based queries over several state-of-the-art techniques. (2) new techniques for successfully predicting NP-query performance. (3) a practical and fully automatic solution to predicting mixed-query performance. In addition, one minor contribution is that we find that the robustness score [1], which was originally proposed for performance prediction, is helpful for query classification. . RELATED WORK As we mentioned in the introduction, a number of prediction techniques have been proposed recently that focus on  contentbased queries in the topical relevance (ad-hoc) task. We know of no published work that addresses other types of queries such as NP queries, let alone a mixture of query types. Next we review some representative models. The major difficulty of performance prediction comes from the fact that many factors have an impact on retrieval performance. Each factor affects performance to a different degree and the overall effect is hard to predict accurately. Therefore, it is not surprising to notice that simple features, such as the frequency of query terms in the collection [4] and the average IDF of query terms [5], do not predict well. In fact, most of the successful techniques are based on measuring some characteristics of the retrieved document set to estimate topic difficulty. For example, the clarity score [6] measures the coherence of a list of documents by the KL-divergence between the query model and the collection model. The robustness score [1] quantifies another property of a ranked list: the robustness of the ranking in the presence of uncertainty. Carmel et al. [2] found that the distance measured by the Jensen-Shannon divergence between the retrieved document set and the collection is significantly correlated to average precision. Vinay et al.[7] proposed four measures to capture the geometry of the top retrieved documents for prediction. The most effective measure is the sensitivity to document perturbation, an idea somewhat similar to the robustness score. Unfortunately, their way of measuring the sensitivity does not perform equally well for short queries and prediction accuracy drops considerably when a state-of-the-art retrieval technique (like Okapi or a language modeling approach) is adopted for retrieval instead of the tf-idf weighting used in their paper [16]. The difficulties of applying these models in web search environments have already been mentioned. In this paper, we mainly adopt the clarity score and the robustness score as our baselines. We experimentally show that the baselines, even after being carefully tuned, are inadequate for the web environment. One of our prediction models, WIG, is related to the Markov random field (MRF) model for information retrieval [8]. The MRF model directly models term dependence and is found be to highly effective across a variety of test collections (particularly web collections) and retrieval tasks. This model is used to estimate the joint probability distribution over documents and queries, an important part of WIG. The superiority of WIG over other prediction techniques based on unigram features, which will be demonstrated later in our paper, coincides with that of MRF for retrieval. In other word, it is interesting to note that term dependence, when being modeled appropriately, can be helpful for both improving and predicting retrieval performance. . PREDICTION MODELS .1 Weighted Information Gain (WIG) This section introduces a weighted information gain approach that incorporates both single term and proximity features for predicting performance for both content-based and Named-Page (NP) finding queries. Given a set of queries Q={Qs} (s=1,2,..N) which includes all possible user queries and a set of documents D={Dt} (t=1,2…M), we assume that each query-document pair (Qs,Dt) is manually judged and will be put in a relevance list if Qs is found to be relevant to Dt. The joint probability P(Qs,Dt) over queries Q and documents D denotes the probability that pair (Qs,Dt) will be in the relevance list. Such assumptions are similar to those used in [8]. Assuming that the user issues query Qi ∈Q and the retrieval results in response to Qi is a ranked list L of documents, we calculate the amount of information contained in P(Qs,Dt) with respect to Qi and L by Eq.1 which is a variant of entropy called the weighted entropy[13]. The weights in Eq.1 are solely determined by Qi and L. )1(),(log),(),( , , ∑−= ts tststsLQ DQPDQweightDQH i In this paper, we choose the weights as follows: LindocumentsKtopthecontainsLTwhere otherwise LTDandisifK DQweight K Kt ts )( )2( ,0 )(,/1 ),( ⎩ ⎨ ⎧ ∈= = The cutoff rank K is a parameter in our model that will be discussed later. Accordingly, Eq.1 can be simplified as follows: )3(),(log  ),( )( , ∑∈ −= LTD titsLQ Kt i DQP K DQH Unfortunately, weighted entropy ),(, tsLQ DQH i computed by Eq.3, which represents the amount of information about how likely the top ranked documents in L would be relevant to query Qi on average, cannot be compared across different queries, making it inappropriate for directly predicting query performance. To mitigate this problem, we come up with a background distribution P(Qs,C) over Q and D by imagining that every document in D is replaced by the same special document C which represents average language usage. In this paper, C is created by concatenating every document in D. Roughly speaking, C is the collection (the document set) {Dt} without document boundaries. Similarly, weighted entropy ),(, CQH sLQi calculated by Eq.3 represents the amount of information about how likely an average document (represented by the whole collection) would be relevant to query Qi. Now we introduce our performance predictor WIG which is the weighted information gain [13] computed as the difference between ),(, tsLQ DQH i and ),(, CQH sLQi .Specifically, given query Qi, collection C and ranked list L of documents, WIG is calculated as follows: )4( ),( ),( log  ),( ),( log),( ),(),(),,( )(, ,, ∑∑ ∈ == −= LTD i ti ts s ts ts tsLQsLQi Kt ii CQP DQP KCQP DQP DQweight DQHCQHLCQWIG WIG computed by Eq.4 measures the change in information about the quality of retrieval (in response to query Qi) from an imaginary state that only an average document is retrieved to a posterior state that the actual search results are observed. We hypothesize that WIG is positively correlated with retrieval effectiveness because high quality retrieval should be much more effective than just returning the average document. The heart of this technique is how to estimate the joint distribution P(Qs,Dt). In the language modeling approach to IR, a variety of models can be applied readily to estimate this distribution. Although most of these models are based on the  bagof-words assumption, recent work on modeling term dependence under the language modeling framework have shown consistent and significant improvements in retrieval effectiveness over  bagof-words models. Inspired by the success of incorporating term proximity features into language models, we decide to adopt a good dependence model to estimate the probability P(Qs,Dt). The model we chose for this paper is Metzler and Croft"s Markov Random Field (MRF) model, which has already demonstrated superiority over a number of collections and different retrieval tasks [8,9]. According to the MRF model, log P(Qi, Dt) can be written as )5()|(loglog),(log )(  ∑∈ +−= iQF tti DPZDQP ξ ξ ξλ where Z1 is a constant that ensures that P(Qi, Dt) sums up to 1. F(Qi) consists of a set of features expanded from the original query Qi . For example, assuming that query Qi is talented student program, F(Qi) includes features like program and talented student. We consider two kinds of features: single term features T and proximity features P. Proximity features include exact phrase (#1) and unordered window (#uwN) features as described in [8]. Note that F(Qi) is the union of T(Qi) and P(Qi). For more details on F(Qi) such as how to expand the original query Qi to F(Qi), we refer the reader to [8] and [9]. P(ξ|Dt) denotes the probability that feature ξ will occur in Dt. More details on P(ξ|Dt) will be provided later in this section. The choice of λξ is somewhat different from that used in [8] since λξ plays a dual role in our model. The first role, which is the same as in [8], is to weight between single term and proximity features. The other role, which is specific to our prediction task, is to normalize the size of F(Qi).We found that the following weight strategy for λξ satisfies the above two roles and generalizes well on a variety of collections and query types. )6( )(, |)(|  )(, |)(| ⎪ ⎪ ⎩ ⎪ ⎪ ⎨ ⎧ ∈ − ∈ = i i T i i T QP QP QT QT ξ λ ξ λ λξ where |T(Qi)| and |P(Qi)| denote the number of single term and proximity features in F(Qi) respectively. The reason for choosing the square root function in the denominator of λξ is to penalize a feature set of large size appropriately, making WIG more comparable across queries of various lengths. λT is a fixed parameter and set to 0.8 according to [8] throughout this paper. Similarly, log P(Qi,C) can be written as: )7()|(loglog),(log )(  ∑∈ +−= iQF i CPZCQP ξ ξ ξλ When constant Z1 and Z2 are dropped, WIG computed in Eq.4 can be rewritten as follows by plugging in Eq.5 and Eq.7 : )8( )|( )|( log  ),,( )( )( ∑ ∑∈ ∈ = LTD QF t i Kt i CP DP K LCQWIG ξ ξ ξ ξ λ One of the advantages of WIG over other techniques is that it can handle well both content-based and NP queries. Based on the type (or the predicted type) of Qi, the calculation of WIG in Eq. 8 differs in two aspects: (1) how to estimate P(ξ|Dt) and P(ξ|C), and (2) how to choose K. For content-based queries, P(ξ|C) is estimated by the relative frequency of feature ξ in collection C as a whole. The estimation of P(ξ|Dt) is the same as in [8]. Namely, we estimate P(ξ|Dt) by the relative frequency of feature ξ in Dt linearly smoothed with collection frequency P(ξ|C). K in Eq.8 is treated as a free parameter. Note that K is the only free parameter in the computation of WIG for content-based queries because all parameters involved in P(ξ|Dt) are assumed to be fixed by taking the suggested values in [8]. Regarding NP queries, we make use of document structure to estimate P(ξ|Dt) and P(ξ|C) by the so-called mixture of language models proposed in [10] and incorporated into the MRF model for Named-Page finding retrieval in [9]. The basic idea is that a document (collection) is divided into several fields such as the title field, the main-body field and the heading field. P(ξ|Dt) and P(ξ|C) are estimated by a linear combination of the language models from each field. Due to space constraints, we refer the reader to [9] for details. We adopt the exact same set of parameters as used in [9] for estimation. With regard to K in Eq.8, we set K to 1 because the Named-Page finding task heavily focuses on the first ranked document. Consequently, there are no free parameters in the computation of WIG for NP queries. .2 Query Feedback In this section, we introduce another technique called query feedback (QF) for prediction. Suppose that a user issues query Q to a retrieval system and a ranked list L of documents is returned. We view the retrieval system as a noisy channel. Specifically, we assume that the output of the channel is L and the input is Q. After going through the channel, Q becomes corrupted and is transformed to ranked list L. By thinking about the retrieval process this way, the problem of predicting retrieval effectiveness turns to the task of evaluating the quality of the channel. In other words, prediction becomes finding a way to measure the degree of corruption that arises when Q is transformed to L. As directly computing the degree of the corruption is difficult, we tackle this problem by approximation. Our main idea is that we measure to what extent information on Q can be recovered from L on the assumption that only L is observed. Specifically, we design a decoder that can accurately translate L back into new query Q" and the similarity S between the original query Q and the new query Q" is adopted as a performance predictor. This is a sketch of how the QF technique predicts query performance. Before filling in more details, we briefly discuss why this method would work. There is a relation between the similarity S defined above and retrieval performance. On the one hand, if the retrieval has strayed from the original sense of the query Q, the new query Q" extracted from ranked list L in response to Q would be very different from the original query Q. On the other hand, a query distilled from a ranked list containing many relevant documents is likely to be similar to the original query. Further examples in support of the relation will be provided later. Next we detail how to build the decoder and how to measure the similarity S. In essence, the goal of the decoder is to compress ranked list L into a few informative terms that should represent the content of the top ranked documents in L. Our approach to this goal is to represent ranked list L by a language model (distribution over terms). Then terms are ranked by their contribution to the language model"s KL (Kullback-Leibler) divergence from the background collection model. Top ranked terms will be chosen to form the new query Q". This approach is similar to that used in Section 4.1 of [11]. Specifically, we take three steps to compress ranked list L into query Q" without referring to the original query. . We adopt the ranked list language model [14], to estimate a language model based on ranked list L. The model can be written as: )9()|()|()|( ∑∈ = LD LDPDwPLwP where w is any term, D is a document. P(D|L) is estimated by a linearly decreasing function of the rank of document D. . Each term in P(w|L) is ranked by the following KL-divergence contribution: )10( )|( )|( log)|( CwP LwP LwP where P(w|C) is the collection model estimated by the relative frequency of term w in collection C as a whole. . The top N ranked terms by Eq.10 form a weighted query Q"={(wi,ti)} i=1,N. where wi denotes the i-th ranked term and weight ti is the KL-divergence contribution of wi in Eq. 10. Term cruise ship vessel sea passenger KL contribution .050 0.040 0.012 0.010 0.009 Table 1: top 5 terms compressed from the ranked list in response to query Cruise ship damage sea life Two representative examples, one for a poorly performing query Cruise ship damage sea life (TREC topic 719; average precision: 0.08) and the other for a high performing query prostate cancer treatments( TREC topic 710; average precision: .49), are shown in Table 1 and 2 respectively. These examples indicate how the similarity between the original and the new query correlates with retrieval performance. The parameter N in step 3 is set to 20 empirically and choosing a larger value of N is unnecessary since the weights after the top 20 are usually too small to make any difference. Term prostate cancer treatment men therapy KL contribution .177 0.140 0.028 0.025 0.020 Table 2: top 5 terms compressed from the ranked list in response to query prostate cancer treatments To measure the similarity between original query Q and new query Q", we first use Q" to do retrieval on the same collection. A variant of the query likelihood model [15] is adopted for retrieval. Namely, documents are ranked by: )11()|()|'( '),( ∑∈ = Qtw t i ii i DwPDQP where wi is a term in Q" and ti is the associated weight. D is a document. Let L" denote the new ranked list returned from the above retrieval. The similarity is measured by the overlap of documents in L and L". Specifically, the percentage of documents in the top K documents of L that are also present in the top K documents in L". the cutoff K is treated as a free parameter. We summarize here how the QF technique predicts performance given a query Q and the associated ranked list L. We first obtain a weighted query Q" compressed from L by the above three steps. Then we use Q" to perform retrieval and the new ranked list is L". The overlap of documents in L and L" is used for prediction. .3 First Rank Change (FRC) In this section, we propose a method called the first rank change (FRC) for performance prediction for NP queries. This method is derived from the ranking robustness technique [1] that is mainly designed for content-based queries. When directly applied to NP queries, the robustness technique will be less effective because it takes the top ranked documents as a whole into account while NP queries usually have only one single relevant document. Instead, our technique focuses on the first rank document while the main idea of the robustness method remains. Specifically, the  pseudocode for computing FRC is shown in figure 1. Input: (1) ranked list L={Di} where i=1,100. Di denotes the i-th ranked document. (2) query Q  initialize: (1) set the number of trials J=100000 (2) counter c=0;  for i=1 to J  Perturb every document in L, let the outcome be a set F={Di"} where Di" denotes the perturbed version of Di.  Do retrieval with query Q on set F  c=c+1 if and only if D1" is ranked first in step 4  end of for  return the ratio c/J Figure 1: pseudo-code for computing FRC FRC approximates the probability that the first ranked document in the original list L will remain ranked first even after the documents are perturbed. The higher the probability is, the more confidence we have in the first ranked document. On the other hand, in the extreme case of a random ranking, the probability would be as low as 0.5. We expect that FRC has a positive association with NP query performance. We adopt [1] to implement the document perturbation step (step 4 in Fig.1) using Poisson distributions. For more details, we refer the reader to [1]. . EVALUATION We now present the results of predicting query performance by our models. Three state-of-the-art techniques are adopted as our baselines. We evaluate our techniques across a variety of Web retrieval settings. As mentioned before, we consider two types of queries, that is, content-based (CB) queries and Named-Page(NP) finding queries. First, suppose that the query types are known. We investigate the correlation between the predicted retrieval performance and the actual performance for both types of queries separately. Results show that our methods yield considerable improvements over the baselines. We then consider a more challenging scenario where no prior information on query types is available. Two sub-cases are considered. In the first one, there exists only one type of query but the actual type is unknown. We assume a mixture of the two query types in the second case. We demonstrate that our models achieve good accuracy under this demanding scenario, making prediction practical in a real-world Web search environment. .1 Experimental Setup Our evaluation focuses on the GOV2 collection which contains about 25 million documents crawled from web sites in the .gov domain during 2004 [3]. We create two kinds of data set for CB queries and NP queries respectively. For the CB type, we use the ad-hoc topics of the Terabyte Tracks of 2004, 2005 and 2006 and name them TB04-adhoc, TB05-adhoc and TB06-adhoc respectively. In addition, we also use the ad-hoc topics of the 004 Robust Track (RT04) to test the adaptability of our techniques to a non-Web environment. For NP queries, we use the Named-Page finding topics of the Terabyte Tracks of 2005 and 006 and we name them TB05-NP and TB06-NP respectively. All queries used in our experiments are titles of TREC topics as we center on web retrieval. Table 3 summarizes the above data sets. Name Collection Topic Number Query Type TB04-adhoc GOV2 701-750 CB TB05-adhoc GOV2 751-800 CB TB06-adhoc GOV2 801-850 CB RT04 Disk 4+5 (minus CR)  01-450;601700 CB TB05-NP GOV2 NP601-NP872 NP TB06-NP GOV2 NP901-NP1081 NP Table 3: Summary of test collections and topics Retrieval performance of individual content-based and NP queries is measured by the average precision and reciprocal rank of the first correct answer respectively. We make use of the Markov Random field model for both ad-hoc and Named-Page finding retrieval. We adopt the same setting of retrieval parameters used in [8,9]. The Indri search engine [12] is used for all of our experiments. Though not reported here, we also tried the query likelihood model for ad-hoc retrieval and found that the results change little because of the very high correlation between the query performances obtained by the two retrieval models (0.96 measured by Pearson"s coefficient). .2 Known Query Types Suppose that query types are known. We treat each type of query separately and measure the correlation with average precision (or the reciprocal rank in the case of NP queries). We adopt the Pearson"s correlation test which reflects the degree of linear relationship between the predicted and the actual retrieval performance. .2.1 Content-based Queries Methods Clarity Robust JSD WIG QF WIG +QF TB04+0  adhoc .333 0.317 0.362 0.574 0.480 0.637 TB06 adhoc .076 0.294 N/A 0.464 0.422 0.511 Table 4: Pearson"s correlation coefficients for correlation with average precision on the Terabyte Tracks (ad-hoc) for clarity score, robustness score, the JSD-based method(we directly cites the score reported in [2]), WIG, query feedback(QF) and a linear combination of WIG and QF. Bold cases mean the results are statistically significant at the 0.01 level. Table 4 shows the correlation with average precision on two data sets: one is a combination of TB04-adhoc and TB05-adhoc(100 topics in total) and the other is TB06-adhoc (50 topics). The reason that we put TB04-adhoc and TB05-adhoc together is to make our results comparable to [2]. Our baselines are the clarity score (clarity) [6],the robustness score (robust)[1] and the  JSDbased method (JSD) [2]. For the clarity and robustness score, we have tried different parameter settings and report the highest correlation coefficients we have found. We directly cite the result of the JSD-based method reported in [2]. The table also shows the results for the Weighted Information Gain (WIG) method and the Query Feedback (QF) method for predicting content-based queries. As we described in the previous section, both WIG and QF have one free parameter to set, that is, the cutoff rank K. We train the parameter on one dataset and test on the other. When combining WIG and QF, a simple linear combination is used and the combination weight is learned from the training data set. From these results, we can see that our methods are considerably more accurate compared to the baselines. We also observe that further improvements are obtained from the combination of WIG and QF, suggesting that they measure different properties of the retrieval process that relate to performance. We discover that our methods generalize well on TB06-adhoc while the correlation for the clarity score with retrieval performance on this data set is considerably worse. Further investigation shows that the mean average precision of  TB06-adhoc is 0.342 and is about 10% better than that of the first data set. While the other three methods typically consider the top 100 or less documents given a ranked list, the clarity method usually needs the top 500 or more documents to adequately measure the coherence of a ranked list. Higher mean average precision makes ranked lists retrieved by different queries more similar in terms of coherence at the level of top 500 documents. We believe that this is the main reason for the low accuracy of the clarity score on the second data set. Though this paper focuses on a Web search environment, it is desirable that our techniques will work consistently well in other situations. To this end, we examine the effectiveness of our techniques on the Robust 2004 Track. For our methods, we evenly divide all of the test queries into five groups and perform five-fold cross validation. Each time we use one group for training and the remaining four groups for testing. We make use of all of the queries for our two baselines, that is, the clarity score and the robustness score. The parameters for our baselines are the same as those used in [1].The results shown in Table 5 demonstrate that the prediction accuracy of our methods is on a par with that of the two strong baselines. Clarity Robust WIG QF .464 0.539 0.468 0.464 Table 5: Comparison of Pearson"s correlation coefficients on the 2004 Robust Track for clarity score, robustness score, WIG and query feedback (QF). Bold cases mean the results are statistically significant at the 0.01 level. Furthermore, we examine the prediction sensitivity of our methods to the cutoff rank K. With respect to WIG, it is quite robust to K on the Terabyte Tracks (2004-2006) while it prefers a small value of K like 5 on the 2004 Robust Track. In other words, a small value of K is a nearly-optimal choice for both kinds of tracks. Considering the fact that all other parameters involved in WIG are fixed and consequently the same for the two cases, this means WIG can achieve nearly-optimal prediction accuracy in two considerably different situations with exactly the same parameter setting. Regarding QF, it prefers a larger value of K such as 100 on the Terabyte Tracks and a smaller value of K such as 25 on the 2004 Robust Track. .2.2 NP Queries We adopt WIG and first rank change (FRC) for predicting  NPquery performance. We also try a linear combination of the two as in the previous section. The combination weight is obtained from the other data set. We use the correlation with the reciprocal ranks measured by the Pearson"s correlation test to evaluate prediction quality. The results are presented in Table 6. Again, our baselines are the clarity score and the robustness score. To make a fair comparison, we tune the clarity score in different ways. We found that using the first ranked document to build the query model yields the best prediction accuracy. We also attempted to utilize document structure by using the mixture of language models mentioned in section 3.1. Little improvement was obtained. The correlation coefficients for the clarity score reported in Table 6 are the best we have found. As we can see, our methods considerably outperform the clarity score technique on both of the runs. This confirms our intuition that the use of a coherence-based measure like the clarity score is inappropriate for NP queries. Methods Clarity Robust. WIG FRC WIG+FRC TB05-NP 0.150 -0.370 0.458 0.440 0.525 TB06-NP 0.112 -0.160 0.478 0.386 0.515 Table 6: Pearson"s correlation coefficients for correlation with reciprocal ranks on the Terabyte Tracks (NP) for clarity score, robustness score, WIG, the first rank change (FRC) and a linear combination of WIG and FRC. Bold cases mean the results are statistically significant at the 0.01 level. Regarding the robustness score, we also tune the parameters and report the best we have found. We observe an interesting and surprising negative correlation with reciprocal ranks. We explain this finding briefly. A high robustness score means that a number of top ranked documents in the original ranked list are still highly ranked after perturbing the documents. The existence of such documents is a good sign of high performance for content-based queries as these queries usually contain a number of relevant documents [1]. However, with regard to NP queries, one fundamental difference is that there is only one relevant document for each query. The existence of such documents can confuse the ranking function and lead to low retrieval performance. Although the negative correlation with retrieval performance exists, the strength of the correlation is weaker and less consistent compared to our methods as shown in Table 6. Based on the above analysis, we can see that current prediction techniques like clarity score and robustness score that are mainly designed for content-based queries face significant challenges and are inadequate to deal with NP queries. Our two techniques proposed for NP queries consistently demonstrate good prediction accuracy, displaying initial success in solving the problem of predicting performance for NP queries. Another point we want to stress is that the WIG method works well for both types of queries, a desirable property that most prediction techniques lack. .3 Unknown Query Types In this section, we run two kinds of experiments without access to query type labels. First, we assume that only one type of query exists but the type is unknown. Second, we experiment on a mixture of content-based and NP queries. The following two subsections will report results for the two conditions respectively. .3.1 Only One Type exists We assume that all queries are of the same type, that is, they are either NP queries or content-based queries. We choose WIG to deal with this case because it shows good prediction accuracy for both types of queries in the previous section. We consider two cases: (1) CB: all 150 title queries from the ad-hoc task of the Terabyte Tracks 2004-2006 (2)NP: all 433 NP queries from the named page finding task of the Terabyte Tracks 2005 and 2006. We take a simple strategy by labeling all of the queries in each case as the same type (either NP or CB) regardless of their actual type. The computation of WIG will be based on the labeled query type instead of the actual type. There are four possibilities with respect to the relation between the actual type and the labeled type. The correlation with retrieval performance under the four possibilities is presented in Table 7. For example, the value 0.445 at the intersection between the second row and the third column shows the Pearson"s correlation coefficient for correlation with average precision when the content-based queries are incorrectly labeled as the NP type. Based on these results, we recommend treating all queries as the NP type when only one query type exists and accurate query classification is not feasible, considering the risk that a large loss of accuracy will occur if NP queries are incorrectly labeled as content-based queries. These results also demonstrate the strong adaptability of WIG to different query types. CB (labeled) NP (labeled) CB (actual) 0.536 0.445 NP (actual) 0.174 0.467 Table 7: Comparison of Pearson"s correlation coefficients for correlation with retrieval performance under four possibilities on the Terabyte Tracks (NP). Bold cases mean the results are statistically significant at the 0.01 level. .3.2 A mixture of contented-based and NP queries A mixture of the two types of queries is a more realistic situation that a Web search engine will meet. We evaluate prediction accuracy by how accurately poorly-performing queries can be identified by the prediction method assuming that actual query types are unknown (but we can predict query types). This is a challenging task because both the predicted and actual performance for one type of query can be incomparable to that for the other type. Next we discuss how to implement our evaluation. We create a query pool which consists of all of the 150 ad-hoc title queries from Terabyte Track 2004-2006 and all of the 433 NP queries from Terabyte Track 2005&2006. We divide the queries in the pool into classes: good (better than 50% of the queries of the same type in terms of retrieval performance) and bad (otherwise). According to these standards, a NP query with the reciprocal rank above 0.2 or a content-based query with the average precision above 0.315 will be considered as good. Then, each time we randomly select one query Q from the pool with probability p that Q is contented-based. The remaining queries are used as training data. We first decide the type of query Q according to a query classifier. Namely, the query classifier tells us whether query Q is NP or content-based. Based on the predicted query type and the score computed for query Q by a prediction technique, a binary decision is made about whether query Q is good or bad by comparing to the score threshold of the predicted query type obtained from the training data. Prediction accuracy is measured by the accuracy of the binary decision. In our implementation, we repeatedly take a test query from the query pool and prediction accuracy is computed as the percentage of correct decisions, that is, a good(bad) query is predicted to be good (bad). It is obvious that random guessing will lead to 50% accuracy. Let us take the WIG method for example to illustrate the process. Two WIG thresholds (one for NP queries and the other for content-based queries) are trained by maximizing the prediction accuracy on the training data. When a test query is labeled as the NP (CB) type by the query type classifier, it will be predicted to be good if and only if the WIG score for this query is above the NP (CB) threshold. Similar procedures will be taken for other prediction techniques. Now we briefly introduce the automatic query type classifier used in this paper. We find that the robustness score, though originally proposed for performance prediction, is a good indicator of query types. We find that on average content-based queries have a much higher robustness score than NP queries. For example, Figure 2 shows the distributions of robustness scores for NP and content-based queries. According to this finding, the robustness score classifier will attach a NP (CB) label to the query if the robustness score for the query is below (above) a threshold trained from the training data.  .5  .5  .5 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1 NP Content-based Figure 2: Distribution of robustness scores for NP and CB queries. The NP queries are the 252 NP topics from the 2005 Terabyte Track. The content-based queries are the 150 ad-hoc title from the Terabyte Tracks 2004-2006. The probability distributions are estimated by the Kernel density estimation method. Strategies Robust WIG-1 WIG-2 WIG-3 Optimal p=0.6 0.565 0.624 0.665 0.684 0.701 P=0.4 0.567 0.633 0.654 0.673 0.696 Table 8: Comparison of prediction accuracy for five strategies in the mixed-query situation. Two ways to sample a query from the pool: (1) the sampled query is content-based with the probability p=0.6. (that is, the query is NP with probability .4 ) (2) set the probability p=0.4. We consider five strategies in our experiments. In the first strategy (denoted by robust), we use the robustness score for query performance prediction with the help of a perfect query classifier that always correctly map a query into one of the two categories (that is, NP or CB). This strategy represents the level of prediction accuracy that current prediction techniques can achieve in an ideal condition that query types are known. In the next following three strategies, the WIG method is adopted for performance prediction. The difference among the three is that three different query classifiers are used for each strategy: (1) the classifier always classifies a query into the NP type. (2) the Robustness Score ProbabilityDensity classifier is the robust score classifier mentioned above. (3) the classifier is a perfect one. These three strategies are denoted by WIG-1, WIG-2 and WIG-3 respectively. The reason we are interested in WIG-1 is based on the results from section 4.3.1. In the last strategy (denoted by Optimal) which serves as an upper bound on how well we can do so far, we fully make use of our prediction techniques for each query type assuming a perfect query classifier is available. Specifically, we linearly combine WIG and QF for content-based queries and WIG and FRC for NP queries. The results for the five strategies are shown in Table 8. For each strategy, we try two ways to sample a query from the pool: (1) the sampled query is CB with probability p=0.6. (the query is NP with probability 0.4) (2) set the probability p=0.4. From Table 8 We can see that in terms of prediction accuracy WIG-2 (the WIG method with the automatic query classifier) is not only better than the first two cases, but also is close to WIG-3 where a perfect classifier is assumed. Some further improvements over WIG-3 are observed when combined with other prediction techniques. The merit of WIG-2 is that it provides a practical solution to automatically identifying poorly performing queries in a Web search environment with mixed query types, which poses considerable obstacles to traditional prediction techniques. . CONCLUSIONS AND FUTURE WORK To our knowledge, our paper is the first to thoroughly explore prediction of query performance in web search environments. We demonstrated that our models resulted in higher prediction accuracy than previously published techniques not specially devised for web search scenarios. In this paper, we focus on two types of queries in web search: content-based and Named-Page (NP) finding queries, corresponding to the ad-hoc retrieval task and the Named-Page finding task respectively. For both types of web queries, our prediction models were shown to be substantially more accurate than the current state-of-the-art techniques. Furthermore, we considered a more realistic case that no prior information on query types is available. We demonstrated that the WIG method is particularly suitable for this situation. Considering the adaptability of WIG to a range of collections and query types, one of our future plans is to apply this method to predict user preference of search results on realistic data collected from a commercial search engine. Other than accuracy, another major issue that prediction techniques have to deal with in a Web environment is efficiency. Fortunately, since the WIG score is computed just over the terms and the phrases that appear in the query, this calculation can be made very efficient with the support of index. On the other hand, the computation of QF and FRC is relatively less efficient since QF needs to retrieve the whole collection twice and FRC needs to repeatedly rank the perturbed documents. How to improve the efficiency of QF and FRC is our future work. In addition, the prediction techniques proposed in this paper have the potential of improving retrieval performance by combining with other IR techniques. For example, our techniques can be incorporated to popular query modification techniques such as query expansion and query relaxation. Guided by performance prediction, we can make a better decision on when to or how to modify queries to enhance retrieval effectiveness. We would like to carry out research in this direction in the future. . ACKNOWLEGMENTS This work was supported in part by the Center for Intelligent Information Retrieval, in part by the Defense Advanced Research Projects Agency (DARPA) under contract number  HR0011-06-C0023, and in part by an award from Google. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect those of the sponsor. In addition, we thank Donald Metzler for his valuable comments on this work. . REFERENCES [1] Y. Zhou ,W. B. Croft ,Ranking Robustness: A Novel Framework to Predict Query Performance, in Proceedings of CIKM 2006. [2] D.Carmel, E.Yom-Tov, A.Darlow,D.Pelleg, What Makes a Query Difficult?, in Proceedings of SIGIR 2006. [3] C.L.A. Clarke, F. Scholer, I.Soboroff, The TREC 2005 Terabyte Track, In the Online Proceedings of 2005 TREC. [4] B. He and I.Ounis. Inferring query performance using  preretrieval predictors. In proceedings of the SPIRE 2004. [5] S. Tomlinson. Robust, Web and Terabyte Retrieval with Hummingbird SearchServer at TREC 2004. In the Online Proceedings of 2004 TREC. [6] S. Cronen-Townsend, Y. Zhou, W. B. Croft, Predicting Query Performance, in Proceedings of SIGIR 2002. [7] V.Vinay, I.J.Cox, N.Mill-Frayling,K.Wood, On Ranking the Effectiveness of Searcher, in Proceedings of SIGIR 2006. [8] D.Metzler, W.B.Croft, A Markov Random Filed Model for Term Dependencies, in Proceedings of SIGIR 2005. [9] D.Metzler, T.Strohman,Y.Zhou,W.B.Croft, Indri at TREC 005: Terabyte Track, In the Online Proceedings of 2004 TREC. [10] P. Ogilvie and J. Callan, Combining document representations for known-item search, in Proceedings of SIGIR 2003. [11] A.Berger, J.Lafferty, Information retrieval as statistical translation, in Proceedings of SIGIR 1999. [12] Indri search engine : http://www.lemurproject.org/indri/ [13] I.J. Taneja: On Generalized Information Measures and Their Applications, Advances in Electronics and Electron Physics, Academic Press (USA), 76, 1989, 327-413. [14] S.Cronen-Townsend, Y. Zhou and Croft, W. B. , "A Framework for Selective Query Expansion," in Proceedings of CIKM 2004. [15] F.Song, W.B.Croft, A general language model for information retrieval, in Proceedings of SIGIR 1999. [16] Personal email contact with Vishwa Vinay and our own experiments [17] E.Yom-Tov, S.Fine, D.Carmel, A.Darlow, Learning to Estimate Query Difficulty Including Applications to Missing Content Detection and Distributed Information retrieval, in Proceedings of SIGIR 2005
Broad Expertise Retrieval in Sparse Data Environments Krisztian Balog ISLA, University of Amsterdam Kruislaan 403, 1098 SJ Amsterdam, The Netherlands kbalog@science.uva.nl Toine Bogers ILK, Tilburg University P.O. Box 90153, 5000 LE Tilburg, The Netherlands A.M.Bogers@uvt.nl Leif Azzopardi Dept. of Computing Science University of Glasgow, Glasgow, G12 8QQ leif@dcs.gla.ac.uk Maarten de Rijke ISLA, University of Amsterdam Kruislaan 403, 1098 SJ Amsterdam, The Netherlands mdr@science.uva.nl Antal van den Bosch ILK, Tilburg University P.O. Box 90153, 5000 LE Tilburg, The Netherlands Antal.vdnBosch@uvt.nl ABSTRACT Expertise retrieval has been largely unexplored on data other than the W3C collection. At the same time, many intranets of  universities and other knowledge-intensive organisations offer examples of relatively small but clean multilingual expertise data, covering broad ranges of expertise areas. We first present two main  expertise retrieval tasks, along with a set of baseline approaches based on generative language modeling, aimed at finding expertise relations between topics and people. For our experimental evaluation, we introduce (and release) a new test set based on a crawl of a  university site. Using this test set, we conduct two series of experiments. The first is aimed at determining the effectiveness of baseline  expertise retrieval methods applied to the new test set. The second is aimed at assessing refined models that exploit characteristic  features of the new test set, such as the organizational structure of the university, and the hierarchical structure of the topics in the test set. Expertise retrieval models are shown to be robust with respect to environments smaller than the W3C collection, and current  techniques appear to be generalizable to other settings. Categories and Subject Descriptors H.3 [Information Storage and Retrieval]: H.3.1 Content  Analysis and Indexing; H.3.3 Information Search and Retrieval; H.3.4 Systems and Software; H.4 [Information Systems Applications]: H.4.2 Types of Systems; H.4.m Miscellaneous General Terms Algorithms, Measurement, Performance, Experimentation . INTRODUCTION An organization"s intranet provides a means for exchanging  information between employees and for facilitating employee  collaborations. To efficiently and effectively achieve this, it is necessary to provide search facilities that enable employees not only to access documents, but also to identify expert colleagues. At the TREC Enterprise Track [22] the need to study and  understand expertise retrieval has been recognized through the  introduction of Expert Finding tasks. The goal of expert finding is to identify a list of people who are knowledgeable about a given topic. This task is usually addressed by uncovering associations between people and topics [10]; commonly, a co-occurrence of the name of a person with topics in the same context is assumed to be  evidence of expertise. An alternative task, which using the same idea of people-topic associations, is expert profiling, where the task is to return a list of topics that a person is knowledgeable about [3]. The launch of the Expert Finding task at TREC has generated a lot of interest in expertise retrieval, with rapid progress being made in terms of modeling, algorithms, and evaluation aspects. However, nearly all of the expert finding or profiling work performed has been validated experimentally using the W3C collection [24] from the Enterprise Track. While this collection is currently the only publicly available test collection for expertise retrieval tasks, it only represents one type of intranet. With only one test collection it is not possible to generalize conclusions to other realistic settings. In this paper we focus on expertise retrieval in a realistic setting that differs from the W3C setting-one in which relatively small amounts of clean, multilingual data are available, that cover a broad range of expertise areas, as can be found on the intranets of  universities and other knowledge-intensive organizations. Typically, this setting features several additional types of structure: topical  structure (e.g., topic hierarchies as employed by the organization),  organizational structure (faculty, department, ...), as well as multiple types of documents (research and course descriptions, publications, and academic homepages). This setting is quite different from the W3C setting in ways that might impact upon the performance of expertise retrieval tasks. We focus on a number of research questions in this paper: Does the relatively small amount of data available on an intranet affect the quality of the topic-person associations that lie at the heart of expertise retrieval algorithms? How do state-of-the-art algorithms developed on the W3C data set perform in the alternative scenario of the type described above? More generally, do the lessons from the Expert Finding task at TREC carry over to this setting? How does the inclusion or exclusion of different documents affect  expertise retrieval tasks? In addition to, how can the topical and  organizational structure be used for retrieval purposes? To answer our research questions, we first present a set of  baseline approaches, based on generative language modeling, aimed at finding associations between topics and people. This allows us to formulate the expert finding and expert profiling tasks in a uniform way, and has the added benefit of allowing us to understand the  relations between the two tasks. For our experimental evaluation, we introduce a new data set (the UvT Expert Collection) which is  representative of the type of intranet that we described above. Our  collection is based on publicly available data, crawled from the  website of Tilburg University (UvT). This type of data is particularly interesting, since (1) it is clean, heterogeneous, structured, and  focused, but comprises a limited number of documents; (2) contains information on the organizational hierarchy; (3) it is bilingual  (English and Dutch); and (4) the list of expertise areas of an individual are provided by the employees themselves. Using the UvT Expert collection, we conduct two sets of experiments. The first is aimed at determining the effectiveness of baseline expertise finding and profiling methods in this new setting. A second group of  experiments is aimed at extensions of the baseline methods that exploit characteristic features of the UvT Expert Collection; specifically, we propose and evaluate refined expert finding and profiling  methods that incorporate topicality and organizational structure. Apart from the research questions and data set that we contribute, our main contributions are as follows. The baseline models  developed for expertise finding perform well on the new data set. While on the W3C setting the expert finding task appears to be more  difficult than profiling, for the UvT data the opposite is the case. We find that profiling on the UvT data set is considerably more  difficult than on the W3C set, which we believe is due to the large (but realistic) number of topical areas that we used for profiling: about 1,500 for the UvT set, versus 50 in the W3C case.  Taking the similarity between topics into account can significantly  improve retrieval performance. The best performing similarity  measures are content-based, therefore they can be applied on the W3C (and other) settings as well. Finally, we demonstrate that the  organizational structure can be exploited in the form of a context model, improving MAP scores for certain models by up to 70%. The remainder of this paper is organized as follows. In the next section we review related work. Then, in Section 3 we provide  detailed descriptions of the expertise retrieval tasks that we address in this paper: expert finding and expert profiling. In Section 4 we present our baseline models, of which the performance is then  assessed in Section 6 using the UvT data set that we introduce in  Section 5. Advanced models exploiting specific features of our data are presented in Section 7 and evaluated in Section 8. We formulate our conclusions in Section 9. . RELATED WORK Initial approaches to expertise finding often employed databases containing information on the skills and knowledge of each  individual in the organization [11]. Most of these tools (usually called  yellow pages or people-finding systems) rely on people to self-assess their skills against a predefined set of keywords. For updating  profiles in these systems in an automatic fashion there is a need for intelligent technologies [5]. More recent approaches use specific document sets (such as email [6] or software [18]) to find expertise. In contrast with focusing on particular document types, there is also an increased interest in the development of systems that index and mine published intranet documents as sources of evidence for  expertise. One such published approach is the P@noptic system [9], which builds a representation of each person by concatenating all documents associated with that person-this is similar to Model 1 of Balog et al. [4], who formalize and compare two methods. Balog et al."s Model 1 directly models the knowledge of an expert from associated documents, while their Model 2 first locates documents on the topic and then finds the associated experts. In the reported experiments the second method performs significantly better when there are sufficiently many associated documents per candidate. Most systems that took part in the 2005 and 2006 editions of the Expert Finding task at TREC implemented (variations on) one of these two models; see [10, 20]. Macdonald and Ounis [16] propose a different approach for ranking candidate expertise with respect to a topic based on data fusion techniques, without using  collectionspecific heuristics; they find that applying field-based weighting models improves the ranking of candidates. Petkova and Croft [19] propose yet another approach, based on a combination of the above Model 1 and 2, explicitly modeling topics. Turning to other expert retrieval tasks that can also be addressed using topic-people associations, Balog and de Rijke [3] addressed the task of determining topical expert profiles. While their methods proved to be efficient on the W3C corpus, they require an amount of data that may not be available in the typical knowledge-intensive organization. Balog and de Rijke [2] study the related task of  finding experts that are similar to a small set of experts given as input. As an aside, creating a textual summary of a person shows some similarities to biography finding, which has received a  considerable amount of attention recently; see e.g., [13]. We use generative language modeling to find associations  between topics and people. In our modeling of expert finding and profiling we collect evidence for expertise from multiple sources, in a heterogeneous collection, and integrate it with the co-occurrence of candidates" names and query terms-the language modeling  setting allows us to do this in a transparent manner. Our modeling proceeds in two steps. In the first step, we consider three baseline models, two taken from [4] (the Models 1 and 2 mentioned above), and one a refined version of a model introduced in [3] (which we refer to as Model 3 below); this third model is also similar to the model described by Petkova and Croft [19]. The models we  consider in our second round of experiments are mixture models  similar to contextual language models [1] and to the expanded  documents of Tao et al. [21]; however, the features that we use for definining our expansions-including topical structure and  organizational structure-have not been used in this way before. . TASKS In the expertise retrieval scenario that we envisage, users seeking expertise within an organization have access to an interface that combines a search box (where they can search for experts or topics) with navigational structures (of experts and of topics) that allows them to click their way to an expert page (providing the profile of a person) or a topic page (providing a list of experts on the topic). To feed the above interface, we face two expertise retrieval tasks, expert finding and expert profiling, that we first define and then formalize using generative language models. In order to model either task, the probability of the query topic being associated to a candidate expert plays a key role in the final estimates for searching and profiling. By using language models, both the candidates and the query are characterized by distributions of terms in the  vocabulary (used in the documents made available by the organization whose expertise retrieval needs we are addressing). .1 Expert finding Expert finding involves the task of finding the right person with the appropriate skills and knowledge: Who are the experts on topic X?. E.g., an employee wants to ascertain who worked on a  particular project to find out why particular decisions were made without having to trawl through documentation (if there is any). Or, they may be in need a trained specialist for consultancy on a specific problem. Within an organization there are usually many possible  candidates who could be experts for given topic. We can state this  problem as follows: What is the probability of a candidate ca being an  expert given the query topic q? That is, we determine p(ca|q), and rank candidates ca according to this probability. The candidates with the highest probability given the query are deemed the most likely experts for that topic. The challenge is how to estimate this probability accurately. Since the query is likely to consist of only a few terms to describe the  expertise required, we should be able to obtain a more accurate estimate by invoking Bayes" Theorem, and estimating: p(ca|q) = p(q|ca)p(ca) p(q) , (1) where p(ca) is the probability of a candidate and p(q) is the  probability of a query. Since p(q) is a constant, it can be ignored for ranking purposes. Thus, the probability of a candidate ca being an expert given the query q is proportional to the probability of a query given the candidate p(q|ca), weighted by the a priori belief p(ca) that candidate ca is an expert. p(ca|q) ∝ p(q|ca)p(ca) (2) In this paper our main focus is on estimating the probability of a query given the candidate p(q|ca), because this probability  captures the extent to which the candidate knows about the query topic. Whereas the candidate priors are generally assumed to be  uniformand thus will not influence the ranking-it has been demonstrated that a sensible choice of priors may improve the performance [20]. .2 Expert profiling While the task of expert searching was concerned with  finding experts given a particular topic, the task of expert profiling seeks to answer a related question: What topics does a candidate know about? Essentially, this turns the questions of expert finding around. The profiling of an individual candidate involves the  identification of areas of skills and knowledge that they have expertise about and an evaluation of the level of proficiency in each of these areas. This is the candidate"s topical profile. Generally, topical profiles within organizations consist of  tabular structures which explicitly catalogue the skills and knowledge of each individual in the organization. However, such practice is limited by the resources available for defining, creating,  maintaining, and updating these profiles over time. By focusing on  automatic methods which draw upon the available evidence within the document repositories of an organization, our aim is to reduce the human effort associated with the maintenance of topical profiles1 . A topical profile of a candidate, then, is defined as a vector where each element i of the vector corresponds to the candidate ca"s  expertise on a given topic ki, (i.e., s(ca, ki)). Each topic ki defines a particular knowledge area or skill that the organization uses to  define the candidate"s topical profile. Thus, it is assumed that a list of topics, {k1, . . . , kn}, where n is the number of pre-defined topics, is given: profile(ca) = s(ca, k1), s(ca, k2), . . . , s(ca, kn) . (3)  Context and evidence are needed to help users of expertise  finding systems to decide whom to contact when seeking expertise in a particular area. Examples of such context are: Who does she work with? What are her contact details? Is she well-connected, just in case she is not able to help us herself? What is her role in the organization? Who is her superior? Collaborators, and affiliations, etc. are all part of the candidate"s social profile, and can serve as a background against which the system"s recommendations should be interpreted. In this paper we only address the problem of  determining topical profiles, and leave social profiling to further work. We state the problem of quantifying the competence of a person on a certain knowledge area as follows: What is the probability of a knowledge area (ki) being part of the candidate"s (expertise) profile? where s(ca, ki) is defined by p(ki|ca). Our task, then, is to  estimate p(ki|ca), which is equivalent to the problem of obtaining p(q|ca), where the topic ki is represented as a query topic q, i.e., a sequence of keywords representing the expertise required. Both the expert finding and profiling tasks rely on the accurate estimation of p(q|ca). The only difference derives from the prior probability that a person is an expert (p(ca)), which can be  incorporated into the expert finding task. This prior does not apply to the profiling task since the candidate (individual) is fixed. . BASELINE MODELS In this section we describe our baseline models for estimating p(q|ca), i.e., associations between topics and people. Both expert finding and expert profiling boil down to this estimation. We  employ three models for calculating this probability. .1 From topics to candidates Using Candidate Models: Model 1 Model 1 [4] defines the  probability of a query given a candidate (p(q|ca)) using standard  language modeling techniques, based on a multinomial unigram  language model. For each candidate ca, a candidate language model θca is inferred such that the probability of a term given θca is  nonzero for all terms, i.e., p(t|θca) > 0. From the candidate model the query is generated with the following probability: p(q|θca) = Y t∈q p(t|θca)n(t,q) , where each term t in the query q is sampled identically and  independently, and n(t, q) is the number of times t occurs in q. The candidate language model is inferred as follows: (1) an empirical model p(t|ca) is computed; (2) it is smoothed with background probabilities. Using the associations between a candidate and a document, the probability p(t|ca) can be approximated by: p(t|ca) = X d p(t|d)p(d|ca), where p(d|ca) is the probability that candidate ca generates a  supporting document d, and p(t|d) is the probability of a term t  occurring in the document d. We use the maximum-likelihood estimate of a term, that is, the normalised frequency of the term t in  document d. The strength of the association between document d and candidate ca expressed by p(d|ca) reflects the degree to which the candidates expertise is described using this document. The  estimation of this probability is presented later, in Section 4.2. The candidate model is then constructed as a linear interpolation of p(t|ca) and the background model p(t) to ensure there are no zero probabilities, which results in the final estimation: p(q|θca) = (4) Y t∈q ( (1 − λ) X d p(t|d)p(d|ca) ! + λp(t) )n(t,q) . Model 1 amasses all the term information from all the documents associated with the candidate, and uses this to represent that  candidate. This model is used to predict how likely a candidate would produce a query q. This can can be intuitively interpreted as the probability of this candidate talking about the query topic, where we assume that this is indicative of their expertise. Using Document Models: Model 2 Model 2 [4] takes a  different approach. Here, the process is broken into two parts. Given a candidate ca, (1) a document that is associated with a candidate is selected with probability p(d|ca), and (2) from this document a query q is generated with probability p(q|d). Then the sum over all documents is taken to obtain p(q|ca), such that: p(q|ca) = X d p(q|d)p(d|ca). (5) The probability of a query given a document is estimated by  inferring a document language model θd for each document d in a similar manner as the candidate model was inferred: p(t|θd) = (1 − λ)p(t|d) + λp(t), (6) where p(t|d) is the probability of the term in the document. The probability of a query given the document model is: p(q|θd) = Y t∈q p(t|θd)n(t,q) . The final estimate of p(q|ca) is obtained by substituting p(q|d) for p(q|θd) into Eq. 5 (see [4] for full details). Conceptually, Model 2 differs from Model 1 because the candidate is not directly modeled. Instead, the document acts like a hidden variable in the process which separates the query from the candidate. This process is akin to how a user may search for candidates with a standard search engine: initially by finding the documents which are relevant, and then seeing who is associated with that document. By examining a number of documents the user can obtain an idea of which  candidates are more likely to discuss the topic q. Using Topic Models: Model 3 We introduce a third model, Model 3. Instead of attempting to model the query generation process via candidate or document models, we represent the query as a topic language model and directly estimate the probability of the  candidate p(ca|q). This approach is similar to the model presented in [3, 19]. As with the previous models, a language model is  inferred, but this time for the query. We adapt the work of Lavrenko and Croft [14] to estimate a topic model from the query. The procedure is as follows. Given a collection of documents and a query topic q, it is assumed that there exists an unknown topic model θk that assigns probabilities p(t|θk) to the term  occurrences in the topic documents. Both the query and the documents are samples from θk (as opposed to the previous approaches, where a query is assumed to be sampled from a specific document or  candidate model). The main task is to estimate p(t|θk), the probability of a term given the topic model. Since the query q is very sparse, and as there are no examples of documents on the topic, this  distribution needs to be approximated. Lavrenko and Croft [14] suggest a reasonable way of obtaining such an approximation, by assuming that p(t|θk) can be approximated by the probability of term t given the query q. We can then estimate p(t|q) using the joint probability of observing the term t together with the query terms, q1, . . . , qm, and dividing by the joint probability of the query terms: p(t|θk) ≈ p(t|q) = p(t, q1, . . . , qm) p(q1, . . . , qm) = p(t, q1, . . . , qm) P t ∈T p(t , q1, . . . , qm) , where p(q1, . . . , qm) = P t ∈T p(t , q1, . . . , qm), and T is the  entire vocabulary of terms. In order to estimate the joint probability p(t, q1, . . . , qm), we follow [14, 15] and assume t and q1, . . . , qm are mutually independent, once we pick a source distribution from the set of underlying source distributions U. If we choose U to be a set of document models. then to construct this set, the query q would be issued against the collection, and the top n returned are assumed to be relevant to the topic, and thus treated as samples from the topic model. (Note that candidate models could be used instead.) With the document models forming U, the joint  probability of term and query becomes: p(t, q1, . . . , qm) = X d∈U p(d) ˘ p(t|θd) mY i=1 p(qi|θd) ¯ . (7) Here, p(d) denotes the prior distribution over the set U, which  reflects the relevance of the document to the topic. We assume that p(d) is uniform across U. In order to rank candidates according to the topic model defined, we use the Kullback-Leibler divergence metric (KL, [8]) to measure the difference between the candidate models and the topic model: KL(θk||θca) = X t p(t|θk) log p(t|θk) p(t|θca) . (8) Candidates with a smaller divergence from the topic model are  considered to be more likely experts on that topic. The candidate model θca is defined in Eq. 4. By using KL divergence instead of the  probability of a candidate given the topic model p(ca|θk), we avoid normalization problems. .2 Document-candidate associations For our models we need to be able to estimate the probability p(d|ca), which expresses the extent to which a document d  characterizes the candidate ca. In [4], two methods are presented for  estimating this probability, based on the number of person names  recognized in a document. However, in our (intranet) setting it is  reasonable to assume that authors of documents can unambiguously be identified (e.g., as the author of an article, the teacher assigned to a course, the owner of a web page, etc.) Hence, we set p(d|ca) to be  if candidate ca is author of document d, otherwise the probability is 0. In Section 6 we describe how authorship can be determined on different types of documents within the collection. . THE UVT EXPERT COLLECTION The UvT Expert collection used in the experiments in this paper fits the scenario outlined in Section 3. The collection is based on the Webwijs (Webwise) system developed at Tilburg University (UvT) in the Netherlands. Webwijs (http://www.uvt.nl/ webwijs/) is a publicly accessible database of UvT employees who are involved in research or teaching; currently, Webwijs  contains information about 1168 experts, each of whom has a page with contact information and, if made available by the expert, a research description and publications list. In addition, each expert can  select expertise areas from a list of 1491 topics and is encouraged to suggest new topics that need to be approved by the Webwijs editor. Each topic has a separate page that shows all experts associated with that topic and, if available, a list of related topics. Webwijs is available in Dutch and English, and this bilinguality has been preserved in the collection. Every Dutch Webwijs page has an English translation. Not all Dutch topics have an English translation, but the reverse is true: the 981 English topics all have a Dutch equivalent. About 42% of the experts teach courses at Tilburg University; these courses were also crawled and included in the profile. In  addition, about 27% of the experts link to their academic homepage from their Webwijs page. These home pages were crawled and added to the collection. (This means that if experts put the full-text versions of their publications on their academic homepage, these were also available for indexing.) We also obtained 1880 full-text versions of publications from the UvT institutional repository and Dutch English no. of experts 1168 1168 no. of experts with ≥ 1 topic 743 727 no. of topics 1491 981 no. of expert-topic pairs 4318 3251 avg. no. of topics/expert 5.8 5.9 max. no. of topics/expert (no. of experts) 60 (1) 35 (1) min. no. of topics/expert (no. of experts) 1 (74) 1 (106) avg. no. of experts/topic 2.9 3.3 max. no. of experts/topic (no. of topics) 30 (1) 30 (1) min. no. of experts/topic (no. of topics) 1 (615) 1 (346) no. of experts with HP 318 318 no. of experts with CD 318 318 avg. no. of CDs per teaching expert 3.5 3.5 no. of experts with RD 329 313 no. of experts with PUB 734 734 avg. no. of PUBs per expert 27.0 27.0 avg. no. of PUB citations per expert 25.2 25.2 avg. no. of full-text PUBs per expert 1.8 1.8 Table 2: Descriptive statistics of the Dutch and English versions of the UvT Expert collection. converted them to plain text. We ran the TextCat [23] language identifier to classify the language of the home pages and the  fulltext publications. We restricted ourselves to pages where the  classifier was confident about the language used on the page. This resulted in four document types: research descriptions (RD), course descriptions (CD), publications (PUB; full-text and  citationonly versions), and academic homepages (HP). Everything was bundled into the UvT Expert collection which is available at http: //ilk.uvt.nl/uvt-expert-collection/. The UvT Expert collection was extracted from a different  organizational setting than the W3C collection and differs from it in a number of ways. The UvT setting is one with relatively small amounts of multilingual data. Document-author associations are clear and the data is structured and clean. The collection covers a broad range of expertise areas, as one can typically find on intranets of universities and other knowledge-intensive institutes.  Additionally, our university setting features several types of structure  (topical and organizational), as well as multiple document types.  Another important difference between the two data sets is that the  expertise areas in the UvT Expert collection are self-selected instead of being based on group membership or assignments by others. Size is another dimension along which the W3C and UvT Expert collections differ: the latter is the smaller of the two. Also realistic are the large differences in the amount of information available for each expert. Utilizing Webwijs is voluntary; 425 Dutch experts did not select any topics at all. This leaves us with 743 Dutch and 27 English usable expert profiles. Table 2 provides descriptive statistics for the UvT Expert collection. Universities tend to have a hierarchical structure that goes from the faculty level, to departments, research groups, down to the  individual researchers. In the UvT Expert collection we have  information about the affiliations of researchers with faculties and institutes, providing us with a two-level organizational hierarchy. Tilburg University has 22 organizational units at the faculty level (including the university office and several research institutes) and 1 departments, which amounts to 3.2 departments per faculty. As to the topical hierarchy used by Webwijs, 131 of the 1491 topics are top nodes in the hierarchy. This hierarchy has an average topic chain length of 2.65 and a maximum length of 7 topics. . EVALUATION Below, we evaluate Section 4"s models for expert finding and profiling onthe UvT Expert collection. We detail our research  questions and experimental setup, and then present our results. .1 Research Questions We address the following research questions. Both expert finding and profiling rely on the estimations of p(q|ca). The question is how the models compare on the different tasks, and in the setting of the UvT Expert collection. In [4], Model 2 outperformed Model 1 on the W3C collection. How do they compare on our data set? And how does Model 3 compare to Model 1? What about performance differences between the two languages in our test collection? .2 Experimental Setup The output of our models was evaluated against the self-assigned topic labels, which were treated as relevance judgements. Results were evaluated separately for English and Dutch. For English we only used topics for which the Dutch translation was available; for Dutch all topics were considered. The results were averaged for the queries in the intersection of relevance judgements and results; missing queries do not contribute a value of 0 to the scores. We use standard information retrieval measures, such as Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR). We also report the percentage of topics (%q) and candidates (%ca)  covered, for the expert finding and profiling tasks, respectively. .3 Results Table 1 shows the performance of Model 1, 2, and 3 on the  expert finding and profiling tasks. The rows of the table correspond to the various document types (RD, CD, PUB, and HP) and to their combinations. RD+CD+PUB+HP is equivalent to the full  collection and will be referred as the BASELINE of our experiments. Looking at Table 1 we see that Model 2 performs the best across the board. However, when the data is clean and very focused (RD), Model 3 outperforms it in a number of cases. Model 1 has the best coverage of candidates (%ca) and topics (%q). The various document types differ in their characteristics and how they improve the finding and profiling tasks. Expert profiling benefits much from the clean data present in the RD and CD document types, while the publications contribute the most to the expert finding task. Adding the homepages does not prove to be particularly useful. When we compare the results across languages, we find that the coverage of English topics (%q) is higher than of the Dutch ones for expert finding. Apart from that, the scores fall in the same range for both languages. For the profiling task the coverage of the  candidates (%ca) is very similar for both languages. However, the  performance is substantially better for the English topics. While it is hard to compare scores across collections, we  conclude with a brief comparison of the absolute scores in Table 1 to those reported in [3, 4] on the W3C test set (2005 edition). For expert finding the MAP scores for Model 2 reported here are about 0% higher than the corresponding figures in [4], while our MRR scores are slightly below those in [4]. For expert profiling, the  differences are far more dramatic: the MAP scores for Model 2  reported here are around 50% below the scores in [3], while the (best) MRR scores are about the same as those in [3]. The cause for the latter differences seems to reside in the number of knowledge areas considered here-approx. 30 times more than in the W3C setting. . ADVANCED MODELS Now that we have developed and assessed basic language  modeling techniques for expertise retrieval, we turn to refined models that exploit special features of our test collection. .1 Exploiting knowledge area similarity One way to improve the scoring of a query given a candidate is to consider what other requests the candidate would satisfy and use them as further evidence to support the original query, proportional Expert finding Expert profiling Document types Model 1 Model 2 Model 3 Model 1 Model 2 Model 3 %q MAP MRR %q MAP MRR %q MAP MRR %ca MAP MRR %ca MAP MRR %ca MAP MRR English RD 97.8 0.126 0.269 83.5 0.144 0.311 83.3 0.129 0.271 100 0.089 0.189 39.3 0.232 0.465 41.1 0.166 0.337 CD 97.8 0.118 0.227 91.7 0.123 0.248 91.7 0.118 0.226 32.8 0.188 0.381 32.4 0.195 0.385 32.7 0.203 0.370 PUB 97.8 0.200 0.330 98.0 0.216 0.372 98.0 0.145 0.257 78.9 0.167 0.364 74.5 0.212 0.442 78.9 0.135 0.299 HP 97.8 0.081 0.186 97.4 0.071 0.168 97.2 0.062 0.149 31.2 0.150 0.299 28.8 0.185 0.335 30.1 0.136 0.287 RD+CD 97.8 0.188 0.352 92.9 0.193 0.360 92.9 0.150 0.273 100 0.145 0.286 61.3 0.251 0.477 63.2 0.217 0.416 RD+CD+PUB 97.8 0.235 0.373 98.1 0.277 0.439 98.1 0.178 0.305 100 0.196 0.380 87.2 0.280 0.533 89.5 0.170 0.344 RD+CD+PUB+HP 97.8 0.237 0.372 98.6 0.280 0.441 98.5 0.166 0.293 100 0.199 0.387 88.7 0.281 0.525 90.9 0.169 0.329 Dutch RD 61.3 0.094 0.229 38.4 0.137 0.336 38.3 0.127 0.295 38.0 0.127 0.386 34.1 0.138 0.420 38.0 0.105 0.327 CD 61.3 0.107 0.212 49.7 0.128 0.256 49.7 0.136 0.261 32.5 0.151 0.389 31.8 0.158 0.396 32.5 0.170 0.380 PUB 61.3 0.193 0.319 59.5 0.218 0.368 59.4 0.173 0.291 78.8 0.126 0.364 76.0 0.150 0.424 78.8 0.103 0.294 HP 61.3 0.063 0.169 56.6 0.064 0.175 56.4 0.062 0.163 29.8 0.108 0.308 27.8 0.125 0.338 29.8 0.098 0.255 RD+CD 61.3 0.159 0.314 51.9 0.184 0.360 51.9 0.169 0.324 60.5 0.151 0.410 57.2 0.166 0.431 60.4 0.159 0.384 RD+CD+PUB 61.3 0.244 0.398 61.5 0.260 0.424 61.4 0.210 0.350 90.3 0.165 0.445 88.2 0.189 0.479 90.3 0.126 0.339 RD+CD+PUB+HP 61.3 0.249 0.401 62.6 0.265 0.436 62.6 0.195 0.344 91.9 0.164 0.426 90.1 0.195 0.488 91.9 0.125 0.328 Table 1: Performance of the models on the expert finding and profiling tasks, using different document types and their combinations. %q is the number of topics covered (applies to the expert finding task), %ca is the number of candidates covered (applies to the expert profiling task). The top and bottom blocks correspond to English and Dutch respectively. The best scores are in boldface. to how related the other requests are to the original query. This can be modeled by interpolating between the p(q|ca) and the further supporting evidence from all similar requests q , as follows: p (q|ca) = λp(q|ca) + (1 − λ) X q p(q|q )p(q |ca), (9) where p(q|q ) represents the similarity between the two topics q and q . To be able to work with similarity methods that are not necessarily probabilities, we set p(q|q ) = w(q,q ) γ , where γ is a normalizing constant, such that γ = P q w(q , q ). We  consider four methods for calculating the similarity score between two topics. Three approaches are strictly content-based, and establish similarity by examining co-occurrence patterns of topics within the collection, while the last approach exploits the hierarchical  structure of topical areas that may be present within an organization (see [7] for further examples of integrating word relationships into  language models). The Kullback-Leibler (KL) divergence metric defined in Eq. 8 provides a measure of how different or similar two probability  distributions are. A topic model is inferred for q and q using the method presented in Section 4.1 to describe the query across the entire vocabulary. Since a lower KL score means the queries are more similar, we let w(q, q ) = max(KL(θq||·) − KL(θq||θq )). Pointwise Mutual Information (PMI, [17]) is a measure of  association used in information theory to determine the extent of  independence between variables. The dependence between two queries is reflected by the SI(q, q ) score, where scores greater than zero indicate that it is likely that there is a dependence, which we take to mean that the queries are likely to be similar: SI(q, q ) = log p(q, q ) p(q)p(q ) (10) We estimate the probability of a topic p(q) using the number of documents relevant to query q within the collection. The joint probability p(q, q ) is estimated similarly, by using the  concatenation of q and q as a query. To obtain p(q|q ), we then set w(q, q ) = SI(q, q ) when SI(q, q ) > 0 otherwise w(q, q ) = 0, because we are only interested in including queries that are similar. The log-likelihood statistic provides another measure of  dependence, which is more reliable than the pointwise mutual  information measure [17]. Let k1 be the number of co-occurrences of q and q , k2 the number of occurrences of q not co-occurring with q , n1 the total number of occurrences of q , and n2 the total number of topic tokens minus the number of occurrences of q . Then, let p1 = k1/n1, p2 = k2/n2, and p = (k1 + k2)/(n1 + n2), (q, q ) = 2( (p1, k1, n1) + (p2, k2, n2) − (p, k1, n1) − (p, k2, n2)), where (p, n, k) = k log p + (n − k) log(1 − p). The higher score indicate that queries are also likely to be similar, thus we set w(q, q ) = (q, q ). Finally, we also estimate the similarity of two topics based on their distance within the topic hierarchy. The topic hierarchy is viewed as a directed graph, and for all topic-pairs the shortest path SP(q, q ) is calculated. We set the similarity score to be the  reciprocal of the shortest path: w(q, q ) = 1/SP(q, q ). .2 Contextual information Given the hierarchy of an organization, the units to which a  person belong are regarded as a context so as to compensate for data sparseness. We model it as follows: p (q|ca) =   − P ou∈OU(ca) λou  · p(q|ca) + P ou∈OU(ca) λou · p(q|ou), where OU(ca) is the set of organizational units of which  candidate ca is a member of, and p(q|o) expresses the strength of the association between query q and the unit ou. The latter probability can be estimated using either of the three basic models, by simply replacing ca with ou in the corresponding equations. An  organizational unit is associated with all the documents that its members have authored. That is, p(d|ou) = maxca∈ou p(d|ca). .3 A simple multilingual model For knowledge institutes in Europe, academic or otherwise, a multilingual (or at least bilingual) setting is typical. The following model builds on a kind of independence assumption: there is no spill-over of expertise/profiles across language boundaries. While a simplification, this is a sensible first approach. That is: p (q|ca) =P l∈L λl · p(ql|ca), where L is the set of languages used in the collection, ql is the translation of the query q to language l, and λl is a language specific smoothing parameter, such that P l∈L λl = 1. . ADVANCED MODELS: EVALUATION In this section we present an experimental evaluation of our  advanced models. Expert finding Expert profiling Language Model 1 Model 2 Model 3 Model 1 Model 2 Model 3 %q MAP MRR %q MAP MRR %q MAP MRR %ca MAP MRR %ca MAP MRR %ca MAP MRR English only 97.8 0.237 0.372 98.6 0.280 0.441 98.5 0.166 0.293 100 0.199 0.387 88.7 0.281 0.525 90.9 0.169 0.329 Dutch only 61.3 0.249 0.401 62.6 0.265 0.436 62.6 0.195 0.344 91.9 0.164 0.426 90.1 0.195 0.488 91.9 0.125 0.328 Combination 99.4 0.297 0.444 99.7 0.324 0.491 99.7 0.223 0.388 100 0.241 0.445 92.1 0.313 0.564 93.2 0.224 0.411 Table 3: Performance of the combination of languages on the expert finding and profiling tasks (on candidates). Best scores for each model are in italic, absolute best scores for the expert finding and profiling tasks are in boldface. Method Model 1 Model 2 Model 3 MAP MRR MAP MRR MAP MRR English BASELINE 0.296 0.454 0.339 0.509 0.221 0.333 KLDIV 0.291 0.453 0.327 0.503 0.219 0.330 PMI 0.291 0.453 0.337 0.509 0.219 0.331 LL 0.319 0.490 0.360 0.524 0.233 0.368 HDIST 0.299 0.465 0.346 0.537 0.219 0.332 Dutch BASELINE 0.240 0.350 0.271 0.403 0.227 0.389 KLDIV 0.239 0.347 0.253 0.386 0.224 0.385 PMI 0.239 0.350 0.260 0.392 0.227 0.389 LL 0.255 0.372 0.281 0.425 0.231 0.389 HDIST 0.253 0.365 0.271 0.407 0.236 0.402 Method Model 1 Model 2 Model 3 MAP MRR MAP MRR MAP MRR English BASELINE 0.485 0.546 0.499 0.548 0.381 0.416 KLDIV 0.510 0.564 0.513 0.558 0.381 0.416 PMI 0.486 0.546 0.495 0.542 0.407 0.451 LL 0.558 0.589 0.586 0.617 0.408 0.453 HDIST 0.507 0.567 0.512 0.563 0.386 0.420 Dutch BASELINE 0.263 0.313 0.294 0.358 0.262 0.315 KLDIV 0.284 0.336 0.271 0.321 0.261 0.314 PMI 0.265 0.317 0.265 0.316 0.273 0.330 LL 0.312 0.351 0.330 0.377 0.284 0.331 HDIST 0.280 0.327 0.288 0.341 0.266 0.321 Table 4: Performance on the expert finding (top) and profiling (bottom) tasks, using knowledge area similarities. Runs were evaluated on the main topics set. Best scores are in boldface. .1 Research Questions Our questions follow the refinements presented in the preceding section: Does exploiting the knowledge area similarity improve  effectiveness? Which of the various methods for capturing word  relationships is most effective? Furthermore, is our way of bringing in contextual information useful? For which tasks? And finally, is our simple way of combining the monolingual scores sufficient for obtaining significant improvements? .2 Experimental setup Given that the self-assessments are also sparse in our collection, in order to be able to measure differences between the various  models, we selected a subset of topics, and evaluated (some of the) runs only on this subset. This set is referred as main topics, and consists of topics that are located at the top level of the topical hierarchy. (A main topic has subtopics, but is not a subtopic of any other topic.) This main set consists of 132 Dutch and 119 English topics. The relevance judgements were restricted to the main topic set, but were not expanded with subtopics. .3 Exploiting knowledge area similarity Table 4 presents the results. The four methods used for  estimating knowledge-area similarity are KL divergence (KLDIV),  PointLang. Topics Model 1 Model 2 Model 3 MAP MRR MAP MRR MAP MRR Expert finding UK ALL 0.423 0.545 0.654 0.799 0.494 0.629 UK MAIN 0.500 0.621 0.704 0.834 0.587 0.699 NL ALL 0.439 0.560 0.672 0.826 0.480 0.630 NL MAIN 0.440 0.584 0.645 0.816 0.515 0.655 Expert profiling UK ALL 0.240 0.640 0.306 0.778 0.223 0.616 UK MAIN 0.523 0.677 0.519 0.648 0.461 0.587 NL ALL 0.203 0.716 0.254 0.770 0.183 0.627 NL MAIN 0.332 0.576 0.380 0.624 0.332 0.549 Table 5: Evaluating the context models on organizational units. wise mutual information (PMI), log-likelihood (LL), and distance within topic hierarchy (HDIST). We managed to improve upon the baseline in all cases, but the improvement is more noticeable for the profiling task. For both tasks, the LL method performed best. The content-based approaches performed consistently better than HDIST. .4 Contextual information A two level hierarchy of organizational units (faculties and  institutes) is available in the UvT Expert collection. The unit a person belongs to is used as a context for that person. First, we evaluated the models of the organizational units, using all topics (ALL) and only the main topics (MAIN). An organizational unit is considered to be relevant for a given topic (or vice versa) if at least one member of the unit selected the given topic as an expertise area. Table 5 reports on the results. As far as expert finding goes, given a topic, the corresponding organizational unit can be identified with high precision. However, the expert profiling task shows a different picture: the scores are low, and the task seems hard. The  explanation may be that general concepts (i.e., our main topics) may belong to several organizational units. Second, we performed another evaluation, where we combined the contextual models with the candidate models (to score  candidates again). Table 6 reports on the results. We find a positive impact of the context models only for expert finding. Noticably, for expert finding (and Model 1), it improves over 50% (for  English) and over 70% (for Dutch) on MAP. The poor performance on expert profiling may be due to the fact that context models alone did not perform very well on the profiling task to begin with. .5 Multilingual models In this subsection we evaluate the method for combining  results across multiple languages that we described in Section 7.3. In our setting the set of languages consists of English and Dutch: L = {UK, NL}. The weights on these languages were set to be identical (λUK = λNL = 0.5). We performed experiments with various λ settings, but did not observe significant differences in performance. Table 3 reports on the multilingual results, where performance is evaluated on the full topic set. All three models significantly  imLang. Method Model 1 Model 2 Model 3 MAP MRR MAP MRR MAP MRR Expert finding UK BL 0.296 0.454 0.339 0.509 0.221 0.333 UK CT 0.330 0.491 0.342 0.500 0.228 0.342 NL BL 0.240 0.350 0.271 0.403 0.227 0.389 NL CT 0.251 0.382 0.267 0.410 0.246 0.404 Expert profiling UK BL 0.485 0.546 0.499 0.548 0.381 0.416 UK CT 0.562 0.620 0.508 0.558 0.440 0.486 NL BL 0.263 0.313 0.294 0.358 0.262 0.315 NL CT 0.330 0.384 0.317 0.387 0.294 0.345 Table 6: Performance of the context models (CT) compared to the baseline (BL). Best scores are in boldface. proved over all measures for both tasks. The coverage of topics and candidates for the expert finding and profiling tasks,  respectively, is close to 100% in all cases. The relative improvement of the precision scores ranges from 10% to 80%. These scores demonstrate that despite its simplicity, our method for combining results over multiple languages achieves substantial improvements over the baseline. . CONCLUSIONS In this paper we focused on expertise retrieval (expert finding and profiling) in a new setting of a typical knowledge-intensive  organization in which the available data is of high quality,  multilingual, and covering a broad range of expertise area. Typically, the amount of available data in such an organization (e.g., a university, a research institute, or a research lab) is limited when compared to the W3C collection that has mostly been used for the experimental evaluation of expertise retrieval so far. To examine expertise retrieval in this setting, we introduced (and released) the UvT Expert collection as a representative case of such knowledge intensive organizations. The new collection reflects the typical properties of knowledge-intensive institutes noted above and also includes several features which may are potentially useful for expertise retrieval, such as topical and organizational structure. We evaluated how current state-of-the-art models for expert  finding and profiling performed in this new setting and then refined these models in order to try and exploit the different  characteristics within the data environment (language, topicality, and  organizational structure). We found that current models of expertise retrieval generalize well to this new environment; in addition we found that refining the models to account for the differences results in significant improvements, thus making up for problems caused by data sparseness issues. Future work includes setting up manual assessments of  automatically generated profiles by the employees themselves, especially in cases where the employees have not provided a profile themselves. 0. ACKNOWLEDGMENTS Krisztian Balog was supported by the Netherlands Organisation for Scientific Research (NWO) under project number 220-80-001. Maarten de Rijke was also supported by NWO under project  numbers 017.001.190, 220-80-001, 264-70-050, 354-20-005,  00.065.120, 612-13-001, 612.000.106, 612.066.302, 612.069.006,  40.001.501, 640.002.501, and by the E.U. IST programme of the 6th FP for RTD under project MultiMATCH contract IST-033104. The work of Toine Bogers and Antal van den Bosch was funded by the IOP-MMI-program of SenterNovem / The Dutch Ministry of Economic Affairs, as part of the `A Propos project. 1. REFERENCES [1] L. Azzopardi. Incorporating Context in the Language Modeling Framework for ad-hoc Information Retrieval. PhD thesis, University of Paisley, 2005. [2] K. Balog and M. de Rijke. Finding similar experts. In This volume, 007. [3] K. Balog and M. de Rijke. Determining expert profiles (with an  application to expert finding). In IJCAI "07: Proc. 20th Intern. Joint Conf. on Artificial Intelligence, pages 2657-2662, 2007. [4] K. Balog, L. Azzopardi, and M. de Rijke. Formal models for expert finding in enterprise corpora. In SIGIR "06: Proc. 29th annual  intern. ACM SIGIR conf. on Research and development in information retrieval, pages 43-50, 2006. [5] I. Becerra-Fernandez. The role of artificial intelligence technologies in the implementation of people-finder knowledge management  systems. In AAAI Workshop on Bringing Knowledge to Business  Processes, March 2000. [6] C. S. Campbell, P. P. Maglio, A. Cozzi, and B. Dom. Expertise  identification using email communications. In CIKM "03: Proc. twelfth intern. conf. on Information and knowledge management, pages  28531, 2003. [7] G. Cao, J.-Y. Nie, and J. Bai. Integrating word relationships into  language models. In SIGIR "05: Proc. 28th annual intern. ACM SIGIR conf. on Research and development in information retrieval, pages 98-305, 2005. [8] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley-Interscience, 1991. [9] N. Craswell, D. Hawking, A. M. Vercoustre, and P. Wilkins. P@noptic expert: Searching for experts not just for documents. In Ausweb, 2001. [10] N. Craswell, A. de Vries, and I. Soboroff. Overview of the  TREC2005 Enterprise Track. In The Fourteenth Text REtrieval Conf. Proc. (TREC 2005), 2006. [11] T. H. Davenport and L. Prusak. Working Knowledge: How  Organizations Manage What They Know. Harvard Business School Press, Boston, MA, 1998. [12] T. Dunning. Accurate methods for the statistics of surprise and  coincidence. Computational Linguistics, 19(1):61-74, 1993. [13] E. Filatova and J. Prager. Tell me what you do and I"ll tell you what you are: Learning occupation-related activities for biographies. In HLT/EMNLP, 2005. [14] V. Lavrenko and W. B. Croft. Relevance based language models. In SIGIR "01: Proc. 24th annual intern. ACM SIGIR conf. on Research and development in information retrieval, pages 120-127, 2001. [15] V. Lavrenko, M. Choquette, and W. B. Croft. Cross-lingual relevance models. In SIGIR "02: Proc. 25th annual intern. ACM SIGIR conf. on Research and development in information retrieval, pages 175-182, 002. [16] C. Macdonald and I. Ounis. Voting for candidates: adapting data  fusion techniques for an expert search task. In CIKM "06: Proc. 15th ACM intern. conf. on Information and knowledge management, pages 87-396, 2006. [17] C. Manning and H. Sch¨utze. Foundations of Statistical Natural  Language Processing. The MIT Press, 1999. [18] A. Mockus and J. D. Herbsleb. Expertise browser: a quantitative  approach to identifying expertise. In ICSE "02: Proc. 24th Intern. Conf. on Software Engineering, pages 503-512, 2002. [19] D. Petkova and W. B. Croft. Hierarchical language models for expert finding in enterprise corpora. In Proc. ICTAI 2006, pages 599-608, 006. [20] I. Soboroff, A. de Vries, and N. Craswell. Overview of the TREC 006 Enterprise Track. In TREC 2006 Working Notes, 2006. [21] T. Tao, X. Wang, Q. Mei, and C. Zhai. Language model information retrieval with document expansion. In HLT-NAACL 2006, 2006. [22] TREC. Enterprise track, 2005. URL: http://www.ins.cwi. nl/projects/trec-ent/wiki/. [23] G. van Noord. TextCat Language Guesser. URL: http://www. let.rug.nl/˜vannoord/TextCat/. [24] W3C. The W3C test collection, 2005. URL: http://research. microsoft.com/users/nickcr/w3c-summary.html.
A Framework for Agent-Based Distributed Machine Learning and Data Mining Jan Tozicka Gerstner Laboratory Czech Technical University Technick«a 2, Prague, 166 27 Czech Republic tozicka@labe.felk.cvut.cz Michael Rovatsos School of Informatics The University of Edinburgh Edinburgh EH8 9LE United Kingdom mrovatso@inf.ed.ac.uk Michal Pechoucek Gerstner Laboratory Czech Technical University Technick«a 2, Prague, 166 27 Czech Republic pechouc@labe.felk.cvut.cz ABSTRACT This paper proposes a framework for agent-based  distributed machine learning and data mining based on (i) the exchange of meta-level descriptions of individual  learning processes among agents and (ii) online reasoning about learning success and learning progress by learning agents. We present an abstract architecture that enables agents to exchange models of their local learning processes and  introduces a number of different methods for integrating these processes. This allows us to apply existing agent  interaction mechanisms to distributed machine learning tasks, thus leveraging the powerful coordination methods available in agent-based computing, and enables agents to engage in meta-reasoning about their own learning decisions. We  apply this architecture to a real-world distributed clustering application to illustrate how the conceptual framework can be used in practical systems in which different learners may be using different datasets, hypotheses and learning  algorithms. We report on experimental results obtained using this system, review related work on the subject, and discuss potential future extensions to the framework. General Terms Theory Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  Intelligence-Multiagent Systems . INTRODUCTION In the areas of machine learning and data mining (cf. [14, 7] for overviews), it has long been recognised that  parallelisation and distribution can be used to improve learning performance. Various techniques have been suggested in this respect, ranging from the low-level integration of  independently derived learning hypotheses (e.g. combining  different classifiers to make optimal classification decisions [4, ], model averaging of Bayesian classifiers [8], or  consensusbased methods for integrating different clusterings [11]), to the high-level combination of learning results obtained by heterogeneous learning agents using meta-learning (e.g. [3, 0, 21]). All of these approaches assume homogeneity of agent  design (all agents apply the same learning algorithm) and/or agent objectives (all agents are trying to cooperatively solve a single, global learning problem). Therefore, the techniques they suggest are not applicable in societies of autonomous learners interacting in open systems. In such systems,  learners (agents) may not be able to integrate their datasets or learning results (because of different data formats and  representations, learning algorithms, or legal restrictions that prohibit such integration [11]) and cannot always be  guaranteed to interact in a strictly cooperative fashion (discovered knowledge and collected data might be economic assets that should only be shared when this is deemed profitable;  malicious agents might attempt to adversely influence others" learning results, etc.). Examples for applications of this kind abound. Many  distributed learning domains involve the use of sensitive data and prohibit the exchange of this data (e.g. exchange of  patient data in distributed brain tumour diagnosis [2]) -  however, they may permit the exchange of local learning  hypotheses among different learners. In other areas, training data might be commercially valuable, so that agents would only make it available to others if those agents could  provide something in return (e.g. in remote ship surveillance and tracking, where the different agencies involved are  commercial service providers [1]). Furthermore, agents might have a vested interest in negatively affecting other agents" learning performance. An example for this is that of  fraudulent agents on eBay which may try to prevent  reputationlearning agents from the construction of useful models for detecting fraud. Viewing learners as autonomous, self-directed agents is the only appropriate view one can take in modelling these distributed learning environments: the agent metaphor  becomes a necessity as oppossed to preferences for scalability, dynamic data selection, interactivity [13], which can also be achieved through (non-agent) distribution and  parallelisation in principle. Despite the autonomy and self-directedness of learning agents, many of these systems exhibit a sufficient overlap in terms of individual learning goals so that beneficial  cooperation might be possible if a model for flexible  interaction between autonomous learners was available that allowed agents to . exchange information about different aspects of their own learning mechanism at different levels of detail without being forced to reveal private information that should not be disclosed, . decide to what extent they want to share information about their own learning processes and utilise  information provided by other learners, and . reason about how this information can best be used to improve their own learning performance. Our model is based on the simple idea that autonomous learners should maintain meta-descriptions of their own learning processes (see also [3]) in order to be able to  exchange information and reason about them in a rational way (i.e. with the overall objective of improving their own  learning results). Our hypothesis is a very simple one: If we can devise a sufficiently general, abstract view of describing learning processes, we will be able to utilise the whole range of methods for (i) rational reasoning and (ii) communication and coordination offered by agent technology so as to build effective autonomous learning agents. To test this hypothesis, we introduce such an abstract  architecture (section 2) and implement a simple, concrete  instance of it in a real-world domain (section 3). We report on empirical results obtained with this implemented system that demonstrate the viability of our approach (section 4). Finally, we review related work (section 5) and conclude with a summary, discussion of our approach and outlook to future work on the subject (section 6). . ABSTRACT ARCHITECTURE Our framework is based on providing formal (meta-level) descriptions of learning processes, i.e. representations of all relevant components of the learning machinery used by a learning agent, together with information about the state of the learning process. To ensure that this framework is sufficiently general, we consider the following general description of a learning  problem: Given data D ⊆ D taken from an instance space D, a hypothesis space H and an (unknown)  target function c ∈ H1 , derive a function h ∈ H that approximates c as well as possible according to some performance measure g : H → Q where Q is a set of possible levels of learning performance.  By requiring this we are ensuring that the learning problem can be solved in principle using the given hypothesis space. This very broad definition includes a number of components of a learning problem for which more concrete specifications can be provided if we want to be more precise. For the cases of classification and clustering, for example, we can further specify the above as follows: Learning data can be described in both cases as D = ×n i=1[Ai] where [Ai] is the domain of the ith attribute and the set of attributes is A = {1, . . . , n}. For the hypothesis space we obtain H ⊆ {h|h : D → {0, 1}} in the case of classification (i.e. a subset of the set of all possible classifiers, the nature of which depends on the  expressivity of the learning algorithm used) and H ⊆ {h|h : D → N, h is total with range {1, . . . , k}} in the case of clustering (i.e. a subset of all sets of possible cluster assignments that map data points to a finite number of clusters numbered 1 to k). For classification, g might be defined in terms of the numbers of false negatives and false positives with respect to some validation set V ⊆ D, and clustering might use various measures of cluster validity to evaluate the quality of a current hypothesis, so that Q = R in both cases (but other sets of learning quality levels can be imagined). Next, we introduce a notion of learning step, which  imposes a uniform basic structure on all learning processes that are supposed to exchange information using our framework. For this, we assume that each learner is presented with a finite set of data D = d1, . . . dk in each step (this is an  ordered set to express that the order in which the samples are used for training matters) and employs a training/update function f : H × D∗ → H which updates h given a series of samples d1, . . . , dk. In other words, one learning step always consists of applying the update function to all samples in D exactly once. We define a learning step as a tuple l = D, H, f, g, h where we require that H ⊆ H and h ∈ H. The intuition behind this definition is that each learning step completely describes one learning iteration as shown in Figure 1: in step t, the learner updates the current  hypothesis ht−1 with data Dt, and evaluates the resulting new hypothesis ht according to the current performance measure gt. Such a learning step is equivalent to the following steps of computation: . train the algorithm on all samples in D (once), i.e.  calculate ft(ht−1, Dt) = ht, . calculate the quality gt of the resulting hypothesis gt(ht). We denote the set of all possible learning steps by L. For ease of notation, we denote the components of any l ∈ L by D(l), H(l), f(l) and g(l), respectively. The reason why such learning step specifications use a subset H of H instead of H itself is that learners often have explicit knowledge about which hypotheses are effectively ruled out by f given h in the future (if this is not the case, we can still set H = H). A learning process is a finite, non-empty sequence l = l1 → l2 → . . . → ln of learning steps such that ∀1 ≤ i < n .h(li+1) = f(li)(h(li), D(li)) The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 679 training function ht performance measure solution quality qtgtft training set Dt hypothesis hypothesis ht−1 Figure 1: A generic model of a learning step i.e. the only requirement the transition relation →⊆ L × L makes is that the new hypothesis is the result of training the old hypothesis on all available sample data that belongs to the current step. We denote the set of all possible learning processes by L (ignoring, for ease of notation, the fact that this set depends on H, D and the spaces of possible  training and evaluation functions f and g). The performance trace associated with a learning process l is the sequence q1, . . . , qn ∈ Qn where qi = g(li)(h(li)), i.e. the sequence of quality values calculated by the performance measures of the individual learning steps on the respective hypotheses. Such specifications allow agents to provide a  selfdescription of their learning process. However, in  communication among learning agents, it is often useful to  provide only partial information about one"s internal learning process rather than its full details, e.g. when advertising this information in order to enter information exchange  negotiations with others. For this purpose, we will assume that learners describe their internal state in terms of sets of learning processes (in the sense of disjunctive choice) which we call learning process descriptions (LPDs) rather than by giving precise descriptions about a single, concrete learning process. This allows us to describe properties of a learning  process without specifying its details exhaustively. As an  example, the set {l ∈ L|∀l = l[i].D(l) ≤ 100} describes all processes that have a training set of at most 100  samples (where all the other elements are arbitrary). Likewise, {l ∈ L|∀l = l[i].D(l) = {d}} is equivalent to just providing information about a single sample {d} and no other details about the process (this can be useful to model, for  example, data received from the environment). Therefore, we use ℘(L), that is the set of all LPDs, as the basis for  designing content languages for communication in the protocols we specify below. In practice, the actual content language chosen will of course be more restricted and allow only for a special type of subsets of L to be specified in a compact way, and its choice will be crucial for the interactions that can occur between learning agents. For our examples below, we simply assume explicit enumeration of all possible elements of the respective sets and function spaces (D, H, etc.) extended by the use of wildcard symbols ∗ (so that our second example above would become ({d}, ∗, ∗, ∗, ∗)). .1 Learning agents In our framework, a learning agent is essentially a  metareasoning function that operates on information about  learning processes and is situated in an environment co-inhabited by other learning agents. This means that it is not only  capable of meta-level control on how to learn, but in doing so it can take information into account that is provided by other agents or the environment. Although purely  cooperative or hybrid cases are possible, for the purposes of this paper we will assume that agents are purely self-interested, and that while there may be a potential for cooperation considering how agents can mutually improve each others" learning performance, there is no global mechanism that can enforce such cooperative behaviour.2 Formally speaking, an agent"s learning function is a  function which, given a set of histories of previous learning  processes (of oneself and potentially of learning processes about which other agents have provided information) and outputs a learning step which is its next learning action. In the most general sense, our learning agent"s internal learning process update can hence be viewed as a function λ : ℘(L) → L × ℘(L) which takes a set of learning histories of oneself and others as inputs and computes a new learning step to be executed while updating the set of known learning process histories (e.g. by appending the new learning action to one"s own learning process and leaving all information about others" learning processes untouched). Note that in λ({l1, . . . ln}) = (l, {l1, . . . ln }) some elements li of the input learning process set may be descriptions of new learning data received from the environment. The λ-function can essentially be freely chosen by the agent as long as one requirement is met, namely that the learning data that is being used always stems from what has been previously observed. More formally, ∀{l1, . . . ln} ∈ ℘(L).λ({l1, . . . ln}) = (l, {l1, . . . ln }) ⇒ „ D(l) ∪  [ l =li[j] D(l ) « ⊆ [ l =li[j] D(l ) i.e. whatever λ outputs as a new learning step and updated set of learning histories, it cannot invent new data; it has to work with the samples that have been made available to it earlier in the process through the environment or from other agents (and it can of course re-train on previously used data). The goal of the agent is to output an optimal learning step in each iteration given the information that it has. One possibility of specifying this is to require that ∀{l1, . . . ln} ∈ ℘(L).λ({l1, . . . ln}) = (l, {l1, . . . ln }) ⇒ l = arg max l ∈L g(l )(h(l )) but since it will usually be unrealistic to compute the  optimal next learning step in every situation, it is more useful  Note that our outlook is not only different from common, cooperative models of distributed machine learning and data mining, but also delineates our approach from multiagent learning systems in which agents learn about other agents [25], i.e. the learning goal itself is not affected by agents" behaviour in the environment. 80 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) i j Dj Hj fj gj hj Di pD→D  (Di, Dj) . .. pD→D kD→D (Di, Dj) . . . . . . n/a . . . Hi . .. ... n/a fi . .. ... n/a gi . .. n/a pg→h  (gi, hj) . .. pg→h kg→h (gi, hj) hi . .. n/a ... Table 1: Matrix of integration functions for  messages sent from learner i to j to simply use g(l )(h(l )) as a running performance measure to evaluate how well the agent is performing. This is too abstract and unspecific for our purposes: While it describes what agents should do (transform the settings for the next learning step in an optimal way), it doesn"t specify how this can be achieved in practice. .2 Integrating learning process information To specify how an agent"s learning process can be affected by integrating information received from others, we need to flesh out the details of how the learning steps it will perform can be modified using incoming information about learning processes described by other agents (this includes the  acquisition of new learning data from the environment as a special case). In the most general case, we can specify this in terms of the potential modifications to the existing  information about learning histories that can be performed using new information. For ease of presentation, we will assume that agents are stationary learning processes that can only record the previously executed learning step and only  exchange information about this one individual learning step (our model can be easily extended to cater for more complex settings). Let lj = Dj, Hj, fj, gj, hj be the current state of agent j when receiving a learning process description li = Di, Hi, fi, gi, hi from agent i (for the time being, we  assume that this is a specific learning step and not a more vague, disjunctive description of properties of the  learning step of i). Considering all possible interactions at an abstract level, we basically obtain a matrix of  possibilities for modifications of j"s learning step specification as shown in Table 1. In this matrix, each entry specifies a family of integration functions pc→c  , . . . , pc→c kc→c where c, c ∈ {D, H, f, g, h} and which define how agent j"s  component cj will be modified using the information ci provided about (the same or a different component of) i"s learning step by applying pc→c r (ci, cj) for some r ∈ {1, . . . , kc→c }. To put it more simply, the collections of p-functions an agent j uses specifies how it will modify its own learning behaviour using information obtained from i. For the diagonal of this matrix, which contains the most common ways of integrating new information in one"s own learning model, obvious ways of modifying one"s own  learning process include replacing cj by ci or ignoring ci  altogether. More complex/subtle forms of learning process  integration include: • Modification of Dj: append Di to Dj; filter out all elements from Dj which also appear in Di; append Di to Dj discarding all elements with attributes  outside ranges which affect gj, or those elements already correctly classified by hj; • Modification of Hi: use the union/intersection of Hi and Hj; alternatively, discard elements of Hj that are inconsistent with Dj in the process of intersection or union, or filter out elements that cannot be obtained using fj (unless fj is modified at the same time) • Modification of fj: modify parameters or background knowledge of fj using information about fi; assess their relevance by simulating previous learning steps on Dj using gj and discard those that do not help improve own performance • Modification of hj: combine hj with hi using (say)  logical or mathematical operators; make the use of hi  contingent on a pre-integration assessment of its quality using own data Dj and gj While this list does not include fully fledged, concrete  integration operations for learning processes, it is indicative of the broad range of interactions between individual agents" learning processes that our framework enables. Note that the list does not include any modifications to gj. This is because we do not allow modifications to the agent"s own quality measure as this would render the model of rational (learning) action useless (if the quality measure is relative and volatile, we cannot objectively judge learning performance). Also note that some of the above examples require consulting other elements of lj than those appearing as arguments of the p-operations; we omit these for ease of notation, but emphasise that information-rich operations will involve consulting many different aspects of lj. Apart from operations along the diagonal of the matrix, more exotic integration operations are conceivable that combine information about different components. In theory we could fill most of the matrix with entries for them, but for lack of space we list only a few examples: • Modification of Dj using fi: pre-process samples in fi, e.g. to achieve intermediate representations that fj can be applied to • Modification of Dj using hi: filter out samples from Dj that are covered by hi and build hj using fj only on remaining samples • Modification of Hj using fi: filter out hypotheses from Hj that are not realisable using fi • Modification of hj using gi: if hj is composed of several sub-components, filter out those sub-components that do not perform well according to gi • . . . Finally, many messages received from others describing properties of their learning processes will contain  information about several elements of a learning step, giving rise to yet more complex operations that depend on which kinds of information are available. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 681 Figure 2: Screenshot of our simulation system,  displaying online vessel tracking data for the North Sea region . APPLICATION EXAMPLE .1 Domain description As an illustration of our framework, we present an  agentbased data mining system for clustering-based surveillance using AIS (Automatic Identification System [1]) data. In our application domain, different commercial and  governmental agencies track the journeys of ships over time  using AIS data which contains structured information  automatically provided by ships equipped with shipborne  mobile AIS stations to shore stations, other ships and aircrafts. This data contains the ship"s identity, type, position, course, speed, navigational status and other safety-related  information. Figure 2 shows a screenshot of our simulation system. It is the task of AIS agencies to detect anomalous  behaviour so as to alarm police/coastguard units to further investigate unusual, potentially suspicious behaviour. Such behaviour might include things such as deviation from the standard routes between the declared origin and destination of the journey, unexpected close encounters between  different vessels on sea, or unusual patterns in the choice of destination over multiple journeys, taking the type of  vessel and reported freight into account. While the reasons for such unusual behaviour may range from pure coincidence or technical problems to criminal activity (such as smuggling, piracy, terrorist/military attacks) it is obviously useful to pre-process the huge amount of vessel (tracking) data that is available before engaging in further analysis by human experts. To support this automated pre-processing task, software used by these agencies applies clustering methods in order to identify outliers and flag those as potentially suspicious entities to the human user. However, many agencies active in this domain are competing enterprises and use their  (partially overlapping, but distinct) datasets and learning  hypotheses (models) as assets and hence cannot be expected to collaborate in a fully cooperative way to improve  overall learning results. Considering that this is the reality of the domain in the real world, it is easy to see that a  framework like the one we have suggested above might be useful to exploit the cooperation potential that is not exploited by current systems. .2 Agent-based distributed learning system design To describe a concrete design for the AIS domain, we need to specify the following elements of the overall system: . The datasets and clustering algorithms available to  individual agents, . the interaction mechanism used for exchanging  descriptions of learning processes, and . the decision mechanism agents apply to make learning decisions. Regarding 1., our agents are equipped with their own private datasets in the form of vessel descriptions. Learning samples are represented by tuples containing data about individual vessels in terms of attributes A = {1, . . . , n} including things such as width, length, etc. with real-valued domains ([Ai] = R for all i). In terms of learning algorithm, we consider clustering with a fixed number of k clusters using the k-means and k-medoids clustering algorithms [5] (fixed meaning that the learning algorithm will always output k clusters;  however, we allow agents to change the value of k over different learning cycles). This means that the hypothesis space can be defined as H = { c1, . . . , ck |ci ∈ R|A| } i.e. the set of all possible sets of k cluster centroids in |A|-dimensional  Euclidean space. For each hypothesis h = c1, . . . , ck and any data point d ∈ ×n i=1[Ai] given domain [Ai] for the ith  attribute of each sample, the assignment to clusters is given by C( c1, . . . , ck , d) = arg min ≤j≤k |d − cj| i.e. d is assigned to that cluster whose centroid is closest to the data point in terms of Euclidean distance. For evaluation purposes, each dataset pertaining to a  particular agent i is initially split into a training set Di and a validation Vi. Then, we generate a set of fake vessels Fi such that |Fi| = |Vi|. These two sets assess the agent"s ability to detect suspicious vessels. For this, we assign a confidence value r(h, d) to every ship d: r(h, d) =  |d − cC(h,d)| where C(h, d) is the index of the nearest centroid. Based on this measure, we classify any vessel in Fi ∪ Vi as fake if its r-value is below the median of all the confidences r(h, d) for d ∈ Fi ∪ Vi. With this, we can compute the quality gi(h) ∈ R as the ratio between all correctly classified vessels and all vessels in Fi ∪ Vi. As concerns 2., we use a simple Contract-Net Protocol (CNP) [20] based hypothesis trading mechanism: Before each learning iteration, agents issue (publicly broadcasted) Calls-For-Proposals (CfPs), advertising their own numerical model quality. In other words, the initiator of a CNP describes its own current learning state as (∗, ∗, ∗, gi(h), ∗) where h is their current hypothesis/model. We assume that agents are sincere when advertising their model quality, but note that this quality might be of limited relevance to other agents as they may specialise on specific regions of the data space not related to the test set of the sender of the CfP. Subsequently, (some) agents may issue bids in which they advertise, in turn, the quality of their own model. If the 82 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) bids (if any) are accepted by the initiator of the protocol who issued the CfP, the agents exchange their hypotheses and the next learning iteration ensues. To describe what is necessary for 3., we have to specify (i) under which conditions agents submit bids in response to a CfP, (ii) when they accept bids in the CNP negotiation process, and (iii) how they integrate the received  information in their own learning process. Concerning (i) and (ii), we employ a very simple rule that is identical in both cases: let g be one"s own model quality and g that advertised by the CfP (or highest bid, respectively). If g > g we respond to the CfP (accept the bid), else respond to the CfP  (accept the bid) with probability P(g /g) and ignore (reject) it else. If two agents make a deal, they exchange their  learning hypotheses (models). In our experiments, g and g are calculated by an additional agent that acts as a global  validation mechanism for all agents (in a more realistic setting a comparison mechanism for different g functions would have to be provided). As for (iii), each agent uses a single model merging  operator taken from the following two classes of operators (hj is the receiver"s own model and hi is the provider"s model): • ph→h (hi, hj) : - m-join: The m best clusters (in terms of coverage of Dj) from hypothesis hi are appended to hj. - m-select: The set of the m best clusters (in terms of coverage of Dj) from the union hi ∪hj is chosen as a new model. (Unlike m-join this method does not prefer own clusters over others".) • ph→D (hi, Dj) : - m-filter: The m best clusters (as above) from hi are identified and appended to a new model formed by using those samples not covered by these clusters applying the own learning  algorithm fj. Whenever m is large enough to encompass all clusters, we simply write join or filter for them. In section 4 we analyse the performance of each of these two classes for different choices of m. It is noteworthy that this agent-based distributed data mining system is one of the simplest conceivable instances of our abstract architecture. While we have previously  applied it also to a more complex market-based architecture using Inductive Logic Programming learners in a transport logistics domain [22], we believe that the system described here is complex enough to illustrate the key design decisions involved in using our framework and provides simple  example solutions for these design issues. . EXPERIMENTAL RESULTS Figure 3 shows results obtained from simulations with three learning agents in the above system using the k-means and k-medoids clustering methods respectively. We  partition the total dataset of 300 ships into three disjoint sets of 00 samples each and assign each of these to one learning agent. The Single Agent is learning from the whole dataset. The parameter k is set to 10 as this is the optimal value for the total dataset according to the Davies-Bouldin index [9]. For m-select we assume m = k which achieves a constant Figure 3: Performance results obtained for different integration operations in homogeneous learner  societies using the k-means (top) and k-medoids  (bottom) methods model size. For m-join and m-filter we assume m = 3 to limit the extent to which models increase over time. During each experiment the learning agents receive ship descriptions in batches of 10 samples. Between these batches, there is enough time to exchange the models among the agents and recompute the models if necessary. Each ship is described using width, length, draught and speed attributes with the goal of learning to detect which vessels have provided fake descriptions of their own properties. The validation set contains 100 real and 100 randomly generated fake ships. To generate sufficiently realistic properties for fake ships, their individual attribute values are taken from randomly selected ships in the validation set (so that each fake sample is a combination of attribute values of several existing ships). In these experiments, we are mainly interested in  investigating whether a simple form of knowledge sharing between self-interested learning agents could improve agent  performance compared to a setting of isolated learners. Thereby, we distinguish between homogeneous learner societies where all agents use the same clustering algorithm and  heterogeneous ones where different agents use different algorithms. As can be seen from the performance plots in Figure 3 (homogeneous case) and 4 (heterogeneous case, two agents use the same method and one agent uses the other) this is clearly the case for the (unrestricted) join and filter  integration operations (m = k) in both cases. This is quite natural, as these operations amount to sharing all available model knowledge among agents (under appropriate constraints  depending on how beneficial the exchange seems to the agents). We can see that the quality of these operations is very close to the Single Agent that has access to all training data. For the restricted (m < k) m-join, m-filter and m-select methods we can also observe an interesting distinction, The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 683 Figure 4: Performance results obtained for  different integration operations in heterogeneous societies with the majority of learners using the k-means (top) and k-medoids (bottom) methods namely that these perform similarly to the isolated learner case in homogeneous agent groups but better than isolated learners in more heterogeneous societies. This suggests that heterogeneous learners are able to benefit even from rather limited knowledge sharing (and this is what using a rather small m = 3 amounts to given that k = 10) while this is not always true for homogeneous agents. This nicely  illustrates how different learning or data mining algorithms can specialise on different parts of the problem space and then integrate their local results to achieve better individual  performance. Apart from these obvious performance benefits,  integrating partial learning results can also have other advantages: The m-filter operation, for example, decreases the number of learning samples and thus can speed up the learning  process. The relative number of filtered examples measured in our experiments is shown in the following table. k-means k-medoids filtering 30-40 % 10-20 % m-filtering 20-30 % 5-15 % The overall conclusion we can draw from these initial  experiments with our architecture is that since a very  simplistic application of its principles has proven capable of  improving the performance of individual learning agents, it is worthwhile investigating more complex forms of  information exchange about learning processes among autonomous learners. . RELATED WORK We have already mentioned work on distributed  (nonagent) machine learning and data mining in the  introductory chapter, so in this section we shall restrict ourselves to approaches that are more closely related to our outlook on distributed learning systems. Very often, approaches that are allegedly agent-based completely disregard agent autonomy and prescribe local decision-making procedures a priori. A typical example for this type of system is the one suggested by Caragea et al. [6] which is based on a distributed support-vector machine  approach where agents incrementally join their datasets  together according to a fixed distributed algorithm. A similar example is the work of Weiss [24], where groups of  classifier agents learn to organise their activity so as to optimise global system behaviour. The difference between this kind of collaborative  agentbased learning systems [16] and our own framework is that these approaches assume a joint learning goal that is pursued collaboratively by all agents. Many approaches rely heavily on a homogeneity  assumption: Plaza and Ontanon [15] suggest methods for  agentbased intelligent reuse of cases in case-based reasoning but is only applicable to societies of homogeneous learners (and coined towards a specific learning method). An  agentbased method for integrating distributed cluster analysis processes using density estimation is presented by Klusch et al. [13] which is also specifically designed for a  particular learning algorithm. The same is true of [22, 23] which both present market-based mechanisms for aggregating the output of multiple learning agents, even though these  approaches consider more interesting interaction mechanisms among learners. A number of approaches for sharing learning data [18] have also been proposed: Grecu and Becker [12] suggest an exchange of learning samples among agents, and Ghosh et al. [11] is a step in the right direction in terms of revealing only partial information about one"s learning process as it deals with limited information sharing in distributed  clustering. Papyrus [3] is a system that provides a markup language for meta-description of data, hypotheses and intermediate results and allows for an exchange of all this information among different nodes, however with a strictly cooperative goal of distributing the load for massively distributed data mining tasks. The MALE system [19] was a very early multiagent  learning system in which agents used a blackboard approach to communicate their hypotheses. Agents were able to critique each others" hypotheses until agreement was reached.  However, all agents in this system were identical and the system was strictly cooperative. The ANIMALS system [10] was used to simulate  multistrategy learning by combining two or more learning  techniques (represented by heterogeneous agents) in order to overcome weaknesses in the individual algorithms, yet it was also a strictly cooperative system. As these examples show and to the best of our knowledge, there have been no previous attempts to provide a  framework that can accommodate both independent and  heterogeneous learning agents and this can be regarded as the main contribution of our work. . CONCLUSION In this paper, we outlined a generic, abstract framework for distributed machine learning and data mining. This framework constitutes, to our knowledge, the first attempt 84 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) to capture complex forms of interaction between  heterogeneous and/or self-interested learners in an architecture that can be used as the foundation for implementing systems that use complex interaction and reasoning mechanisms to enable agents to inform and improve their learning abilities with information provided by other learners in the system,  provided that all agents engage in a sufficiently similar learning activity. To illustrate that the abstract principles of our  architecture can be turned into concrete, computational systems, we described a market-based distributed clustering system which was evaluated in the domain of vessel tracking for purposes of identifying deviant or suspicious behaviour.  Although our experimental results only hint at the potential of using our architecture, they underline that what we are proposing is feasible in principle and can have beneficial  effects even in its most simple instantiation. Yet there is a number of issues that we have not addressed in the presentation of the architecture and its empirical  evaluation: Firstly, we have not considered the cost of  communication and made the implicit assumption that the required communication comes for free. This is of course  inadequate if we want to evaluate our method in terms of the total effort required for producing a certain quality of  learning results. Secondly, we have not experimented with agents using completely different learning algorithms (e.g. symbolic and numerical). In systems composed of completely different agents the circumstances under which successful information exchange can be achieved might be very different from those described here, and much more complex communication and reasoning methods may be necessary to achieve a useful  integration of different agents" learning processes. Finally, more sophisticated evaluation criteria for such distributed  learning architectures have to be developed to shed some light on what the right measures of optimality for autonomously reasoning and communicating agents should be. These issues, together with a more systematic and  thorough investigation of advanced interaction and  communication mechanisms for distributed, collaborating and  competing agents will be the subject of our future work on the subject. Acknowledgement: We gratefully acknowledge the  support of the presented research by Army Research  Laboratory project N62558-03-0819 and Office for Naval Research project N00014-06-1-0232. . REFERENCES [1] http://www.aislive.com. [2] http://www.healthagents.com. [3] S. Bailey, R. Grossman, H. Sivakumar, and A. Turinsky. Papyrus: A System for Data Mining over Local and Wide Area Clusters and Super-Clusters. In Proc. of the Conference on Supercomputing. 1999. [4] E. Bauer and R. Kohavi. An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants. Machine Learning, 36, 1999. [5] P. Berkhin. Survey of Clustering Data Mining Techniques, Technical Report, Accrue Software, 2002. [6] D. Caragea, A. Silvescu, and V. Honavar. Agents that Learn from Distributed Dynamic Data sources. In Proc. of the Workshop on Learning Agents, 2000. [7] N. Chawla and S. E. abd L. O. Hall. Creating ensembles of classifiers. In Proceedings of ICDM 2001, pages 580-581, San Jose, CA, USA, 2001. [8] D. Dash and G. F. Cooper. Model Averaging for Prediction with Discrete Bayesian Networks. Journal of Machine Learning Research, 5:1177-1203, 2004. [9] D. L. Davies and D. W. Bouldin. A Cluster Separation Measure. IEEE Transactions on Pattern Analysis and Machine Intelligence, 4:224-227, 1979. [10] P. Edwards and W. Davies. A Heterogeneous Multi-Agent Learning System. In Proceedings of the Special Interest Group on Cooperating Knowledge Based Systems, pages 163-184, 1993. [11] J. Ghosh, A. Strehl, and S. Merugu. A Consensus Framework for Integrating Distributed Clusterings Under Limited Knowledge Sharing. In NSF Workshop on Next Generation Data Mining, 99-108, 2002. [12] D. L. Grecu and L. A. Becker. Coactive Learning for Distributed Data Mining. In Proceedings of KDD-98, pages 209-213, New York, NY, August 1998. [13] M. Klusch, S. Lodi, and G. Moro. Agent-based distributed data mining: The KDEC scheme. In AgentLink, number 2586 in LNCS. Springer, 2003. [14] T. M. Mitchell. Machine Learning, pages 29-36. McGraw-Hill, New York, 1997. [15] S. Ontanon and E. Plaza. Recycling Data for Multi-Agent Learning. In Proc. of ICML-05, 2005. [16] L. Panait and S. Luke. Cooperative multi-agent learning: The state of the art. Autonomous Agents and Multi-Agent Systems, 11(3):387-434, 2005. [17] B. Park and H. Kargupta. Distributed Data Mining: Algorithms, Systems, and Applications. In N. Ye, editor, Data Mining Handbook, pages 341-358, 2002. [18] F. J. Provost and D. N. Hennessy. Scaling up: Distributed machine learning with cooperation. In Proc. of AAAI-96, pages 74-79. AAAI Press, 1996. [19] S. Sian. Extending learning to multiple agents: Issues and a model for multi-agent machine learning (ma-ml). In Y. Kodratoff, editor, Machine  LearningEWSL-91, pages 440-456. Springer-Verlag, 1991. [20] R. Smith. The contract-net protocol: High-level communication and control in a distributed problem solver. IEEE Transactions on Computers, C-29(12):1104-1113, 1980. [21] S. J. Stolfo, A. L. Prodromidis, S. Tselepis, W. Lee, D. W. Fan, and P. K. Chan. Jam: Java Agents for Meta-Learning over Distributed Databases. In Proc. of the KDD-97, pages 74-81, USA, 1997. [22] J. Toˇziˇcka, M. Jakob, and M. Pˇechouˇcek. Market-Inspired Approach to Collaborative Learning. In Cooperative Information Agents X (CIA 2006), volume 4149 of LNCS, pages 213-227. Springer, 2006. [23] Y. Z. Wei, L. Moreau, and N. R. Jennings. Recommender systems: a market-based design. In Proceedings of AAMAS-03), pages 600-607, 2003. [24] G. Weiß. A Multiagent Perspective of Parallel and Distributed Machine Learning. In Proceedings of Agents"98, pages 226-230, 1998. [25] G. Weiss and P. Dillenbourg. What is "multi" in multi-agent learning? Collaborative-learning: Cognitive and Computational Approaches, 64-80, 1999. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 685
Bidding Algorithms for a Distributed Combinatorial Auction Benito Mendoza ∗ and Jos´e M. Vidal Computer Science and Engineering University of South Carolina Columbia, SC 29208 mendoza2@engr.sc.edu, vidal@sc.edu ABSTRACT Distributed allocation and multiagent coordination  problems can be solved through combinatorial auctions.  However, most of the existing winner determination algorithms for combinatorial auctions are centralized. The PAUSE  auction is one of a few efforts to release the auctioneer from having to do all the work (it might even be possible to get rid of the auctioneer). It is an increasing price  combinatorial auction that naturally distributes the problem of  winner determination amongst the bidders in such a way that they have an incentive to perform the calculation. It can be used when we wish to distribute the computational load among the bidders or when the bidders do not wish to reveal their true valuations unless necessary. PAUSE establishes the rules the bidders must obey. However, it does not tell us how the bidders should calculate their bids. We have developed a couple of bidding algorithms for the bidders in a PAUSE auction. Our algorithms always return the set of bids that maximizes the bidder"s utility. Since the problem is NP-Hard, run time remains exponential on the number of items, but it is remarkably better than an exhaustive search. In this paper we present our bidding algorithms, discuss their virtues and drawbacks, and compare the  solutions obtained by them to the revenue-maximizing solution found by a centralized winner determination algorithm. Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Distributed  Artificial Intelligence-Intelligent Agents, Multiagent Systems. General Terms Algorithms, Performance. . INTRODUCTION Both the research and practice of combinatorial auctions have grown rapidly in the past ten years. In a  combinatorial auction bidders can place bids on combinations of items, called packages or bidsets, rather than just  individual items. Once the bidders place their bids, it is necessary to find the allocation of items to bidders that maximizes the auctioneer"s revenue. This problem, known as the  winner determination problem, is a combinatorial optimization problem and is NP-Hard [10]. Nevertheless, several  algorithms that have a satisfactory performance for problem sizes and structures occurring in practice have been  developed. The practical applications of combinatorial auctions include: allocation of airport takeoff and landing time slots, procurement of freight transportation services, procurement of public transport services, and industrial procurement [2]. Because of their wide applicability, one cannot hope for a general-purpose winner determination algorithm that can efficiently solve every instance of the problem. Thus,  several approaches and algorithms have been proposed to  address the winner determination problem. However, most of the existing winner determination algorithms for  combinatorial auctions are centralized, meaning that they require all agents to send their bids to a centralized auctioneer who then determines the winners. Examples of these algorithms are CASS [3], Bidtree [11] and CABOB [12]. We believe that distributed solutions to the winner determination problem should be studied as they offer a better fit for some  applications as when, for example, agents do not want to reveal their valuations to the auctioneer. The PAUSE (Progressive Adaptive User Selection  Environment) auction [4, 5] is one of a few efforts to distribute the problem of winner determination amongst the bidders. PAUSE establishes the rules the participants have to adhere to so that the work is distributed amongst them. However, it is not concerned with how the bidders determine what they should bid. In this paper we present two algorithms, pausebid and cachedpausebid, which enable agents in a PAUSE  auction to find the bidset that maximizes their utility. Our algorithms implement a myopic utility maximizing strategy and are guaranteed to find the bidset that maximizes the agent"s utility given the outstanding best bids at a given time. pausebid performs a branch and bound search  completely from scratch every time that it is called.  cachedpausebid is a caching-based algorithm which explores fewer nodes, since it caches some solutions. 94 78-81-904262-7-5 (RPS) c 2007 IFAAMAS . THE PAUSE AUCTION A PAUSE auction for m items has m stages. Stage 1  consists of having simultaneous ascending price open-cry  auctions and during this stage the bidders can only place bids on individual items. At the end of this state we will know what the highest bid for each individual item is and who placed that bid. Each successive stage k = 2, 3, . . . , m consists of an ascending price auction where the bidders must submit bidsets that cover all items but each one of the bids must be for k items or less. The bidders are allowed to use bids that other agents have placed in previous rounds when building their bidsets, thus allowing them to find better solutions. Also, any new bidset has to have a sum of bid prices which is bigger than that of the currently winning bidset. At the end of each stage k all agents know the best bid for every subset of size k or less. Also, at any point in time after stage  has ended there is a standing bidset whose value increases monotonically as new bidsets are submitted. Since in the final round all agents consider all possible bidsets, we know that the final winning bidset will be one such that no agent can propose a better bidset. Note, however, that this  bidset is not guaranteed to be the one that maximizes revenue since we are using an ascending price auction so the  winning bid for each set will be only slightly bigger than the second highest bid for the particular set of items. That is, the final prices will not be the same as the prices in a  traditional combinatorial auction where all the bidders bid their true valuation. However, there remains the open question of whether the final distribution of items to bidders found in a PAUSE auction is the same as the revenue maximizing solution. Our test results provide an answer to this question. The PAUSE auction makes the job of the auctioneer very easy. All it has to do is to make sure that each new  bidset has a revenue bigger than the current winning bidset, as well as make sure that every bid in an agent"s bidset that is not his does indeed correspond to some other agents"  previous bid. The computational problem shifts from one of winner determination to one of bid generation. Each agent must search over the space of all bidsets which contain at least one of its bids. The search is made easier by the fact that the agent needs to consider only the current best bids and only wants bidsets where its own utility is higher than in the current winning bidset. Each agent also has a clear incentive for performing this computation, namely, its  utility only increases with each bidset it proposes (of course, it might decrease with the bidsets that others propose).  Finally, the PAUSE auction has been shown to be envy-free in that at the conclusion of the auction no bidder would prefer to exchange his allocation with that of any other bidder [2]. We can even envision completely eliminating the  auctioneer and, instead, have every agent perform the task of the auctioneer. That is, all bids are broadcast and when an agent receives a bid from another agent it updates the set of best bids and determines if the new bid is indeed better than the current winning bid. The agents would have an  incentive to perform their computation as it will increase their expected utility. Also, any lies about other agents" bids are easily found out by keeping track of the bids sent out by  every agent (the set of best bids). Namely, the only one that can increase an agent"s bid value is the agent itself.  Anyone claiming a higher value for some other agent is lying. The only thing missing is an algorithm that calculates the utility-maximizing bidset for each agent. . PROBLEM FORMULATION A bid b is composed of three elements bitems (the set of items the bid is over), bagent (the agent that placed the bid), and bvalue (the value or price of the bid). The agents  maintain a set B of the current best bids, one for each set of items of size ≤ k, where k is the current stage. At any point in the auction, after the first round, there will also be a set W ⊆ B of currently winning bids. This is the set of bids that covers all the items and currently maximizes the revenue, where the revenue of W is given by r(W) = b∈W bvalue . (1) Agent i"s value function is given by vi(S) ∈ where S is a set of items. Given an agent"s value function and the current winning bidset W we can calculate the agent"s utility from W as ui(W) = b∈W | bagent=i vi(bitems ) − bvalue . (2) That is, the agent"s utility for a bidset W is the value it receives for the items it wins in W minus the price it must pay for those items. If the agent is not winning any items then its utility is zero. The goal of the bidding agents in the PAUSE auction is to maximize their utility, subject to the constraint that their next set of bids must have a total revenue that is at least bigger than the current revenue, where is the smallest increment allowed in the auction. Formally, given that W is the current winning bidset, agent i must find a g∗ i such that r(g∗ i ) ≥ r(W) + and g∗ i = arg max g⊆2B ui(g), (3) where each g is a set of bids that covers all items and ∀b∈g (b ∈ B) or (bagent = i and bvalue > B(bitems ) and size(bitems ) ≤ k), and where B(items) is the value of the bid in B for the set items (if there is no bid for those items it returns zero). That is, each bid b in g must satisfy at least one of the two following conditions. 1) b is already in B, 2) b is a bid of size ≤ k in which the agent i bids higher than the price for the same items in B. . BIDDING ALGORITHMS According to the PAUSE auction, during the first stage we have only several English auctions, with the bidders  submitting bids on individual items. In this case, an agent"s  dominant strategy is to bid higher than the current winning bid until it reaches its valuation for that particular item. Our algorithms focus on the subsequent stages: k > 1. When k > 1, agents have to find g∗ i . This can be done by  performing a complete search on B. However, this approach is computationally expensive since it produces a large search tree. Our algorithms represent alternative approaches to overcome this expensive search. .1 The PAUSEBID Algorithm In the pausebid algorithm (shown in Figure 1) we  implement some heuristics to prune the search tree. Given that bidders want to maximize their utility and that at any given point there are likely only a few bids within B which The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 695 pausebid(i, k)  my-bids ← ∅  their-bids ← ∅  for b ∈ B  do if bagent = i or vi(bitems ) > bvalue  then my-bids ← my-bids +new Bid(bitems , i, vi(bitems ))  else their-bids ← their-bids +b  for S ∈ subsets of k or fewer items such that vi(S) > 0 and ¬∃b∈Bbitems = S  do my-bids ← my-bids +new Bid(S, i, vi(S))  bids ← my-bids + their-bids 0 g∗ ← ∅ £ Global variable 1 u∗ ← ui(W)£ Global variable 2 pbsearch(bids, ∅) 3 surplus ← b∈g∗ | bagent=i bvalue − B(bitems ) 4 if surplus = 0 5 then return g∗ 6 my-payment ← vi(g∗ ) − u∗ 7 for b ∈ g∗ | bagent = i 8 do if my-payment ≤ 0 9 then bvalue ← B(bitems ) 0 else bvalue ← B(bitems ) + my-payment ·bvalue −B(bitems ) surplus 1 return g∗ Figure 1: The pausebid algorithm which implements a branch and bound search. i is the agent and k is the current stage of the auction, for k ≥ 2. the agent can dominate, we start by defining my-bids to be the list of bids for which the agent"s valuation is higher than the current best bid, as given in B. We set the value of these bids to be the agent"s true valuation (but we won"t necessarily be bidding true valuation, as we explain later). Similarly, we set their-bids to be the rest of the bids from B. Finally, the agent"s search list is simply the concatenation of my-bids and their-bids. Note that the agent"s own bids are placed first on the search list as this will enable us to do more pruning (pausebid lines 3 to 9). The agent can now perform a branch and bound search on the branch-on-bids tree produced by these bids. This branch and bound search is implemented by pbsearch (Figure 2). Our algorithm not only implements the standard bound but it also implements other pruning techniques in order to further reduce the size of the search tree. The bound we use is the maximum utility that the agent can expect to receive from a given set of bids. We call it u∗ . Initially, u∗ is set to ui(W) (pausebid line 11) since that is the utility the agent currently receives and any solution he proposes should give him more utility. If pbsearch ever comes across a partial solution where the maximum utility the agent can expect to receive is less than u∗ then that subtree is pruned (pbsearch line 21). Note that we can determine the maximum utility only after the algorithm has searched over all of the agent"s own bids (which are first on the list) because after that we know that the solution will not include any more bids where the agent is the winner thus the agent"s utility will no longer increase. For example, pbsearch(bids, g)  if bids = ∅ then return  b ← first(bids)  bids ← bids −b  g ← g + b  ¯Ig ← items not in g  if g does not contain a bid from i  then return  if g includes all items  then min-payment ← max(0, r(W) + − (r(g) − ri(g)), b∈g | bagent=i B(bitems )) 0 max-utility ← vi(g) − min-payment 1 if r(g) > r(W) and max-utility ≥ u∗ 2 then g∗ ← g 3 u∗ ← max-utility 4 pbsearch(bids, g − b) £ b is Out 5 else max-revenue ← r(g) + max(h(¯Ig), hi(¯Ig)) 6 if max-revenue ≤ r(W) 7 then pbsearch(bids, g − b) £ b is Out 8 elseif bagent = i 9 then min-payment ← (r(W) + ) −(r(g) − ri(g)) − h(¯Ig) 0 max-utility ← vi(g) − min-payment 1 if max-utility > u∗ 2 then pbsearch({x ∈ bids | xitems ∩ bitems = ∅}, g) £ b is In 3 pbsearch(bids, g − b) £ b is Out 4 else 5 pbsearch({x ∈ bids | xitems ∩ bitems = ∅}, g) £ b is In 6 pbsearch(bids, g − b) £ b is Out 7 return Figure 2: The pbsearch recursive procedure where bids is the set of available bids and g is the current partial solution. if an agent has only one bid in my-bids then the maximum utility he can expect is equal to his value for the items in that bid minus the minimum possible payment we can make for those items and still come up with a set of bids that has revenue greater than r(W). The calculation of the minimum payment is shown in line 19 for the partial solution case and line 9 for the case where we have a complete solution in pbsearch. Note that in order to calculate the min-payment for the partial solution case we need an upper bound on the payments that we must make for each item. This upper bound is provided by h(S) = s∈S max b∈B | s∈bitems bvalue size(bitems) . (4) This function produces a bound identical to the one used by the Bidtree algorithm-it merely assigns to each individual item in S a value equal to the maximum bid in B divided by the number of items in that bid. To prune the branches that cannot lead to a solution with revenue greater than the current W, the algorithm considers both the values of the bids in B and the valuations of the 96 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent. Similarly to (4) we define hi(S, k) = s∈S max S | size(S )≤k and s∈S and vi(S )>0 vi(S ) size(S ) (5) which assigns to each individual item s in S the maximum value produced by the valuation of S divided by the size of S , where S is a set for which the agent has a valuation greater than zero, contains s, and its size is less or equal than k. The algorithm uses the heuristics h and hi (lines 15 and 19 of pbsearch), to prune the just mentioned branches in the same way an A∗ algorithm uses its heuristic. A final pruning technique implemented by the algorithm is ignoring any branches where the agent has no bids in the current answer g and no more of the agent"s bids are in the list (pbsearch lines 6 and 7). The resulting g∗ found by pbsearch is thus the set of bids that has revenue bigger than r(W) and maximizes agent i"s utility. However, agent i"s bids in g∗ are still set to his own valuation and not to the lowest possible price. Lines 17 to 20 in pausebid are responsible for setting the agent"s payments so that it can achieve its maximum utility u∗ . If the agent has only one bid in g∗ then it is simply a matter of reducing the payment of that bid by u∗ from the current maximum of the agent"s true valuation. However, if the agent has more than one bid then we face the problem of how to distribute the agent"s payments among these bids. There are many ways of distributing the payments and there does not appear to be a dominant strategy for performing this distribution. We have chosen to distribute the payments in proportion to the agent"s true valuation for each set of items. pausebid assumes that the set of best bids B and the  current best winning bidset W remains constant during its  execution, and it returns the agent"s myopic utility-maximizing bidset (if there is one) using a branch and bound search. However it repeats the whole search at every stage. We can minimize this problem by caching the result of previous searches. .2 The CACHEDPAUSEBID Algorithm The cachedpausebid algorithm (shown in Figure 3) is our second approach to solve the bidding problem in the PAUSE auction. It is based in a cache table called C-Table where we store some solutions to avoid doing a complete search every time. The problem is the same; the agent i has to find g∗ i . We note that g∗ i is a bidset that contains at least one bid of the agent i. Let S be a set of items for which the agent i has a valuation such that vi(S) ≥ B(S) > 0, let gS i be a bidset over S such that r(gS i ) ≥ r(W) + and gS i = arg max g⊆2B ui(g), (6) where each g is a set of bids that covers all items and ∀b∈g (b ∈ B) or (bagent = i and bvalue > B(bitems )) and (∃b∈gbitems = S and bagent = i). That is, gS i is i"s best  bidset for all items which includes a bid from i for all S items. In the PAUSE auction we cannot bid for sets of items with size greater than k. So, if we have for each set of items S for which vi(S) > 0 and size(S) ≤ k its corresponding gS i then g∗ i is the gS i that maximizes the agent"s utility. That is g∗ i = arg max {S | vi(S)>0∧size(S)≤k} ui(gS i ). (7) Each agent i implements a hash table C-Table such that C-Table[S] = gS for all S which vi(S) ≥ B(S) > 0. We can cachedpausebid(i, k, k-changed)  for each S in C-Table  do if vi(S) < B(S)  then remove S from C-Table  else if k-changed and size(S) = k  then B ← B + new Bid(i, S, vi(S))  g∗ ← ∅  u∗ ← ui(W)  for each S with size(S) ≤ k in C-Table  do ¯S ← Items − S 0 gS ← C-Table[S] £ Global variable 1 min-payment ← max(r(W) + , b∈gS B(bitems )) 2 uS ← r(gS ) − min-payment £ Global variable 3 if (k-changed and size(S) = k) or (∃b∈B bitems ⊆ ¯S and bagent = i) 4 then B ← {b ∈ B |bitems ⊆ ¯S} 5 bids ← B +{b ∈ B|bitems ⊆ ¯S and b /∈ B } 6 for b ∈ bids 7 do if vi(bitems ) > bvalue 8 then bagent ← i 9 bvalue ← vi(bitems ) 0 if k-changed and size(S) = k 1 then n ← size(bids) 2 uS ← 0 3 else n ← size(B ) 4 g ← ∅ + new Bid(S, i, vi(S)) 5 cpbsearch(bids, g, n) 6 C-Table[S] ← gS 7 if uS > u∗ and r(gS ) ≥ r(W) + 8 then surplus ← b∈gS | bagent=i bvalue − B(bitems ) 9 if surplus > 0 0 then my-payment ← vi(gS ) − ui(gS ) 1 for b ∈ gS | bagent = i 2 do if my-payment ≤ 0 3 then bvalue ← B(bitems ) 4 else bvalue ← B(bitems )+ my-payment ·bvalue −B(bitems ) surplus 5 u∗ ← ui(gS ) 6 g∗ ← gS 7 else if uS ≤ 0 and vi(S) < B(S) 8 then remove S from C-Table 9 return g∗ Figure 3: The cachedpausebid algorithm that  implements a caching based search to find a bidset that maximizes the utility for the agent i. k is the  current stage of the auction (for k ≥ 2), and k-changed is a boolean that is true right after the auction moved to the next stage. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 697 cpbsearch(bids, g, n)  if bids = ∅ or n ≤ 0 then return  b ← first(bids)  bids ← bids −b  g ← g + b  ¯Ig ← items not in g  if g includes all items  then min-payment ← max(0, r(W) + − (r(g) − ri(g)), b∈g | bagent=i B(bitems ))  max-utility ← vi(g) − min-payment  if r(g) > r(W) and max-utility ≥ uS 0 then gS ← g 1 uS ← max-utility 2 cpbsearch(bids, g − b, n − 1) £ b is Out 3 else max-revenue ← r(g) + max(h(¯Ig), hi(¯Ig)) 4 if max-revenue ≤ r(W) 5 then cpbsearch(bids, g − b, n − 1) £ b is Out 6 elseif bagent = i 7 then min-payment ← (r(W) + ) −(r(g) − ri(g)) − h(¯Ig) 8 max-utility ← vi(g) − min-payment 9 if max-utility > uS 0 then cpbsearch({x ∈ bids | xitems ∩ bitems = ∅}, g, n + 1) £ b is In 1 cpbsearch(bids, g − b, n − 1) £ b is Out 2 else 3 cpbsearch({x ∈ bids | xitems ∩ bitems = ∅}, g, n + 1) £ b is In 4 cpbsearch(bids, g − b, n − 1) £ b is Out 5 return Figure 4: The cpbsearch recursive procedure where bids is the set of available bids, g is the current  partial solution and n is a value that indicates how deep in the list bids the algorithm has to search. then find g∗ by searching for the gS , stored in C-Table[S], that maximizes the agent"s utility, considering only the set of items S with size(S) ≤ k. The problem remains in  maintaining the C-Table updated and avoiding to search every gS every time. cachedpausebid deals with this and other details. Let B be the set of bids that contains the new best bids, that is, B contains the bids recently added to B and the bids that have changed price (always higher), bidder, or both and were already in B. Let ¯S = Items − S be the complement of S (the set of items not included in S). cachedpausebid takes three parameters: i the agent, k the current stage of the auction, and k-changed a boolean that is true right after the auction moved to the next stage. Initially C-Table has one row or entry for each set S for which vi(S) > 0. We start by eliminating the entries corresponding to each set S for which vi(S) < B(S) from C-Table (line 3). Then, in the case that k-changed is true, for each set S with size(S) = k, we add to B a bid for that set with value equal to vi(S) and bidder agent i (line 5); this a bid that the agent is now allowed to consider. We then search for g∗ amongst the gS stored in C-Table, for this we only need to consider the sets with size(S) ≤ k (line 8). But how do we know that the gS in C-Table[S] is still the best solution for S? There are only two cases when we are not sure about that and we need to do a search to update C-Table[S]. These cases are: i) When k-changed is true and size(S) ≤ k, since there was no gS stored in C-Table for this S. ii) When there exists at least one bid in B for the set of items ¯S or a subset of it submitted by an agent different than i, since it is probable that this new bid can produce a solution better than the one stored in C-Table[S]. We handle the two cases mentioned above in lines 13 to 26 of cachedpausebid. In both of these cases, since gS must contain a bid for S we need to find a bidset that cover the missing items, that is ¯S. Thus, our search space consists of all the bids on B for the set of items ¯S or for a subset of it. We build the list bids that contains only those bids. However, we put the bids from B at the beginning of bids (line 14) since they are the ones that have changed. Then, we replace the bids in bids that have a price lower than the valuation the agent i has for those same items with a bid from agent i for those items and value equal to the agent"s valuation (lines 16-19). The recursive procedure cpbsearch, called in line 25 of cachedpausebid and shown in Figure 4, is the one that finds the new gS . cpbsearch is a slightly modified version of our branch and bound search implemented in pbsearch. The first modification is that it has a third parameter n that indicates how deep on the list bids we want to search, since it stops searching when n less or equal to zero and not only when the list bids is empty (line 1). Each time that there is a recursive call of cpbsearch n is decreased by one when a bid from bids is discarded or out (lines 12, 15, 21, and 24) and n remains the same otherwise (lines 20 and 23). We set the value of n before calling cpbsearch, to be the size of the list bids (cachedpausebid line 21) in case i), since we want cpbsearch to search over all bids; and we set n to be the number of bids from B included in bids (cachedpausebid line 23) in case ii), since we know that only the those first n bids in bids changed and can affect our current gS . Another difference with pbsearch is that the bound in cpbsearch is uS which we set to be 0 (cachedpausebid line 2) when in case i) and r(gS )−min-payment (cachedpausebid line 12) when in case ii). We call cpbsearch with g already containing a bid for S. After cpbsearch is executed we are sure that we have the right gS , so we store it in the corresponding C-Table[S] (cachedpausebid line 26). When we reach line 27 in cachedpausebid, we are sure that we have the right gS . However, agent i"s bids in gS are still set to his own valuation and not to the lowest possible price. If uS is greater than the current u∗ , lines 31 to 34 in cachedpausebid are responsible for setting the agent"s payments so that it can achieve its maximum utility uS . As in pausebid, we have chosen to distribute the payments in proportion to the agent"s true valuation for each set of items. In the case that uS less than or equal to zero and the valuation that the agent i has for the set of items S is lower than the current value of the bid in B for the same set of items, we remove the corresponding C-Table[S] since we know that is not worthwhile to keep it in the cache table (cachedpausebid line 38). The cachedpausebid function is called when k > 1 and returns the agent"s myopic utility-maximizing bidset, if there is one. It assumes that W and B remains constant during its execution. 98 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) generatevalues(i, items)  for x ∈ items  do vi(x) = expd(.01)  for n ← 1 . . . (num-bids − items)  do s1, s2 ←Two random sets of items with values.  vi(s1 ∪ s2) = vi(s1) + vi(s2) + expd(.01) Figure 5: Algorithm for the generation of random value functions. expd(x) returns a random number taken from an exponential distribution with mean /x.  0 0 0 0 00  3 4 5 6 7 8 9 10 Number of Items CachedPauseBid  3 3 3 3 3  3   PauseBid + + + + + + + + + + Figure 6: Average percentage of convergence (y-axis), which is the percentage of times that our algorithms converge to the revenue-maximizing  solution, as function of the number of items in the auction. . TEST AND COMPARISON We have implemented both algorithms and performed a series of experiments in order to determine how their  solution compares to the revenue-maximizing solution and how their times compare with each other. In order to do our tests we had to generate value functions for the agents1 . The algorithm we used is shown in Figure 5. The type of valuations it generates correspond to domains where a set of agents must perform a set of tasks but there are cost  savings for particular agents if they can bundle together certain subsets of tasks. For example, imagine a set of robots which must pick up and deliver items to different locations. Since each robot is at a different location and has different  abilities, each one will have different preferences over how to bundle. Their costs for the item bundles are subadditive, which means that their preferences are superadditive. The first experiment we performed simply ensured the proper  Note that we could not use CATS [6] because it generates sets of bids for an indeterminate number of agents. It is as if you were told the set of bids placed in a combinatorial auction but not who placed each bid or even how many people placed bids, and then asked to determine the value function of every participant in the auction.  0 0 0 0 00  3 4 5 6 7 8 9 10 Number of Items CachedPauseBid    3  3 3 3 3  PauseBid + + + + + + + + + + Figure 7: Average percentage of revenue from our algorithms relative to maximum revenue (y-axis) as function of the number of items in the auction. functioning of our algorithms. We then compared the  solutions found by both of them to the revenue-maximizing solution as found by CASS when given a set of bids that corresponds to the agents" true valuation. That is, for each agent i and each set of items S for which vi(S) > 0 we  generated a bid. This set of bids was fed to CASS which  implements a centralized winner determination algorithm to find the solution which maximizes revenue. Note, however, that the revenue from the PAUSE auction on all the auctions is always smaller than the revenue of the revenue-maximizing solution when the agents bid their true valuations. Since PAUSE uses English auctions the final prices (roughly)  represent the second-highest valuation, plus , for that set of items. We fixed the number of agents to be 5 and we  experimented with different number of items, namely from 2 to 0. We ran both algorithms 100 times for each  combination. When we compared the solutions of our algorithms to the revenue-maximizing solution, we realized that they do not always find the same distribution of items as the revenue-maximizing solution (as shown in Figure 6). The cases where our algorithms failed to arrive at the  distribution of the revenue-maximizing solution are those where there was a large gap between the first and second  valuation for a set (or sets) of items. If the revenue-maximizing solution contains the bid (or bids) using these higher  valuation then it is impossible for the PAUSE auction to find this solution because that bid (those bids) is never placed. For example, if agent i has vi(1) = 1000 and the second highest valuation for (1) is only 10 then i only needs to place a bid of 11 in order to win that item. If the revenue-maximizing solution requires that 1 be sold for 1000 then that solution will never be found because that bid will never be placed. We also found that average percentage of times that our  algorithms converges to the revenue-maximizing solution  decreases as the number of items increases. For 2 items is almost 100% but decreases a little bit less than 1 percent as the items increase, so that this average percentage of  convergence is around 90% for 10 items. In a few instances our algorithms find different solutions this is due to the different The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 699  0 00 000 0000  3 4 5 6 7 8 9 10 Number of Items CachedPauseBid          PauseBid + + + + + + + + + + Figure 8: Average number of expanded nodes (y-axis) as function of items in the auction. ordering of the bids in the bids list which makes them search in different order. We know that the revenue generated by the PAUSE  auction is generally lower than the revenue of the  revenuemaximizing solution, but how much lower? To answer this question we calculated percentage representing the  proportion of the revenue given by our algorithms relative to the revenue given by CASS. We found that the percentage of revenue of our algorithms increases in average 2.7% as the number of items increases, as shown in Figure 7. However, we found that cachedpausebid generates a higher revenue than pausebid (4.3% higher in average) except for auctions with 2 items where both have about the same percentage. Again, this difference is produced by the order of the search. In the case of 2 items both algorithms produce in average a revenue proportion of 67.4%, while in the other extreme (10 items), cachedpausebid produced in average a revenue proportion of 91.5% while pausebid produced in average a revenue proportion of 87.7%. The scalability of our algorithms can be determined by counting the number of nodes expanded in the search tree. For this we count the number of times that pbsearch gets invoked for each time that pausebid is called and the  number of times that fastpausebidsearch gets invoked for each time that cachedpausebid, respectively for each of our  algorithms. As expected since this is an NP-Hard problem, the number of expanded nodes does grow exponentially with the number of items (as shown in Figure 8). However, we found that cachedpausebid outperforms pausebid, since it expands in average less than half the number of nodes. For example, the average number of nodes expanded when  items is zero for cachedpausebid while for pausebid is ; and in the other extreme (10 items) cachedpausebid  expands in average only 633 nodes while pausebid expands in average 1672 nodes, a difference of more than 1000 nodes. Although the number of nodes expanded by our algorithms increases as function of the number of items, the actual  number of nodes is a much smaller than the worst-case scenario of nn where n is the number of items. For example, for 10 items we expand slightly more than 103 nodes for the case of pausebid and less than that for the case of  cachedpause0.1  0 00 000  3 4 5 6 7 8 9 10 Number of Items CachedPauseBid           PauseBid + + + + + + + + + + Figure 9: Average time in seconds that takes to  finish an auction (y-axis) as function of the number of items in the auction. bid which are much smaller numbers than 1010 . Notice also that our value generation algorithm (Figure 5) generates a number of bids that is exponential on the number of items, as might be expected in many situations. As such, these results do not support the conclusion that time grows  exponentially with the number of items when the number of bids is independent of the number of items. We expect that both algorithms will grow exponentially as a function the number of bids, but stay roughly constant as the number of items grows. We wanted to make sure that less expanded nodes does indeed correspond to faster execution, especially since our algorithms execute different operations. We thus ran the same experiment with all the agents in the same machine, an Intel Centrino 2.0 GHz laptop PC with 1 GB of RAM and a 7200 RMP 60 GB hard drive, and calculated the average time that takes to finish an auction for each algorithm. As shown in Figure 9, cachedpausebid is faster than  pausebid, the difference in execution speed is even more clear as the number of items increases. . RELATED WORK A lot of research has been done on various aspects of  combinatorial auctions. We recommend [2] for a good review. However, the study of distributed winner determination  algorithms for combinatorial auctions is still relatively new. One approach is given by the algorithms for distributing the winner determination problem in combinatorial auctions presented in [7], but these algorithms assume the  computational entities are the items being sold and thus end up with a different type of distribution. The VSA algorithm [3] is another way of performing distributed winner  determination in combinatorial auction but it assumes the bids themselves perform the computation. This algorithm also fails to converge to a solution for most cases. In [9] the  authors present a distributed mechanism for calculating VCG payments in a mechanism design problem. Their  mechanism roughly amounts to having each agent calculate the payments for two other agents and give these to a secure 00 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) central server which then checks to make sure results from all pairs agree, otherwise a re-calculation is ordered. This general idea, which they call the redundancy principle, could also be applied to our problem but it requires the existence of a secure center agent that everyone trusts. Another  interesting approach is given in [8] where the bidding agents prioritize their bids, thus reducing the set of bids that the centralized winner determination algorithm must consider, making that problem easier. Finally, in the computation procuring clock auction [1] the agents are given an  everincreasing percentage of the surplus achieved by their  proposed solution over the current best. As such, it assumes the agents are impartial computational entities, not the set of possible buyers as assumed by the PAUSE auction. . CONCLUSIONS We believe that distributed solutions to the winner  determination problem should be studied as they offer a better fit for some applications as when, for example, agents do not want to reveal their valuations to the auctioneer or when we wish to distribute the computational load among the bidders. The PAUSE auction is one of a few approaches to decentralize the winner determination problem in  combinatorial auctions. With this auction, we can even envision completely eliminating the auctioneer and, instead, have  every agent performe the task of the auctioneer. However, while PAUSE establishes the rules the bidders must obey, it does not tell us how the bidders should calculate their bids. We have presented two algorithms, pausebid and  cachedpausebid, that bidder agents can use to engage in a PAUSE auction. Both algorithms implement a myopic utility  maximizing strategy that is guaranteed to find the bidset that maximizes the agent"s utility given the set of outstanding best bids at any given time, without considering possible future bids. Both algorithms find, most of the time, the same distribution of items as the revenue-maximizing  solution. The cases where our algorithms failed to arrive at that distribution are those where there was a large gap between the first and second valuation for a set (or sets) of items. As it is an NP-Hard problem, the running time of our  algorithms remains exponential but it is significantly better than a full search. pausebid performs a branch and bound search completely from scratch each time it is invoked.  cachedpausebid caches partial solutions and performs a branch and bound search only on the few portions affected by the changes on the bids between consecutive times.  cachedpausebid has a better performance since it explores fewer nodes (less than half) and it is faster. As expected the revenue generated by a PAUSE auction is lower than the revenue of a revenue-maximizing solution found by a  centralized winner determination algorithm, however we found that cachedpausebid generates in average 4.7% higher  revenue than pausebid. We also found that the revenue  generated by our algorithms increases as function of the number of items in the auction. Our algorithms have shown that it is feasible to implement the complex coordination constraints supported by  combinatorial auctions without having to resort to a centralized winner determination algorithm. Moreover, because of the design of the PAUSE auction, the agents in the auction also have an incentive to perform the required computation. Our bidding algorithms can be used by any multiagent system that would use combinatorial auctions for coordination but would rather not implement a centralized auctioneer. . REFERENCES [1] P. J. Brewer. Decentralized computation procurement and computational robustness in a smart market. Economic Theory, 13(1):41-92, January 1999. [2] P. Cramton, Y. Shoham, and R. Steinberg, editors. Combinatorial Auctions. MIT Press, 2006. [3] Y. Fujishima, K. Leyton-Brown, and Y. Shoham. Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches. In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 548-553. Morgan Kaufmann Publishers Inc., 1999. [4] F. Kelly and R. Stenberg. A combinatorial auction with multiple winners for universal service. Management Science, 46(4):586-596, 2000. [5] A. Land, S. Powell, and R. Steinberg. PAUSE: A computationally tractable combinatorial auction. In Cramton et al. [2], chapter 6, pages 139-157. [6] K. Leyton-Brown, M. Pearson, and Y. Shoham. Towards a universal test suite for combinatorial auction algorithms. In Proceedings of the 2nd ACM conference on Electronic commerce, pages 66-76. ACM Press, 2000. http://cats.stanford.edu. [7] M. V. Narumanchi and J. M. Vidal. Algorithms for distributed winner determination in combinatorial auctions. In LNAI volume of AMEC/TADA. Springer, 006. [8] S. Park and M. H. Rothkopf. Auctions with endogenously determined allowable combinations. Technical report, Rutgets Center for Operations Research, January 2001. RRR 3-2001. [9] D. C. Parkes and J. Shneidman. Distributed implementations of vickrey-clarke-groves auctions. In Proceedings of the Third International Joint Conference on Autonomous Agents and MultiAgent Systems, pages 261-268. ACM, 2004. [10] M. H. Rothkopf, A. Pekec, and R. M. Harstad. Computationally manageable combinational auctions. Management Science, 44(8):1131-1147, 1998. [11] T. Sandholm. An algorithm for winner determination in combinatorial auctions. Artificial Intelligence, 35(1-2):1-54, February 2002. [12] T. Sandholm, S. Suri, A. Gilpin, and D. Levine. CABOB: a fast optimal algorithm for winner determination in combinatorial auctions. Management Science, 51(3):374-391, 2005. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 701
A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general  framework that can model complex problems in multi-agent systems. Several current algorithms that solve general DCOP instances,  including ADOPT and DPOP, arrange agents into a traditional  pseudotree structure. We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements. Our  algorithm correctly solves DCOP instances for pseudotrees that  include edges between nodes in separate branches. The algorithm also solves instances with traditional pseudotree arrangements  using the same procedure as DPOP. We compare our algorithm with DPOP using several metrics  including the induced width of the pseudotrees, the maximum  dimensionality of messages and computation, and the maximum  sequential path cost through the algorithm. We prove that for some  problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree. We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity. For some problem instances we observe significant improvements in message and computation sizes compared to DPOP. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  Intelligence-Multiagent Systems General Terms Algorithms . INTRODUCTION Many historical problems in the AI community can be  transformed into Constraint Satisfaction Problems (CSP). With the  advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems. CSPs were originally extended to distributed agent environments in [9]. Early domains for  distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2]. Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained  problems that are difficult or impossible to satisfy for every constraint. Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions. Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility. This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1]. Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming. Search based  algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].  Dynamic programming based algorithms include DPOP and its  extensions [5, 6, 7]. To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem. It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree. However, it was also shown that  finding the optimal pseudotree was NP-Hard. We began to  investigate the performance of traditional pseudotrees generated by  current edge-traversal heuristics. We found that these heuristics  often produced little parallelism as the pseudotrees tended to have high depth and low branching factors. We suspected that there could be other ways to arrange the pseudotrees that would  provide increased parallelism and smaller message sizes. After  exploring these other arrangements we found that cross-edged  pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees. Our hypothesis was that these  crossedged pseudotrees would outperform traditional pseudotrees for some problem types. In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees. We begin with a definition of 41 78-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees. We then provide a summary of the original DPOP algorithm and  introduce our DCPOP algorithm. We discuss the complexity of our algorithm as well as the impact of pseudotree generation  heuristics. We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem  instances. We conclude with a selection of ideas for future work and extensions for DCPOP. . PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6]. A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal. Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities. The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values. For this paper we only consider binary utility functions involving two variables. Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. .1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches. As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding X"s parent). Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C,  BD), and one back-edge (A-C). Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree. Solid line edges  represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship. Figure 2: A cross-edged pseudotree. Solid line edges represent parent-child relationships, the dashed line represents a  pseudoparent-pseudo-child relationship, and the dotted line  represents a branch-parent-branch-child relationship. The bolded node, B, is the merge point for node E. .2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root. A cross-edged  pseudotree is a traditional pseudotree with the addition of cross-edges. Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E). In a cross-edged pseudotree we designate certain edges as primary. The set of primary edges defines a spanning tree of the nodes. The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this  primary edge spanning tree. This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) .3 Pseudotree Generation 42 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to  generate a traditional pseudotree from a general DCOP instance. Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion. First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U. Next, various heuristics are used to arrange this graph into a pseudotree. One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion. We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph. This includes DFS, breadth-first search, and best-first search based traversals. Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. . DPOP ALGORITHM The original DPOP algorithm operates in three main phases. The first phase generates a traditional pseudotree from the DCOP  instance using a distributed algorithm. The second phase joins utility hypercubes from children and the local node and propagates them towards the root. The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node. The complexity of DPOP depends on the size of the largest  computation and utility message during phase two. It has been shown that this size directly corresponds to the induced width of the  pseudotree generated in phase one [6]. DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard. Several distributed  edgetraversal heuristics have been developed to find low width  pseudotrees [8]. At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. .1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube. This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X). This hypercube has dimensional size equal to the number of pseudo-parents plus one. A message  containing this hypercube is sent to P(X). Agents located at non-leaf nodes wait for all messages from children to arrive. Once the agent at node Y has all utility messages, it calculates its local utility  hypercube which includes domains for P(Y), PP(Y), and Y. The local utility hypercube is then joined with all of the hypercubes from the child messages. At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube. This elimination process chooses the best utility over the domain of Y for each combination of the remaining  domains. A message containing this hypercube is now sent to P(Y). The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility  hypercube. This dynamic programming based propagation phase  continues until the agent at the root node of the pseudotree has received all messages from its children. .2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children. Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes  received from its children. The combined hypercube contains only values for the domain for Z. At this point the agent at node Z  simply chooses the assignment for its domain that has the best utility. A value propagation message with this assignment is sent to each node in C(Z). Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the  message. The node adds its domain assignment to the assignments it received and passes the set of assignments to its children. The  algorithm is complete when all nodes have chosen an assignment for their domain. . DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in  Algorithm 1, shares the same three phases. The first phase generates the cross-edged pseudotree for the DCOP instance. The second phase merges branches and propagates the utility hypercubes. The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node. For the first phase we generate a pseudotree using several  distributed heuristics and select the one with lowest overall  complexity. The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree. Instead, we use a polynomial time method for calculating the maximum computation and utility  message size for a given cross-edged pseudotree. A description of this method and the pseudotree selection process appears in  Section 5. At the end of the first phase, each agent knows its  parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. .1 Merging Branches and Utility  Propagation In the original DPOP algorithm a node X only had utility  functions involving its parent and its pseudo-parents. In DCPOP, a node X is allowed to have a utility function involving a branch-parent. The concept of a branch can be seen in Figure 2 with node E  representing our node X. The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent. This  message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X). It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a  single representation by this branch information structure (this  number starts at 1). Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X. In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch. As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent. In DCPOP this message contains dimensions for the domains of P(X) and PP(X). If node X also has branch-parents, then the utility  propagation message also contains a dimension for the domain of X, and will include a branch information structure. In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch. When a node Y receives utility propagation messages from all of The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X. The merged branch information structure accumulates the number of merged branches for X. If the  cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X. This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X. In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility  hypercubes. To illustrate this process, we will examine what happens in the second phase for node B in Figure 2. In the second phase Node B receives two utility propagation messages. The first comes from node C and includes dimensions for domains E, B, and A. It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch. The second comes from node D and includes dimensions for domains E and B. It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch. Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility  propagation message to node A, containing only one dimension for the domain of A. Although not possible in DPOP, this method of utility  propagation and dimension elimination may produce hypercubes at node Y that do not share any domains. In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y. This lazy approach to joins helps to reduce message sizes. .2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children. At this point the agent at node Z chooses the assignment for its domain that has the best utility. If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X. Thus any node that is a merge point will choose assignments for a domain other than its own. These assignments are then passed down the primary edge hierarchy. If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X. Every node in the  hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children. The algorithm is complete when all nodes have chosen or received an assignment for their domain. .3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP. Given a traditional pseudotree as  input, the DCPOP algorithm execution is identical to DPOP. Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges. Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains  belonging to the parent or pseudo-parents of a node. Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node. Thus all value propagation assignments are chosen at the node of the assignment domain. For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points. We note that any node X that is not a merge point assigns its value exactly as in DPOP. The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X). As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X). Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X). Thus after eliminating domains for which assignments are known, only the domain of X is left. The agent at node X can now correctly choose the assignment with maximum utility for its own domain. If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root. From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages. Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree. For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X). Thus X has utility  information about all of the utility functions of which Y is a part. By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y. The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. .4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X). The second phase sends one value assignment message to each C(X). Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance. The actual complexity of DCPOP depends on two additional  measurements: message size and computation size. Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of  overlapping back-edges. It was shown in [6] that the number of  overlapping back-edges is equal to the induced width of the pseudotree. In a poorly constructed cross-edged pseudotree, the number of  overlapping branches at node X can be as large as the total number of descendants of X. Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph. However, in practice a well  constructed cross-edged pseudotree can achieve much better results. Later we address the issue of choosing well constructed  crossedged pseudotrees from a set. We introduce an additional measurement of the maximum  sequential path cost through the algorithm. This measurement  directly relates to the maximum amount of parallelism achievable by the algorithm. To take this measurement we first store the total computation size for each node during phase two and three. This computation size represents the number of individual accesses to a value in a hypercube at each node. For example, a join between two domains of size 4 costs 4 ∗ 4 = 16. Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation  messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes. The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. . HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm. We acknowledge 44 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm : DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation : elect leader from all Xj ∈ X : elected leader initiates pseudotree creation : afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation : if |BP(Xi)| > 0 then : BRANCHXi ← |BP(Xi)| + 1 : for all Xk ∈BP(Xi) do : UTILXi (Xk) ←Compute utils(Xi, Xk) : Send message(Xk,UTILXi (Xk),BRANCHXi ) 0: if |C(Xi)| = 0(i.e. Xi is a leaf node) then 1: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 2: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 3: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 4: activate UTIL Message handler() Phase 3: VALUE message propagation 5: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 6: store UTILXk (Xi),BRANCHXk (Xi) 7: if UTIL messages from all children and branch children arrived then 8: for all Bj ∈BRANCH(Xi) do 9: if Bj is merged then 0: join all hypercubes where Bj ∈UTIL(Xi) 1: eliminate Bj from the joined hypercube 2: if P(Xi) == null (that means Xi is the root) then 3: v ∗ i ← Choose optimal(null) 4: Send VALUE(Xi, v ∗ i) to all C(Xi) 5: else 6: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 7: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 8: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 9: Xi ← v ∗ i =Choose optimal(agent view) 0: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance. The problem of finding the best pseudotree for a given DCOP instance is NP-Hard. Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic. Some previous research focused on finding heuristics to generate good pseudotrees [8]. While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees. We consider only heuristics that run in polynomial time with  respect to the number of nodes in the original DCOP instance. The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in  linear space-time complexity. To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments. Instead, messages include  dimensional and branch information but no utility hypercubes. After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the  measurement information up to the chosen root in that pseudotree. The root then broadcasts the total complexity for that heuristic to all nodes. After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree. Each node then proceeds to begin the DCPOP algorithm using its  knowledge of the pseudotree generated by the best heuristic. The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal. The general distributed algorithm uses a token passing mechanism and a linear number of messages.  Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion. The DFS based heuristics used in our experiments come from the work done in [4, ]. .1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees  perform a best-first traversal. A general distributed best-first  algorithm for node expansion is presented in Algorithm 2. An  evaluation function at each node provides the values that are used to determine the next best node to expand. Note that in this  algorithm each node only exchanges its best value with its neighbors. In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which  contains a list of neighbors (with each neighbor"s placement depth in the tree if it was placed). From these we can calculate  branchparents, branch-children, and unknown relationships for a potential node placement. The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the  number of unknown relationships being a tiebreak. After completion each node has knowledge of its parent and ancestors, so it can  easily determine which connected nodes are pseudo-parents,  branchparents, pseudo-children, and branch-children. The complexity of the best-first traversal depends on the  complexity of the evaluation function. Assuming a complexity of O(V ) for the evaluation function, which is the case for our best  overall function, the best-first traversal is O(V · E) which is at worst O(n3 ). For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation. The place operation is at most O(V ) because of the sent messages.  Finding the next node uses recursion and traverses only already placed The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all  neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions. Each recursion performs a  recursive getBestNeighbor operation that traverses all placed nodes and their neighbors. This operation is O(V · E), but results can be cached using only O(V ) space at each node. Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E). If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E). This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E). Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). . COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP  performs the same as DPOP. We also have shown that we can  accurately predict performance of a given pseudotree in linear  spacetime complexity. If we use a constant number of heuristics to  generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity. We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal  heuristics). In Figure 3(a) we have a DCOP instance with six nodes. This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged  pseudotree arrangement for the DCOP instance partition. In Figure 3(b) we see a traditional pseudotree  arrangement for this DCOP instance. It is easy to see that any  edgetraversal based heuristic cannot expand two nodes from the same partition in succession. We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree. Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b). We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP  algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in  Figure 3(c) requires only a maximum of four domains in any  computation during DCPOP. Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches. In addition each of these nodes has node A as its parent. Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F). Since no better traditional pseudotree arrangement can be  created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal. We acknowledge that pseudotree  arrangements that allow parent-child relationships without an actual  constraint can solve the problem in Figure 3(a) with maximum  computation size of four domains. However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require  information about nodes with which it has no constraint. Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar. In practice, since finding the best pseudotree  arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. . EXPERIMENTAL RESULTS 46 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size. We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP  instance. We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism  achievable by the algorithm. The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node. We also include as metrics the  maximum computation size in number of dimensions (CD) and  maximum message size in number of dimensions (MD). To analyze the relative complexity of a given DCOP instance, we find the  minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. .1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each. Each problem was generated by  assigning a random number (picked from a range) of constraints to each variable. The generator then created binary constraints until each variable reached its maximum number of constraints. The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5. The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3. Since most of the problems in the second set were too complex to actually  compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem. Results are shown for the first set in Table 1 and for the second set in Table 2. For the two problem sets we split the cases into low density and high density categories. Low density cases consist of those  problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g. IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems). High density problems consist of the remainder of the problem sets. In both Table 1 and Table 2 we have listed performance  metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP  algorithm using traditional and cross-edged pseudotrees (DCPOP-All). The pseudotrees used for DPOP were generated using 5  heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC. These are all versions of the guided DFS traversal discussed in Section 5. The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B. These are all versions of the best-first traversal discussed in Section 5. For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set. For DCPOP-All we chose the best pseudotree produced by all 0 heuristics for each problem in the set. For the CD and MD  metrics the value shown is the average number of dimensions. For the PC metric the value shown is the natural logarithm of the  maximum sequential path cost (since the actual value grows  exponentially with the complexity of the problem). The final row in both tables is a measurement of improvement of DCPOP-All over DPOP. For the CD and MD metrics the value shown is a reduction in number of dimensions. For the PC metric the value shown is a percentage reduction in the maximum  sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100). Notice that  DCPOPAll outperforms DPOP on all metrics. This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP. Thus given the choice between the  pseudotrees produced by all 10 heuristics, DCPOP-All will always  outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 0 4 12 13.5 2.25 -0.01 -0.01 5.6% 0 14 44 57.6 3.63 0.09 0.09 10.9% 0 24 76 101.3 4.17 0.08 0.09 10.7% 00 49 156 212.9 5.04 0.16 0.20 30.0% 50 74 236 321.8 5.32 0.21 0.23 35.8% 00 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP. Another trend we notice is that the improvement is greater for high density problems than low density problems. We show this trend in greater detail in Figures 4, 5, and 6. Notice how the improvement increases as the complexity of the problem increases. .2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6]. The problem setup includes a number of people that are grouped into departments. Each person must attend a specified number of meetings. Meetings can be held within departments or among departments, and can be assigned to one of eight time slots. The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting. All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot. All variables that belong to the same meeting have equality constraints so that all of the  participants choose the same time slot. Unary constraints are placed on each variable to account for a person"s valuation of each meeting and time slot. For our tests we generated 100 sample problems for each  combination of agents and meetings. Results are shown in Table 3. The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total  number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree. The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP. Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. . CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves  general DCOP instances using cross-edged pseudotree arrangements. Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase. Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes. We have shown that DCPOP fully extends DPOP by performing the same operations given the same input. We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem  instances by extending the allowable input set to include cross-edged pseudotrees. We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees. We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity. Given the importance of a good pseudotree for performance, future work will include new  heuristics to find better pseudotrees. Future work will also include  adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. . REFERENCES [1] J. Liu and K. P. Sycara. Exploiting problem structure for distributed constraint optimization. In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni. A dynamic distributed constraint satisfaction approach to resource allocation. Lecture Notes in Computer Science, 239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo. An asynchronous complete method for distributed constraint optimization. In AAMAS 03, 2003. [4] A. Petcu. Frodo: A framework for open/distributed constraint optimization. Technical Report No. 2006/001 006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings. A-dpop: Approximations in distributed optimization. In poster in CP 2005, pages 02-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings. Dpop: A scalable method for multiagent constraint optimization. In IJCAI 05, pages 66-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes. M-dpop: Faithful distributed implementation of efficient social choice problems. In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov. Solving meeting scheduling problems using distributed pseudotree-optimization procedure. Master"s thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara. Distributed constraint satisfaction for formalizing distributed problem solving. In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara. The distributed constraint satisfaction problem: Formalization and algorithms. Knowledge and Data Engineering, 0(5):673-685, 1998. 48 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Dynamics Based Control with an Application to Area-Sweeping Problems Zinovi Rabinovich Engineering and Computer Science Hebrew University of Jerusalem Jerusalem, Israel nomad@cs.huji.ac.il Jeffrey S. Rosenschein Engineering and Computer Science Hebrew University of Jerusalem Jerusalem, Israel jeff@cs.huji.ac.il Gal A. Kaminka The MAVERICK Group Department of Computer Science Bar Ilan University, Israel galk@cs.biu.ac.il ABSTRACT In this paper we introduce Dynamics Based Control (DBC), an approach to planning and control of an agent in stochastic  environments. Unlike existing approaches, which seek to optimize  expected rewards (e.g., in Partially Observable Markov Decision  Problems (POMDPs)), DBC optimizes system behavior towards  specified system dynamics. We show that a recently developed planning and control approach, Extended Markov Tracking (EMT) is an  instantiation of DBC. EMT employs greedy action selection to  provide an efficient control algorithm in Markovian environments. We exploit this efficiency in a set of experiments that applied  multitarget EMT to a class of area-sweeping problems (searching for moving targets). We show that such problems can be naturally  defined and efficiently solved using the DBC framework, and its EMT instantiation. Categories and Subject Descriptors I.2.8 [Problem Solving, Control Methods, and Search]:  Control Theory; I.2.9 [Robotics]; I.2.11 [Distributed Artificial  Intelligence]: Intelligent Agents General Terms Algorithms, Theory . INTRODUCTION Planning and control constitutes a central research area in  multiagent systems and artificial intelligence. In recent years, Partially Observable Markov Decision Processes (POMDPs) [12] have  become a popular formal basis for planning in stochastic  environments. In this framework, the planning and control problem is often addressed by imposing a reward function, and computing a policy (of choosing actions) that is optimal, in the sense that it will result in the highest expected utility. While theoretically attractive, the complexity of optimally solving a POMDP is prohibitive [8, 7]. We take an alternative view of planning in stochastic  environments. We do not use a (state-based) reward function, but instead optimize over a different criterion, a transition-based specification of the desired system dynamics. The idea here is to view  planexecution as a process that compels a (stochastic) system to change, and a plan as a dynamic process that shapes that change according to desired criteria. We call this general planning framework  Dynamics Based Control (DBC). In DBC, the goal of a planning (or control) process becomes to ensure that the system will change in accordance with specific  (potentially stochastic) target dynamics. As actual system behavior may deviate from that which is specified by target dynamics (due to the stochastic nature of the system), planning in such  environments needs to be continual [4], in a manner similar to classical closed-loop controllers [16]. Here, optimality is measured in terms of probability of deviation magnitudes. In this paper, we present the structure of Dynamics Based  Control. We show that the recently developed Extended Markov  Tracking (EMT) approach [13, 14, 15] is subsumed by DBC, with EMT employing greedy action selection, which is a specific  parameterization among the options possible within DBC. EMT is an efficient instantiation of DBC. To evaluate DBC, we carried out a set of experiments applying multi-target EMT to the Tag Game [11]; this is a variant on the area sweeping problem, where an agent is trying to tag a moving target (quarry) whose position is not known with certainty.  Experimental data demonstrates that even with a simple model of the environment and a simple design of target dynamics, high success rates can be produced both in catching the quarry, and in surprising the quarry (as expressed by the observed entropy of the controlled agent"s position). The paper is organized as follows. In Section 2 we motivate DBC using area-sweeping problems, and discuss related work. Section 3 introduces the Dynamics Based Control (DBC) structure, and its specialization to Markovian environments. This is followed by a review of the Extended Markov Tracking (EMT) approach as a DBC-structured control regimen in Section 4. That section also discusses the limitations of EMT-based control relative to the  general DBC framework. Experimental settings and results are then presented in Section 5. Section 6 provides a short discussion of the overall approach, and Section 7 gives some concluding remarks and directions for future work. 90 78-81-904262-7-5 (RPS) c 2007 IFAAMAS . MOTIVATION AND RELATED WORK Many real-life scenarios naturally have a stochastic target  dynamics specification, especially those domains where there exists no ultimate goal, but rather system behavior (with specific  properties) that has to be continually supported. For example, security guards perform persistent sweeps of an area to detect any sign of intrusion. Cunning thieves will attempt to track these sweeps, and time their operation to key points of the guards" motion. It is thus advisable to make the guards" motion dynamics appear irregular and random. Recent work by Paruchuri et al. [10] has addressed such  randomization in the context of single-agent and distributed POMDPs. The goal in that work was to generate policies that provide a measure of action-selection randomization, while maintaining rewards within some acceptable levels. Our focus differs from this work in that DBC does not optimize expected rewards-indeed we do not  consider rewards at all-but instead maintains desired dynamics  (including, but not limited to, randomization). The Game of Tag is another example of the applicability of the approach. It was introduced in the work by Pineau et al. [11]. There are two agents that can move about an area, which is divided into a grid. The grid may have blocked cells (holes) into which no agent can move. One agent (the hunter) seeks to move into a cell  occupied by the other (the quarry), such that they are co-located (this is a successful tag). The quarry seeks to avoid the hunter agent, and is always aware of the hunter"s position, but does not know how the hunter will behave, which opens up the possibility for a hunter to surprise the prey. The hunter knows the quarry"s probabilistic law of motion, but does not know its current location. Tag is an instance of a family of area-sweeping (pursuit-evasion) problems. In [11], the hunter modeled the problem using a POMDP. A  reward function was defined, to reflect the desire to tag the quarry, and an action policy was computed to optimize the reward  collected over time. Due to the intractable complexity of determining the optimal policy, the action policy computed in that paper was essentially an approximation. In this paper, instead of formulating a reward function, we use EMT to solve the problem, by directly specifying the target  dynamics. In fact, any search problem with randomized motion, the  socalled class of area sweeping problems, can be described through specification of such target system dynamics. Dynamics Based Control provides a natural approach to solving these problems. . DYNAMICS BASED CONTROL The specification of Dynamics Based Control (DBC) can be  broken into three interacting levels: Environment Design Level, User Level, and Agent Level. • Environment Design Level is concerned with the formal specification and modeling of the environment. For  example, this level would specify the laws of physics within the system, and set its parameters, such as the gravitation  constant. • User Level in turn relies on the environment model produced by Environment Design to specify the target system  dynamics it wishes to observe. The User Level also specifies the  estimation or learning procedure for system dynamics, and the measure of deviation. In the museum guard scenario above, these would correspond to a stochastic sweep schedule, and a measure of relative surprise between the specified and actual sweeping. • Agent Level in turn combines the environment model from the Environment Design level, the dynamics estimation  procedure, the deviation measure and the target dynamics  specification from User Level, to produce a sequence of actions that create system dynamics as close as possible to the  targeted specification. As we are interested in the continual development of a stochastic system, such as happens in classical control theory [16] and  continual planning [4], as well as in our example of museum sweeps, the question becomes how the Agent Level is to treat the  deviation measurements over time. To this end, we use a probability threshold-that is, we would like the Agent Level to maximize the probability that the deviation measure will remain below a certain threshold. Specific action selection then depends on system formalization. One possibility would be to create a mixture of available system trends, much like that which happens in Behavior-Based Robotic architectures [1]. The other alternative would be to rely on the  estimation procedure provided by the User Level-to utilize the  Environment Design Level model of the environment to choose actions, so as to manipulate the dynamics estimator into believing that a  certain dynamics has been achieved. Notice that this manipulation is not direct, but via the environment. Thus, for strong enough  estimator algorithms, successful manipulation would mean a successful simulation of the specified target dynamics (i.e., beyond discerning via the available sensory input). DBC levels can also have a back-flow of information (see  Figure 1). For instance, the Agent Level could provide data about target dynamics feasibility, allowing the User Level to modify the requirement, perhaps focusing on attainable features of system  behavior. Data would also be available about the system response to different actions performed; combined with a dynamics estimator defined by the User Level, this can provide an important tool for the environment model calibration at the Environment Design Level. UserEnv. Design Agent Model Ideal Dynamics Estimator Estimator Dynamics Feasibility System Response Data Figure 1: Data flow of the DBC framework Extending upon the idea of Actor-Critic algorithms [5], DBC data flow can provide a good basis for the design of a learning  algorithm. For example, the User Level can operate as an exploratory device for a learning algorithm, inferring an ideal dynamics target from the environment model at hand that would expose and verify most critical features of system behavior. In this case, feasibility and system response data from the Agent Level would provide key information for an environment model update. In fact, the  combination of feasibility and response data can provide a basis for the application of strong learning algorithms such as EM [2, 9]. .1 DBC for Markovian Environments For a Partially Observable Markovian Environment, DBC can be specified in a more rigorous manner. Notice how DBC discards rewards, and replaces it by another optimality criterion (structural differences are summarized in Table 1): • Environment Design level is to specify a tuple < S, A, T, O, Ω, s0 >, where: - S is the set of all possible environment states; - s0 is the initial state of the environment (which can also be viewed as a probability distribution over S); The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 791 - A is the set of all possible actions applicable in the  environment; - T is the environment"s probabilistic transition function: T : S ×A → Π(S). That is, T(s |a, s) is the  probability that the environment will move from state s to state s under action a; - O is the set of all possible observations. This is what the sensor input would look like for an outside observer; - Ω is the observation probability function: Ω : S × A × S → Π(O). That is, Ω(o|s , a, s) is the probability that one will observe o given that the environment has moved from state s to state s under action a. • User Level, in the case of Markovian environment, operates on the set of system dynamics described by a family of  conditional probabilities F = {τ : S × A → Π(S)}. Thus specification of target dynamics can be expressed by q ∈ F, and the learning or tracking algorithm can be represented as a function L : O×(A×O)∗ → F; that is, it maps sequences of observations and actions performed so far into an estimate τ ∈ F of system dynamics. There are many possible variations available at the User Level to define divergence between system dynamics; several of them are: - Trace distance or L1 distance between two  distributions p and q defined by D(p(·), q(·)) =   x |p(x) − q(x)| - Fidelity measure of distance F(p(·), q(·)) = x p(x)q(x) - Kullback-Leibler divergence DKL(p(·) q(·)) = x p(x) log p(x) q(x) Notice that the latter two are not actually metrics over the space of possible distributions, but nevertheless have  meaningful and important interpretations. For instance,  KullbackLeibler divergence is an important tool of information  theory [3] that allows one to measure the price of encoding an information source governed by q, while assuming that it is governed by p. The User Level also defines the threshold of dynamics  deviation probability θ. • Agent Level is then faced with a problem of selecting a  control signal function a∗ to satisfy a minimization problem as follows: a∗ = arg min a Pr(d(τa, q) > θ) where d(τa, q) is a random variable describing deviation of the dynamics estimate τa, created by L under control signal a, from the ideal dynamics q. Implicit in this minimization problem is that L is manipulated via the environment, based on the environment model produced by the Environment  Design Level. .2 DBC View of the State Space It is important to note the complementary view that DBC and POMDPs take on the state space of the environment. POMDPs regard state as a stationary snap-shot of the environment;  whatever attributes of state sequencing one seeks are reached through properties of the control process, in this case reward accumulation. This can be viewed as if the sequencing of states and the attributes of that sequencing are only introduced by and for the controlling mechanism-the POMDP policy. DBC concentrates on the underlying principle of state  sequencing, the system dynamics. DBC"s target dynamics specification can use the environment"s state space as a means to describe, discern, and preserve changes that occur within the system. As a result, DBC has a greater ability to express state sequencing properties, which are grounded in the environment model and its state space definition. For example, consider the task of moving through rough terrain towards a goal and reaching it as fast as possible. POMDPs would encode terrain as state space points, while speed would be ensured by negative reward for every step taken without reaching the  goalaccumulating higher reward can be reached only by faster motion. Alternatively, the state space could directly include the notion of speed. For POMDPs, this would mean that the same concept is encoded twice, in some sense: directly in the state space, and  indirectly within reward accumulation. Now, even if the reward  function would encode more, and finer, details of the properties of  motion, the POMDP solution will have to search in a much larger space of policies, while still being guided by the implicit concept of the reward accumulation procedure. On the other hand, the tactical target expression of variations and correlations between position and speed of motion is now grounded in the state space representation. In this situation, any further  constraints, e.g., smoothness of motion, speed limits in different  locations, or speed reductions during sharp turns, are explicitly and uniformly expressed by the tactical target, and can result in faster and more effective action selection by a DBC algorithm. . EMT-BASED CONTROL AS A DBC Recently, a control algorithm was introduced called EMT-based Control [13], which instantiates the DBC framework. Although it provides an approximate greedy solution in the DBC sense, initial experiments using EMT-based control have been encouraging [14, 5]. EMT-based control is based on the Markovian environment definition, as in the case with POMDPs, but its User and Agent Levels are of the Markovian DBC type of optimality. • User Level of EMT-based control defines a limited-case  target system dynamics independent of action: qEMT : S → Π(S). It then utilizes the Kullback-Leibler divergence measure to compose a momentary system dynamics estimator-the  Extended Markov Tracking (EMT) algorithm. The algorithm keeps a system dynamics estimate τt EMT that is capable of explaining recent change in an auxiliary Bayesian system state estimator from pt−1 to pt, and updates it conservatively using Kullback-Leibler divergence. Since τt EMT and pt−1,t are respectively the conditional and marginal probabilities over the system"s state space, explanation simply means that pt(s ) = s τt EMT (s |s)pt−1(s), and the dynamics estimate update is performed by solving a 92 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Table 1: Structure of POMDP vs. Dynamics-Based Control in Markovian Environment Level Approach MDP Markovian DBC Environment < S, A, T, O, Ω >,where S - set of states A - set of actions Design T : S × A → Π(S) - transition O - observation set Ω : S × A × S → Π(O) User r : S × A × S → R q : S × A → Π(S) F(π∗ ) → r L(o1, ..., ot) → τ r - reward function q - ideal dynamics F - reward remodeling L - dynamics estimator θ - threshold Agent π∗ = arg max π E[ γt rt] π∗ = arg min π Prob(d(τ q) > θ) minimization problem: τt EMT = H[pt, pt−1, τt−1 EMT ] = arg min τ DKL(τ × pt−1 τt−1 EMT × pt−1) s.t. pt(s ) = s (τ × pt−1)(s , s) pt−1(s) = s (τ × pt−1)(s , s) • Agent Level in EMT-based control is suboptimal with  respect to DBC (though it remains within the DBC  framework), performing greedy action selection based on  prediction of EMT"s reaction. The prediction is based on the  environment model provided by the Environment Design level, so that if we denote by Ta the environment"s transition  function limited to action a, and pt−1 is the auxiliary Bayesian system state estimator, then the EMT-based control choice is described by a∗ = arg min a∈A DKL(H[Ta × pt, pt, τt EMT ] qEMT × pt−1) Note that this follows the Markovian DBC framework precisely: the rewarding optimality of POMDPs is discarded, and in its place a dynamics estimator (EMT in this case) is manipulated via action effects on the environment to produce an estimate close to the  specified target system dynamics. Yet as we mentioned, naive  EMTbased control is suboptimal in the DBC sense, and has several  additional limitations that do not exist in the general DBC framework (discussed in Section 4.2). .1 Multi-Target EMT At times, there may exist several behavioral preferences. For example, in the case of museum guards, some art items are more heavily guarded, requiring that the guards stay more often in their close vicinity. On the other hand, no corner of the museum is to be left unchecked, which demands constant motion. Successful museum security would demand that the guards adhere to, and  balance, both of these behaviors. For EMT-based control, this would mean facing several tactical targets {qk}K k=1, and the question  becomes how to merge and balance them. A balancing mechanism can be applied to resolve this issue. Note that EMT-based control, while selecting an action, creates a preference vector over the set of actions based on their predicted performance with respect to a given target. If these preference  vectors are normalized, they can be combined into a single unified  preference. This requires replacement of standard EMT-based action selection by the algorithm below [15]: • Given: - a set of target dynamics {qk}K k=1, - vector of weights w(k) • Select action as follows - For each action a ∈ A predict the future state  distribution ¯pa t+1 = Ta ∗ pt; - For each action, compute Da = H(¯pa t+1, pt, PDt) - For each a ∈ A and qk tactical target, denote V (a, k) = DKL (Da qk) pt . Let Vk(a) = 1 Zk V (a, k), where Zk = a∈A V (a, k) is a normalization factor. - Select a∗ = arg min a k k=1 w(k)Vk(a) The weights vector w = (w1, ..., wK ) allows the additional tuning of importance among target dynamics without the need to redesign the targets themselves. This balancing method is also seamlessly integrated into the EMT-based control flow of  operation. .2 EMT-based Control Limitations EMT-based control is a sub-optimal (in the DBC sense)  representative of the DBC structure. It limits the User by forcing EMT to be its dynamic tracking algorithm, and replaces Agent optimization by greedy action selection. This kind of combination, however, is common for on-line algorithms. Although further development of EMT-based controllers is necessary, evidence so far suggests that even the simplest form of the algorithm possesses a great deal of power, and displays trends that are optimal in the DBC sense of the word. There are two further, EMT-specific, limitations to EMT-based control that are evident at this point. Both already have partial  solutions and are subjects of ongoing research. The first limitation is the problem of negative preference. In the POMDP framework for example, this is captured simply, through The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 793 the appearance of values with different signs within the reward structure. For EMT-based control, however, negative preference means that one would like to avoid a certain distribution over  system development sequences; EMT-based control, however,  concentrates on getting as close as possible to a distribution. Avoidance is thus unnatural in native EMT-based control. The second limitation comes from the fact that standard  environment modeling can create pure sensory actions-actions that do not change the state of the world, and differ only in the way  observations are received and the quality of observations received. Since the world state does not change, EMT-based control would not be able to differentiate between different sensory actions. Notice that both of these limitations of EMT-based control are absent from the general DBC framework, since it may have a  tracking algorithm capable of considering pure sensory actions and,  unlike Kullback-Leibler divergence, a distribution deviation measure that is capable of dealing with negative preference. . EMT PLAYING TAG The Game of Tag was first introduced in [11]. It is a single agent problem of capturing a quarry, and belongs to the class of area sweeping problems. An example domain is shown in Figure 2.  51 2 3 4 6  8 10 12 13 61514 7 18 19 221 3  11Q A 0 Figure 2: Tag domain; an agent (A) attempts to seek and  capture a quarry (Q) The Game of Tag extremely limits the agent"s perception, so that the agent is able to detect the quarry only if they are co-located in the same cell of the grid world. In the classical version of the game, co-location leads to a special observation, and the ‘Tag" action can be performed. We slightly modify this setting: the moment that both agents occupy the same cell, the game ends. As a result, both the agent and its quarry have the same motion capability, which allows them to move in four directions, North, South, East, and West. These form a formal space of actions within a Markovian environment. The state space of the formal Markovian environment is described by the cross-product of the agent and quarry"s positions. For  Figure 2, it would be S = {s0, ..., s23} × {s0, ..., s23}. The effects of an action taken by the agent are deterministic, but the environment in general has a stochastic response due to the  motion of the quarry. With probability q0  it stays put, and with  probability 1 − q0 it moves to an adjacent cell further away from the  In our experiments this was taken to be q0 = 0.2. agent. So for the instance shown in Figure 2 and q0 = 0.1: P(Q = s9|Q = s9, A = s11) = 0.1 P(Q = s2|Q = s9, A = s11) = 0.3 P(Q = s8|Q = s9, A = s11) = 0.3 P(Q = s14|Q = s9, A = s11) = 0.3 Although the evasive behavior of the quarry is known to the agent, the quarry"s position is not. The only sensory information available to the agent is its own location. We use EMT and directly specify the target dynamics. For the Game of Tag, we can easily formulate three major trends: catching the quarry, staying mobile, and stalking the quarry. This results in the following three target dynamics: Tcatch(At+1 = si|Qt = sj, At = sa) ∝  si = sj  otherwise Tmobile(At+1 = si|Qt = so, At = sj) ∝  si = sj  otherwise Tstalk(At+1 = si|Qt = so, At = sj) ∝ 1 dist(si,so) Note that none of the above targets are directly achievable; for instance, if Qt = s9 and At = s11, there is no action that can move the agent to At+1 = s9 as required by the Tcatch target dynamics. We ran several experiments to evaluate EMT performance in the Tag Game. Three configurations of the domain shown in Figure 3 were used, each posing a different challenge to the agent due to  partial observability. In each setting, a set of 1000 runs was performed with a time limit of 100 steps. In every run, the initial position of both the agent and its quarry was selected at random; this means that as far as the agent was concerned, the quarry"s initial position was uniformly distributed over the entire domain cell space. We also used two variations of the environment observability function. In the first version, observability function mapped all joint positions of hunter and quarry into the position of the hunter as an observation. In the second, only those joint positions in which hunter and quarry occupied different locations were mapped into the hunter"s location. The second version in fact utilized and  expressed the fact that once hunter and quarry occupy the same cell the game ends. The results of these experiments are shown in Table 2.  Balancing [15] the catch, move, and stalk target dynamics described in the previous section by the weight vector [0.8, 0.1, 0.1], EMT  produced stable performance in all three domains. Although direct comparisons are difficult to make, the EMT  performance displayed notable efficiency vis-`a-vis the POMDP  approach. In spite of a simple and inefficient Matlab implementation of the EMT algorithm, the decision time for any given step  averaged significantly below 1 second in all experiments. For the  irregular open arena domain, which proved to be the most difficult, 1000 experiment runs bounded by 100 steps each, a total of 42411 steps, were completed in slightly under 6 hours. That is, over 4 × 104 online steps took an order of magnitude less time than the offline computation of POMDP policy in [11]. The significance of this  differential is made even more prominent by the fact that, should the environment model parameters change, the online nature of EMT would allow it to maintain its performance time, while the POMDP policy would need to be recomputed, requiring yet again a large overhead of computation. We also tested the behavior cell frequency entropy, empirical measures from trial data. As Figure 4 and Figure 5 show,  empir794 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) A Q Q A  1 2 3 4  6 7 8 9 0 11 12 3 14 15 6 17 18 A Q Figure 3: These configurations of the Tag Game space were used: a) multiple dead-end, b) irregular open arena, c) circular corridor Table 2: Performance of the EMT-based solution in three Tag Game domains and two observability models: I) omniposition quarry, II) quarry is not at hunter"s position Model Domain Capture% E(Steps) Time/Step I Dead-ends 100 14.8 72(mSec) Arena 80.2 42.4 500(mSec) Circle 91.4 34.6 187(mSec) II Dead-ends 100 13.2 91(mSec) Arena 96.8 28.67 396(mSec) Circle 94.4 31.63 204(mSec) ical entropy grows with the length of interaction. For runs where the quarry was not captured immediately, the entropy reaches  between 0.85 and 0.952 for different runs and scenarios. As the agent actively seeks the quarry, the entropy never reaches its maximum. One characteristic of the entropy graph for the open arena  scenario particularly caught our attention in the case of the  omniposition quarry observation model. Near the maximum limit of trial length (100 steps), entropy suddenly dropped. Further analysis of the data showed that under certain circumstances, a fluctuating  behavior occurs in which the agent faces equally viable versions of quarry-following behavior. Since the EMT algorithm has greedy action selection, and the state space does not encode any form of commitment (not even speed or acceleration), the agent is locked within a small portion of cells. It is essentially attempting to  simultaneously follow several courses of action, all of which are  consistent with the target dynamics. This behavior did not occur in our second observation model, since it significantly reduced the set of eligible courses of action-essentially contributing to tie-breaking among them. . DISCUSSION The design of the EMT solution for the Tag Game exposes the core difference in approach to planning and control between EMT or DBC, on the one hand, and the more familiar POMDP approach, on the other. POMDP defines a reward structure to optimize, and influences system dynamics indirectly through that optimization. EMT discards any reward scheme, and instead measures and  influences system dynamics directly.  Entropy was calculated using log base equal to the number of  possible locations within the domain; this properly scales entropy  expression into the range [0, 1] for all domains. Thus for the Tag Game, we did not search for a reward function that would encode and express our preference over the agent"s  behavior, but rather directly set three (heuristic) behavior preferences as the basis for target dynamics to be maintained. Experimental data shows that these targets need not be directly achievable via the agent"s actions. However, the ratio between EMT performance and achievability of target dynamics remains to be explored. The tag game experiment data also revealed the different  emphasis DBC and POMDPs place on the formulation of an environment state space. POMDPs rely entirely on the mechanism of reward accumulation maximization, i.e., formation of the action selection procedure to achieve necessary state sequencing. DBC, on the other hand, has two sources of sequencing specification: through the properties of an action selection procedure, and through direct specification within the target dynamics. The importance of the second source was underlined by the Tag Game experiment data, in which the greedy EMT algorithm, applied to a POMDP-type state space specification, failed, since target description over such a state space was incapable of encoding the necessary behavior  tendencies, e.g., tie-breaking and commitment to directed motion. The structural differences between DBC (and EMT in  particular), and POMDPs, prohibits direct performance comparison, and places them on complementary tracks, each within a suitable niche. For instance, POMDPs could be seen as a much more natural  formulation of economic sequential decision-making problems, while EMT is a better fit for continual demand for stochastic change, as happens in many robotic or embodied-agent problems. The complementary properties of POMDPs and EMT can be  further exploited. There is recent interest in using POMDPs in hybrid solutions [17], in which the POMDPs can be used together with other control approaches to provide results not easily achievable with either approach by itself. DBC can be an effective partner in such a hybrid solution. For instance, POMDPs have prohibitively large off-line time requirements for policy computation, but can be readily used in simpler settings to expose beneficial behavioral trends; this can serve as a form of target dynamics that are provided to EMT in a larger domain for on-line operation. . CONCLUSIONS AND FUTURE WORK In this paper, we have presented a novel perspective on the  process of planning and control in stochastic environments, in the form of the Dynamics Based Control (DBC) framework. DBC  formulates the task of planning as support of a specified target system  dynamics, which describes the necessary properties of change within the environment. Optimality of DBC plans of action are measured The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 795  20 40 60 80 100 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Dead−ends  20 40 60 80 100 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Arena  20 40 60 80 100 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Circle Figure 4: Observation Model I: Omniposition quarry. Entropy development with length of Tag Game for the three experiment scenarios: a) multiple dead-end, b) irregular open arena, c) circular corridor.  10 20 30 40 50 60 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Dead−ends  20 40 60 80 100 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Arena  20 40 60 80 100 .2 .3 .4 .5 .6 .7 .8 .9  Steps Entropy Circle Figure 5: Observation Model II: quarry not observed at hunter"s position. Entropy development with length of Tag Game for the three experiment scenarios: a) multiple dead-end, b) irregular open arena, c) circular corridor. with respect to the deviation of actual system dynamics from the target dynamics. We show that a recently developed technique of Extended Markov Tracking (EMT) [13] is an instantiation of DBC. In fact, EMT can be seen as a specific case of DBC parameterization, which employs a greedy action selection procedure. Since EMT exhibits the key features of the general DBC  framework, as well as polynomial time complexity, we used the  multitarget version of EMT [15] to demonstrate that the class of area sweeping problems naturally lends itself to dynamics-based  descriptions, as instantiated by our experiments in the Tag Game  domain. As enumerated in Section 4.2, EMT has a number of  limitations, such as difficulty in dealing with negative dynamic  preference. This prevents direct application of EMT to such problems as Rendezvous-Evasion Games (e.g., [6]). However, DBC in  general has no such limitations, and readily enables the formulation of evasion games. In future work, we intend to proceed with the development of dynamics-based controllers for these problems. . ACKNOWLEDGMENT The work of the first two authors was partially supported by  Israel Science Foundation grant #898/05, and the third author was partially supported by a grant from Israel"s Ministry of Science and Technology. . REFERENCES [1] R. C. Arkin. Behavior-Based Robotics. MIT Press, 1998. [2] J. A. Bilmes. A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and Hidden Markov Models. Technical Report TR-97-021, Department of Electrical Engeineering and Computer Science, University of California at Berkeley, 1998. [3] T. M. Cover and J. A. Thomas. Elements of information theory. Wiley, 1991. [4] M. E. desJardins, E. H. Durfee, C. L. Ortiz, and M. J. Wolverton. A survey of research in distributed, continual planning. AI Magazine, 4:13-22, 1999. [5] V. R. Konda and J. N. Tsitsiklis. Actor-Critic algorithms. SIAM Journal on Control and Optimization, 2(4):1143-1166, 2003. [6] W. S. Lim. A rendezvous-evasion game on discrete locations with joint randomization. Advances in Applied Probability, 9(4):1004-1017, December 1997. [7] M. L. Littman, T. L. Dean, and L. P. Kaelbling. On the complexity of solving Markov decision problems. In Proceedings of the 11th Annual Conference on Uncertainty in Artificial Intelligence (UAI-95), pages 394-402, 1995. [8] O. Madani, S. Hanks, and A. Condon. On the undecidability of probabilistic planning and related stochastic optimization problems. Artificial Intelligence Journal, 147(1-2):5-34, July 2003. [9] R. M. Neal and G. E. Hinton. A view of the EM algorithm 96 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) that justifies incremental, sparse, and other variants. In M. I. Jordan, editor, Learning in Graphical Models, pages 55-368. Kluwer Academic Publishers, 1998. [10] P. Paruchuri, M. Tambe, F. Ordonez, and S. Kraus. Security in multiagent systems by policy randomization. In Proceeding of AAMAS 2006, 2006. [11] J. Pineau, G. Gordon, and S. Thrun. Point-based value iteration: An anytime algorithm for pomdps. In International Joint Conference on Artificial Intelligence (IJCAI), pages 025-1032, August 2003. [12] M. L. Puterman. Markov Decision Processes. Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics Section. Wiley-Interscience Publication, New York, 1994. [13] Z. Rabinovich and J. S. Rosenschein. Extended Markov Tracking with an application to control. In The Workshop on Agent Tracking: Modeling Other Agents from Observations, at the Third International Joint Conference on Autonomous Agents and Multiagent Systems, pages 95-100, New-York, July 2004. [14] Z. Rabinovich and J. S. Rosenschein. Multiagent coordination by Extended Markov Tracking. In The Fourth International Joint Conference on Autonomous Agents and Multiagent Systems, pages 431-438, Utrecht, The Netherlands, July 2005. [15] Z. Rabinovich and J. S. Rosenschein. On the response of EMT-based control to interacting targets and models. In The Fifth International Joint Conference on Autonomous Agents and Multiagent Systems, pages 465-470, Hakodate, Japan, May 2006. [16] R. F. Stengel. Optimal Control and Estimation. Dover Publications, 1994. [17] M. Tambe, E. Bowring, H. Jung, G. Kaminka, R. Maheswaran, J. Marecki, J. Modi, R. Nair, J. Pearce, P. Paruchuri, D. Pynadath, P. Scerri, N. Schurr, and P. Varakantham. Conflicts in teamwork: Hybrids to the The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 797
Implementing Commitment-Based Interactions∗ Michael Winikoff School of Computer Science and IT RMIT University Melbourne, Australia michael.winikoff@rmit.edu.au ABSTRACT Although agent interaction plays a vital role in MAS, and  messagecentric approaches to agent interaction have their drawbacks, present agent-oriented programming languages do not provide support for implementing agent interaction that is flexible and robust. Instead, messages are provided as a primitive building block. In this  paper we consider one approach for modelling agent interactions: the commitment machines framework. This framework supports  modelling interactions at a higher level (using social commitments),  resulting in more flexible interactions. We investigate how  commitmentbased interactions can be implemented in conventional agent-oriented programming languages. The contributions of this paper are: a mapping from a commitment machine to a collection of BDI-style plans; extensions to the semantics of BDI programming languages; and an examination of two issues that arise when distributing  commitment machines (turn management and race conditions) and  solutions to these problems. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  IntelligenceMultiagent systems; I.2.5 [Artificial Intelligence]: Programming Languages and Software General Terms Design . INTRODUCTION Agents are social, and agent interaction plays a vital role in  multiagent systems. Consequently, design and implementation of agent interaction is an important research topic. The standard approach for designing agent interactions is  messagecentric: interactions are defined by interaction protocols that give the permissible sequences of messages, specified using notations such as finite state machines, Petri nets, or Agent UML. It has been argued that this message-centric approach to  interaction design is not a good match for intelligent agents. Intelligent agents should exhibit the ability to persist in achieving their goals in the face of failure (robustness) by trying different approaches (flexibility). On the other hand, when following an interaction  protocol, an agent has limited flexibility and robustness: the ability to persistently try alternative means to achieving the interaction"s aim is limited to those options that the protocol"s designer provided, and in practice, message-centric design processes do not tend to lead to protocols that are flexible or robust. Recognising these limitations of the traditional approach to  designing agent interactions, a number of approaches have been  proposed in recent years that move away from message-centric  interaction protocols, and instead consider designing agent interactions using higher-level concepts such as social commitments [8, 10, 8] or interaction goals [2]. There has also been work on richer forms of interaction in specific settings, such as teams of  cooperative agents [5, 11]. However, although there has been work on designing flexible and robust agent interactions, there has been virtually no work on  providing programming language support for implementing such  interactions. Current Agent Oriented Programming Languages  (AOPLs) do not provide support for implementing flexible and robust agent interactions using higher-level concepts than messages.  Indeed, modern AOPLs [1], with virtually no exceptions, provide only simple message sending as the basis for implementing agent interaction. This paper presents what, to the best of our knowledge, is the second AOPL to support high-level, flexible, and robust agent  interaction implementation. The first such language, STAPLE, was proposed a few years ago [9], but is not described in detail, and is arguably impractical for use by non-specialists, due to its logical basis and heavy reliance on temporal and modal logic. This paper presents a scheme for extending BDI-like AOPLs to support direct implementation of agent interactions that are  designed using Yolum & Singh"s commitment machine (CM)  framework [19]. In the remainder of this paper we briefly review  commitment machines and present a simple abstraction of BDI AOPLs which lies in the common subset of languages such as Jason, 3APL, and CAN. We then present a scheme for translating commitment machines to this language, and indicate how the language needs to be extended to support this. We then extend our scheme to  address a range of issues concerned with distribution, including turn tracking [7], and race conditions. . BACKGROUND .1 Commitment Machines The aim of the commitment machine framework is to allow for the definition of interactions that are more flexible than traditional message-centric approaches. A Commitment Machine (CM) [19] specifies an interaction between entities (e.g. agents, services,  processes) in terms of actions that change the interaction state. This interact state consists of fluents (predicates that change value over time), but also social commitments, both base-level and conditional. A base-level social commitment is an undertaking by debtor A to creditor B to bring about condition p, denoted C(A, B, p). This is sometimes abbreviated to C(p), where it is not important to specify the identities of the entities in question. For example, a  commitment by customer C to merchant M to make the fluent paid true would be written as C(C, M, paid). A conditional social commitment is an undertaking by debtor A to creditor B that should condition q become true, A will then  commit to bringing about condition p. This is denoted by CC(A, B, q, p), and, where the identity of the entities involved is unimportant (or obvious), is abbreviated to CC(q p) where the arrow is a  reminder of the causal link between q becoming true and the creation of a commitment to make p true. For example, a commitment to make the fluent paid true once goods have been received would be written CC(goods paid). The semantics of commitments (both base-level and conditional) is defined with rules that specify how commitments change over time. For example, the commitment C(p) (or CC(q p)) is  discharged when p becomes true; and the commitment CC(q p) is replaced by C(p) when q becomes true. In this paper we use the more symmetric semantics proposed by [15] and subsequently  reformalised by [14]. In brief, these semantics deal with a number of more complex cases, such as where commitments are created when conditions already hold: if p holds when CC(p q) is meant to be created, then C(q) is created instead of CC(p q). An interaction is defined by specifying the entities involved, the possible contents of the interaction state (both fluents and  commitments), and (most importantly) the actions that each entity can  perform along with the preconditions and effects of each action,  specified as add and delete lists. A commitment machine (CM) defines a range of possible  interactions that each start in some state1 , and perform actions until reaching a final state. A final state is one that has no base-level commitments. One way of visualising the interactions that are  possible with a given commitment machine is to generate the finite state machine corresponding to the CM. For example, figure 1 gives the FSM2 corresponding to the NetBill [18] commitment machine: a simple CM where a customer (C) and merchant (M) attempt to trade using the following actions3 :  Unlike standard interaction protocols, or finite state machines, there is no designated initial state for the interaction.  The finite state machine is software-generated: the nodes and  connections were computed by an implementation of the axioms  (available from http://www.winikoff.net/CM) and were then laid out by graphviz (http://www.graphviz.org/).  We use the notation A(X) : P ⇒ E to indicate that action A is performed by entity X, has precondition P (with : P omitted if empty) and effect E. • sendRequest(C) ⇒ request • sendQuote(M) ⇒ offer where offer ≡ promiseGoods ∧ promiseReceipt and promiseGoods ≡ CC(M, C, accept, goods) and promiseReceipt ≡ CC(M, C, pay, receipt) • sendAccept(C) ⇒ accept where accept ≡ CC(C, M, goods, pay) • sendGoods(M) ⇒ promiseReceipt ∧ goods where promiseReceipt ≡ CC(M, C, pay, receipt) • sendEPO(C) : goods ⇒ pay • sendReceipt(M) : pay ⇒ receipt. The commitment accept is the customer"s promise to pay once goods have been sent, promiseGoods is the merchant"s promise to send the goods once the customer accepts, and promiseReceipt is the merchant"s promise to send a receipt once payment has been made. As seen in figure 1, commitment machines can support a range of interaction sequences. .2 An Abstract Agent ProgrammingLanguage Agent programming languages in the BDI tradition (e.g. dMARS, JAM, PRS, UM-PRS, JACK, AgentSpeak(L), Jason, 3APL, CAN, Jadex) define agent behaviour in terms of event-triggered plans, where each plan specifies what it is triggered by, under what  situations it can be considered to be applicable (defined using a so-called context condition), and a plan body: a sequence of steps that can include posting events which in turn triggers further plans. Given a collection of plans and an event e that has been posted the agent first collects all plans types that are triggered by that event (the  relevant plans), then evaluates the context conditions of these plans to obtain a set of applicable plan instances. One of these is chosen and is executed. We now briefly define the formal syntax and semantics of a  Simple Abstract (BDI) Agent Programming Language (SAAPL). This language is intended to be an abstraction that is in the common subset of such languages as Jason [1, Chapter 1], 3APL [1,  Chapter 2], and CAN [16]. Thus, it is intentionally incomplete in some areas, for instance it doesn"t commit to a particular mechanism for dealing with plan failure, since different mechanisms are used by different AOPLs. An agent program (denoted by Π) consists of a collection of plan clauses of the form e : C ← P where e is an event, C is a context condition (a logical formula over the agent"s beliefs), and P is the plan body. The plan body is built up from the following constructs. We have the empty step which always succeeds and does nothing, operations to add (+b) and delete (−b) beliefs, sending a message m to agent N (↑N m), and posting an event4 (e). These can be sequenced (P; P). C ::= b | C ∧ C | C ∨ C | ¬C | ∃x.C P ::= | +b | −b | e | ↑N m | P; P Formal semantics for this language is given in figure 2. This  semantics is based on the semantics for AgentSpeak given by [12], which in turn is based on the semantics for CAN [16]. The  semantics is in the style of Plotkin"s Structural Operational Semantics, and assumes that operations exist that check whether a condition  We use ↓N m as short hand for the event corresponding to  receiving message m from agent N. 74 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 1: Finite State Machine for NetBill (shaded = final states) follows from a belief set, that add a belief to a belief set, and that delete a belief from a belief set. In the case of beliefs being a set of ground atoms these operations are respectively consequence  checking (B |= C), and set addition (B ∪ {b}) and deletion (B \ {b}). More sophisticated belief management methods may be used, but are not considered here. We define a basic configuration S = Q, N, B, P where Q is a (global) message queue (modelled as a sequence5 where messages are added at one end and removed from the other end), N is the name of the agent, B is the beliefs of the agent and P is the plan body being executed (i.e. the intention). We also define an agent configuration, where instead of a single plan body P there is a set of plan instances, Γ. Finally, a complete MAS is a pair Q, As of a global message queue Q and a set of agent configurations (without the queue, Q). The global message queue is a sequence of triplets of the form sender:recipient:message. A transition S0 −→ S1 specifies that executing S0 a single step yields S1. We annotate the arrow with an indication of whether the configuration in question is basic, an agent configuration, or a MAS configuration. The transition relation is defined using rules of the form S −→ S or of the form S −→ Sr S −→ Sr ; the latter are  conditional with the top (numerator) being the premise and the bottom (denominator) being the conclusion. Note that there is non-determinism in SAAPL, e.g. the choice of plan to execute from a set of applicable plans. This is resolved by using selection functions: SO selects one of the applicable plan instances to handle a given event, SI selects which of the plan  instances that can be executed should be executed next, and SA  selects which agent should execute (a step) next. . IMPLEMENTING COMMITMENT-BASED INTERACTIONS In this section we present a mapping from a commitment  machine to a collection of SAAPL programs (one for each role). We begin by considering the simple case of two interacting agents, and  The + operator is used to denote sequence concatenation. assume that the agents take turns to act. In section 4 we relax these assumptions. Each action A(X) : P ⇒ E is mapped to a number of plans: there is a plan (for agent X) with context condition P that  performs the action (i.e. applies the effects E to the agent"s beliefs) and sends a message to the other agent, and a plan (for the other agent) that updates its state when a message is received from X. For example, given the action sendAccept(C) ⇒ accept we have the following plans, where each plan is preceded by M: or C: to indicate which agent that plan belongs to. Note that where the identify of the sender (respectively recipient) is obvious, i.e. the other agent, we abbreviate ↑N m to ↑m (resp. ↓N m to ↓m). Turn taking is captured through the event ı (short for interact): the agent that is active has an ı event that is being handled. Handling the event involves sending a message to the other agent, and then doing nothing until a response is received. C: ı : true ← +accept; ↑sendAccept. M: ↓sendAccept : true ← +accept; ı. If the action has a non-trivial precondition then there are two plans in the recipient: one to perform the action (if possible), and another to report an error if the action"s precondition doesn"t hold (we  return to this in section 4). For example, the action sendReceipt(M) : pay ⇒ receipt generates the following plans: M: ı : pay ← +receipt; ↑sendReceipt. C: ↓sendReceipt : pay ← +receipt; ı. C: ↓sendReceipt : ¬pay ← . . . report error . . . . In addition to these plans, we also need plans to start and finish the interaction. An interaction can be completed whenever there are no base-level commitments, so both agents have the following plans: ı : ¬∃p.C(p) ← ↑done. ↓done : ¬∃p.C(p) ← . ↓done : ∃p.C(p) ← . . . report error . . . . An interaction is started by setting up an agent"s initial beliefs, and then having it begin to interact. Exactly how to do this depends on the agent platform: e.g. the agent platform in question may offer a simple way to load beliefs from a file. A generic approach that is a little cumbersome, but is portable, is to send each of the agents involved in the interaction a sequence of init messages, each The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 875 Q, N, B, +b Basic −→ Q, N, B ∪ {b}, Q, N, B, −b Basic −→ Q, N, B \ {b}, Δ = {Piθ|(ti : ci ← Pi) ∈ Π ∧ tiθ = e ∧ B |= ciθ} Q, N, B, e Basic −→ Q, N, B, SO(Δ) Q, N, B, P1 Basic −→ Q , N, B , P Q, N, B, P1; P2 Basic −→ Q , N, B , P ; P2 Q, N, B, ; P Basic −→ Q, N, B, P Q, N, B, ↑NB m Basic −→ Q + N:NB:m, N, B, Q = NA:N:m + Q Q, N, B, Γ Agent −→ Q , N, B, Γ ∪ {↓NA m} P = SI(Γ) Q, N, B, P Basic −→ Q , N, B , P Q, N, B, Γ Agent −→ Q , N, B , (Γ \ {P}) ∪ {P } P = SI(Γ) P = Q, N, B, Γ Agent −→ Q, N, B, (Γ \ {P}) N, B, Γ = SA(As) Q, N, B, Γ Agent −→ Q , N, B , Γ Q, As MAS −→ Q , (As ∪ { N, B , Γ }) \ { N, B, Γ } Figure 2: Operational Semantics for SAAPL containing a belief to be added; and then send one of the agents a start message which begins the interaction. Both agents thus have the following two plans: ↓init(B) : true ← +B. ↓start : true ← ı. Figure 3 gives the SAAPL programs for both merchant and  customer that implement the NetBill protocol. For conciseness the error reporting plans are omitted. We now turn to refining the context conditions. There are three refinements that we consider. Firstly, we need to prevent  performing actions that have no effect on the interaction state. Secondly, an agent may want to specify that certain actions that it is able to perform should not be performed unless additional conditions hold. For example, the customer may not want to agree to the merchant"s offer unless the goods have a certain price or property. Thirdly, the context conditions of the plans that terminate the interaction need to be refined in order to avoid terminating the interaction prematurely. For each plan of the form ı : P ← +E; ↑m we replace the  context condition P with the enhanced condition P ∧ P ∧ ¬E where P is any additional conditions that the agent wishes to impose, and ¬E is the negation of the effects of the action. For  example, the customer"s payment plan becomes (assuming no additional conditions, i.e. no P ): ı : goods ∧ ¬pay ← +pay; ↑sendEPO. For each plan of the form ↓m : P ← +E; ı we could add ¬E to the precondition, but this is redundant, since it is already checked by the performer of the action, and if the action has no effect then Customer"s plans: ı : true ← +request; ↑sendRequest. ı : true ← +accept; ↑sendAccept. ı : goods ← +pay; ↑sendEPO. ↓sendQuote : true ← +promiseGoods; +promiseReceipt; ı. ↓sendGoods : true ← +promiseReceipt; +goods; ı. ↓sendReceipt : pay ← +receipt; ı. Merchant"s plans: ı : true ← +promiseGoods; +promiseReceipt; ↑sendQuote. ı : true ← +promiseReceipt; +goods; ↑sendGoods. ı : pay ← +receipt; ↑sendReceipt. ↓sendRequest : true ← +request; ı. ↓sendAccept : true ← +accept; ı. ↓sendEPO : goods ← +pay; ı. Shared plans (i.e. plans of both agents): ı : ¬∃p.C(p) ← ↑done. ↓done : ¬∃p.C(p) ← . ↓init(B) : true ← +B. ↓start : true ← ı. Where accept ≡ CC(goods pay) promiseGoods ≡ CC(accept goods) promiseReceipt ≡ CC(pay receipt) offer ≡ promiseGoods ∧ promiseReceipt Figure 3: SAAPL Implementation of NetBill the sender won"t perform it and send the message (see also the  discussion in section 4). When specifying additional conditions (P ), some care needs to be taken to avoid situations where progress cannot be made because the only action(s) possible are prevented by additional conditions. One way of indicating preference between actions (in many agent platforms) is to reorder the agent"s plans. This is clearly safe, since actions are not prevented, just considered in a different order. The third refinement of context conditions concerns the plans that terminate the interaction. In the Commitment Machine  framework any state that has no base-level commitment is final, in that the interaction may end there (or it may continue). However, only some of these final states are desirable final states. Which final states are considered to be desirable depends on the domain and the desired interaction outcome. In the NetBill example, the  desirable final state is one where the goods have been sent and paid for, and a receipt issued (i.e. goods ∧ pay ∧ receipt). In order to prevent an agent from terminating the interaction too early we add this as a precondition to the termination plan: ı : goods ∧ pay ∧ receipt ∧ ¬∃p.C(p) ← ↑done. Figure 4 shows the plans that are changed from figure 3. In order to support the realisation of CMs, we need to change SAAPL in a number of ways. These changes, which are discussed below, can be applied to existing BDI languages to make them commitment machine supportive. We present the three changes, explain what they involve, and for each change explain how the change was implemented using the 3APL agent oriented  programming language. The three changes are: . extending the beliefs of the agent so that they can contain commitments; 76 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Customer"s plans: ı : ¬request ← +request; ↑sendRequest. ı : ¬accept ← +accept; ↑sendAccept. ı : goods ∧ ¬pay ← +pay; ↑sendEPO. Merchant"s plans: ı : ¬offer ← +promiseGoods; +promiseReceipt; ↑sendQuote. ı : ¬(promiseReceipt ∧ goods) ← +promiseReceipt; +goods; ↑sendGoods. ı : pay ∧ ¬receipt ← +receipt; ↑sendReceipt. Where accept ≡ CC(goods pay) promiseGoods ≡ CC(accept goods) promiseReceipt ≡ CC(pay receipt) offer ≡ promiseGoods ∧ promiseReceipt Figure 4: SAAPL Implementation of NetBill with refined  context conditions (changed plans only) . changing the definition of |= to encompass implied  commitments; and . whenever a belief is added, updating existing commitments, according to the rules of commitment dynamics. Extending the notion of beliefs to encompass commitments in fact requires no change in agent platforms that are prolog-like and support terms as beliefs (e.g. Jason, 3APL, CAN). However, other agent platforms do require an extension. For example, JACK, which is an extension of Java, would require changes to support  commitments that can be nested. In the case of 3APL no change is needed to support this. Whenever a context condition contains commitments,  determining whether the context condition is implied by the agent"s beliefs (B |= C) needs to take into account the notion of implied  commitments [15]. In brief, a commitment can be considered to follow from a belief set B if the commitment is in the belief set (C ∈ B), but also under other conditions. For example, a commitment to pay C(pay) can be considered to be implied by a belief set containing pay because the commitment may have held and been discharged when pay was made true. Similar rules apply for conditional  commitments. These rules, which were introduced in [15] were  subsequently re-formalised in a simpler form by [14] resulting in the four inference rules in the bottom part of figure 5. The change that needs to be made to SAAPL to support  commitment machine implementations is to extend the definition of |= to include these four rules. For 3APL this was realised by having each agent include the following Prolog clauses: holds(X) :- clause(X,true). holds(c(P)) :- holds(P). holds(c(P)) :- clause(cc(Q,P),true), holds(Q). holds(cc(_,Q)) :- holds(Q). holds(cc(_,Q)) :- holds(c(Q)). The first clause simply says that anything holds if it is in agent"s beliefs (clause(X,true) is true if X is a fact). The  remaining four clauses correspond respectively to the inference rules C1, C2, CC1 and CC2. To use these rules we then modify context conditions in our program so that instead of writing, for  example, cc(m,c, pay, receipt) we write holds(cc(m,c, pay, receipt)). B = norm(B ∪ {b}) Q, N, B, +b −→ Q, N, B , function norm(B) B ← B for each b ∈ B do if b = C(p) ∧ B |= p then B ← B \ {b} elseif b = CC(p q) then if B |= q then B ← B \ {b} elseif B |= p then B ← (B \ {b}) ∪ {C(q)} elseif B |= C(q) then B ← B \ {b} endif endif endfor return B end function B |= P B |= C(P) C1 CC(Q P) ∈ B B |= Q B |= P C2 B |= CC(P Q) B |= Q CC1 B |= C(Q) B |= CC(P Q) CC2 Figure 5: New Operational Semantics The final change is to update commitments when a belief is added. Formally, this is done by modifying the semantic rule for belief addition so that it applies an algorithm to update  commitments. The modified rule and algorithm (which mirrors the  definition of norm in [14]) can be found in the top part of figure 5. For 3APL this final change was achieved by manually inserting update() after updating beliefs, and defining the following rules for update(): update() <- c(P) AND holds(P) | {Deletec(P) ; update()}, update() <- cc(P,Q) AND holds(Q) | {Deletecc(P,Q) ; update()}, update() <- cc(P,Q) AND holds(P) | {Deletecc(P,Q) ; Addc(Q) ; update()}, update() <- cc(P,Q) AND holds(c(Q)) | {Deletecc(P,Q) ; update()}, update() <- true | Skip where Deletec and Deletecc delete respectively a base-level and conditional commitment, and Addc adds a base-level  commitment. One aspect that doesn"t require a change is linking commitments and actions. This is because commitments don"t trigger actions  directly: they may trigger actions indirectly, but in general their effect is to prevent completion of an interaction while there are  outstanding (base level) commitments. Figure 6 shows the message sequences from a number of runs of a 3APL implementation of the NetBill commitment machine6 . In order to illustrate the different possible interactions the code was modified so that each agent selected randomly from the actions that it could perform, and a number of runs were made with the customer as the initiator, and then with the merchant as the  initiator. There are other possible sequences of messages, not shown,  Source code is available from http://www.winikoff.net/CM The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 877 Figure 6: Sample runs from 3APL implementation (alternating turns) including the obvious one: request, quote, accept, goods, payment, receipt, and then done. One minor difference between the 3APL implementation and SAAPL concerns the semantics of messages. In the semantics of SAAPL (and of most AOPLs), receiving a message is treated as an event. However, in 3APL, receiving a message is modelled as the addition to the agent"s beliefs of a fact indicating that the message was received [6]. Thus in the 3APL implementation we have PG rules that are triggered by these beliefs, rather than by any event. One issue with this approach is that the belief remains there, so we need to ensure that the belief in question is either deleted once  handled, or that we modify preconditions of plans to avoid handling it more than once. In our implementation we delete these received beliefs when they are handled, to avoid duplicate handling of  messages. . BEYOND TWO PARTICIPANTS Generalising to more than two interaction participants requires revisiting how turn management is done, since it is no longer  possible to assume alternating turns [7]. In fact, perhaps surprisingly, even in the two participant setting, an alternating turn setup is an unreasonable assumption! For  example, consider the path (in figure 1) from state 1 to 15 (sendGoods) then to state 12 (sendAccept). The result, in an alternating turn setup, is a dead-end: there is only a single possible action in state 2, namely sendEPO, but this action is done by the customer, and it is the merchant"s turn to act! Figure 7 shows the FSM for NetBill with alternating initiative. A solution to this problem that works in this example, but doesn"t generalise7 , is to weaken the alternating turn taking regime by  allowing an agent to act twice in a row if its second action is driven by a commitment. A general solution is to track whose turn it is to act. This can be done by working out which agents have actions that are able to be performed in the current state. If there is only a single active agent, then it is clearly that agent"s turn to act. However, if more than one agent is active then somehow the agents need to work out who should act next. Working this out by negotiation is not a particularly good solution for two reasons. Firstly, this negotiation has to be done at every step of the interaction where more than one agent is active (in the NetBill, this applies to seven out of sixteen states), so it is highly desirable to have a light-weight mechanism for doing this. Secondly, it is not clear how the negotiation can avoid an infinite regress situation (you go first, no, you go first, . ..) without imposing some arbitrary rule. It is also possible to resolve who should act by imposing an arbitrary rule, for example, that the customer always acts in preference to the merchant, or that each agent has a numerical priority (perhaps determined by the order in which they joined the interaction?) that determines who acts. An alternative solution, which exploits the symmetrical  properties of commitment machines, is to not try and manage turn taking.  Consider actions A1(C) ⇒ p, A2(C) ⇒ q, and A3(M) : p ∧ q ⇒ r. Figure 7: NetBill with alternating initiative Instead of tracking and controlling whose turn it is, we simply allow the agents to act freely, and rely on the properties of the interaction space to ensure that things work out, a notion that we shall make precise, and prove, in the remainder of this section. The issue with having multiple agents be active simultaneously is that instead of all agents agreeing on the current interaction state, agents can be in different states. This can be visualised as each agent having its own copy of the FSM that it navigates through where it is possible for agents to follow different paths through the FSM. The two specific issues that need to be addressed are: . Can agents end up in different final states? . Can an agent be in a position where an error occurs because it cannot perform an action corresponding to a received  message? We will show that, because actions commute under certain  assumptions, agents cannot end up in different final states, and  furthermore, that errors cannot occur (again, under certain  assumptions). By actions commute we mean that the state resulting from  performing a sequence of actions A1 . . . An is the same, regardless of the order in which the actions are performed. This means that even if agents take different paths through the FSM, they still end up in the same resulting state, because once all messages have been  processed, all agents will have performed the same set of actions. This addresses the issue of ending up in different final states. We return to the possibility of errors occurring shortly. Definition 1 (Monotonicity) An action is monotonic if it does not delete8 any fluents or commitments. A Commitment Machine is  That is directly deletes, it is fine to discharge commitments by adding fluents/commitments. 78 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) monotonic if all of its actions are monotonic. (Adapted from [14, Definition 6]) Theorem 1 If A1 and A2 are monotonic actions, then performing A1 followed by A2 has the same effect on the agent"s beliefs as performing A2 followed by A1. (Adapted from [14, Theorem 2]). This assumes that both actions can be performed. However, it is possible for the performance of A1 to disable A2 from being done. For example, if A1 has the effect +p, and A2 has precondition ¬p, then although both actions may be enabled in the initial state, they cannot be performed in either order. We can prevent this by ensuring that actions" preconditions do not contain negation (or  implication), since a monotonic action cannot result in a precondition that is negation-free becoming false. Note that this restriction only applies to the original action precondition, P, not to any additional preconditions imposed by the agent (P ). This is because only P is used to determine whether another agent is able to perform the action. Thus monotonic CMs with preconditions that do not contain negations have actions that commute. However, in fact, the  restriction to monotonic CMs is unnecessarily strong: all that is needed is that whenever there is a choice of agent that can act, then the possible actions are monotonic. If there is only a single agent that can act, then no restriction is needed on the actions: they may or may not be monotonic. Definition 2 (Locally Monotonic) A commitment machine is  locally monotonic if for any state S either (a) only a single agent has actions that can be performed; or (b) all actions that can be performed in S are monotonic. Theorem 2 In a locally monotonic CM, once all messages have been processed, all agents will be in the same state. Furthermore, no errors can occur. Proof: Once all messages have been processed we have that all agents will have performed the same action set, perhaps in a  different order. The essence of the proof is to argue that as long as agents haven"t yet converged to the same state, all actions must be monotonic, and hence that these actions commute, and cannot disable any other actions. Consider the first point of divergence, where an agent performs action A and at the same time another agent (call it XB) performs action B. Clearly, this state has actions of more than one agent  enabled, so, since the CM is locally monotonic, the relevant actions must be monotonic. Therefore, after doing A, the action B must still be enabled, and so the message to do B can be processed by updating the recipient agent"s beliefs with the effects of B.  Furthermore, because monotonic actions commute, the result of doing A before B is the same as doing B before A: S A −−−−−→ SA ? ? yB B ? ? y SB −−−−−→ A SAB However, what happens if the next action after A is not B, but C? Because B is enabled, and C is not done by agent XB (see below), we must have that C is also monotonic, and hence (a) the result of doing A and B and C is the same regardless of the order in which the three actions are done; and (b) C doesn"t disable B, so B can still be done after C. S A −−−−−→ SA C −−−−−→ SAC ? ? yB B ? ? y B ? ? y SB −−−−−→ A SAB −−−−−→ C SABC The reason why C cannot be done by XB is that messages are processed in the order of their arrival9 . From the perspective of XB the action B was done before C, and therefore from any other agent"s perspective the message saying that B was done must be received (and processed) before a message saying that C is done. This argument can be extended to show that once agents start taking different paths through the FSM all actions taken until the point where they converge on a single state must be monotonic, and hence it is always possible to converge (because actions aren"t disabled), so the interaction is error free; and the resulting state once convergence occurs is the same (because monotonic actions commute). This theorem gives a strong theoretical guarantee that not  doing turn management will not lead to disaster. This is analogous to proving that disabling all traffic lights would not lead to any  accidents, and is only possible because the refined CM axioms are symmetrical. Based on this theorem the generic transformation from CM to code should allow agents to act freely, which is achieved by simply changing ı : P ∧ P ∧ ¬E ← +E; ↑A to ı : P ∧ P ∧ ¬E ← +E; ↑A; ı For example, instead of ı : ¬request ← +request; ↑sendRequest we have ı : ¬request ← +request; ↑sendRequest; ı. One consequence of the theorem is that it is not necessary to ensure that agents process messages before continuing to  interact. However, in order to avoid unnecessary parallelism, which can make debugging harder, it may still be desirable to process  messages before performing actions. Figure 8 shows a number of runs from the 3APL implementation that has been modified to allow free, non-alternating, interaction. . DISCUSSION We have presented a scheme for mapping commitment machines to BDI platforms (using SAAPL as an exemplar), identified three changes that needed to be made to SAAPL to support CM-based  interaction, and shown that turn management can be avoided in  CMbased interaction, provided the CM is locally monotonic. The three changes to SAAPL, and the translation scheme from commitment machine to BDI plans are both applicable to any BDI language. As we have mentioned in section 1, there has been some work on designing flexible and robust agent interaction, but virtually no work on implementing flexible and robust interactions. We have already discussed STAPLE [9, 10]. Another piece of work that is relevant is the work by Cheong and Winikoff on their Hermes methodology [2]. Although the main focus of their work is a pragmatic design methodology, they also provide guidelines for implementing Hermes designs using BDI platforms (specifically Jadex) [3]. However, since Hermes does not yield a design that is formal, it is only possible to generate skeleton code that then needs to be completed. Also, they do not address the turn taking issue: how to decide which agent acts when more than one agent is able to act.  We also assume that the communication medium does not deliver messages out of order, which is the case for (e.g.) TCP. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 879 Figure 8: Sample runs from 3APL implementation (non-alternating turns) The work of Kremer and Flores (e.g. [8]) also uses  commitments, and deals with implementation. However, they provide  infrastructure support (CASA) rather than a programming language, and do not appear to provide assistance to a programmer seeking to implement agents. Although we have implemented the NetBill interaction using APL, the changes to the semantics were done by modifying our NetBill 3APL program, rather than by modifying the 3APL  implementation itself. Clearly, it would be desirable to modify the semantics of 3APL (or of another language) directly, by changing the implementation. Also, although we have not done so, it should be clear that the translation from a CM to its implementation could easily be automated. Another area for further work is to look at how the assumptions required to ensure that actions commute can be relaxed. Finally, there is a need to perform empirical evaluation. There has already been some work on comparing Hermes with a  conventional message-centric approach to designing interaction, and this has shown that using Hermes results in designs that are  significantly more flexible and robust [4]. It would be interesting to compare commitment machines with Hermes, but, since  commitment machines are a framework, not a design methodology, we need to compare Hermes with a methodology for designing  interactions that results in commitment machines [13, 17]. . REFERENCES [1] R. H. Bordini, M. Dastani, J. Dix, and A. E. F. Seghrouchni, editors. Multi-Agent Programming: Languages, Platforms and Applications. Springer, 2005. [2] C. Cheong and M. Winikoff. Hermes: Designing goal-oriented agent interactions. In Proceedings of the 6th International Workshop on Agent-Oriented Software Engineering (AOSE-2005), July 2005. [3] C. Cheong and M. Winikoff. Hermes: Implementing goal-oriented agent interactions. In Proceedings of the Third international Workshop on Programming Multi-Agent Systems (ProMAS), July 2005. [4] C. Cheong and M. Winikoff. Hermes versus prometheus: A comparative evaluation of two agent interaction design approaches. Submitted for publication, 2007. [5] P. R. Cohen and H. J. Levesque. Teamwork. Nous, 5(4):487-512, 1991. [6] M. Dastani, J. van der Ham, and F. Dignum. Communication for goal directed agents. In Proceedings of the Agent Communication Languages and Conversation Policies Workshop, 2002. [7] F. P. Dignum and G. A. Vreeswijk. Towards a testbed for multi-party dialogues. In Advances in Agent Communication, pages 212-230. Springer, LNCS 2922, 2004. [8] R. Kremer and R. Flores. Using a performative subsumption lattice to support commitment-based conversations. In F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh, and M. Wooldridge, editors, Autonomous Agents and Multi-Agent Systems (AAMAS), pages 114-121. ACM Press, 2005. [9] S. Kumar and P. R. Cohen. STAPLE: An agent programming language based on the joint intention theory. In Proceedings of the Third International Joint Conference on Autonomous Agents & Multi-Agent Systems (AAMAS 2004), pages 390-1391. ACM Press, July 2004. [10] S. Kumar, M. J. Huber, and P. R. Cohen. Representing and executing protocols as joint actions. In Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 543 - 550, Bologna, Italy, 5 - 19 July 2002. ACM Press. [11] M. Tambe and W. Zhang. Towards flexible teamwork in persistent teams: Extended report. Journal of Autonomous Agents and Multi-agent Systems, 2000. Special issue on Best of ICMAS 98. [12] M. Winikoff. An AgentSpeak meta-interpreter and its applications. In Third International Workshop on Programming Multi-Agent Systems (ProMAS), pages 23-138. Springer, LNCS 3862 (post-proceedings, 2006), 005. [13] M. Winikoff. Designing commitment-based agent interactions. In Proceedings of the 2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology (IAT-06), 2006. [14] M. Winikoff. Implementing flexible and robust agent interactions using distributed commitment machines. Multiagent and Grid Systems, 2(4), 2006. [15] M. Winikoff, W. Liu, and J. Harland. Enhancing commitment machines. In J. Leite, A. Omicini, P. Torroni, and P. Yolum, editors, Declarative Agent Languages and Technologies II, number 3476 in Lecture Notes in Artificial Intelligence (LNAI), pages 198-220. Springer, 2004. [16] M. Winikoff, L. Padgham, J. Harland, and J. Thangarajah. Declarative & procedural goals in intelligent agent systems. In Proceedings of the Eighth International Conference on Principles of Knowledge Representation and Reasoning (KR2002), Toulouse, France, 2002. [17] P. Yolum. Towards design tools for protocol development. In F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh, and M. Wooldridge, editors, Autonomous Agents and Multi-Agent Systems (AAMAS), pages 99-105. ACM Press, 2005. [18] P. Yolum and M. P. Singh. Flexible protocol specification and execution: Applying event calculus planning using commitments. In Proceedings of the 1st Joint Conference on Autonomous Agents and MultiAgent Systems (AAMAS), pages 527-534, 2002. [19] P. Yolum and M. P. Singh. Reasoning about commitments in the event calculus: An approach for specifying and executing protocols. Annals of Mathematics and Artificial Intelligence (AMAI), 2004. 80 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Modular Interpreted Systems Wojciech Jamroga Department of Informatics Clausthal University of Technology, Germany wjamroga@in.tu-clausthal.de Thomas Ågotnes Department of Computer Engineering Bergen University College, Norway tag@hib.no ABSTRACT We propose a new class of representations that can be used for  modeling (and model checking) temporal, strategic and epistemic  properties of agents and their teams. Our representations borrow the main ideas from interpreted systems of Halpern, Fagin et al.;  however, they are also modular and compact in the way concurrent  programs are. We also mention preliminary results on model checking alternating-time temporal logic for this natural class of models. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  IntelligenceMultiagent Systems; I.2.4 [Artificial Intelligence]: Knowledge  Representation Formalisms and Methods-Modal logic General Terms Theory . INTRODUCTION The logical foundations of multi-agent systems have received much attention in recent years. Logic has been used to represent and reason about, e.g., knowledge [7], time [6], cooperation and strategic ability [3]. Lately, an increasing amount of research has focused on higher level representation languages for models of such logics, motivated mainly by the need for compact representations, and for representations that correspond more closely to the actual systems which are modeled. Multi-agent systems are open systems, in the sense that agents interact with an environment only partially known in advance. Thus, we need representations of models of multi-agent systems which are modular, in the sense that a  component, such as an agent, can be replaced, removed, or added, without major changes to the representation of the whole model. However, as we argue in this paper, few existing representation languages are both modular, compact and computationally grounded on the one hand, and allow for representing properties of both knowledge and strategic ability, on the other. In this paper we present a new class of representations for  models of open multi-agent systems, which are modular, compact and come with an implicit methodology for modeling and designing actual systems. The structure of the paper is as follows. First, in Section 2, we present the background of our work - that is, logics that combine time, knowledge, and strategies. More precisely: modal logics that combine branching time, knowledge, and strategies under  incomplete information. We start with computation tree logic CTL, then we add knowledge (CTLK), and then we discuss two variants of alternating-time temporal logic (ATL): one for the perfect, and one for the imperfect information case. The semantics of logics like the ones presented in Section 2 are usually defined over explicit models (Kripke structures) that enumerate all possible (global) states of the system. However, enumerating these states is one of the things one mostly wants to avoid, because there are too many of them even for simple systems. Thus, we usually need representations that are more compact. Another reason for using a more specialized class of models is that general Kripke structures do not always give enough help in terms of methodology, both at the stage of design, nor at  implementation. This calls for a semantics which is more grounded, in the sense that the correspondence between elements of the model, and the entities that are modeled, is more immediate. In Section 3, we present an overview of representations that have been used for modeling and model checking systems in which time, action (and possibly knowledge) are important; we mention especially  representations used for theoretical analysis. We point out that the  compact and/or grounded representations of temporal models do not play their role in a satisfactory way when agents" strategies are considered. Finally, in Section 4, we present our framework of modular interpreted systems (MIS), and show where it fits in the picture. We conclude with a somewhat surprising hypothesis, that model checking ability under imperfect information for MIS can be computationally cheaper than model checking perfect information. Until now, almost all complexity results were distinctly in favor of perfect information strategies (and the others were indifferent). . LOGICS OF TIME, KNOWLEDGE, AND STRATEGIC ABILITY First, we present the logics CTL, CTLK, ATL and ATLir that are the starting point of our study. .1 Branching Time: CTL Computation tree logic CTL [6] includes operators for temporal properties of systems: i.e., path quantifier E (there is a path),  together with temporal operators: f(in the next state), 2 (always from now on) and U (until).1 Every occurrence of a temporal operator is immediately preceded by exactly one path quantifier (this variant of the language is sometimes called vanilla CTL). Let Π be a set of atomic propositions with a typical element p. CTL formulae ϕ are defined as follows: ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | E fϕ | E2ϕ | Eϕ U ϕ. The semantics of CTL is based on Kripke models M = St, R, π , which include a nonempty set of states St, a state transition relation R ⊆ St × St, and a valuation of propositions π : Π → P(St). A path λ in M refers to a possible behavior (or computation) of system M, and can be represented as an infinite sequence of states q0q1q2... such that qiRqi+1 for every i = 0, 1, 2, .... We denote the ith state in λ by λ[i]. A q-path is a path that starts in q.  Interpretation of a formula in a state q in model M is defined as follows: M, q |= p iff q ∈ π(p); M, q |= ¬ϕ iff M, q |= ϕ; M, q |= ϕ ∧ ψ iff M, q |= ϕ and M, q |= ψ; M, q |= E fϕ iff there is a q-path λ such that M, λ[1] |= ϕ; M, q |= E2ϕ iff there is a q-path λ such that M, λ[i] |= ϕ for every i ≥ 0; M, q |= Eϕ U ψ iff there is a q-path λ and i ≥ 0 such that M, λ[i] |= ψ and M, λ[j] |= ϕ for every 0 ≤ j < i. .2 Adding Knowledge: CTLK CTLK [19] is a straightforward combination of CTL and standard epistemic logic [10, 7]. Let Agt = {1, ..., k} be a set of agents with a typical element a. Epistemic logic uses operators for representing agents" knowledge: Kaϕ is read as agent a knows that ϕ. Models of CTLK extend models of CTL with epistemic indistinguishability relations ∼a⊆ St × St (one per agent). We assume that all ∼a are equivalences. The semantics of epistemic operators is defined as follows: M, q |= Kaϕ iff M, q |= ϕ for every q such that q ∼a q . Note that, when talking about agents" knowledge, we  implicitly assume that agents may have imperfect information about the actual current state of the world (otherwise the notion of  knowledge would be trivial). This does not have influence on the way we model evolution of a system as a single unit, but it will become important when particular agents and their strategies come to the fore. .3 Agents and Their Strategies: ATL Alternating-time temporal logic ATL [3] is a logic for  reasoning about temporal and strategic properties of open computational systems (multi-agent systems in particular). The language of ATL consists of the following formulae: ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | A fϕ | A 2ϕ | A ϕ U ϕ. where A ⊆ Agt. Informally, A ϕ says that agents A have a  collective strategy to enforce ϕ. It should be noted that the CTL path quantifiers A, E can be expressed with ∅ , Agt respectively. The semantics of ATL is defined in so called concurrent game structures (CGSs). A CGS is a tuple M = Agt, St, Act, d, o, Π, π ,  Additional operators A (for every path) and 3 (sometime in the future) are defined in the usual way. consisting of: a set Agt = {1, . . . , k} of agents; set St of states; valuation of propositions π : Π → P(St); set Act of atomic  actions. Function d : Agt × St → P(Act) indicates the actions available to agent a ∈ Agt in state q ∈ St. Finally, o is a  deterministic transition function which maps a state q ∈ St and an action profile α1, . . . , αk ∈ Actk , αi ∈ d(i, q), to another state q = o(q, α1, . . . , αk). DEFINITION 1. A (memoryless) strategy of agent a is a function sa : St → Act such that sa(q) ∈ d(a, q).2 A collective strategy SA for a team A ⊆ Agt specifies an individual strategy for each agent a ∈ A. Finally, the outcome of strategy SA in state q is defined as the set of all computations that may result from executing SA from q on: out(q, SA) = {λ = q0q1q2... | q0 = q and for every i = 1, 2, ... there exists αi−1  , ..., αi−1 k such that αi−1 a = SA(a)(qi−1) for each a ∈ A, αi−1 a ∈ d(a, qi−1) for each a /∈ A, and o(qi−1, αi−1  , ..., αi−1 k ) = qi}. The semantics of cooperation modalities is as follows: M, q |= A fϕ iff there is a collective strategy SA such that, for every λ ∈ out(q, SA), we have M, λ[1] |= ϕ; M, q |= A 2ϕ iff there exists SA such that, for every λ ∈ out(q, SA), we have M, λ[i] for every i ≥ 0; M, q |= A ϕ U ψ iff there exists SA such that for every λ ∈ out(q, SA) there is a i ≥ 0, for which M, λ[i] |= ψ, and M, λ[j] |= ϕ for every 0 ≤ j < i. .4 Agents with Imperfect Information: ATLir As ATL does not include incomplete information in its scope, it can be seen as a logic for reasoning about agents who always have complete knowledge about the current state of the whole system. ATLir [21] includes the same formulae as ATL, except that the  cooperation modalities are presented with a subscript: A ir indicates that they address agents with imperfect information and imperfect recall. Formally, the recursive definition of ATLir formulae is: ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | A ir fϕ | A ir2ϕ | A irϕ U ϕ Models of ATLir, concurrent epistemic game structures (CEGS), can be defined as tuples M = Agt, St, Act, d, o, ∼1, ..., ∼k, Π, π , where Agt, St, Act, d, o, Π, π is a CGS, and ∼1, ..., ∼k are  epistemic (equivalence) relations. It is required that agents have the same choices in indistinguishable states: q ∼a q implies d(a, q) = d(a, q ). ATLir restricts the strategies that can be used by agents to uniform strategies, i.e. functions sa : St → Act, such that: (1) sa(q) ∈ d(a, q), and (2) if q ∼a q then sa(q) = sa(q ). A collective strategy is uniform if it contains only uniform individual strategies. Again, the function out(q, SA) returns the set of all paths that may result from agents A executing collective strategy SA from state q. The semantics of ATLir formulae can be defined as follows: M, q |= A ir fϕ iff there is a uniform collective strategy SA such that, for every a ∈ A, q such that q ∼a q , and λ ∈ out(SA, q ), we have M, λ[1] |= ϕ;  This is a deviation from the original semantics of ATL [3], where strategies assign agents" choices to sequences of states, which  suggests that agents can by definition recall the whole history of each game. While the choice of one or another notion of strategy affects the semantics of the full ATL ∗ , and most ATL extensions (e.g. for games with imperfect information), it should be pointed out that both types of strategies yield equivalent semantics for pure ATL (cf. [21]). 98 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) M, q |= A ir2ϕ iff there exists SA such that, for every a ∈ A, q such that q ∼a q , and λ ∈ out(SA, q ), we have M, λ[i] for every i ≥ 0; M, q |= A irϕ U ψ iff there exist SA such that, for every a ∈ A, q such that q ∼a q , and λ ∈ out(SA, q ), there is i ≥ 0 for which M, λ[i] |= ψ, and M, λ[j] |= ϕ for every 0 ≤ j < i. That is, A irϕ holds iff A have a uniform collective strategy, such that for every path that can possibly result from execution of the strategy according to at least one agent from A, ϕ is the case. . MODELS AND MODEL CHECKING In this section, we present and discuss various (existing)  representations of systems that can be used for modeling and model checking. We believe that the two most important points of  reference are in this case: (1) the modeling formalism (i.e., the logic and the semantics we use), and (2) the phenomenon, or more  generally, the domain we are going to model (to which we will often refer as the real world). Our aim is a representation which is  reasonably close to the real world (i.e., it is sufficiently compact and grounded), and still not too far away from the formalism (so that it e.g. easily allows for theoretical analysis of computational  problems). We begin with discussing the merits of explicit  modelsin our case, these are transition systems, concurrent game structures and CEGSs, presented in the previous section. .1 Explicit Models Obviously, an advantage of explicit models is that they are very close to the semantics of our logics (simply because they are the semantics). On the other hand, they are in many ways difficult to use to describe an actual system: • Exponential size: temporal models usually have an  exponential number of states with respect to any higher-level  description (e.g. Boolean variables, n-ary attributes etc.). Also, their size is exponential in the number of processes (or agents) if the evolution of a system results from joint (synchronous or asynchronous) actions of several active entities [15]. For CGSs the situation is even worse: here, also the number of transitions is exponential, even if we fix the number of states.3 In practice, this means that such representations are very  seldom scalable. • Explicit models include no modularity. States in a model refer to global states of the system; transitions in the model correspond to global transitions as well, i.e., they represent (in an atomic way) everything that may happen in one single step, regardless of who has done it, to whom, and in what way. • Logics like ATL are often advertised as frameworks for  modeling and reasoning about open computational systems.  Ideally, one would like the elements of such a system to have as little interdependencies as possible, so that they can be plugged in and out without much hassle, for instance when we want to test various designs or implementations of the active component. In the case of a multi-agent system the  Another class of ATL models, alternating transition systems [2] represent transitions in a more succinct way. While we still have exponentially many states in an ATS, the number of transitions is simply quadratic wrt. to states (like for CTL models).  Unfortunately, ATS are even less modular and harder to design than  concurrent game structures, and they cannot be easily extended to handle incomplete information (cf. [9]). need is perhaps even more obvious. We do not only need to re-plug various designs of a single agent in the overall architecture; we usually also need to change (e.g., increase) the number of agents acting in a given environment without necessarily changing the design of the whole system.  Unfortunately, ATL models are anything but open in this sense. Theoretical complexity results for explicit models are as follows. Model checking CTL and CTLK is P-complete, and can be done in time O(ml), where m is the number of transitions in the model, and l is the length of the formula [5]. Alternatively, it can be done in time O(n2 l), where n is the number of states. Model checking ATL is P-complete wrt. m, l and ΔP  -complete wrt. n, k, l (k being the number of agents) [3, 12, 16]. Model checking ATLir is ΔP  complete wrt. m, l and ΔP  -complete wrt. n, k, l [21, 13]. .2 Compressed Representations Explicit representation of all states and transitions is inefficient in many ways. An alternative is to represent the state/transition space in a symbolic way [17, 18]. Such models offer some hope for feasible model checking  properties of open/multi-agent systems, although it is well known that they are compact only in a fraction of all cases.4 For us, however, they are insufficient for another reason: they are merely optimized representations of explicit models. Thus, they are neither more open nor better grounded: they were meant to optimize  implementation rather than facilitate design or modeling methodology. .3 Interpreted Systems Interpreted systems [11, 7] are held by many as a prime example of computationally grounded models of distributed systems. An  interpreted system can be defined as a tuple IS = St1, ..., Stk, Stenv, R, π . St1, ..., Stk are local state spaces of agents 1, ..., k, and Stenv is the set of states of the environment. The set of global states is defined as St = St1 × ... × Stk × Stenv; R ⊆ St × St is a transition relation, and π : Π → P(St). While the transition relation encapsulates the (possible) evolution of the system over time, the epistemic  dimension is defined by the local components of each global state: q1, ..., qk, qenv ∼i q1, ..., qk, qenv iff qi = qi . It is easy to see that such a representation is modular and  compact as far as we are concerned with states. Moreover, it gives a natural (grounded) approach to knowledge, and suggests an  intuitive methodology for modeling epistemic states. Unfortunately, the way transitions are represented in interpreted systems is neither compact, nor modular, nor grounded: the temporal aspect of the system is given by a joint transition function, exactly like in  explicit models. This is not without a reason: if we separate activities of the agents too much, we cannot model interaction in the  framework any more, and interaction is the most interesting thing here. But the bottom line is that the temporal dimension of an interpreted system has exponential representation. And it is almost as difficult to plug components in and out of an interpreted system, as for an ordinary CTL or ATL model, since the local activity of an agent is completely merged with his interaction with the rest of the system. .4 Concurrent Programs The idea of concurrent programs has been long known in the literature on distributed systems. Here, we use the formulation from [15]. A concurrent program P is composed of k  concurrent processes, each described by a labeled transition system Pi = Sti, Acti, Ri, Πi, πi , where Sti is the set of local states of process  Representation R of an explicit model M is compact if the size of R is logarithmic with respect to the size of M. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 899 i, Acti is the set of local actions, Ri ⊆ Sti ×Acti ×Sti is a transition relation, and Πi, πi are the set of local propositions and their  valuation. The behavior of program P is given by the product  automaton of P1, ..., Pk under the assumption that processes work  asynchronously, actions are interleaved, and synchronization is obtained through common action names. Concurrent programs have several advantages. First of all, they are modular and compact. They allow for local modeling of  components - much more so than interpreted systems (not only states, but also actions are local here). Moreover, they allow for  representing explicit interaction between local transitions of reactive  processes, like willful communication, and synchronization. On the other hand, they do not allow for representing implicit,  incidental, or not entirely benevolent interaction between processes. For example, if we want to represent the act of pushing somebody, the pushed object must explicitly execute an action of being pushed, which seems somewhat ridiculous. Side effects of actions are also not easy to model. Still, this is a minor complaint in the context of CTL, because for temporal logics we are only interested in the flow of transitions, and not in the underlying actions. For temporal reasoning about k asynchronous processes with no implicit  interaction, concurrent programs seem just about perfect. The situation is different when we talk about autonomous,  proactive components (like agents), acting together (cooperatively or adversely) in a common environment - and we want to address their strategies and abilities. Now, particular actions are no less  important than the resulting transitions. Actions may influence other agents" local states without their consent, they may have side  effects on other agents" states etc. Passing messages and/or calling procedures is by no means the only way of interaction between agents. Moreover, the availability of actions (to an agent) should not depend on the actions that will be executed by other agents at the same time - these are the outcome states that may depend on these actions! Finally, we would often like to assume that agents act synchronously. In particular, all agents play simultaneously in  concurrent game structures. But, assuming synchrony and autonomy of actions, synchronization can no longer be a means of  coordination. To sum up, we need a representation which is very much like concurrent programs, but allows for modeling agents that play  synchronously, and which enables modeling more sophisticated  interaction between agents" actions. The first postulate is easy to satisfy, as we show in the following section. The second will be addressed in Section 4. We note that model checking CTL against concurrent programs is PSPACE-complete in the number of local states and the length of the formula [15]. .5 Synchronous CP and Simple Reactive  Modules The semantics of ATL is based on synchronous models where availability of actions does not depend on the actions currently  executed by the other players. A slightly different variant of  concurrent programs can be defined via synchronous product of programs, so that all agents play simultaneously.5 Unfortunately, under such interpretation, no direct interaction between agents" actions can be modeled at all. DEFINITION 2. A synchronous concurrent program consists of k concurrent processes Pi = Sti, Acti, Ri, Πi, πi with the  follow5 The concept is not new, of course, and has already existed in folk knowledge, although we failed to find an explicit definition in the literature. ing unfolding to a CGS: Agt = {1, ..., k}, St = Qk i=1 Sti, Act = Sk i=1 Acti, d(i, q1, ..., qk ) = {αi | qi, αi, qi ∈ Ri for some qi ∈ Sti}, o( q1, ..., qk , α1, ..., αk) = q1, ..., qk such that qi, αi, qi ∈ Ri for every i; Π = Sk i=1 Πi, and π(p) = πi(p) for p ∈ Πi. We note that the simple reactive modules (SRML) from [22] can be seen as a particular implementation of synchronous concurrent programs. DEFINITION 3. A SRML system is a tuple Σ, Π, m1, . . . , mk , where Σ = {1, . . . , k} is a set of modules (or agents), Π is a set of Boolean variables, and, for each i ∈ Σ, we have mi = ctri, initi, updatei , where ctri ⊆ Π. Sets initi and updatei consist of guarded commands of the form φ ; v1 := ψ1; . . . ; vk := ψk, where every vj ∈ ctri, and φ, ψ1, . . . , ψk are propositional  formulae over Π. It is required that ctr1, . . . ctrk partitions Π. The idea is that agent i controls the variables ctri. The init guarded commands are used to initialize the controlled variables, while the update guarded commands can change their values in each round. A guarded command is enabled if the guard φ is true in the current state of the system. In each round an enabled update guarded  command is executed: each ψj is evaluated against the current state of the system, and its logical value is assigned to vj. Several guarded commands being enabled at the same time model non-deterministic choice. Model checking ATL for SRML has been proved  EXPTIMEcomplete in the size of the model and the length of the formula [22]. .6 Concurrent Epistemic Programs Concurrent programs (both asynchronous and synchronous) can be used to encode epistemic relations too - exactly in the same way as interpreted systems do [20]. That is, when unfolding a concurrent program to a model of CTLK or ATLir, we define that q1, ..., qk ∼i q1, ..., qk iff qi = qi . Model checking CTLK against concurrent epistemic programs is PSPACE-complete [20]. SRML can be also interpreted in the same way; then, we would assume that every agent can see only the variables he controls. Concurrent epistemic programs are modular and have a grounded semantics. They are usually compact (albeit not always: for  example, an agent with perfect information will always blow up the size of such a program). Still, they inherit all the problems of  concurrent programs with perfect information, discussed in Section 3.4: limited interaction between components, availability of local  actions depending on the actual transition etc. The problems were already important for agents with perfect information, but they  become even more crucial when agents have only limited knowledge of the current situation. One of the most important applications of logics that combine strategic and epistemic properties is  verification of communication protocols (e.g., in the context of security). Now, we may want to, e.g., check agents" ability to pass an  information between them, without letting anybody else intercept the message. The point is that the action of intercepting is by definition enabled; we just look for a protocol in which the transition of  successful interception is never carried out. So, availability of actions must be independent of the actions chosen by the other agents under incomplete information. On the other hand, interaction is arguably the most interesting feature of multi-agent systems, and it is really hard to imagine models of strategic-epistemic logics, in which it is not possible to represent communication. .7 Reactive Modules Reactive modules [1] can be seen as a refinement of  concurrent epistemic programs (primarily used by the MOCHA model checker [4]), but they are much more powerful, expressive and 00 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) grounded. We have already mentioned a very limited variant of RML (i.e., SRML). The vocabulary of RML is very close to  implementations (in terms of general computational systems): the  modules are essentially collections of variables, states are just  valuations of variables; events/actions are variable updates. However, the sets of variables controlled by different agents can overlap, they can change over time etc. Moreover, reactive modules  support incomplete information (through observability of variables), although it is not the main focus of RML. Again, the relationship between sets of observable variables (and to sets of controlled  variables) is mostly left up to the designer of a system. Agents can act synchronously as well as asynchronously. To sum up, RML define a powerful framework for modeling  distributed systems with various kinds of synchrony and asynchrony. However, we believe that there is still a need for a simpler and slightly more abstract class of representations. First, the  framework of RML is technically complicated, involving a number  auxiliary concepts and their definitions. Second, it is not always  convenient to represent all that is going on in a multi-agent system as reading and/or writing from/to program variables. This view of a multi-agent system is arguably close to its computer  implementation, but usually rather distant from the real world  domainhence the need for a more abstract, and more conceptually flexible framework. Third, the separation of the local complexity, and the complexity of interaction is not straightforward. Our new proposal, more in the spirit of interpreted systems, takes these observations as the starting point. The proposed framework is presented in  Section 4. . MODULAR INTERPRETED SYSTEMS The idea behind distributed systems (multi-agent systems even more so) is that we deal with several loosely coupled components, where most of the processing goes on inside components (i.e.,  locally), and only a small fraction of the processing occurs between the components. Interaction is crucial (which makes concurrent programs an insufficient modeling tool), but it usually consumes much less of the agent"s resources than local computations (which makes the explicit transition tables of CGS, CEGS, and interpreted systems an overkill). Modular interpreted systems, proposed here, extrapolate the modeling idea behind interpreted systems in a way that allows for a tight control of the interaction complexity. DEFINITION 4. A modular interpreted system (MIS) is defined as a tuple S = Agt, env, Act, In , where Agt = {a1, ..., ak} is a set of agents, env is the environment, Act is a set of actions, and In is a set of symbols called interaction alphabet. Each agent has the following internal structure: ai = Sti, di, outi, ini, oi, Πi, πi , where: • Sti is a set of local states, • di : Sti → P(Act) defines local availability of actions; for convenience of the notation, we additionally define the set of situated actions as Di = { qi, α | qi ∈ Sti, α ∈ di(qi)}, • outi, ini are interaction functions; outi : Di → In refers to the influence that a given situated action (of agent ai) may possibly have on the external world, and ini : Sti ×Ink → In translates external manifestations of the other agents (and the environment) into the impression that they make on ai"s transition function depending on the local state of ai, • oi : Di × In → Sti is a (deterministic) local transition  function, • Πi is a set of local propositions of agent ai where we require that Πi and Πj are disjunct when i = j, and • πi : Πi → P(Sti) is a valuation of these propositions. The environment env = Stenv, outenv, inenv, oenv, Πenv, πenv has the same structure as an agent except that it does not perform actions, and that thus outenv : Stenv → In and oenv : Stenv × In → Stenv. Within our framework, we assume that every action is executed by an actor, that is, an agent. As a consequence, every actor is explicitly represented in a MIS as an agent, just like in the case of CGS and CEGS. The environment, on the other hand, represents the (passive) context of agents" actions. In practice, it serves to capture the aspects of the global state that are not observable by any of the agents. The input functions ini seem to be the fragile spots here: when given explicitly as tables, they have size exponential wrt. the  number of agents (and linear wrt. the size of In). However, we can use, e.g., a construction similar to the one from [16] to represent interaction functions more compactly. DEFINITION 5. Implicit input function for state q ∈ Sti is given by a sequence ϕ1, η1 , ..., ϕn, ηn , where each ηj ∈ In is an  interaction symbol, and each ϕj is a boolean combination of  propositions ˆηi , with η ∈ In; ˆηi stands for η is the symbol currently generated by agent i. The input function is now defined as  follows: ini(q, 1, ..., k, env) = ηj iff j is the lowest index such that {ˆ1 , ..., ˆk k, ˆenv env} |= ϕj. It is required that ϕn ≡ , so that the  mapping is effective. REMARK 1. Every ini can be encoded as an implicit input  function, with each ϕj being of polynomial size with respect to the  number of interaction symbols (cf. [16]). Note that, for some domains, the MIS representation of a system requires exponentially many symbols in the interaction alphabet In. In such a case, the problem is inherent to the domain, and ini will have size exponential wrt the number of agents. .1 Representing Agent Systems with MIS Let Stg = ( Qk i=1 Sti)×Stenv be the set of all possible global states generated by a modular interpreted system S. DEFINITION 6. The unfolding of a MIS S for initial states Q ⊆ Stg to a CEGS cegs(S, Q) = Agt , St , Π , π , Act , d , o , ∼1, ..., ∼k is defined as follows: • Agt = {1, ..., k} and Act = Act, • St is the set of global states from Stg which are reachable from some state in Q via the transition relation defined by o (below), • Π = Sk i=1 Πi ∪ Πenv, • For each q = q1, . . . , qk, qenv ∈ St and i = 1, ..., k, env, we define q ∈ π (p) iff p ∈ Πi and qi ∈ πi(p), • d (i, q) = di(qi) for global state q = q1, ..., qk, qenv , • The transition function is constructed as follows. Let q = q1, ..., qk, qenv ∈ St , and α = α1, ..., αk be an action profile s.t. αi ∈ d (i, q). We define inputi(q, α) = ini ` qi, out1(q1, α1), . . . , outi−1(qi−1, αi−1), outi+1(qi+1, αi+1), . . . , outk(qk, αk), outenv(qenv) ´ for each agent i = 1, . . . , k, and inputenv(q, α) = inenv ` qenv, out1(q1, α1), . . . , outk(qk, αk) ´ . Then, o (q, α) = o1( q1, α1 , input1(q, α)), . . . , ok( qk, αk , inputk(q, α)), oenv(qenv, inputenv(q, α)) ; The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 901 • For each i = 1, ..., k: q1, ..., qk, qenv ∼i q1, ..., qk, qenv iff qi = qi .6 REMARK 2. Note that MISs can be used as representations of CGSs too. In that case, epistemic relations ∼i are simply omitted in the unfolding. We denote the unfolding of a MIS S for initial states Q into a CGS by cgs(S, Q). Propositions 3 and 5 state that modular interpreted systems can be used as representations for explicit models of multi-agent  systems. On the other hand, these representations are not always  compact, as demonstrated by Propositions 7 and 8. PROPOSITION 3. For every CEGS M, there is a MIS SM and a set of global states Q of SM such that cegs(SM , Q) is isomorphic to M.7 PROOF. Let M = {1, . . . , k}, St, Act, d, o, Π, π, ∼1, . . . , ∼k be a CEGS. We construct a MIS SM = {a1, . . . , ak}, env, Act, In with agents ai = Sti, di, outi, ini, oi, Πi, πi and environment env = Stenv, outenv, inenv, oenv, Πenv, πenv , plus a set Q ⊆ Stg of global states, as follows. • In = Act ∪ St ∪ (Actk−1 × St), • Sti = {[q]∼i | q ∈ St} for 1 ≤ i ≤ k (i.e., Sti is the set of i"s indistinguishability classes in M), • Stenv = St, • di([q]∼i ) = d(i, q) for 1 ≤ i ≤ k (this is well-defined since d(i, q) = d(i, q ) whenever q ∼i q ), • outi([q]∼i , αi) = αi for 1 ≤ i ≤ k; outenv(q) = q, • ini([q]∼i , α1, . . . , αi−1, αi+1, . . . , αk, qenv) = α1, . . . , αi−1, αi+1, . . . , αk, qenv for i ∈ {1, . . . , k}; inenv(q, α1 . . . , αk) = α1, . . . , αk ; ini(x) and inenv(x) are arbitrary for other arguments x, • oi( [q]∼i , αi , α1, . . . , αi−1, αi+1, . . . , αk, qenv ) = [o(qenv, α1, . . . , αk)]∼i for 1 ≤ i ≤ k and αi ∈ di([q]∼i ); oenv(q, α1, . . . , αk ) = o(q, α1, . . . , αk); oi and oenv are arbitrary for other arguments, • Πi = ∅ for 1 ≤ i ≤ k, and Πenv = Π, • πenv(p) = π(p) • Q = { [q]∼1 , . . . , [q]∼k , q : q ∈ St} Let M = cegs(SM , Q) = Agt , St , Act , d , o , Π , π , ∼1, . . . , ∼k . We argue that M and M are isomorphic by establishing a  oneto-one correspondence between the respective sets of states, and showing that the other parts of the structures agree on  corresponding states. First we show that, for any ˆq = [q ]∼1 , . . . , [q ]∼k , q ∈ Q and any α = α1, . . . , αk such that αi ∈ d (i, ˆq ), we have o (ˆq , α) = [q]∼1 , . . . , [q]∼k , q where q = o(q , α) (1) Let ˆq = o (ˆq , α). Now, for any i: inputi(ˆq , α) = ini([q ]∼i , out1([q ]∼1 , α1), ..., outi−1([q ]∼i−1 , αi−1), outi+1([q ]∼i+1 , αi+1), . . . , outk([q ]∼k , αk), outenv(q )) = ini([q ]∼i , α1, . . . , αi−1, αi+1,  This shows another difference between the environment and the agents: the environment does not possess knowledge.  We say that two CEGS are isomorphic if they only differ in the names of states and/or actions. . . . , αk, q ) = α1, . . . , αi−1, αi+1, . . . , αk, q . Similarly, we get that inputenv(ˆq , α) = α1, . . . , αk . Thus we get that o (ˆq , α) = o1( [q ]∼1 , α1 , input1(ˆq , α)), . . . , ok( [q ]∼k , αk , inputk(ˆq , α)), oenv(q , inputenv(ˆq , α)) = [o(q , α1, . . . , αk)]∼1 , . . . , [o(q , α1, . . . , αk)]∼k , o(q , α1, . . . , αk) . Thus, ˆq = [q]∼1 , . . . , [q]∼k , q for q = o(q , α1, . . . , αk), which completes the proof of (1). We now argue that St = Q. Clearly, Q ⊆ St . Let ˆq ∈ St ; we must show that ˆq ∈ Q. The argument is on induction on the length of the least o path from Q to ˆq. The base case, ˆq ∈ Q, is immediate. For the inductive step, ˆq = o (ˆq , α) for some ˆq ∈ Q, and then we have that ˆq ∈ Q by (1). Thus, St = Q. Now we have a one-to-one correspondence between St and St : r ∈ St corresponds to [r]∼1 , . . . , [r]∼k , r ∈ St . It remains to be shown that the other parts of the structures M and M agree on corresponding states: • Agt = Agt, • Act = Act, • Π = Sk i=1 Πi ∪ Πenv = Π, • For p ∈ Π = Π: [q ]∼1 , . . . , [q ]∼k , q ∈ π (p) iff q ∈ πenv(p) iff q ∈ π(p) (same valuations at corresponding states), • d (i, [q ]∼1 , . . . , [q ]∼k , q ) = di([q ]∼i ) = d(i, q), • It follows immediately from (1), and the fact that Q = St , that o ( [q ]∼1 , . . . , [q ]∼k , q , α) = [r ]∼1 , . . . , [r ]∼k , r iff o(q , α) = r (transitions on the same joint action in  corresponding states lead to corresponding states), • [q ]∼1 , . . . , [q ]∼k , q ∼i [r ]∼1 , . . . , [r ]∼k , r iff [q ]∼i = [r ]∼i iff q ∼i r (the accessibility relations relate  corresponding states), which completes the proof. COROLLARY 4. For every CEGS M, there is an ATLir-equivalent MIS S with initial states Q, that is, for every state q in M there is a state q in cegs(S, Q) satisfying exactly the same ATLir formulae, and vice versa. PROPOSITION 5. For every CGS M, there is a MIS SM and a set of global states Q of SM such that cgs(SM , Q) is isomorphic to M. PROOF. Let M = Agt, St, Act, d, o, Π, π be given. Now, let ˆM = Agt, St, Act, d, o, Π, π, ∼1, . . . , ∼k for some arbitrary  accessibility relations ∼i over St. By Proposition 3, there exists a MIS S ˆM with global states Q such that ˆM = cegs(S ˆM , Q) is isomorphic to ˆM. Let M be the CGS obtained by removing the accessibility relations from ˆM . Clearly, M is isomorphic to M. COROLLARY 6. For every CGS M, there is an ATL-equivalent MIS S with initial states Q. That is, for every state q in M there is a state q in cgs(S, Q) satisfying exactly the same ATL formulae, and vice versa. PROPOSITION 7. The local state spaces in a MIS are not  always compact with respect to the underlying concurrent epistemic game structure. PROOF. Take a CEGS M in which agent i has always perfect  information about the current global state of the system. When  constructing a modular interpreted system S such that M = cegs(S, Q), we have that Sti must be isomorphic with St. 02 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The above property is a part of the interpreted systems heritage. The next proposition stems from the fact that explicit models (and interpreted systems) allow for intensive interaction between agents. PROPOSITION 8. The size of In in S is, in general, exponential with respect to the number of local states and local actions. This is the case even when epistemic relations are not relevant (i.e., when S is taken as a representation of an ordinary CGS). PROOF. Consider a CGS M with agents Agt = {1, ..., k}, global states St = Qk i=1{qi , ..., qi i}, and actions Act = {0, 1}, all enabled everywhere. The transition function is defined as o( q1 j1 , ..., qk jk , α1, ..., αk) = q1 l1 , ..., qk lk , where li = (ji + α1 + ... + αk) mod i. Note that M can be represented as a modular  interpreted system with succinct local state spaces Sti = {qi , ..., qi i}. Still, the current actions of all agents are relevant to determine the resulting local transition of agent i. We will call items In, outi, ini the interaction layer of a  modular interpreted system S; the other elements of S constitute the local layer of the MIS. In this paper we are ultimately interested in model checking complexity with respect to the size of the local layer. To this end, we will assume that the size of interaction layer is  polynomial in the number of local states and actions. Note that, by Propositions 7 and 8, not every explicit model submits to compact representation with a MIS. Still, as we declared at the beginning of Section 4, we are mainly interested in a modeling framework for systems of loosely coupled components, where interaction is  essential, but most processing is done locally anyway. More  importantly, the framework of MIS allows for separating the interaction of agents from their local structure to a larger extent. Moreover, we can control and measure the complexity of each layer in a finer way than before. First, we can try to abstract from the complexity of a layer (e.g. like in this paper, by assuming that the other layer is kept within certain complexity bounds). Second, we can also measure separately the interaction complexity of different agents. .2 Modular Interpreted Systems vs. Simple Reactive Modules In this section we show that simple reactive modules are (as we already suggested) a specific (and somewhat limited)  implementation of modular interpreted systems. First, we define our (quite strong) notion of equivalence of representations. DEFINITION 7. Two representations are equivalent if they  unfold to isomorphic concurrent epistemic game structures. They are CGS-equivalent if they unfold to the same CGS. PROPOSITION 9. For any SRML there is a CGS-equivalent MIS. PROOF. Consider an SRML R with k modules and n variables. We construct S = Agt, Act, In with Agt = {a1, ..., ak}, Act = { 1, ..., n, ⊥1, ..., ⊥n}, and In = Sk i=1 Sti × Sti (the local state spaces Sti will be defined in a moment). Let us assume without loss of generality that ctri = {x1, ..., xr}. Also, we consider all guarded commands of i to be of type γi,ψ : ψ ; xi := , or γ⊥ i,ψ : ψ ; xi := ⊥. Now, agent ai in S has the following components: Sti = P(ctri) (i.e., local states of ai are valuations of variables controlled by i); di(qi) = { 1, ..., r, ⊥1, ..., ⊥r}; outi(qi, α) = qi, qi ; ini(qi, q1, q1 , ..., qi−1, qi−1 , qi+1, qi+1 , qk, qk ) = {xi ∈ ctri | q1, ..., qk |= W γi,ψ ψ}, {xi ∈ ctri | q1, ..., qk |= W γ⊥ i,ψ ψ} . To define local transitions, we consider three cases. If t = f = ∅ (no update is enabled), then oi(qi, α, t, f ) = qi for every action α. If t = ∅, we take any arbitrary ˆx ∈ t, and  define oi(qi, j, t, f ) = qi ∪ {xj} if xj ∈ t, and qi ∪ {ˆx} otherwise; oi(qi, ⊥j, t, f ) = qi \ {xj} if xj ∈ f, and qi ∪ {ˆx} otherwise. Moreover, if t = ∅ = f, we take any arbitrary ˆx ∈ f, and  define oi(qi, j, t, f ) = qi ∪ {xj} if xj ∈ t, and qi \ {ˆx} otherwise; oi(qi, ⊥j, t, f ) = qi \{xj} if xj ∈ f, and qi \{ˆx} otherwise. Finally, Πi = ctri, and qi ∈ πi(xj) iff xj ∈ qi. The above construction shows that SRML have more compact representation of states than MIS: ri local variables of agent i give rise to 2ri local states. In a way, reactive modules (both simple and full) are two-level representations: first, the system is  represented as a product of modules; next, each module can be seen as a product of its variables (together with their update operations). Note, however, that specification of updates with respect to a single variable in an SRML may require guarded commands of total length O(2 Pk i=1 ri ). Thus, the representation of transitions in SRML is (in the worst case) no more compact than in MIS, despite the two-level structure of SRML. We observe finally that MIS are more general, because in SRML the current actions of other agents have no  influence on the outcome of agent i"s current action (although the outcome can be influenced by other agents" current local states). .3 Model Checking Modular Interpreted  Systems One of our main aims was to study the complexity of symbolic model checking ATLir in a meaningful way. Following the  reviewers" remarks, we state our complexity results only as conjectures. Preliminary proofs can be found in [14]. CONJECTURE 10. Model checking ATL for modular interpreted systems is EXPTIME-complete. CONJECTURE 11. Model checking ATLir for the class of  modular interpreted systems is PSPACE-complete. A summary of complexity results for model checking  temporal and strategic logics (with and without epistemic component) is given in the table below. The table presents completeness  results for various models and settings of input parameters. Symbols n, k, m stand for the number of states, agents and transitions in an explicit model; l is the length of the formula, and nlocal is the  number of local states in a concurrent program or modular interpreted system. The new results, conjectured in this paper, are printed in italics. Note that the result for model checking ATL against modular interpreted systems is an extension of the result from [22]. m, l n, k, l nlocal, k, l CTL P [5] P [5] PSPACE [15] CTLK P [5, 8] P [5, 8] PSPACE [20] ATL P [3] ΔP  [12, 16] EXPTIME ATLir ΔP  [21, 13] ΔP  [13] PSPACE If we are right, then the results for ATL and ATLir form an  intriguing pattern. When we compare model checking agents with perfect vs. imperfect information, the first problem appears to be much easier against explicit models measured with the number of transitions; next, we get the same complexity class against explicit models measured with the number of states and agents; finally, model checking imperfect information turns out to be easier than model checking perfect information for modular interpreted  systems. Why can it be so? First, a MIS unfolds into CEGS and CGS in a different way. In the first case, the MIS is assumed to encode the epistemic relations explicitly (which makes it explode when we model agents with  perfect, or almost perfect information). In the latter case, the epistemic The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 903 aspect is ignored, which gives some extra room for encoding the transition relation more efficiently. Another crucial factor is the number of available strategies (relative to the size of input  parameters). The number of all strategies is exponential in the number of global states; for uniform strategies, there are usually much less of them but still exponentially many in general. Thus, the fact that perfect information strategies can be synthesized incrementally has a substantial impact on the complexity of the problem. However, measured in terms of local states and agents, the number of all strategies is doubly exponential, while there are only  exponentially many uniform strategies - which settles the results in favor of imperfect information. . CONCLUSIONS We have presented a new class of representations for open  multiagent systems. Our representations, called modular interpreted  systems, are: modular, in the sense that components can be changed, replaced, removed or added, with as little changes to the whole  representation as possible; more compact than traditional explicit  representations; and grounded, in the sense that the correspondences between the primitives of the model and the entities being  modeled are more immediate, giving a methodology for designing and implementing systems. We also conjecture that the complexity of model checking strategic ability for our representations is higher if we assume perfect information than if we assume imperfect  information. The solutions, proposed in this paper, are not necessarily  perfect (for example, the impression functions ini seem to be the main source of non-modularity in MIS, and can be perhaps  improved), but we believe them to be a step in the right direction. We also do not mean to claim that our representations should  replace more elaborate modeling languages like Promela or reactive modules. We only suggest that there is a need for compact, modular and reasonably grounded models that are more expressive than  concurrent (epistemic) programs, and still allow for easier theoretical analysis than reactive modules. We also suggest that MIS might be better suited for modeling simple multi-agent domains, especially for human-oriented (as opposed to computer-oriented) design. . ACKNOWLEDGMENTS We thank the anonymous reviewers and Andrzej Tarlecki for their helpful remarks. Thomas Ågotnes" work on this paper was supported by grants 166525/V30 and 176853/S10 from the  Research Council of Norway. . REFERENCES [1] R. Alur and T. A. Henzinger. Reactive modules. Formal Methods in System Design, 15(1):7-48, 1999. [2] R. Alur, T. A. Henzinger, and O. Kupferman. Alternating-time Temporal Logic. Lecture Notes in Computer Science, 1536:23-60, 1998. [3] R. Alur, T. A. Henzinger, and O. Kupferman. Alternating-time Temporal Logic. Journal of the ACM, 9:672-713, 2002. [4] R. Alur, T.A. Henzinger, F.Y.C. Mang, S. Qadeer, S.K. Rajamani, and S. Tasiran. MOCHA user manual. In Proceedings of CAV"98, volume 1427 of Lecture Notes in Computer Science, pages 521-525, 1998. [5] E.M. Clarke, E.A. Emerson, and A.P. Sistla. Automatic verification of finite-state concurrent systems using temporal logic specifications. ACM Transactions on Programming Languages and Systems, 8(2):244-263, 1986. [6] E.A. Emerson and J.Y. Halpern. "sometimes" and "not never" revisited: On branching versus linear time temporal logic. In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, pages 151-178, 1982. [7] R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning about Knowledge. MIT Press: Cambridge, MA, 995. [8] M. Franceschet, A. Montanari, and M. de Rijke. Model checking for combined logics. In Proceedings of the 3rd International Conference on Temporal Logic (ICTL), 2000. [9] V. Goranko and W. Jamroga. Comparing semantics of logics for multi-agent systems. Synthese, 139(2):241-280, 2004. [10] J. Y. Halpern. Reasoning about knowledge: a survey. In D. M. Gabbay, C. J. Hogger, and J. A. Robinson, editors, The Handbook of Logic in Artificial Intelligence and Logic Programming, Volume IV, pages 1-34. Oxford University Press, 1995. [11] J.Y. Halpern and R. Fagin. Modelling knowledge and action in distributed systems. Distributed Computing, (4):159-177, 1989. [12] W. Jamroga and J. Dix. Do agents make model checking explode (computationally)? In M. P˘echou˘cek, P. Petta, and L.Z. Varga, editors, Proceedings of CEEMAS 2005, volume 690 of Lecture Notes in Computer Science, pages 398-407. Springer Verlag, 2005. [13] W. Jamroga and J. Dix. Model checking abilities of agents: A closer look. Submitted, 2006. [14] W. Jamroga and T. Ågotnes. Modular interpreted systems: A preliminary report. Technical Report IfI-06-15, Clausthal University of Technology, 2006. [15] O. Kupferman, M.Y. Vardi, and P. Wolper. An automata-theoretic approach to branching-time model checking. Journal of the ACM, 47(2):312-360, 2000. [16] F. Laroussinie, N. Markey, and G. Oreiby. Expressiveness and complexity of ATL. Technical Report LSV-06-03, CNRS & ENS Cachan, France, 2006. [17] K.L. McMillan. Symbolic Model Checking: An Approach to the State Explosion Problem. Kluwer Academic Publishers, 993. [18] K.L. McMillan. Applying SAT methods in unbounded symbolic model checking. In Proceedings of CAV"02, volume 2404 of Lecture Notes in Computer Science, pages 50-264, 2002. [19] W. Penczek and A. Lomuscio. Verifying epistemic properties of multi-agent systems via bounded model checking. In Proceedings of AAMAS"03, pages 209-216, New York, NY, USA, 2003. ACM Press. [20] F. Raimondi and A. Lomuscio. The complexity of symbolic model checking temporal-epistemic logics. In L. Czaja, editor, Proceedings of CS&P"05, 2005. [21] P. Y. Schobbens. Alternating-time logic with imperfect recall. Electronic Notes in Theoretical Computer Science, 5(2), 2004. [22] W. van der Hoek, A. Lomuscio, and M. Wooldridge. On the complexity of practical ATL model checking. In P. Stone and G. Weiss, editors, Proceedings of AAMAS"06, pages 01-208, 2006. 04 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Operational Semantics of Multiagent Interactions Juan M. Serrano University Rey Juan Carlos C/Tulipan S/N Madrid, Spain juanmanuel.serrano@urjc.es Sergio Saugar University Rey Juan Carlos C/Tulipan S/N Madrid, Spain sergio.saugar@urjc.es ABSTRACT The social stance advocated by institutional frameworks and most multi-agent system methodologies has resulted in a wide spectrum of organizational and communicative  abstractions which have found currency in several programming frameworks and software platforms. Still, these tools and frameworks are designed to support a limited range of  interaction capabilities that constrain developers to a fixed set of particular, pre-defined abstractions. The main hypothesis motivating this paper is that the variety of multi-agent  interaction mechanisms - both, organizational and  communicative, share a common semantic core. In the realm of software architectures, the paper proposes a connector-based model of multi-agent interactions which attempts to identify the essential structure underlying multi-agent interactions.  Furthermore, the paper also provides this model with a formal execution semantics which describes the dynamics of social interactions. The proposed model is intended as the  abstract machine of an organizational programming language which allows programmers to accommodate an open set of interaction mechanisms. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  Intelligence-multi-agent systems General Terms Languages, Theory, Design . INTRODUCTION The suitability of agent-based computing to manage the complex patterns of interactions naturally occurring in the development of large scale, open systems, has become one of its major assets over the last few years [26, 24, 15].  Particularly, the organizational or social stance advocated by institutional frameworks [2] and most multi-agent system (MAS) methodologies [26, 10], provides an excellent basis to deal with the complexity and dynamism of the interactions among system components. This approach has resulted in a wide spectrum of organizational and communicative  abstractions, such as institutions, normative positions, power relationships, organizations, groups, scenes, dialogue games, communicative actions (CAs), etc., to effectively model the interaction space of MAS. This wealth of computational  abstractions has found currency in several programming  frameworks and software platforms (AMELI [9], MadKit [13],  INGENIAS toolkit [18], etc.), which leverage multi-agent  middlewares built upon raw ACL-based interaction mechanism [14], and minimize the gap between organizational  metamodels and target implementation languages. Still, these tools and frameworks are designed to support a limited range of interaction capabilities that constrain  developers to a fixed set of particular, pre-defined abstractions. The main hypothesis motivating this paper is that the  variety of multi-agent interaction mechanisms - both,  organizational and communicative, share a common semantic core. This paper thus focuses on the fundamental building blocks of multi-agent interactions: those which may be composed, extended or refined in order to define more complex  organizational or communicative types of interactions. Its first goal is to carry out a principled analysis of  multiagent interactions, departing from general features commonly ascribed to agent-based computing: autonomy, situatedness and sociality [26]. To approach this issue, we draw on the notion of connector, put forward within the field of software architectures [1, 17]. The outcome of this analysis will be a connector-based model of multi-agent interactions between autonomous social and situated components, i.e. agents,  attempting to identify their essential structure. Furthermore, the paper also provides this model with a formal  execution semantics which describes the dynamics of multi-agent (or social) interactions. Structural Operational Semantics (SOS)[21], a common technique to specify the operational semantics of programming languages, is used for this  purpose. The paper is structured as follows: first, the major entities and relationships which constitute the structure of social interactions are introduced. Next, the dynamics of social interactions will show how these entities and relationships evolve. Last, relevant work in the literature is discussed 89 78-81-904262-7-5 (RPS) c 2007 IFAAMAS with respect to the proposal, limitations are addressed, and current and future work is described. . SOCIAL INTERACTION STRUCTURE From an architectural point of view, interactions between software components are embodied in software connectors: first-class entities defined on the basis of the different roles played by software components and the protocols that  regulate their behaviour [1]. The roles of a connector represent its participants, such as the caller and callee roles of an RPC connector, or the sender and receiver roles in a  message passing connector. The attachment operation binds a component to the role of a given connector. The analysis of social interactions introduced in this  section gives rise to a new kind of social connector. It refines the generic model in several respects, attending to the features commonly ascribed to agent-based computing: • According to the autonomy feature, we may  distinguish a first kind of participant (i.e. role) in a  social interaction, so-called agents. Basically, agents are those software components which will be regarded as autonomous within the scope of the interaction1 . • A second group of participants, so-called  environmental resources, may be identified from the situatedness feature. Unlike agents, resources represent those  nonautonomous components whose state may be  externally controlled by other components (agents or  resources) within the interaction. Moreover, the  participation of resources in an interaction is not  mandatory. • Last, according to the sociality of agents, the  specification of social connector protocols - the glue linking agents among themselves and with resources, will rely on normative concepts such as permissions, obligations and empowerments [23]. Besides agents, resources and social protocols, two other kinds of entities are of major relevance in our analysis of  social interactions: actions, which represent the way in which agents alter the environmental and social state of the  interaction; and events, which represent the changes in the interaction resulting from the performance of actions or the activity of environmental resources. In the following, we describe the basic entities involved in social interactions. Each kind of entity T will be specified as a record type T l1 : T1, . . . ln : Tn , possibly followed by a number of invariants, definitions, and the actions affecting their state. Instances or values v of a record type T will be represented as v = v1, . . . , vn : T. The type SetT  represents a collection of values drawn from type T. The type QueueT represents a queue of values v : T waiting to be  processed. The value v in the expression [v| ] : Queue[T]  represents the head of the queue. The type Enum {v1, . . . , vn}  Note that we think of the autonomy feature in a relative, rather than absolute, perspective. Basically, this means that software components counting as agents in a social  interaction may behave non-autonomously in other contexts, e.g. in their interactions through human-user interfaces. This conceptualization of agenthood resembles the way in which objects are understood in CORBA: as any kind of software component (C, Prolog, Cobol, etc.) attached to an ORB. represents an enumeration type whose values are v1, . . . , vn. Given some value v : T, the term vl refers to the value of the field l of a record type T. Given some labels l1, l2, . . . , the expression vl1,l2,... is syntactic sugar for ((vl1 )l2 ) . . .. The special term nil will be used to represent the absence of proper value for an optional field, so that vl = nil will be true in those cases and false otherwise. The formal model will be illustrated with several examples drawn from the  design of a virtual organization to aid in the management of university courses. .1 Social Interactions Social interactions shall be considered as composite  connectors [17], structured in terms of a tree of nested  subinteractions. Let"s consider an interaction representing a university course (e.g. on data structures). On the one hand, this interaction is actually a complex one, made up of lower-level interactions. For instance, within the scope of the course agents will participate in programming  assignment groups, lectures, tutoring meetings, examinations and so on. Assignment groups, in turn, may hold a number of assignment submissions and test requests interactions. A test request may also be regarded as a complex interaction, ultimately decomposed in the atomic, or bottom-level  interactions represented by communicative actions (e.g.  request, agree, refuse, . . . ). On the other hand, courses are run within the scope of a particular degree (e.g. computer science), a higher-level interaction. Traversing upwards from a degree to its ancestors, we find its faculty, the university and, finally, the multi-agent community or agent society. The community is thus the top-level interaction which  subsumes any other kind of multi-agent interaction2 . The organizational and communicative interaction types identified above clearly differ in many ways. However, we may identify four major components in all of them: the participating agents, the resources that agents manipulate, the protocol regulating the agent activities and the  subinteraction space. Accordingly, we may specify the type I of social interactions, ranged over by the meta-variable i, as follows: I state : SI, ini : A, mem : Set A, env : Set R, sub : Set I, prot : P, ch : CH def. : (1) icontext = i1 ⇔ i ∈ isub  inv. : (2) iini = nil ⇔ icontext = nil act. : setUp, join, create, destroy where the member and environment fields represent the agents (A) and local resources (R) participating in the  interaction; the sub-interaction field, its set of inner interactions; and the protocol field the rules that govern the interaction (P). The event channel, to be described in the next  section, allows the dispatching of local events to external  interactions. The context of some interaction is defined as its super-interaction (def. 1), so that the context of the  toplevel interaction is nil. The type SI Enum {open, closing, closed} represents the possible execution states of the interaction. Any  interaction, but the top-level one, is set up within the context of another interaction by an initiator agent. The initiator is  In the context of this application, a one-to-one mapping between human users and software components attached to the community as agents would be a right choice. 90 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thus a mandatory feature for any interaction different to the community (inv. 2). The life-cycle of the interaction begins in the open state. Its sets of agent and resource participants, initially empty, vary as agents join and leave the interaction, and as they create and destroy resources from its local  environment. Eventually, the interaction may come to an end (according to the protocol"s rules), or be explicitly closed by some agent, thus prematurely disabling the activity of its participants. The transient closing state will be described in the next section. .2 Agents Components attach themselves as agents in social  interactions with the purpose of achieving something. The purpose declared by some agent when it joins an interaction shall be regarded as the institutional goal that it purports to satisfy within that context3 . The types of agents participating in a given interaction are primarily identified from their  purposes. For instance, students are those agents participating in a course who purport to obtain a certificate in the course"s subject. Other members of the course include lecturers and teaching assistants. The type A of agents, ranged over by meta-variable a, is defined as follows: A state : SA, player : A, purp : F, att : Queue ACT , ev : Queue E, obl : Set O def. : (3) acontext = i ⇔ a ∈ imem (4) a1 ∈ aroles ⇔ aplayer  = a (5) i ∈ apartIn ⇔ a1 ∈ imem ∧ a1 ∈ aroles act. : see where the purpose is represented as a well-formed boolean formula, of a generic type F, which evaluates to true if the purpose is satisfied and false otherwise. The context of some agent is defined as the interaction in which it participates (def. 3). The type SA Enum {playing, leaving, succ, unsuc} represents the execution state of the agent. Its life-cycle  begins in the playing state when its player agent joins the  interaction, or some software component is attached as an agent to the multi-agent system (in this latter case, the player value is nil). The derived roles and partIn features  represent the roles played by the agent and the contexts in which these roles are played (def. 4, 5)4 . An agent may play roles at interactions within or outside the scope of its context. For instance, students of a course are played by student agents belonging to the (undergraduate) degree, whereas lecturers may be played by teachers of a given department and the assistant role may be played by students of a Ph.D degree (both, the department and the Ph.D. degrees, are modelled as sub-interactions of the faculty). Components will normally attempt to perform different actions (e.g. to set up sub-interactions) in order to satisfy their purposes within some interaction. Moreover,  components need to be aware of the current state of the interaction, so that they will also be capable of observing certain events from the interaction. Both, the visibility of the interaction  Thus, it may or may not correspond to actual internal goals or intentions of the component.  Free variables in the antecedents/consequents of  implications shall be understood as universally/existentially  quantified. and the attempts of members, are subject to the rules  governing the interaction. The attempts and events fields of the agent structure represent the queues of attempts to  execute some actions (ACT ), and the events (E) received by the agent which have not been observed yet. An agent may update its event queue by seeing the state of some entity of the community. The last field of the structure represents the obligations (O) of agents, to be described later. Eventually, the participation of some agent in the  interaction will be over. This may either happen when certain conditions are met (specified by the protocol rules), or when the agent takes the explicit decision of leaving the  interaction. In either case, the final state of the agent will be successful if its purpose was satisfied; unsuccessful  otherwise. The transient leaving state will be described in the next section. .3 Resources Resources are software components which may represent different types of non-autonomous informational or  computational entities. For instance, objectives, topics,  assignments, grades and exams are different kinds of informational resources created by lecturers and assistants in the context of the course interaction. Students may also create programs to satisfy the requirements of some assignment. Other types of computational resources put at the disposal of students by teachers include compilers and interpreters. The type R of resources, ranged over by meta-variable r, can be specified by the following record type: R cr : A, owners : Set A, op : Set OP def. : (6) rcontext = i ⇔ r ∈ ienv act. : take, share, give, invoke Essentially, resources can be regarded as objects deployed in a social setting. This means that resources are created, accessed and manipulated by agents in a social interaction context (def. 6), according to the rules specified by its  protocol. The mandatory feature creator represents the agent who created this resource. Moreover, resources may have owners. The ownership relationship between members and resources is considered as a normative device aimed at the simplification of the protocol"s rules that govern the  interaction of agents and the environment. Members may gain ownership of some resource by taking it, and grant  ownership to other agents by giving or sharing their own  properties. For instance, the ownership of programs may be shared by several students if the assignment can be performed by groups of two or more students. The last operations feature represents the interface of the resource, consisting of a set of operations. A resource is structured around several public operations that  participants may invoke, in accordance to the rules specified by the interaction"s protocol. The set of operations of a resource makes up its interface. .4 Protocols The protocol of any interaction is made up of the rules which govern its overall state and dynamics. The present specification abstracts away the particular formalism used to specify these rules, and focuses instead on several  requirements concerning the structure and interface of protocols. Accordingly, the type P of protocols, ranged over by  metaThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 891 variable p, is defined as follows5 : P emp : A × ACT → Boolean, perm : A × ACT → Boolean, obl :→ Set (A × Set O × Set E), monitor : E → Set A, finish :→ Boolean, over : A → Boolean def. : (7) pcontext = i ⇔ p = iprot inv. : (8) pfinish() ∧ s ∈ pcontext,sub ⇒ sprot,finish() (9) pfinish() ∧ a ∈ pcontext,mem ⇒ pover(a) (10) pover(a) ∧ ai ∈ aroles ⇒ acontext,prot,over i (ai) (11) αadd ∪ {a} ⊆ pmonitor( a, α, ) act. : Close, Leave We demand from protocols four major kinds of functions. Firstly, protocols shall include rules to identify the  empowerments and permissions of any agent attempting to alter the state of the interaction (e.g. its members, the  environment, etc.) through the execution of some action (e.g. join, create, etc.). Empowerments shall be regarded as the  institutional capabilities which some agent possesses in order to satisfy its purpose. Corresponding rules, encapsulated by the empowered function field, shall allow to determine whether some agent is capable to perform a given action over the interaction. Empowerments may only be exercised under certain circumstances - that permissions specify.  Permission rules shall allow to determine whether the attempt of an empowered agent to perform some particular action is satisfied or not (cf. permitted field). For instance, the course"s protocol specifies that the agents empowered to join the interaction as students are those students of the degree who have payed the fee established for the course"s subject, and own the certificates corresponding to its  prerequisite subjects. Permission rules, in turn, specify that those students may only join the course in the admission stage. Hence, even if some student has paid the fee, the attempt to join the course will fail if the course has not entered the corresponding stage6 . Secondly, protocols shall allow to determine the  obligations of agents towards the interaction. Obligations  represent a normative device of social enforcement, fully  compatible with the autonomy of agents, used to bias their  behaviour in a certain direction. These kinds of rules shall allow to determine whether some agent must perform an  action of a given type, as well as if some obligation was fulfilled, violated or needs to be revoked. The function obligations of the protocol structure thus identifies the agents whose  obligation set must be updated. Moreover, it returns for each agent a collection of events representing the changes in the obligation set. For instance, the course"s protocol  establishes that members of departments must join the course as teachers whenever they are assigned to the course"s subject. Thirdly, the protocol shall allow to specify monitoring rules for the different events originating within the  interaction. Corresponding rules shall establish the set of agents that must be awared of some event. For instance, this  func5 The formalization assumes that protocol"s functions  implicitly recieve as input the interaction being regulated.  The hasPaidFee relationship between (degree) students and subject resources is represented by an additional, application-dependent field of the agent structure for this kind of roles. Similarly, the admission stage is an additional boolean field of the structure for school interactions. The generic types I, A, R and P are thus extendable. tionality is exploited by teachers in order to monitor the enrollment of students to the course. Last, the protocol shall allow to control the state of the  interaction as well as the states of its members. Corresponding rules identify the conditions under which some interaction will be automatically finished, and whether the participation of some member agent will be automatically over. Thus, the function field finish returns true if the regulated interaction must finish its execution. If so happens, a well-defined set of protocols must ensure that its sub-interactions and members are finished as well (inv. 8,9). Similarly, the function over  returns true if the participation of the specified member must be over. Well-formed protocols must ensure the consistency between these functions across playing roles (inv. 10)7 . For instance, the course"s protocol establishes that the  participation of students is over when they gain ownership of the course"s certificate or the chances to get it are exhausted. It also establishes that the course must be finished when the admission stage has passed and all the students finished their participation. . SOCIAL INTERACTION DYNAMICS The dynamics of the multi-agent community is influenced by the external actions executed by software components and the protocols governing their interactions. This section focuses on the dynamics resulting from a particular kind of external action: the attempt of some component, attached to the community as an agent, to execute a given (internal) action. The description of other external actions concerning agents (e.g. observe the events from its event queue, enter or exit from the community) and resources (e.g. a timer resource may signal the pass of time) will be skipped. The processing of some attempt may give rise to changes in the scope of the target interaction, such as the  instantiation of new participants (agents or resources) or the  setting up of new sub-interactions. These resulting events may cause further changes in the state of other interactions (the target one included), namely, in its execution state as well as in the execution state, obligations and visibility of their members. This section will also describe the way in which these events are processed. The resulting dynamics described bellow allows for actions and events corresponding to different agents and interactions to be processed  simultaneously. Due to lack of space, we only include some of the operational rules that formalise the execution semantics. .1 Attempt processing An attempt is defined by the structure AT T perf : A, act : ACT , where the performer represents the agent in charge of executing the specified action. This action is intended to alter the state of some target interaction  (possibly, the performer"s context itself), and notify a collection of addressees of the changes resulting from a successful  execution. Accordingly, the type ACT of actions, ranged over by meta-variable α, is specified as follows: ACT state : SACT , target : I, add : Set A def. : (12) αperf = a ⇔ α ∈ aatt  The close and leave actions update the finish and over  function fields as explained in the next section. Additional  actions, such as permit, forbid, empower, etc., to update other protocol"s fields are yet to be identified in future work. 92 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) where: the performer is formally defined as the agent who stores the action in its queue of attempts, and the state field represents the current phase of processing. This process goes through four major phases, as specified by the  enumeration type SACT Enum {emp, perm, exec} :  empowerment checking, permission checking and action execution, described in the sequel. .1.1 Empowerment checking The post-condition of an attempt consists of inserting the action in the queue of attempts of the specified performer. As rule 1 specifies8 , this will only be possible if the  performer is empowered to execute that action according to the rules that govern the state of the target interaction. If this condition is not met, the attempt will simply be ignored. Moreover, the performer agent must be in the playing state (this pre-condition is also required for any rule concerning the processing of attempts). If these pre-conditions are  satisfied the rule is fired and the processing of the action  continues in the permission checking stage. For instance, when the software component attached as a student in a degree  attempts to join as a student the course in which some subject is teached, the empowerment rules of the course interaction are checked. If the (degree) student has passed the course"s prerequisite subjects the join action will be inserted in its queue of attempts and considered for execution. αtarget,prot,emp(a, α) a = playing, , , qACT , , a,α :AT T −→ playing, , , qACT , , (1) W here : (α )state = perm (qACT ) = insert(α , qACT ) .1.2 Permissions checking The processing of the action resumes when the possible preceding actions in the performer"s queue of attempts are fully processed and removed from the queue. Moreover, there should be no pending events to be processed in the interaction, for these events may cause the member or the interaction to be finished (as will be shortly explained in the next sub-section). If these conditions are met the  permissions to execute the given action (and notify the specified addressees) are checked (e.g. it will be checked whether the student paid the fee for the course"s subject). If the protocol of the target interaction grants permission, the processing of the attempt moves to the action execution stage (rule 2). Otherwise, the action is discharged and removed from the queue. Unlike unempowered attempts, a forbidden one will cause an event to be generated and transfered to the event channel for further processing. αstate = perm ∧ acontext,ch,in,ev = ∅ ∧ αtarget,prot,perm(a, α) a = playing, , , [α| ], , −→ playing, , , [α | ], , (2) W here : (α )state = exec  Labels of record instances are omitted to allow for more compact specifications. Moreover, note that record updates in where clauses only affect the specified fields. .1.3 Action execution The transitions fired in this stage are classified  according to the different types of actions to be executed. The intended effects of some actions may directly be achieved in a single step, while others will required an indirect  approach and possibly several execution steps. Actions of the first kind are constructive ones such as set up and join. The second group of actions include those, such as close and leave, whose effects are indirectly achieved by updating the interaction protocol. As an example of constructive action, let"s consider the execution of a set up action, whose type is defined as  follows9 : SetUp ACT · new : I inv. : (13) αnew,mem = αnew,res = αnew,sub = ∅ (14) αnew,state = open where the new field represents the new interaction to be initiated. Its sets of participants (agents and resources) and sub-interactions must be empty (inv. 13) and its state must be open (inv. 14). The setting up of the new interaction may thus affect its protocol and possible application-dependent fields (e.g. the subject of a course interaction). According to rule 3, the outcome of the execution is threefold: firstly, the performer"s attempt queue is updated so that the  executing action is removed; secondly, the new interaction is added to the target"s set of sub-interactions (moreover, its initiator field is set to the performer agent); last, the event representing this change (which includes a description of the change, the agent that caused it and the action performed) is inserted in the output port of the target"s event channel. αstate = exec ∧ α : SetUp ∧ αnew = i a = playing, , , [α|qACT ], , −→ playing, , , qACT , , αtarget = open, , , , , sI , c −→ open, , , , , sI ∪ i , c (3) W here : (i )ini = a (c )out,ev = insert( a, α, sub(αtarget , i ) , cout,ev ) Let"s consider now the case of a close action. This action represents an attempt by the performer to force some  interaction to finish, thus bypassing its current protocol rules (those concerning the finish function). The way to achieve this effect is to cause an update on the protocol so that the finish function returns true afterwards10 . Accordingly, we may specify this type of action as follows: Close ACT · upd : (→ Bool) → (→ Bool) inv. : (15) αtarget,state = open (16) αtarget,context = nil (17) αupd(αtarget,prot,finish)() where the inherited target field represents the interaction to be closed (which must be open and different to the  topinteraction, according to invariants 15 and 16) and the new  The resulting type consists of the fields of the ACT record extended with an additional new field. 0 This strategy is also followed in the definition of leave and may also be used in the definition of other types of actions such as fire, permit, forbid, etc. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 893 update field represents a proper higher-order function to  update the target"s protocol (inv. 17). The transition which models the execution of this action, specified by rule 4,  defines two effects in the target interaction: its protocol is updated and the event representing this change is inserted in its output port. This event will actually trigger the  closing process of the interaction as described in the next  subsection. αstate = exec ∧ α : Close a = playing, , , [α|qACT ], , −→ playing, , , qACT , , αtarget = open, , , , , p, c −→ open, , , , , p , c (4) W here : (p )finish = αupd (pfinish ) (c )out,ev = insert( a, α, finish(αtarget ) , cout,ev ) .2 Event Processing The processing of events is encapsulated in the event  channels of interactions. Channels, ranged over by meta-variable c, are defined by two input and output ports, according to the following definition: CH out : OutP, in : InP inv. : (18) ccontext ∈ cout,disp( , , finish(ccontext) ) (19) ccontext ∈ cout,disp( , , over(a) ) (20) ccontext,sub ⊆ cout,disp(closing(ccontext)) (21) apartsIn ⊆ cout,disp(leaving(a)) (22) ccontext ∈ cout,disp(closed(i)) (23) {ccontext, aplayer,context} ⊆ cout,disp(left(a)) OutP ev : Queue E, disp : E → Set I, int : Set I, ag : Set A InP ev : Queue E, stage : Enum {int, mem, obl}, ag : Set A The output port stores and processes the events originated within the scope of the channel"s interaction. Its first  purpose is to dispatch the local events to the agents  identified by the protocol"s monitoring function. Moreover, since these events may influence the results of the finishing, over and obligation functions of certain protocols, they will also be dispatched to the input ports of the interactions  identified through a dispatching function - whose invariants will be explained later on. Thus, input ports serve as a  coordination mechanism which activate the re-evaluation of the above functios whenever some event is received11 .  Accordingly, the processing of some event goes through four major stages: event dispatching, interaction state update, member state update and obligations update. The first one takes place in the output port of the interaction in which the event  originated, whereas the other ones execute in separate control threads associated to the input ports of the interactions to which the event was dispatched. .2.1 Event dispatching The processing of some event stored in the output port is triggered when all its preceding events have been dispatched. As a first step, the auxiliary int and ag fields are initialised 1 Alternatively, we may have assumed that interactions are fully aware of any change in the multi-agent community. In this scenario, interactions would trigger themselves without requiring any explicit notification. On the contrary, we  adhere to the more realistic assumption of limited awareness. with the returned values of the dispatching and protocol"s monitoring functions, respectively (rule 5). Then, additional rules simply iterate over these collections until all agents and interactions have been notified (i.e., both sets are empty). Last, the event is removed from the queue and the auxiliary fields are re-set to nil. The dispatching function shall identify the set of  interactions (possibly, empty) that may be affected by the event (which may include the channel"s interaction itself)12 . For instance, according to the finishing rule of university courses mentioned in the last section, the event representing the end of the admission stage, originated within the scope of the school interaction, will be dispatched to every course of the school"s degrees. Concerning the monitoring function, according to invariant 11 of protocols, if the event is  generated as the result of an action performance, the agents to be notified will include the performer and addressees of that action. Thus, according to the monitoring rule of  university courses, if a student of some degree joins a certain course and specifies a colleague as addressee of that action, the course"s teachers and itself will also be notified of the successful execution. ccontext,state s = open ∧ ccontext,prot,monitor s = mon cs = [e| ], d, nil, nil , −→ [e| ], , d(e), mon(e) , (5) .2.2 Interaction state update Input port activity is triggered when a new event is  received. Irrespective of the kind of incoming event, the first processing action is to check whether the channel"s  interaction must be finished. Thus, the dispatching of the finish event resulting from a close action (inv. 18) serves as a  trigger of the closing procedure. If the interaction has not to be finished, the input port stage field is set to the member state update stage and the auxiliary ag field is initialised to the interaction members. Otherwise, we can consider two possible scenarios. In the first one, the interaction has no members and no sub-interactions. In this case, the  interaction can be inmediately closed down. As rule 6 shows, the interaction is closed, removed from the context"s set of sub-interactions and a closed event is inserted in its output channel. According to invariant 22, this event will be later inserted to its input channel to allow for further treatment. cin,ev  = ∅ ∧ cin,stage  = int ∧ pfinish() , , , , {i} ∪ sI , , c −→ , , , , sI , , c i = , , ∅, , ∅, p, c1 −→ closed, , , , , , (6) W here : (c )out,ev = insert(closed(i), cout,ev ) In the second scenario, the interaction has some member or sub-interaction. In this case, clean-up is required prior to the disposal of the interaction (e.g. if the admission period ends and no student has matriculated for the course,  teachers has to be finished before finishing the course itself). As rule 7 shows, the interaction is moved to the transient  closing state and a corresponding event is inserted in the output port. According to invariant 20, the closing event will be dispatched to every sub-interaction in order to activate its closing procedure (guaranteed by invariant 8). Moreover, 2 This is essentially determined by the protocol rules of these interactions. The way in which the dispatching function is initialised and updated is out of the scope of this paper. 94 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the stage and ag fields are properly initialised so that the process goes on in the next member state update stage. This stage will further initiate the leaving process of the members (according to invariant 9). cin,ev = ∅ ∧ cin,stage = int ∧ pfinish() ∧ (sA = ∅ ∨ sI = ∅) i = open, , sA, , sI , p, c −→ closing, , sA, , sI , p, c (7) W here : (c )out,ev = insert(closing(i), cout,ev ) (c )in,stage = mem (c )in,ag = sA Eventually, every member will leave the interaction and every sub-interaction will be closed. Corresponding events will be received by the interaction (according to invariants 3 and 22) so that the conditions of the first scenario will hold. .2.3 Member state update This stage simply iterates over the members of the  interaction to check whether they must be finished according to the protocol"s over function. When all members have been checked, the stage field will be set to the next obligation update stage and the auxiliary ag field will be initalised with the agents identified by the protocol"s obligation  update function. If some member has to end its participation in the  interaction and it is not playing any role, it will be inmediately abandoned (successfully or unsuccessfully, according to the satisfaction of its purpose). The corresponding event will be forwarded to its interaction and to the interaction of its player agent to account for further changes (inv. 23).  Otherwise, the member enters the transient leaving state, thus preventing any action performance. Then, it waits for the completion of the leaving procedures of its played roles,  triggered by proper dispatching of the leaving event (inv. 21). .2.4 Obligations update In this stage, the obligations of agents (not necessaryly members of the interaction) towards the interaction are  updated accordingly. When all the identified agents have been updated, the event is removed from the input queue and the stage field is set back to the interaction state update. For instance, when a course interaction receives an event representing the assignment of some department member to its subject, an obligation to join the course as a teacher is created for that member. Moreover, the event representing this change is added to the output channel of the department interaction. . DISCUSSION This paper has attempted to expose a possible  semantic core underlying the wide spectrum of interaction types between autonomous, social and situated software  components. In the realm of software architectures, this core has been formalised as an operational model of social  connectors, intended to describe both the basic structure and  dynamics of multi-agent interactions, from the largest (the agent society itself) down to the smallest ones  (communicative actions). Thus, top-level interactions may represent the kind of agent-web pursued by large-scale initiatives such as the Agentcities/openNet one [25]. Large-scale interactions, modelling complex aggregates of agent interactions such as those represented by e-institutions or virtual organizations [2, 26], are also amenable to be conceptualised as  particular kinds of first-level social interactions. The last  levels of the interaction tree may represent small-scale  multiagent interactions such as those represented by interaction protocols [11], dialogue games [16], or scenes [2]. Finally, bottom-level interactions may represent communicative  actions. From this perspective, the member types of a CA include the speaker and possibly many listeners. The  purpose of the speaker coincides with the illocutionary purpose of the CA [22], whereas the purpose of any listener is to  declare that it (actually, the software component) successfully processed the meaning of the CA. The analysis of social interactions put forward in this  paper draws upon current proposals of the literature in  several general respects, such as the institutional and  organizational character of multi-agent systems [2, 26, 10, 7] and the normative perspective on multi-agent protocols [12, 23, 20]. These proposals as well as others focusing in relevant  abstractions such as power relationships, contracts, trust and reputation mechanisms in organizational settings, etc., could be further exploited in order to characterize more accurately the organizational character of some multi-agent  interactions. Similarly, the conceptualization of communicative actions as atomic interactions may similarly benefit from public semantics of communicative actions such as the one introduced in [3]. Last, the abstract model of protocols may be refined taking into account existing operational models of norms [12, 6]. These analyses shall result in new  organizational and communicative abstractions obtained through a refinement and/or extension of the general model of  social interactions. Thus, the proposed model is not intended to capture every organizational or communicative feature of multi-agent interactions, but to reveal their roots in basic interaction mechanisms. In turn, this would allow for the exploitation of common formalisms, particularly concerning protocols. Unlike the development of individual agents, which has greatly benefited from the design of several agent  programming languages [4], societal features of multi-agent systems are mostly implemented in terms of visual modelling [8, 18] and a fixed set of interaction abstractions. We argue that the current field of multi-agent system programming may greatly benefit from multi-agent programming languages that allow programmers to accommodate an open set of  interaction mechanisms. The model of social interactions put forward in this paper is intended as the abstract machine of a language of this type. This abstract machine would be independent of particular agent architectures and  languages (i.e. software components may be programmed in a BDI language such as Jason [5] or in a non-agent oriented language). On top of the presented execution semantics, current and future work aims at the specification of the type system [19] which allows to program the abstract machine, the  specification of the corresponding surface syntaxes (both textual and visual) and the design and implementation of a virtual machine over existing middleware technologies such as FIPA platforms or Web services. We also plan to study particular refinements and limitations to the proposed model,  particularly with respect to the dispatching of events, semantics The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 895 of obligations, dynamic updates of protocols and rule  formalisms. In this latter aspect, we plan to investigate the use of Answer Set Programming to specify the rules of  protocols, attending to the role that incompleteness (rules may only specify either necessary or sufficient conditions, for  instance), explicit negation (e.g. prohibitions) and defaults play in this domain. . ACKNOWLEDGMENTS The authors thank anonymous reviewers for their  comments and suggestions. Research sponsored by the Spanish Ministry of Science and Education (MEC), project  TIN200615455-C03-03. . REFERENCES [1] R. Allen and D. Garlan. A Formal Basis for Architectural Connection. ACM Transactions on Software Engineering and Methodology, 6(3):213-249, June 1997. [2] J. L. Arcos, M. Esteva, P. Noriega, J. A. Rodr´ıguez, and C. Sierra. Engineering open environments with electronic institutions. Journal on Engineering Applications of Artificial Intelligence, 18(2):191-204, 005. [3] G. Boella, R. Damiano, J. Hulstijn, and L. W. N. van der Torre. Role-based semantics for agent communication: embedding of the "mental attitudes" and "social commitments" semantics. In AAMAS, pages 688-690, 2006. [4] R. H. Bordini, L. Braubach, M. Dastani, A. E. F. Seghrouchni, J. J. G. Sanz, J. Leite, G. O"Hare, A. Pokahr, and A. Ricci. A survey of programming languages and platforms for multi-agent systems. Informatica, 30:33-44, 2006. [5] R. H. Bordini, J. F. H¨ubner, and R. Vieira. Jason and the golden fleece of agent-oriented programming. In R. H. Bordini, D. M., J. Dix, and A. El Fallah Seghrouchni, editors, Multi-Agent Programming: Languages, Platforms and Applications, chapter 1. Springer-Verlag, 2005. [6] O. Cliffe, M. D. Vos, and J. A. Padget. Specifying and analysing agent-based social institutions using answer set programming. In EUMAS, pages 476-477, 2005. [7] V. Dignum, J. V´azquez-Salceda, and F. Dignum. Omni: Introducing social structure, norms and ontologies into agent organizations. In R. Bordini, M. Dastani, J. Dix, and A. Seghrouchni, editors, Programming Multi-Agent Systems Second International Workshop ProMAS 2004, volume 3346 of LNAI, pages 181-198. Springer, 2005. [8] M. Esteva, D. de la Cruz, and C. Sierra. ISLANDER: an electronic institutions editor. In M. Gini, T. Ishida, C. Castelfranchi, and W. L. Johnson, editors, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS"02), pages 1045-1052. ACM Press, July 2002. [9] M. Esteva, B. Rosell, J. A. Rodr´ıguez-Aguilar, and J. L. Arcos. AMELI: An agent-based middleware for electronic institutions. In Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, volume 1, pages 236-243, 004. [10] J. Ferber, O. Gutknecht, and F. Michel. From agents to organizations: An organizational view of multi-agent systems. In AOSE, pages 214-230, 2003. [11] Foundation for Intelligent Physical Agents. FIPA Interaction Protocol Library Specification. http://www.fipa.org/repository/ips.html, 2003. [12] A. Garc´ıa-Camino, J. A. Rodr´ıguez-Aguilar, C. Sierra, and W. Vasconcelos. Norm-oriented programming of electronic institutions. In AAMAS, pages 670-672, 006. [13] O. Gutknecht and J. Ferber. The MadKit agent platform architecture. Lecture Notes in Computer Science, 1887:48-55, 2001. [14] JADE. The JADE project home page. http://jade.cselt.it, 2005. [15] M. Luck, P. McBurney, O. Shehory, and S. Willmott. Agent Technology: Computing as Interaction - A Roadmap for Agent-Based Computing. AgentLink III, 005. [16] P. McBurney and S. Parsons. A formal framework for inter-agent dialogues. In J. P. M¨uller, E. Andre, S. Sen, and C. Frasson, editors, Proceedings of the Fifth International Conference on Autonomous Agents, pages 178-179, Montreal, Canada, May 2001. ACM Press. [17] N. R. Mehta, N. Medvidovic, and S. Phadke. Towards a taxonomy of software connectors. In Proceedings of the 22nd International Conference on Software Engineering, pages 178-187. ACM Press, June 2000. [18] J. Pav´on and J. G´omez-Sanz. Agent oriented software engineering with ingenias. In V. Marik, J. Muller, and M. Pechoucek, editors, Proceedings of the 3rd International Central and Eastern European Conference on Multi-Agent Systems. Springer Verlag, 003. [19] B. C. Pierce. Types and Programming Languages. The MIT Press, Cambridge, MA, 2002. [20] J. Pitt, L. Kamara, M. Sergot, and A. Artikis. Voting in multi-agent systems. Feb. 27 2006. [21] G. Plotkin. A structural approach to operational semantics. Technical Report DAIMI FN-19, Aarhus University, Sept. 1981. [22] J. Searle. Speech Acts. Cambridge University Press, 969. [23] M. Sergot. A computational theory of normative positions. ACM Transactions on Computational Logic, (4):581-622, Oct. 2001. [24] M. P. Singh. Agent-based abstractions for software development. In F. Bergenti, M.-P. Gleizes, and F. Zambonelli, editors, Methodologies and Software Engineering for Agent Systems, chapter 1, pages 5-18. Kluwer, 2004. [25] S. Willmot and al. Agentcities / opennet testbed. http://x-opennet.net, 2004. [26] F. Zambonelli, N. R. Jennings, and M. Wooldridge. Developing multiagent systems: The Gaia methodology. ACM Transactions on Software Engineering and Methodology, 12(3):317-370, July 003. 96 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB. 2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are  assumed to have multiple goals of increasing priority, and  investigate the computational complexity and game theoretic properties of this model. In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a  multiagent system. A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system. We specify an agent"s goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy. Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative  system or not. We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the  complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory . INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1]. Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same  basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge. The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden  actions), the objective formula was guaranteed to be satisfied in the system [15]. However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not. This model of  normative systems was further extended by attributing to each agent a single goal in [16]. However, this model was still too  impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law. In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate. In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority. We specify an agent"s goals as a hierarchy of formulae of  Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy. Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our  Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not. We thus  provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4]. We then characterise the  computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a  normative system which has the property of being a Nash implementation is NP-complete. . KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for  multiagent systems [8]. A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 81 78-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 5] for related models which include actions as first class citizens). We let S0 denote the set of possible initial states of the system. Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents. It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action. This  assumption is not in fact essential for our analysis, but it greatly  simplifies the presentation. However, we find it convenient to include within our model the agents that cause transitions. We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.  Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state. Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state. In the interests of brevity, we shall hereafter refer to an  agentlabelled Kripke structure simply as a Kripke structure. A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on). A path π such that π[0] = s is an s-path. Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from  context, we often omit reference to R, and simply write Π(s). We will sometimes refer to and think of an s-path as a possible  computation, or system evolution, from s. EXAMPLE 1. Our running example is of a system with a single non-sharable resource, which is desired by two agents. Consider the Kripke structure depicted in Figure 1. We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are  In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here. It is also worth noting that for some domains, other constraints may be more appropriate than simple totality. For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition  available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. p t p    s   Figure 1: The resource control running example. mutually exclusive. Think of pi as meaning agent i has currently control over the resource. Each agent has two possible actions, when in possession of the resource: either give it away, or keep it. Obviously there are infinitely many different s-paths and t-paths. Let us say that our set of initial states S0 equals {s, t}, i.e., we don"t make any assumptions about who initially has control over the resource. .1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8]. Note that since CTL is well known and widely  documented in the literature, our presentation, though complete, will be somewhat terse. We will use CTL to express agents" goals. The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ. We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it. The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language. The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t. K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t. K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner. The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8]. We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 82 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) . NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1]. More precisely, a  normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not. Different normative systems may differ on whether or not a transition is legal. Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \ η is a total relation. The requirement that R\η is total is a  reasonableness constraint: it prevents normative systems which lead to states with no successor. Let N (R) = {η : (η ⊆ R) & (R \ η is total)} be the set of normative systems over R. The intended  interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \ η denotes the legal transitions of η. Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state. We denote the empty normative system by η∅, so η∅ = ∅. Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke  structure is to eliminate from it all transitions that are forbidden  according to this normative system (see [15, 1]). If K is a Kripke  structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η. Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise. Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t). A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever. Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}. Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system. In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the  normative system. Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η  except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \ C). Note that we have η C = η (A\C) and η C = η (A\C). EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}. Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. . GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agent"s strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system. We will model an agent"s goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold. The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the  hierarchy a goal is, the more it is desired by i. Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the  hierarchy. Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = . We use a natural number  indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on. We denote the largest index of any element in γ by |γ|. A particular Kripke structure K is said to satisfy a goal at  index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal  hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy. Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1]. The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level. Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies. EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself. Define each agent"s goal hierarchy as: γi = ( ϕi  = , ϕi  = E♦pi , ϕi  = E E♦pi , ϕi  = E♦E pi , ϕi  = A E♦pi , ϕi  = E♦A pi ϕi  = A A♦pi , ϕi  = A (A♦pi ∧ E pi ), ϕi  = A pi ) The most desired goal of agent i is to, in every computation,  always have the resource, pi (this is expressed in ϕi ). Thanks to our reasonableness constraint, this goal implies ϕi  which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds. Goal ϕi  is a fairness  constraint implied by it. Note that A♦pi says that every computation eventually reaches a pi state. This may mean that after pi has  happened, it will never happen again. ϕi  circumvents this: it says that, no matter where you are, there should be a future pi state. The goal ϕi  is like the strong goal ϕi  but it accepts that this is only achieved in some computation, eventually. ϕi  requires that in every path, there is always a continuation that eventually gives pi . Goal ϕi  says that pi should be true on some branch, from some moment on. It implies ϕi  which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi . This implies ϕi , which says that pi should at least not be impossible. If we even drop that demand, we have the trivial goal ϕi . We remark that it may seem more natural to express a fairness constraint ϕi  as A ♦pi . However, this is not a proper CTL  formula. It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent. However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like. Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]). We  comment on the implications of alternative goal representations at the conclusion of the next section. A multi-agent system collects together a Kripke structure  (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system. Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. .1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent. The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure. We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the  multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example. Recall that we have defined S0 as {s, t}. Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not. To see that ϕ2  = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true. Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥  CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . . Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale. The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j . Thus, it does not make sense to  compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate  individual utilities, such as social welfare), do not make sense when applied in this setting. However, as we shall see shortly, other  measures - such as Pareto efficiency - can be usefully applied. There are other representations for goals, which would allow us to define cardinal utilities. The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R. We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility. We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity. Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems. Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K). Then the utility of η to agent i wrt K is δi (K, K † η). We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative. Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke  structure. If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than  then the agent would be worse off if η were imposed than in the original system. We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is  individually rational for every agent. A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M . EXAMPLE 1. The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before. Recall that u1(K) = u2(K) = 4. .2 Universal and Existential Goals 84 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following  observation, borrowing from [15]. Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system. Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2. Note that typically K † η K. Then we have (cf. [15]). THEOREM 1. Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1. Let K be a structure, and η a normative  system. Let γi denote a goal hierarchy for agent i. . Suppose agent i"s utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula). Then, for any normative system η, δi (K, η) ≥ 0. . Suppose agent i"s utility ui (K † η) is n, and γi [n] is an existential formula ε. Then, δi (K † η, K) ≥ 0. Corollary 1"s first item says that an agent whose current  maximal goal in a system is a universal formula, need never fear the imposition of a new norm η. The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true). It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η. The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η. Hence, an agent with only existential goals might well fear any norm η. However, these observations implicitly assume that all agents in the system will comply with the norm. Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do. This motivates us to consider normative system games. . NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of  normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them. Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective). Our agent - let"s say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not? Note that this reasoning takes place before the agent is in the system - it is a design time consideration. We can understand the reasoning here as a game, as follows. A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between  alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents. Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn . Then we can associate a game - the  normative system game - GΣ with Σ, as follows. The agents AG in GΣ are as in Σ. Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system. If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ. Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ. We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ). So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0. In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η). We can now start to investigate some properties of normative system games. EXAMPLE 1. (continued) For our example system, we have  displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2. For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). The first term of this is the utility of 1 in the system K where we implement η3 for the  cooperating agent, i.e., 1, only. This means that the transitions are R \ {(s, s)}. In this system, still ϕ1  = A E♦p1 is the highest goal for agent 1. This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0. Agent 2 of course benefits if agent 1 complies with η3 while 2 does not. His utility would be 3, since η3 AGC C,D is in fact η1. .1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise. This is a necessary, although not sufficient condition on a norm to expect that everybody respects it. Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows. Let Σ = M , η be a social system. Then the following are equivalent: The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. . η is individually rational in M ; . ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ. The decision problem associated with individually rational  normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M . Question: Does there exist an individually rational  normative system for M ? THEOREM 2. IRNS is NP-complete, even in one-agent systems. PROOF. For membership of NP, guess a normative system η, and verify that it is individually rational. Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time. To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ. Hence verifying that ui (K † η) > ui (K) requires only polynomial time. For NP-hardness, we reduce SAT [12, p.77]. Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows. First, we define a single agent A = {1}. For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance. We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ. Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )). Next, consider the following  formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable. First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1]. For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by  considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all  variables xi , but (2) ensures that we cannot forbid arcs to both. So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true. The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ. For ⇐, note that for any satisfying valuation for ϕ we can  construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state. The resulting normative system ensures γ1[1], and is thus individually rational. Notice that the Kripke structure constructed in the reduction  contains just a single agent, and so the Theorem is proven. .2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7]. Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off. In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient. This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η. If η makes every agent better off than η, then we say η Pareto dominates η. The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M . Question: Is η Pareto efficient for M ? THEOREM 3. PENS is co-NP-complete, even for one-agent  systems. PROOF. Let M and η be as in the Theorem. We show that the complement problem to PENS, which we refer to as PARETO  DOMINATED, is NP-complete. In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η. For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking  problems, each of which takes polynomial time. Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time. For NP-hardness, we reduce IRNS, which we know to be  NPcomplete from Theorem 2. Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system. Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M . Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 86 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example? Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}. The utilities for each system are given in Table 1. From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7. Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi  is not true in K † η8). .3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14]. A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the  assumption that the other agents play theirs. Nash equilibria are important because they provide stable solutions to the problem of what  strategy an agent should play. Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash  equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2). In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ. The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no  benefit to deviating from it, indeed, there is a positive incentive for all to comply. If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in  implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.) NASH IMPLEMENTATION (NI) : Given: Multi-agent system M . Question: Does there exist a non-empty normative  system η over M such that M , η forms a Nash  implementation? Verifying that a particular social system forms a Nash  implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time. THEOREM 4. The NI problem is NP-complete, even for  twoagent systems. PROOF. For membership of NP, simply guess a normative  system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1)       1  1 1            t(x1) f(x1) t(x2) f(x2) t(xk) f(xk)   t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time. For NP-hardness, we reduce SAT. Suppose we are given a SAT  instance ϕ over Boolean variables x1, . . . , xk . Then we construct an instance of NI as follows. We create two agents, A = {1, 2}. For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in  Figure 4, with s0 being the only initial state; the arc labelling in  Figure 4 gives the α function, and each state is labelled with the  propositions that are true in that state. For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically  substituting xi for xi . Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the  following formulae: The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ. Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true. We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true. No other arcs, apart from those so defined, as included in η. Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system. To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D). For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅. Then ϕ is satisfiable; for suppose not. Then the goals γi [2] are not achievable by any normative system, (by construction). Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η. But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium. This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] .4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9]. The main difference is that  determining ui (K) in a given multi-agent system M when such a goal  language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]). In fact, it seems that for each of the three problems we consider above, the  corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete. It cannot be any easier, since  determining the utility of a particular Kripke structure involves  solving a PSPACE-complete problem. To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. . CONCLUSIONS Social norms are supposed to restrict our behaviour. Of course, such a restriction does not have to be bad: the fact that an agent"s behaviour is restricted may seem a limitation, but there may be  benefits if he can assume that others will also constrain their behaviour. The question then, for an agent is, how to be sure that others will comply with a norm. And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm. Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have  proposed a way to translate key questions concerning logic-based  normative systems to game theoretical questions. We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main  questions about them. Of course, our approach is in many senses open for extension or enrichment. An obvious issue is to consider is the complexity of the questions we give for more practical  representations of models (cf. [1]), and to consider other classes of allowable goals. . REFERENCES [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge. On the logic of normative systems. In Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman. Alternating-time temporal logic. Jnl. of the ACM, 9(5):672-713, 2002. [3] K. Binmore. Game Theory and the Social Contract Volume : Playing Fair. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Game Theory and the Social Contract Volume : Just Playing. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm. Complexity of mechanism design. In Proc. UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm. Complexity results about nash equilibria. In Proc. IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash equilibrium. In Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson. Temporal and modal logic. In Handbook of Theor. Comp. Sci. Vol. B, pages 996-1072. Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern. ‘Sometimes" and ‘not never" revisited: on branching time versus linear time temporal logic. Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz. Choosing social laws for multi-agent systems: Minimality and simplicity. Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein. A Course in Game Theory. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Computational Complexity. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz. On the synthesis of useful social laws for artificial agent societies. In Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz. On social laws for artificial agent societies: Off-line design. In Computational Theories of Interaction and Agency, pages 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. Social laws in alternating time: Effectiveness, feasibility, and synthesis. Synthese, 2007. [16] M. Wooldridge and W. van der Hoek. On obligations and normative ability. Jnl. of Appl. Logic, 3:396-420, 2005. 88 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
A Multilateral Multi-issue Negotiation Protocol Miniar Hemaissia THALES Research & Technology France RD 128 F-91767 Palaiseau Cedex, France miniar.hemaissia@lip6.fr Amal El Fallah Seghrouchni LIP6, University of Paris 6  rue du Capitaine Scott F-75015 Paris, France amal.elfallah@lip6.fr Christophe Labreuche and Juliette Mattioli THALES Research & Technology France RD 128 F-91767 Palaiseau Cedex, France ABSTRACT In this paper, we present a new protocol to address  multilateral multi-issue negotiation in a cooperative context. We consider complex dependencies between multiple issues by modelling the preferences of the agents with a multi-criteria decision aid tool, also enabling us to extract relevant  information on a proposal assessment. This information is used in the protocol to help in accelerating the search for a consensus between the cooperative agents. In addition, the negotiation procedure is defined in a crisis management context where the common objective of our agents is also considered in the preferences of a mediator agent. Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent agents, Multiagent systems General Terms Theory, Design, Experimentation . INTRODUCTION Multi-issue negotiation protocols represent an important field of study since negotiation problems in the real world are often complex ones involving multiple issues. To date, most of previous work in this area ([2, 3, 19, 13]) dealt  almost exclusively with simple negotiations involving  independent issues. However, real-world negotiation problems  involve complex dependencies between multiple issues. When one wants to buy a car, for example, the value of a given car is highly dependent on its price, consumption, comfort and so on. The addition of such interdependencies greatly complicates the agents utility functions and classical  utility functions, such as the weighted sum, are not sufficient to model this kind of preferences. In [10, 9, 17, 14, 20], the authors consider inter-dependencies between issues, most  often defined with boolean values, except for [9], while we can deal with continuous and discrete dependent issues thanks to the modelling power of the Choquet integral. In [17], the authors deal with bilateral negotiation while we are  interested in a multilateral negotiation setting. Klein et al. [10] present an approach similar to ours, using a mediator too and information about the strength of the approval or rejection that an agent makes during the negotiation. In our protocol, we use more precise information to improve the proposals thanks to the multi-criteria methodology and tools used to model the preferences of our agents. Lin, in [14, 0], also presents a mediation service but using an  evolutionary algorithm to reach optimal solutions and as explained in [4], players in the evolutionary models need to repeatedly interact with each other until the stable state is reached. As the population size increases, the time it takes for the population to stabilize also increases, resulting in excessive computation, communication, and time overheads that can become prohibitive, and for one-to-many and many-to-many negotiations, the overheads become higher as the number of players increases. In [9], the authors consider a non-linear utility function by using constraints on the domain of the issues and a mediation service to find a combination of bids maximizing the social welfare. Our preference model, a  nonlinear utility function too, is more complex than [9] one since the Choquet integral takes into account the interactions and the importance of each decision criteria/issue, not only the dependencies between the values of the issues, to determine the utility. We also use an iterative protocol enabling us to find a solution even when no bid combination is possible. In this paper, we propose a negotiation protocol suited for multiple agents with complex preferences and taking into  account, at the same time, multiple interdependent issues and recommendations made by the agents to improve a proposal. Moreover, the preferences of our agents are modelled using a multi-criteria methodology and tools enabling us to take into account information about the improvements that can be made to a proposal, in order to help in accelerating the search for a consensus between the agents. Therefore, we propose a negotiation protocol consisting of solving our  decision problem using a MAS with a multi-criteria decision aiding modelling at the agent level and a cooperation-based multilateral multi-issue negotiation protocol. This protocol is studied under a non-cooperative approach and it is shown 43 78-81-904262-7-5 (RPS) c 2007 IFAAMAS that it has subgame perfect equilibria, provided that agents behave rationally in the sense of von Neumann and  Morgenstern. The approach proposed in this paper has been first introduced and presented in [8]. In this paper, we present our first experiments, with some noteworthy results, and a more complex multi-agent system with representatives to enable us to have a more robust system. In Section 2, we present our application, a crisis  management problem. Section 3 deals with the general aspect of the proposed approach. The preference modelling is described in sect. 4, whereas the motivations of our protocol are  considered in sect. 5 and the agent/multiagent modelling in sect. 6. Section 7 presents the formal modelling and  properties of our protocol before presenting our first experiments in sect. 8. Finally, in Section 9, we conclude and present the future work. . CASE STUDY This protocol is applied to a crisis management problem. Crisis management is a relatively new field of management and is composed of three types of activities: crisis  prevention, operational preparedness and management of declared crisis. The crisis prevention aims to bring the risk of crisis to an acceptable level and, when possible, avoid that the  crisis actually happens. The operational preparedness includes strategic advanced planning, training and simulation to  ensure availability, rapid mobilisation and deployment of  resources to deal with possible emergencies. The management of declared crisis is the response to - including the  evacuation, search and rescue - and the recovery from the crisis by minimising the effects of the crises, limiting the impact on the community and environment and, on a longer term, by bringing the community"s systems back to normal. In this paper, we focus on the response part of the management of declared crisis activity, and particularly on the evacuation of the injured people in disaster situations. When a crisis is declared, the plans defined during the operational  preparedness activity are executed. For disasters, master plans are executed. These plans are elaborated by the authorities with the collaboration of civil protection agencies, police, health services, non-governmental organizations, etc. When a victim is found, several actions follow. First, a rescue party is assigned to the victim who is examined and is given first aid on the spot. Then, the victims can be placed in an emergency centre on the ground called the medical advanced post. For all victims, a sorter physician -  generally a hospital physician - examines the seriousness of their injuries and classifies the victims by pathology. The  evacuation by emergency health transport if necessary can take place after these clinical examinations and classifications. Nowadays, to evacuate the injured people, the physicians contact the emergency call centre to pass on the medical assessments of the most urgent cases. The emergency call centre then searches for available and appropriate spaces in the hospitals to care for these victims. The physicians are informed of the allocations, so they can proceed to the  evacuations choosing the emergency health transports according to the pathologies and the transport modes provided. In this context, we can observe that the evacuation is based on three important elements: the examination and  classification of the victims, the search for an allocation and the transport. In the case of the 11 March 2004 Madrid attacks, for instance, some injured people did not receive the  appropriate health care because, during the search for space, the emergency call centre did not consider the transport  constraints and, in particular, the traffic. Therefore, for a large scale crisis management problem, there is a need to support the emergency call centre and the physicians in the  dispatching to take into account the hospitals and the transport  constraints and availabilities. . PROPOSED APPROACH To accept a proposal, an agent has to consider several  issues such as, in the case of the crisis management problem, the availabilities in terms of number of beds by unit,  medical and surgical staffs, theatres and so on. Therefore, each agent has its own preferences in correlation with its resource constraints and other decision criteria such as, for the case study, the level of congestion of a hospital. All the agents also make decisions by taking into account the dependencies between these decision criteria. The first hypothesis of our approach is that there are  several parties involved in and impacted by the decision, and so they have to decide together according to their own  constraints and decision criteria. Negotiation is the process by which a group facing a conflict communicates with one  another to try and come to a mutually acceptable agreement or decision and so, the agents have to negotiate. The  conflict we have to resolve is finding an acceptable solution for all the parties by using a particular protocol. In our  context, multilateral negotiation is a negotiation protocol type that is the best suited for this type of problem : this type of protocol enables the hospitals and the physicians to  negotiate together. The negotiation also deals with multiple issues. Moreover, an other hypothesis is that we are in a cooperative context where all the parties have a common objective which is to provide the best possible solution for everyone. This implies the use of a negotiation protocol  encouraging the parties involved to cooperate as satisfying its preferences. Taking into account these aspects, a Multi-Agent System (MAS) seems to be a reliable method in the case of a  distributed decision making process. Indeed, a MAS is a suitable answer when the solution has to combine, at least,  distribution features and reasoning capabilities. Another motivation for using MAS lies in the fact that MAS is well known for facilitating automated negotiation at the operative decision making level in various applications. Therefore, our approach consists of solving a multiparty decision problem using a MAS with • The preferences of the agents are modelled using a multi-criteria decision aid tool, MYRIAD, also  enabling us to consider multi-issue problems by evaluating proposals on several criteria. • A cooperation-based multilateral and multi-issue  negotiation protocol. . THE PREFERENCE MODEL We consider a problem where an agent has several decision criteria, a set Nk = {1, . . . , nk} of criteria for each agent k involved in the negotiation protocol. These decision criteria enable the agents to evaluate the set of issues that are  negotiated. The issues correspond directly or not to the decision criteria. However, for the example of the crisis management 44 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) problem, the issues are the set of victims to dispatch  between the hospitals. These issues are translated to decision criteria enabling the hospital to evaluate its congestion and so to an updated number of available beds, medical teams and so on. In order to take into account the complexity that exists between the criteria/issues, we use a multi-criteria  decision aiding (MCDA) tool named MYRIAD [12] developed at Thales for MCDA applications based on a two-additive Choquet integral which is a good compromise between  versatility and ease to understand and model the interactions between decision criteria [6]. The set of the attributes of Nk is denoted by Xk  , . . . , Xk nk . All the attributes are made commensurate thanks to the  introduction of partial utility functions uk i : Xk i → [0, 1]. The [0, 1] scale depicts the satisfaction of the agent k regarding the values of the attributes. An option x is identified to an element of Xk = Xk  × · · · × Xk nk , with x = (x1, . . . , xnk ). Then the overall assessment of x is given by Uk(x) = Hk(uk  (x1), . . . , uh nk (xnk )) (1) where Hk : [0, 1]nk → [0, 1] is the aggregation function. The overall preference relation over Xk is then x y ⇐⇒ Uk(x) ≥ Uk(y) . The two-additive Choquet integral is defined for (z1, . . . , znk ) ∈ [0, 1]nk by [7] Hk(z1, . . . , znk ) = X i∈Nk  @vk i −   X j=i |Ik i,j|  A zi + X Ik i,j >0 Ik i,j zi ∧ zj + X Ii,j <0 |Ii,j| zi ∨ zj (2) where vk i is the relative importance of criterion i for agent k and Ik i,j is the interaction between criteria i and j, ∧ and ∨ denote the min and max functions respectively. Assume that zi < zj. A positive interaction between criteria i and j depicts complementarity between these criteria (positive synergy) [7]. Hence, the lower score of z on criterion i  conceals the positive effect of the better score on criterion j to a larger extent on the overall evaluation than the impact of the relative importance of the criteria taken independently of the other ones. In other words, the score of z on criterion j is penalized by the lower score on criterion i. Conversely, a negative interaction between criteria i and j depicts  substitutability between these criteria (negative synergy) [7]. The score of z on criterion i is then saved by a better score on criterion j. In MYRIAD, we can also obtain some recommendations corresponding to an indicator ωC (H, x) measuring the worth to improve option x w.r.t. Hk on some criteria C ⊆ Nk as follows ωC (Hk, x)= Z 1  Hk ` (1 − τ)xC + τ, xNk\C ´ − Hk(x) EC (τ, x) dτ where ((1−τ)xC +τ, xNk\C ) is the compound act that equals (1 − τ)xi + τ if i ∈ C and equals xi if i ∈ Nk \ C. Moreover, EC (τ, x) is the effort to go from the profile x to the profile ((1 − τ)xC + τ, xNk\C ). Function ωC (Hk, x) depicts the  average improvement of Hk when the criteria of coalition A range from xC to 1C divided by the average effort needed for this improvement. We generally assume that EC is of order 1, that is EC (τ, x) = τ P i∈C (1 − xi). The expression of ωC (Hk, x) when Hk is a Choquet integral, is given in [11]. The agent is then recommended to improve of coalition C for which ωC (Hk, x) is maximum. This recommendation is very useful in a negotiation protocol since it helps the agents to know what to do if they want an offer to be accepted while not revealing their own preference model. . PROTOCOL MOTIVATIONS For multi-issue problems, there are two approaches: a complete package approach where the issues are  negotiated simultaneously in opposition to the sequential approach where the issues are negotiated one by one. When the issues are dependant, then it is the best choice to bargain  simultaneously over all issues [5]. Thus, the complete package is the adopted approach so that an offer will be on the  overall set of injured people while taking into account the other decision criteria. We have to consider that all the parties of the  negotiation process have to agree on the decision since they are all involved in and impacted by this decision and so an  unanimous agreement is required in the protocol. In addition, no party can leave the process until an agreement is reached, i.e. a consensus achieved. This makes sense since a proposal concerns all the parties. Moreover, we have to guarantee the availability of the resources needed by the parties to ensure that a proposal is realistic. To this end, the information about these availabilities are used to determine admissible proposals such that an offer cannot be made if one of the  parties has not enough resources to execute/achieve it. At the beginning of the negotiation, each party provides its  maximum availabilities, this defining the constraints that have to be satisfied for each offer submitted. The negotiation has also to converge quickly on an  unanimous agreement. We decided to introduce in the negotiation protocol an incentive to cooperate taking into account the passed negotiation time. This incentive is defined on the basis of a time dependent penalty, the discounting factor as in [18] or a time-dependent threshold. This penalty has to be used in the accept/reject stage of our consensus  procedure. In fact, in the case of a discounting factor, each party will accept or reject an offer by evaluating the proposal  using its utility function deducted from the discounting factor. In the case of a time-dependent threshold, if the evaluation is greater or equal to this threshold, the offer is accepted, otherwise, in the next period, its threshold is reduced. The use of a penalty is not enough alone since it does not help in finding a solution. Some information about the assessments of the parties involved in the negotiation are needed. In particular, it would be helpful to know why an offer has been rejected and/or what can be done to make a proposal that would be accepted. MYRIAD provides an analysis that determines the flaws an option, here a  proposal. In particular, it gives this type of information: which criteria of a proposal should be improved so as to reach the highest possible overall evaluation [11]. As we use this tool to model the parties involved in the negotiation, the  information about the criteria to improve can be used by the mediator to elaborate the proposals. We also consider that the dual function can be used to take into account another type of information: on which criteria of a proposal, no  improvement is necessary so that the overall evaluation of a proposal is still acceptable, do not decrease. Thus, all  information is a constraint to be satisfied as much as possible by The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 945 Figure 1: An illustration of some system. the parties to make a new proposal. We are in a cooperative context and revealing one"s  opinion on what can be improved is not prohibited, on the  contrary, it is useful and recommended here seeing that it helps in converging on an agreement. Therefore, when one of the parties refuses an offer, some information will be  communicated. In order to facilitate and speed up the negotiation, we introduce a mediator. This specific entity is in charge of making the proposals to the other parties in the system by taking into account their public constraints (e.g. their availabilities) and the recommendations they make. This mediator can also be considered as the representative of the general interest we can have, in some applications, such as in the crisis management problem, the physician will be the mediator and will also have some more information to consider when making an offer (e.g. traffic state, transport mode and time). Each party in a negotiation N, a  negotiator, can also be a mediator of another negotiation N , this party becoming the representative of N in the negotiation N, as illustrated by fig. 1 what can also help in reducing the communication time. . AGENTIFICATION How the problem is transposed in a MAS problem is a very important aspect when designing such a system. The agentification has an influence upon the systems efficiency in solving the problem. Therefore, in this section, we describe the elements and constraints taken into account during the modelling phase and for the model itself. However, for this negotiation application, the modelling is quite natural when one observes the negotiation protocol motivations and main properties. First of all, it seems obvious that there should be one agent for each player of our multilateral multi-issue negotiation protocol. The agents have the involved parties" information and preferences. These agents are: • Autonomous: they decide for themselves what, when and under what conditions actions should be  performed; • Rational: they have a means-ends competence to fit its decisions, according to its knowledge, preferences and goal; • Self-interested: they have their own interests which may conflict with the interests of other agents. Moreover, their preferences are modelled and a proposal evaluated and analysed using MYRIAD. Each agent has private information and can access public information as knowledge. In fact, there are two types of agents: the mediator type for the agents corresponding to the mediator of our  negotiation protocol, the delegated physician in our application, and the negotiator type for the agents corresponding to the other parties, the hospitals. The main behaviours that an agent of type mediator needs to negotiate in our protocol are the following: • convert_improvements: converts the information  given by the other agents involved in the negotiation about the improvements to be done, into constraints on the next proposal to be made; • convert_no_decrease: converts the information given by the other agents involved in the negotiation about the points that should not be changed into constraints on the next proposal to be made; • construct_proposal: constructs a new proposal  according to the constraints obtained with  convert_improvements, convert_no_decrease and the agent  preferences; The main behaviours that an agent of type negotiator needs to negotiate in our protocol are the following: • convert_proposal: converts a proposal to a MYRIAD option of the agent according to its preferences model and its private data; • convert_improvements_wc: converts the agent  recommendations for the improvements of a MYRIAD  option into general information on the proposal; • convert_no_decrease_wc: converts the agent  recommendations about the criteria that should not be  changed in the MYRIAD option into general information on the proposal; In addition to these behaviours, there are, for the two types of agents, access behaviours to MYRIAD functionalities such as the evaluation and improvement functions: • evaluate_option: evaluates the MYRIAD option  obtained using the agent behaviour convert_proposal; • improvements: gets the agent recommendations to  improve a proposal from the MYRIAD option; • no_decrease: gets the agent recommendations to not change some criteria from the MYRIAD option; Of course, before running the system with such agents, we must have defined each party preferences model in  MYRIAD. This model has to be part of the agent so that it could be used to make the assessments and to retrieve the  improvements. In addition to these behaviours, the communication acts between the agents is as follows. . mediator agent communication acts: 46 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) m1 m   m inform1 m mediator negotiator accept−proposal l  accept−proposal m−l reject−proposal propose propose Figure 2: The protocol diagram in AUML, and where m is the number of negotiator agents and l is the number of agents refusing current proposal. (a) propose: sends a message containing a proposal to all negotiator agents; (b) inform: sends a message to all negotiator agents to inform them that an agreement has been  reached and containing the consensus outcome. . negotiator agent communication acts: (a) accept-proposal: sends a message to the  mediator agent containing the agent recommendations to improve the proposal and obtained with convert_improvements_wc; (b) reject-proposal: sends a message to the  mediator agent containing the agent recommendations about the criteria that should not be changed and obtained with convert_no_decrease_wc. Such agents are interchangeable, in a case of failure, since they all have the same properties and represent a user with his preference model, not depending on the agent, but on the model defined in MYRIAD. When the issues and the  decision criteria are different from each other, the information about the criteria improvement have to be pre-processed to give some instructions on the directions to take and about the negotiated issues. It is the same for the evaluation of a proposal: each agent has to convert the information about the issues to update its private information and to obtain the values of each attribute of the decision criteria. . OUR PROTOCOL Formally, we consider negotiations where a set of  players A = {1, 2, . . . , m} and a player a are negotiating over a set Q of size q. The player a is the protocol  mediator, the mediator agent of the agentification. The  utility/preference function of a player k ∈ A ∪ {a} is Uk,  defined using MYRIAD, as presented in Section 4, with a set Nk of criteria, Xk an option, and so on. An offer is a  vector P = (P1, P2, · · · , Pm), a partition of Q, in which Pk is player k"s share of Q. We have P ∈ P where P is the set of admissible proposals, a finite set. Note that P is determined using all players general constraints on the proposals and Q. Moreover, let ˜P denote a particular proposal defined as a"s preferred proposal. We also have the following notation: δk is the  threshold decrease factor of player k, Φk : Pk → Xk is player k"s function to convert a proposal to an option and Ψk is the function indicating which points P has to be improved, with Ψk its dual function - on which points no  improvement is necessary. Ψk is obtained using the dual function of ωC (Hk, x): eωC (Hk, x)= Z 1  Hk(x) − Hk ` τ xC , xNk\C ´ eEC (τ, x) dτ Where eEC (τ, x) is the cost/effort to go from (τxC , xNk\C ) to x. In period t of our consensus procedure, player a proposes an agreement P. All players k ∈ A respond to a by  accepting or rejecting P. The responses are made simultaneously. If all players k ∈ A accept the offer, the game ends. If any player k rejects P, then the next period t+1 begins: player a makes another proposal P by taking into account  information provided by the players and the ones that have rejected P apply a penalty. Therefore, our negotiation protocol can be as follows: Protocol P1. • At the beginning, we set period t = 0 • a makes a proposal P ∈ P that has not been proposed before. • Wait that all players of A give their opinion Yes or No to the player a. If all players agree on P, this later is chosen. Otherwise t is incremented and we go back to previous point. • If there is no more offer left from P, the default offer ˜P will be chosen. • The utility of players regarding a given  offer decreases over time. More precisely, the utility of player k ∈ A at period t regarding offer P is Uk(Φk(Pk), t) = ft(Uk(Φk(Pk))), where one can take for instance ft(x) = x.(δk)t or ft(x) = x − δk.t, as penalty  function. Lemma 1. Protocol P1 has at least one subgame perfect equilibrium 1 . Proof : Protocol P1 is first transformed in a game in  extensive form. To this end, one shall specify the order in which the responders A react to the offer P of a. However the order in which the players answer has no influence on the course of the game and in particular on their personal  utility. Hence protocol P1 is strictly equivalent to a game in  A subgame perfect equilibrium is an equilibrium such that players" strategies constitute a Nash equilibrium in every subgame of the original game [18, 16]. A Nash equilibrium is a set of strategies, one for each player, such that no player has incentive to unilaterally change his/her action [15]. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 947 extensive form, considering any order of the players A. This game is clearly finite since P is finite and each offer can only be proposed once. Finally P1 corresponds to a game with perfect information. We end the proof by using a  classical result stating that any finite game in extensive form with perfect information has at least one subgame perfect equilibrium (see e.g. [16]). Rational players (in the sense of von Neumann and  Morgenstern) involved in protocol P1 will necessarily come up with a subgame perfect equilibrium. Example 1. Consider an example with A = {1, 2} and P = {P1 , P2 , P3 } where the default offer is P1 . Assume that ft(x) = x − 0.1 t. Consider the following table giving the utilities at t = 0. P1 P2 P3 a 1 0.8 0.7  0.1 0.7 0.5  0.1 0.3 0.8 It is easy to see that there is one single subgame perfect  equilibrium for protocol P1 corresponding to these values. This equilibrium consists of the following choices: first a proposes P3 ; player 1 rejects this offer; a proposes then P2 and both players 1 and 2 accepts otherwise they are threatened to  receive the worse offer P1 for them. Finally offer P2 is  chosen. Option P1 is the best one for a but the two other players vetoed it. It is interesting to point out that, even though a prefers P2 to P3 , offer P3 is first proposed and this make P2 being accepted. If a proposes P2 first, then the subgame perfect equilibrium in this situation is P3 . To sum up, the worse preferred options have to be proposed first in order to get finally the best one. But this entails a waste of time. Analysing the previous example, one sees that the game outcome at the equilibrium is P2 that is not very attractive for player 2. Option P3 seems more balanced since no player judges it badly. It could be seen as a better solution as a consensus among the agents. In order to introduce this notion of balanceness in the protocol, we introduce a condition under which a player will be obliged to accept the proposal, reducing the autonomy of the agents but for increasing rationality and cooperation. More precisely if the utility of a player is larger than a given threshold then acceptance is required. The threshold  decreases over time so that players have to make more and more concession. Therefore, the protocol becomes as  follows. Protocol P2. • At the beginning we set period t = 0 • a makes a proposal P ∈ P that has not been proposed before. • Wait that all players of A give their opinion Yes or No to the player a. A player k must accept the offer if Uk(Φk(Pk)) ≥ ρk(t) where ρk(t) tends to zero when t grows.  Moreover there exists T such that for all t ≥ T, ρk(t) = 0. If all players agree on P, this later is chosen. Otherwise t is incremented and we go back to previous point. • If there is no more offer left from P, the default offer ˜P will be chosen. One can show exactly as in Lemma 1 that protocol P2 has at least one subgame perfect equilibrium. We expect that protocol P2 provides a solution not to far from P , so it favours fairness among the players. Therefore, our cooperation-based multilateral multi-issue protocol is the following: Protocol P. • At the beginning we set period t = 0 • a makes a proposal P ∈ P that has not been proposed before, considering Ψk(Pt ) and Ψk(Pt ) for all players k ∈ A. • Wait that all players of A give their opinion (Yes , Ψk(Pt )) or (No , Ψk(Pt )) to the player a. A player k must accept the offer if Uk(Φk(Pk)) ≥ ρk(t) where ρk(t) tends to zero when t grows. Moreover there exists T such that for all t ≥ T, ρk(t) = 0. If all players agree on P, this later is chosen. Otherwise t is incremented and we go back to previous point. • If there is no more offer left from P, the default offer ˜P will be chosen. . EXPERIMENTS We developed a MAS using the widely used JADE agent platform [1]. This MAS is designed to be as general as  possible (e.g. a general framework to specialise according to the application) and enable us to make some preliminary  experiments. The experiments aim at verifying that our approach gives solutions as close as possible to the Maximin solution and in a small number of rounds and hopefully in a short time since our context is highly cooperative. We defined the two types of agents and their behaviours as introduced in section 6. The agents and their behaviours correspond to the main classes of our prototype, NegotiatorAgent and NegotiatorBehaviour for the negotiator agents, and MediatorAgent and MediatorBehaviour for the mediator agent. These classes extend JADE classes and integrate MYRIAD into the agents, reducing the amount of  communications in the system. Some functionalities depending on the application have to be implemented according to the  application by extending these classes. In particular, all  conversion parts of the agents have to be specified according to the application since to convert a proposal into decision  criteria, we need to know, first, this model and the correlations between the proposals and this model. First, to illustrate our protocol, we present a simple  example of our dispatch problem. In this example, we have three hospitals, H1, H2 and H3. Each hospital can receive victims having a particular pathology in such a way that H1 can receive patients with the pathology burn, surgery or orthopedic, H2 can receive patients with the pathology surgery, orthopedic or cardiology and H3 can receive  patients with the pathology burn or cardiology. All the  hospitals have similar decision criteria reflecting their preferences on the level of congestion they can face for the overall  hospital and the different services available, as briefly explained for hospital H1 hereafter. For hospital H1, the preference model, fig. 3, is composed of five criteria. These criteria correspond to the preferences on the pathologies the hospital can treat. In the case of 48 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: The H1 preference model in MYRIAD. the pathology burn, the corresponding criterion, also named burn as shown in fig. 3, represents the preferences of H1  according to the value of Cburn which is the current capacity of burn. Therefore, the utility function of this criterion  represents a preference such that the more there are patients of this pathology in the hospital, the less the hospital may  satisfy them, and this with an initial capacity. In addition to reflecting this kind of viewpoint, the aggregation function as defined in MYRIAD introduces a veto on the criteria burn, surgery, orthopedic and EReceipt, where EReceipt is the criterion for the preferences about the capacity to receive a number of patients at the same time. In this simplified example, the physician have no  particular preferences on the dispatch and the mediator agent chooses a proposal randomly in a subset of the set of  admissibility. This subset have to satisfy as much as possible the recommendations made by the hospitals. To solve this  problem, for this example, we decided to solve a linear problem with the availability constraints and the recommendations as linear constraints on the dispatch values. The set of  admissibility is then obtained by solving this linear problem by the use of Prolog. Moreover, only the recommendations on how to improve a proposal are taken into account. The problem to solve is then to dispatch to hospital H1, H2 and H3, the set of victims composed of 5 victims with the  pathology burn, 10 with surgery, 3 with orthopedic and 7 with cardiology. The availabilities of the hospitals are as  presented in the following table. Available Overall burn surg. orthop. cardio. H1 11 4 8  0H2 25 - 3 4 10 H3 7 10 - - 3 We obtain a multiagent system with the mediator agent and three agents of type negotiator for the three hospital in the problem. The hospitals threshold are fixed  approximatively to the level where an evaluation is considered as good. To start, the negotiator agents send their  availabilities. The mediator agent makes a proposal chosen randomly in admissible set obtained with these availabilities as  linear constraints. This proposal is the vector P0 = [[H1,burn, ], [H1, surgery, 8], [H1, orthopaedic, 0], [H2, surgery, 2], [H2, orthopaedic, 3], [H2, cardiology, 6], [H3, burn, 2], [H3, cardiology, 1]] and the mediator sends propose(P0) to H1, H2 and H3 for approval. Each negotiator agent evaluates this proposal and answers back by accepting or rejecting P0: • Agent H1 rejects this offer since its evaluation is very far from the threshold (0.29, a bad score) and gives a recommendation to improve burn and surgery by sending the message  reject_proposal([burn,surgery]); • Agent H2 accepts this offer by sending the message accept_proposal(), the proposal evaluation being  good; • Agent H3 accepts P0 by sending the message accept_ proposal(), the proposal evaluation being good. Just with the recommendations provided by agent H1, the mediator is able to make a new proposal by restricting the value of burn and surgery. The new proposal obtained is then P1 = [[H1,burn, 0], [H1, surgery, 8], [H1, orthopaedic, ], [H2, surgery, 2], [H2, orthopaedic, 2], [H2, cardiology, ], [H3, burn, 5], [H3, cardiology, 1]]. The mediator sends propose(P1) the negotiator agents. H1, H2 and H3 answer back by sending the message accept_proposal(), P1 being evaluated with a high enough score to be acceptable, and also considered as a good proposal when using the  explanation function of MYRIAD. An agreement is reached with P1. Note that the evaluation of P1 by H3 has decreased in comparison with P0, but not enough to be rejected and that this solution is the Pareto one, P∗ . Other examples have been tested with the same settings: issues in IN, three negotiator agents and the same mediator agent, with no preference model but selecting randomly the proposal. We obtained solutions either equal or close to the Maximin solution, the distance from the standard deviation being less than 0.0829, the evaluations not far from the ones obtained with P∗ and with less than seven proposals made. This shows us that we are able to solve this multi-issue  multilateral negotiation problem in a simple and efficient way, with solutions close to the Pareto solution. . CONCLUSION AND FUTURE WORK This paper presents a new protocol to address  multilateral multi-issue negotiation in a cooperative context. The first main contribution is that we take into account complex inter-dependencies between multiple issues with the use of a complex preference modelling. This contribution is  reinforced by the use of multi-issue negotiation in a multilateral context. Our second contribution is the use of sharp  recommendations in the protocol to help in accelerating the search of a consensus between the cooperative agents and in finding an optimal solution. We have also shown that the protocol has subgame perfect equilibria and these equilibria converge to the usual maximum solution. Moreover, we tested this protocol in a crisis management context where the  negotiation aim is where to evacuate a whole set of injured people to predefined hospitals. We have already developed a first MAS, in particular  integrating MYRIAD, to test this protocol in order to know more about its efficiency in terms of solution quality and quickness in finding a consensus. This prototype enabled us to solve some examples with our approach and the  results we obtained are encouraging since we obtained quickly good agreements, close to the Pareto solution, in the light of the initial constraints of the problem: the availabilities. We still have to improve our MAS by taking into account The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 949 the two types of recommendations and by adding a  preference model to the mediator of our system. Moreover, a comparative study has to be done in order to evaluate the performance of our framework against the existing ones and against some variations on the protocol. 0. ACKNOWLEDGEMENT This work is partly funded by the ICIS research project under the Dutch BSIK Program (BSIK 03024). 1. REFERENCES [1] JADE. http://jade.tilab.com/. [2] P. Faratin, C. Sierra, and N. R. Jennings. Using similarity criteria to make issue trade-offs in automated negotiations. Artificial Intelligence, 42(2):205-237, 2003. [3] S. S. Fatima, M. Wooldridge, and N. R. Jennings. Optimal negotiation of multiple issues in incomplete information settings. In 3rd International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS"04), pages 1080-1087, New York, USA, 2004. [4] S. S. Fatima, M. Wooldridge, and N. R. Jennings. A comparative study of game theoretic and evolutionary models of bargaining for software agents. Artificial Intelligence Review, 23:185-203, 2005. [5] S. S. Fatima, M. Wooldridge, and N. R. Jennings. On efficient procedures for multi-issue negotiation. In 8th International Workshop on Agent-Mediated Electronic Commerce(AMEC"06), pages 71-84, Hakodate, Japan, 006. [6] M. Grabisch. The application of fuzzy integrals in multicriteria decision making. European J. of Operational Research, 89:445-456, 1996. [7] M. Grabisch, T. Murofushi, and M. Sugeno. Fuzzy Measures and Integrals. Theory and Applications (edited volume). Studies in Fuzziness. Physica Verlag, 000. [8] M. Hemaissia, A. El Fallah-Seghrouchni, C. Labreuche, and J. Mattioli. Cooperation-based multilateral multi-issue negotiation for crisis management. In 2th International Workshop on Rational, Robust and Secure Negotiation (RRS"06), pages 77-95, Hakodate, Japan, May 2006. [9] T. Ito, M. Klein, and H. Hattori. A negotiation protocol for agents with nonlinear utility functions. In AAAI, 2006. [10] M. Klein, P. Faratin, H. Sayama, and Y. Bar-Yam. Negotiating complex contracts. Group Decision and Negotiation, 12:111-125, March 2003. [11] C. Labreuche. Determination of the criteria to be improved first in order to improve as much as possible the overall evaluation. In IPMU 2004, pages 609-616, Perugia, Italy, 2004. [12] C. Labreuche and F. Le Hu´ed´e. MYRIAD: a tool suite for MCDA. In EUSFLAT"05, pages 204-209, Barcelona, Spain, 2005. [13] R. Y. K. Lau. Towards genetically optimised multi-agent multi-issue negotiations. In Proceedings of the 38th Annual Hawaii International Conference on System Sciences (HICSS"05), Big Island, Hawaii, 2005. [14] R. J. Lin. Bilateral multi-issue contract negotiation for task redistribution using a mediation service. In Agent Mediated Electronic Commerce VI (AMEC"04), New York, USA, 2004. [15] J. F. Nash. Non cooperative games. Annals of Mathematics, 54:286-295, 1951. [16] G. Owen. Game Theory. Academic Press, New York, 995. [17] V. Robu, D. J. A. Somefun, and J. A. L. Poutr´e. Modeling complex multi-issue negotiations using utility graphs. In 4th International Joint Conference on Autonomous agents and multiagent systems (AAMAS"05), pages 280-287, 2005. [18] A. Rubinstein. Perfect equilibrium in a bargaining model. Econometrica, 50:97-109, jan 1982. [19] L.-K. Soh and X. Li. Adaptive, confidence-based multiagent negotiation strategy. In 3rd International Joint Conference on Autonomous agents and multiagent systems (AAMAS"04), pages 1048-1055, Los Alamitos, CA, USA, 2004. [20] H.-W. Tung and R. J. Lin. Automated contract negotiation using a mediation service. In 7th IEEE International Conference on E-Commerce Technology (CEC"05), pages 374-377, Munich, Germany, 2005. 50 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Agents, Beliefs, and Plausible Behavior in a Temporal Setting Nils Bulling and Wojciech Jamroga Department of Informatics, Clausthal University of Technology, Germany {bulling,wjamroga}@in.tu-clausthal.de ABSTRACT Logics of knowledge and belief are often too static and  inflexible to be used on real-world problems. In particular, they usually offer no concept for expressing that some course of events is more likely to happen than another. We address this problem and extend CTLK (computation tree logic with knowledge) with a notion of plausibility, which allows for practical and counterfactual reasoning. The new logic CTLKP (CTLK with plausibility) includes also a  particular notion of belief. A plausibility update operator is added to this logic in order to change plausibility assumptions  dynamically. Furthermore, we examine some important  properties of these concepts. In particular, we show that, for a natural class of models, belief is a KD45 modality. We also show that model checking CTLKP is PTIME-complete and can be done in time linear with respect to the size of models and formulae. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial  Intelligence-Multiagent Systems; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-Modal logic General Terms Theory . INTRODUCTION Notions like time, knowledge, and beliefs are very  important for analyzing the behavior of agents and multi-agent systems. In this paper, we extend modal logics of time and knowledge with a concept of plausible behavior: this notion is added to the language of CTLK [19], which is a  straightforward combination of the branching-time temporal logic CTL [4, 3] and standard epistemic logic [9, 5]. In our approach, plausibility can be seen as a temporal property of behaviors. That is, some behaviors of the  system can be assumed plausible and others implausible, with the underlying idea that the latter should perhaps be  ignored in practical reasoning about possible future courses of action. Moreover, behaviors can be formally understood as temporal paths in the Kripke structure modeling a  multiagent system. As a consequence, we obtain a language to reason about what can (or must) plausibly happen. We propose a particular notion of beliefs (inspired by [20, 7]), defined in terms of epistemic relations and plausibility. The main intuition is that beliefs are facts that an agent would know if he assumed that only plausible things could happen. We believe that humans use such a concept of plausibility and practical beliefs quite often in their everyday  reasoning. Restricting one"s reasoning to plausible possibilities is essential to make the reasoning feasible, as the space of all possibilities is exceedingly large in real life. We investigate some important properties of plausibility, knowledge, and belief in this new framework. In particular, we show that knowledge is an S5 modality, and that beliefs satisfy  axioms K45 in general, and KD45 for the class of plausibly serial models. Finally, we show that the relationship  between knowledge and belief for plausibly serial models is natural and reflects the initial intuition well. We also show how plausibility assumptions can be specified in the object language via a plausibility update operator, and we study properties of such updates. Finally, we show that model checking of the new logic is no more complex than model checking CTL and CTLK. Our ultimate goal is to come up with a logic that  allows the study of strategies, time, knowledge, and  plausible/rational behavior under both perfect and imperfect  information. As combining all these dimensions is highly  nontrivial (cf. [12, 14]) it seems reasonable to split this task. While this paper deals with knowledge, plausibility, and  belief, the companion paper [11] proposes a general framework for multi-agent systems that regard game-theoretical  rationality criteria like Nash equilibrium, Pareto optimality, etc. The latter approach is based on the more powerful logic ATL [1]. The paper is structured as follows. Firstly, we briefly present branching-time logic with knowledge, CTLK. In Section 3 we present our approach to plausibility and  formally define CTLK with plausibility. We also show how 82 78-81-904262-7-5 (RPS) c 2007 IFAAMAS temporal formulae can be used to describe plausible paths, and we compare our logic with existing related work. In  Section 4, properties of knowledge, belief, and plausibility are explored. Finally, we present verification complexity results for CTLKP in Section 5. . BRANCHING TIME AND KNOWLEDGE In this paper we develop a framework for agents" beliefs about how the world can (or must) evolve. Thus, we need a notion of time and change, plus a notion of what the agents are supposed to know in particular situations. CTLK [19] is a straightforward combination of the computation tree logic CTL [4, 3] and standard epistemic logic [9, 5]. CTL includes operators for temporal properties of  systems: i.e., path quantifier E (there is a path), together with temporal operators: f(in the next state), 2  (always from now on) and U (until).1 Every occurrence of a temporal operator is preceded by exactly one path  quantifier in CTL (this variant of the language is sometimes called vanilla CTL). Epistemic logic uses operators for  representing agents" knowledge: Kaϕ is read as agent a knows that ϕ. Let Π be a set of atomic propositions with a typical  element p, and Agt = {1, ..., k} be a set of agents with a typical element a. The language of CTLK consists of formulae ϕ, given as follows: ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | Eγ | Kaϕ γ ::= fϕ | 2 ϕ | ϕU ϕ. We will sometimes refer to formulae ϕ as (vanilla) state formulae and to formulae γ as (vanilla) path formulae. The semantics of CTLK is based on Kripke models M = Q, R, ∼1, ..., ∼k, π , which include a nonempty set of states Q, a state transition relation R ⊆ Q × Q, epistemic  indistinguishability relations ∼a⊆ Q × Q (one per agent), and a valuation of propositions π : Π → P(Q). We assume that relation R is serial and that all ∼a are equivalence relations. A path λ in M refers to a possible behavior (or  computation) of system M, and can be represented as an infinite sequence of states that follow relation R, that is, a sequence q0q1q2... such that qiRqi+1 for every i = 0, 1, 2, ... We  denote the ith state in λ by λ[i]. The set of all paths in M is denoted by ΛM (if the model is clear from context, M will be omitted). A q-path is a path that starts from q, i.e., λ[0] = q. A q-subpath is a sequence of states, starting from q, which is a subpath of some path in the model, i.e. a sequence q0q1... such that q = q0 and there are q0 , ..., qi such that q0 ...qi q0q1... ∈ ΛM.2 The semantics of CTLK is defined as follows: M, q |= p iff q ∈ π(p); M, q |= ¬ϕ iff M, q |= ϕ; M, q |= ϕ ∧ ψ iff M, q |= ϕ and M, q |= ψ; M, q |= E fϕ iff there is a q-path λ such that M, λ[1] |= ϕ; M, q |= E2 ϕ iff there is a q-path λ such that M, λ[i] |= ϕ for every i ≥ 0;  Additional operators A (for every path) and ♦  (sometime in the future) are defined in the usual way.  For CTLK models, λ is a q-subpath iff it is a q-path. It will not always be so when plausible paths are introduced. M, q |= EϕU ψ iff there is a q-path λ and i ≥ 0 such that M, λ[i] |= ψ, and M, λ[j] |= ϕ for every 0 ≤ j < i; M, q |= Kaϕ iff M, q |= ϕ for every q such that q ∼a q . . EXTENDING TIME AND KNOWLEDGE WITH PLAUSIBILITY AND BELIEFS In this section we discuss the central concept of this  paper, i.e. the concept of plausibility. First, we outline the idea informally. Then, we extend CTLK with the notion of plausibility by adding plausible path operators Pl a and physical path operator Ph to the logic. Formula Pl aϕ has the intended meaning: according to agent a, it is plausible that ϕ holds; formula Ph ϕ reads as: ϕ holds in all  physically possible scenarios (i.e., even in implausible ones). The plausible path operator restricts statements only to those paths which are defined to be sensible, whereas the  physical path operator generates statements about all paths that may theoretically occur. Furthermore, we define beliefs on top of plausibility and knowledge, as the facts that an agent would know if he assumed that only plausible things could happen. Finally, we discuss related work [7, 8, 20, 18, 16], and compare it with our approach. .1 The Concept of Plausibility It is well known how knowledge (or beliefs) can be  modeled with Kripke structures. However, it is not so obvious how we can capture knowledge and beliefs in a sensible way in one framework. Clearly, there should be a connection between these two notions. Our approach is to use the  notion of plausibility for this purpose. Plausibility can serve as a primitive concept that helps to define the semantics of beliefs, in a similar way as indistinguishability of states (represented by relation ∼a) is the semantic concept that underlies knowledge. In this sense, our work follows [7, 20]: essentially, beliefs are what an agent would know if he took only plausible options into account. In our approach,  however, plausibility is explicitly seen as a temporal property. That is, we do not consider states (or possible worlds) to be more plausible than others but rather define some behaviors to be plausible, and others implausible. Moreover,  behaviors can be formally understood as temporal paths in the Kripke structure modeling a multi-agent system. An actual notion of plausibility (that is, a particular set of plausible paths) can emerge in many different ways. It may result from observations and learning; an agent can learn from its observations and see specific patterns of events as plausible (a lot of people wear black shoes if they wear a suit). Knowledge exchange is another possibility (e.g., an agent a can tell agent b that player c always bluffs when he is smiling). Game theory, with its rationality criteria  (undominated strategies, maxmin, Nash equilibrium etc.) is  another viable source of plausibility assumptions. Last but not least, folk knowledge can be used to establish  plausibilityrelated classifications of behavior (players normally want to win a game, people want to live). In any case, restricting the reasoning to plausible  possibilities can be essential if we want to make the reasoning  feasible, as the space of all possibilities (we call them physical possibilities in the rest of the paper) is exceedingly large in real life. Of course, this does not exclude a more extensive analysis in special cases, e.g. when our plausibility  assumptions do not seem accurate any more, or when the cost of The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 583 inaccurate assumptions can be too high (as in the case of high-budget business decisions). But even in these cases, we usually do not get rid of plausibility assumptions completely - we only revise them to make them more cautious.3 To formalize this idea, we extend models of CTLK with sets of plausible paths and add plausibility operators Pl a, physical paths operator Ph , and belief operators Ba to the language of CTLK. Now, it is possible to make statements that refer to plausible paths only, as well as statements that regard all paths that may occur in the system. .2 CTLK with Plausibility In this section, we extend the logic of CTLK with  plausibility; we call the resulting logic CTLKP. Formally, the language of CTLKP is defined as: ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | Eγ | Pl aϕ | Ph ϕ | Kaϕ | Baϕ γ ::= fϕ | 2 ϕ | ϕU ϕ. For instance, we may claim it is plausible to assume that a shop is closed after the opening hours, though the manager may be physically able to open it at any time: Pl aA2 (late → ¬open) ∧ Ph E♦ (late ∧ open). The semantics of CTLKP extends that of CTLK as  follows. Firstly, we augment the models with sets of plausible paths. A model with plausibility is given as M = Q, R, ∼1, ..., ∼k, Υ1, ..., Υk, π , where Q, R, ∼1, ..., ∼k, π is a CTLK model, and Υa ⊆ ΛM is the set of paths in M that are plausible according to agent a. If we want to make it clear that Υa is taken from model M, we will write ΥM a . It seems worth emphasizing that this notion of plausibility is subjective and holistic. It is  subjective because Υa represents agent a"s subjective view on what is plausible - and indeed, different agents may have  different ideas on plausibility (i.e., Υa may differ from Υb). It is holistic because Υa represents agent a"s idea of the  plausible behavior of the whole system (including the behavior of other agents). Remark 1. In our models, plausibility is also global, i.e., plausibility sets do not depend on the state of the system. Investigating systems, in which plausibility is relativized with respect to states (like in [7]), might be an interesting avenue of future work. However, such an approach - while obviously more flexible - allows for potentially counterintuitive system descriptions. For example, it might be the case that path λ is plausible in q = λ[0], but the set of plausible paths in q = λ[1] is empty. That is, by following plausible path λ we are bound to get to an implausible situation. But then, does it make sense to consider λ as plausible? Secondly, we use a non-standard satisfaction relation |=P , which we call plausible satisfaction. Let M be a CTLKP  That is, when planning to open an industrial plant in the UK, we will probably consider the possibility of our main contractor taking her life, but we will still not take into  account the possibilities of: an invasion of UFO, England being destroyed by a meteorite, Fidel Castro becoming the British Prime Minister etc. Note that this is fundamentally different from using a probabilistic model in which all these unlikely scenarios are assigned very low probabilities: in that case, they also have a very small influence on our final decision, but we must process the whole space of physical possibilities to evaluate the options. model and P ⊆ ΛM be an arbitrary subset of paths in M (not necessarily any ΥM a ). |=P restricts the evaluation of temporal formulae to the paths given in P only. The  absolute satisfaction relation |= is defined as |=ΛM . Let on(P) be the set of all states that lie on at least one path in P, i.e. on(P) = {q ∈ Q | ∃λ ∈ P∃i (λ[i] = q)}. Now, the semantics of CTLKP can be given through the  following clauses: M, q |=P p iff q ∈ π(p); M, q |=P ¬ϕ iff M, q |=P ϕ; M, q |=P ϕ ∧ ψ iff M, q |=P ϕ and M, q |=P ψ; M, q |=P E fϕ iff there is a q-subpath λ ∈ P such that M, λ[1] |=P ϕ; M, q |=P E2 ϕ iff there is a q-subpath λ ∈ P such that M, λ[i] |=P ϕ for every i ≥ 0; M, q |=P EϕU ψ iff there is a q-subpath λ ∈ P and i ≥ 0 such that M, λ[i] |=P ψ, and M, λ[j] |=P ϕ for every  ≤ j < i; M, q |=P Pl aϕ iff M, q |=Υa ϕ; M, q |=P Ph ϕ iff M, q |= ϕ; M, q |=P Kaϕ iff M, q |= ϕ for every q such that q ∼a q ; M, q |=P Baϕ iff for all q ∈ on(Υa) with q ∼a q , we have that M, q |=Υa ϕ. One of the main reasons for using the concept of  plausibility is that we want to define agents" beliefs out of more primitive concepts - in our case, these are plausibility and indistinguishability - in a way analogous to [20, 7]. If an agent knows that ϕ, he must be sure about it. However, beliefs of an agent are not necessarily about reliable facts. Still, they should make sense to the agent; if he believes that ϕ, then the formula should at least hold in all futures that he envisages as plausible. Thus, beliefs of an agent may be seen as things known to him if he disregards all non-plausible possibilities. We say that ϕ is M-true (M |= ϕ) if M, q |= ϕ for all q ∈ QM. ϕ is valid (|= ϕ) if M |= ϕ for all models M. ϕ is M-strongly true (M |≡ ϕ) if M, q |=P ϕ for all q ∈ QM and all P ⊆ ΛM. ϕ is strongly valid ( |≡ ϕ) if M |≡ ϕ for all models M. Proposition 2. Strong truth and strong validity imply truth and validity, respectively. The reverse does not hold. Ultimately, we are going to be interested in normal (not strong) validity, as parameterizing the satisfaction relation with a set P is just a technical device for propagating sets of plausible paths Υa into the semantics of nested formulae. The importance of strong validity, however, lies in the fact that |≡ ϕ ↔ ψ makes ϕ and ψ completely interchangeable, while the same is not true for normal validity. Proposition 3. Let Φ[ϕ/ψ] denote formula Φ in which every occurrence of ψ was replaced by ϕ. Also, let |≡ ϕ ↔ ψ. Then for all M, q, P: M, q |=P Φ iff M, q |=P Φ[ϕ/ψ] (in particular, M, q |= Φ iff M, q |= Φ[ϕ/ψ]). Note that |= ϕ ↔ ψ does not even imply that M, q |= Φ iff M, q |= Φ[ϕ/ψ]. 84 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 1: Guessing Robots game Example 1 (Guessing Robots). Consider a simple game with two agents a and b, shown in Figure 1. First, a chooses a real number r ∈ [0, 1] (without revealing the number to b); then, b chooses a real number r ∈ [0, 1]. The agents win the game (and collect EUR 1, 000, 000) if both chose 1, otherwise they lose. Formally, we model the game with a CTLKP model M, in which the set of states Q includes qs for the initial situation, states qr, r ∈ [0, 1], for the situations after a has chosen number r, and final states qw, ql for the winning and the losing situation,  respectively. The transition relation is as follows: qsRqr and qrRql for all r ∈ [0, 1]; q1Rqw, qwRqw, and qlRql. Moreover, π(one) = {q1} and π(win) = {qw}. Player a has perfect  information in the game (i.e., q ∼a q iff q = q ), but player b does not distinguish between states qr (i.e., qr ∼b qr for all r, r ∈ [0, 1]). Obviously, the only sensible thing to do for both agents is to choose 1 (using game-theoretical  vocabulary, these strategies are strongly dominant for the  respective players). Thus, there is only one plausible course of events if we assume that our players are rational, and hence Υa = Υb = {qsq1qwqw . . .}. Note that, in principle, the outcome of the game is  uncertain: M, qs |= ¬A♦ win∧¬A2 ¬win. However, assuming  rationality of the players makes it only plausible that the game must end up with a win: M, qs |= Pla A♦ win ∧ Plb A♦ win, and the agents believe that this will be the case: M, qs |= BaA♦ win ∧ BbA♦ win. Note also that, in any of the states qr, agent b believes that a (being rational) has played 1: M, qr |= Bbone for all r ∈ [0, 1]. .3 Defining Plausible Paths with Formulae So far, we have assumed that sets of plausible paths are somehow given in models. In this section we present a  dynamic approach where an actual notion of plausibility can be specified in the object language. Note that we want to specify (usually infinite) sets of infinite paths, and we need a finite representation of these structures. One logical solution is given by using path formulae γ. These formulae describe properties of paths; therefore, a specific formula can be used to characterize a set of paths. For instance, think about a country in Africa where it has never snowed. Then,  plausible paths might be defined as ones in which it never snows, i.e., all paths that satisfy 2 ¬snows. Formally, let γ be a CTLK path formula. We define |γ|M to be the set of paths that satisfy γ in model M: | fϕ|M = {λ | M, λ[1] |= ϕ} |2 ϕ|M = {λ | ∀i (M, λ[i] |= ϕ)} |ϕ1U ϕ2|M = {λ | ∃i ` M, λ[i] |= ϕ2 ∧ ∀j(0 ≤ j < i ⇒ M, λ[j] |= ϕ1) ´ }. Moreover, we define the plausible paths model update as follows. Let M = Q, R, ∼1, ..., ∼k, Υ1, ..., Υk, π be a CTLKP model, and let P ⊆ ΛM be a set of paths. Then Ma,P = Q, R, ∼1, ..., ∼k, Υ1, ..., Υa−1, P, Υa+1, ..., Υk, π  denotes model M with a"s set of plausible paths reset to P. Now we can extend the language of CTLKP with  formulae (set-pla γ)ϕ with the intuitive reading: suppose that γ exactly characterizes the set of plausible paths, then ϕ holds, and formal semantics given below: M, q |=P (set-pla γ)ϕ iff Ma,|γ|M , q |=P ϕ. We observe that this update scheme is similar to the one proposed in [13]. .4 Comparison to Related Work Several modal notions of plausibility were already  discussed in the existing literature [7, 8, 20, 18, 16]. In these papers, like in ours, plausibility is used as a primitive  semantic concept that helps to define beliefs on top of agents" knowledge. A similar idea was introduced by Moses and Shoham in [18]. Their work preceded both [7, 8] and  [20]and although Moses and Shoham do not explicitly mention the term plausibility, it seems appropriate to summarize their idea first. Moses and Shoham: Beliefs as Conditional Knowledge In [18], beliefs are relativized with respect to a formula α (which can be seen as a plausibility assumption expressed in the object language). More precisely, worlds that satisfy α can be considered as plausible. This concept is expressed via symbols Bα i ϕ; the index i ∈ {1, 2, 3} is used to distinguish between three different implementations of beliefs. The first version is given by Bα  ϕ ≡ K(α → ϕ).4 A drawback of this version is that if α is false, then everything will be believed with respect to α. The second version overcomes this problem: Bα  ϕ ≡ K(α → ϕ) ∧ (K¬α → Kϕ); now ϕ is only believed if it is known that ϕ follows from assumption α, and ϕ must be known if assumption α is known to be false. Finally, Bα  ϕ ≡ K(α → ϕ) ∧ ¬K¬α: if the assumption α is known to be false, nothing should be believed with respect to α. The strength of these different notions is given as follows: Bα  ϕ implies Bα  ϕ, and Bα  ϕ implies Bα  ϕ. In this approach, belief is strongly connected to knowledge in the sense that belief is knowledge with respect to a given assumption. Friedman and Halpern: Plausibility Spaces The work of Friedman and Halpern [7] extends the concepts of knowledge and belief with an explicit notion of  plausibility; i.e., some worlds are more plausible for an agent than others. To implement this idea, Kripke models are extended with function P which assigns a plausibility space P(q, a) = (Ω(q,a), (q,a)) to every state, or more generally every possible world q, and agent a. The plausibility space  Unlike in most approaches, K is interpreted over all worlds and not only over the indistinguishable worlds. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 585 is just a partially ordered subset of states/worlds; that is, Ω(q, a) ⊆ Q, and (q,a)⊆ Q ×Q is a reflexive and transitive relation. Let S, T ⊆ Ω(q,a) be finite subsets of states; now, T is defined to be plausible given S with respect to P(q, a), denoted by S →P (q,a) T, iff all minimal points/states in S (with respect to (q,a)) are also in T.5 Friedman and Halpern"s view to modal plausibility is closely related to probability and, more generally, plausibility measures.  Logics of plausibility can be seen as a qualitative description of agents preferences/knowledge; logics of probability [6, 15], on the other hand, offer a quantitative description. The logic from [7] is defined by the following grammar: ϕ ::= p | ϕ∧ϕ | ¬ϕ | Kaϕ | ϕ →a ϕ, where the semantics of all operators except →a is given as usual, and formulae ϕ →a ψ have the meaning that ψ is true in the most plausible worlds in which ϕ holds. Formally, the semantics for →a is given as: M, q |= ϕ →a ψ iff Sϕ P (q,a) →P(q,a) Sψ P (q,a), where Sϕ (q,a) = {q ∈ Ω(q,a) | M, q |= ϕ} are the states in Ω(q,a) that satisfy ϕ. The idea of defining beliefs is given by the assumption that an agent believes in something if he knows that it is true in the most plausible worlds of Ω(q,a); formally, this can be stated as Baϕ ≡ Ka( →a ϕ). Friedman and Halpern have shown that the KD45  axioms are valid for operator Ba if plausibility spaces satisfy consistency (for all states q ∈ Q it holds that Ω(q,a) ⊆ { q ∈ Q | q ∼a q }) and normality (for all states q ∈ Q it holds that Ω(q,a) = ∅).6 A temporal extension of the language (mentioned briefly in [7], and discussed in more detail in [8]) uses the interpreted systems approach [10, 5]. A system R is given by runs, where a run r : N → Q is a function from time moments (modeled by N) to global states, and a time point (r, i) is given by a time point i ∈ N and a run r. A global state is a combination of local states, one per agent. An interpreted system M = (R, π) is given by a system R and a valuation of propositions π. Epistemic relations are defined over time points, i.e., (r , m ) ∼a (r, m) iff agent a"s local states ra(m ) and ra(m) of (r , m ) and (r, m) are equal. Formulae are interpreted in a straightforward way with respect to interpreted systems, e.g. M, r, m |= Kaϕ iff M, r , m |= ϕ for all (r , m ) ∼a (r, m). Now, these are time points that play the role of possible worlds; consequently, plausibility spaces P(r,m,a) are assigned to each point (r, m) and agent a. Su et al.: KBC Logic Su et al. [20] have developed a multi-modal,  computationally grounded logic with modalities K, B, and C (knowledge, belief, and certainty). The computational model consists of (global) states q = (qvis , qinv , qper , Qpls ) where the  environment is divided into a visible (qvis ) and an invisible part (qinv ), and qper captures the agent"s perception of the visible part of the environment. External sources may provide the agent with information about the invisible part of a state, which results in a set of states Qpls that are plausible for the agent. Given a global state q, we additionally define V is(q) = qvis , Inv(q) = qinv , Per(q) = qper , and Pls(q) = Qpls . The  When there are infinite chains . . . q3 q2 a q1, the definition is much more sophisticated. An interested reader is referred to [7] for more details.  Note that this normality is essentially seriality of states wrt plausibility spaces. semantics is given by an extension of interpreted systems [10, ], here, it is called interpreted KBC systems. KBC  formulae are defined as ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | Kϕ | Bϕ | Cϕ. The epistemic relation ∼vis is captured in the following way: (r, i) ∼vis (r , i ) iff V is(r(i)) = V is(r (i )). The semantic clauses for belief and certainty are given below. M, r, i |= Bϕ iff M, r , i |= ϕ for all (r , i ) with V is(r (i )) = Per(r(i)) and Inv(r (i )) ∈ Pls(r(i)) M, r, i |= Cϕ iff M, r , i |= ϕ for all (r (i )) with V is(r (i )) = Per(r(i)) Thus, an agent believes ϕ if, and only if, ϕ is true in all states which look like what he sees now and seem plausible in the current state. Certainty is stronger: if an agent is certain about ϕ, the formula must hold in all states with a visible part equal to the current perception, regardless of whether the invisible part is plausible or not. The logic does not include temporal formulae, although it might be extended with temporal operators, as time is already present in KBC models. What Are the Differences to Our Logic? In our approach, plausibility is explicitly seen as a temporal property, i.e., it is a property of temporal paths rather than states. In the object language, this is reflected by the fact that plausibility assumptions are specified through path  formulae. In contrast, the approach of [18] and [20] is static: not only the logics do not include operators for talking about time and/or change, but these are states that are assumed plausible or not in their semantics. The differences to [7, 8] are more subtle. Firstly, the framework of Friedman and Halpern is static in the sense that plausibility is taken as a property of (abstract)  possible worlds. This formulation is flexible enough to allow for incorporating time; still, in our approach, time is inherent to plausibility rather than incidental. Secondly, our framework is more computationally oriented. The implementation of temporal plausibility in [7, 8] is based on the interpreted systems approach with time points (r, m) being subject to plausibility. As runs are included in time points, they can also be defined plausible or implausible.7 However, it also means that time points serve the role of possible worlds in the basic formulation, which yields Kripke structures with uncountable possible world spaces in all but the most trivial cases. Thirdly, [7, 8] build on linear time: a run (more precisely, a time moment (r, m)) is fixed when a formula is interpreted. In contrast, we use branching time with explicit  quantification over temporal paths.8 We believe that branching time is more suitable for non-deterministic domains (cf. e.g. [4]), of which multi-agent systems are a prime example. Note that branching time makes our notion of belief different from Friedman and Halpern"s. Most notably, property Kϕ → Bϕ is valid in their approach, but not in ours: an agent may  Friedman and Halpern even briefly mention how  plausibility of runs can be embedded in their framework.  To be more precise, time in [7] does implicitly branch at epistemic states. This is because (r, m) ∼a (r , m ) iff a"s local state corresponding to both time points is the same (ra(m) = ra(m )). In consequence, the semantics of Kaϕ can be read as for every run, and every moment on this run that yields the same local state as now, ϕ holds. 86 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) know that some course of events is in principle possible, without believing that it can really become the case (see Section 4.2). As Proposition 13 suggests, such a subtle  distinction between knowledge and beliefs is possible in our approach because branching time logics allow for existential quantification over runs. Fourthly, while Friedman and Halpern"s models are very flexible, they also enable system descriptions that may seem counterintuitive. Suppose that (r, m) is plausible in itself (formally: (r, m) is minimal wrt (r,m,a)), but (r, m + 1) is not plausible in (r, m + 1). This means that following the plausible path makes it implausible (cf. Remark 1), which is even stranger in the case of linear time. Combining the argument with computational aspects, we suggest that our approach can be more natural and straightforward for many applications. Last but not least, our logic provides a mechanism for specifying (and updating) sets of plausible paths in the  object language. Thus, plausibility sets can be specified in a succinct way, which is another feature that makes our  framework computation-friendly. The model checking results from Section 5 are especially encouraging in this light. . PLAUSIBILITY, KNOWLEDGE, AND  BELIEFS IN CTLKP In this section we study some relevant properties of  plausibility, knowledge, and beliefs; in particular, axioms KDT45 are examined. But first, we identify two important  subclasses of models with plausibility. A CTLKP model is plausibly serial (or p-serial) for agent a if every state of the system is part of a plausible path  according to a, i.e. on(Υa) = Q. As we will see further, a weaker requirement is sometimes sufficient. We call a model weakly p-serial if every state has at least one  indistinguishable counterpart which lies on a plausible path, i.e. for each q ∈ Q there is a q ∈ Q such that q ∼a q and q ∈ on(Υa). Obviously, p-seriality implies weak p-seriality. We get the following characterization of both model classes. Proposition 4. M is plausibly serial for agent a iff  formula Pl aE f is valid in M. M is weakly p-serial for agent a iff ¬KaPl aA f⊥ is valid in M. .1 Axiomatic Properties Theorem 5. Axioms K, D, 4, and 5 for knowledge are strongly valid, and axiom T is valid. That is, modalities Ka form system S5 in the sense of normal validity, and KD45 in the sense of strong validity. We do not include proofs here due to lack of space. The interested reader is referred to [2], where detailed proofs are given. Proposition 6. Axioms K, 4, and 5 for beliefs are strongly valid. That is, we have: |≡ (Baϕ ∧ Ba(ϕ → ψ)) → Baψ, |≡ (Baϕ → BaBaϕ), and |≡ (¬Baϕ → Ba¬Baϕ). The next proposition concerns the consistency axiom D: Baϕ → ¬Ba¬ϕ. It is easy to see that the axiom is not valid in general: as we have no restrictions on plausibility sets Υa, it may be as well that Υa = ∅. In that case we have Baϕ ∧ Ba¬ϕ for all formulae ϕ, because the set of states to be considered becomes empty. However, it turns out that D is valid for a very natural class of models. Proposition 7. Axiom D for beliefs is not valid in the class of all CTLKP models. However, it is strongly valid in the class of weak p-serial models (and therefore also in the class of p-serial models). Moreover, as one may expect, beliefs do not have to be always true. Proposition 8. Axiom T for beliefs is not valid; i.e., |= (Baϕ → ϕ). The axiom is not even valid in the class of p-serial models. Theorem 9. Belief modalities Ba form system K45 in the class of all models, and KD45 in the class of weakly plausibly serial models (in the sense of both normal and strong validity). Axiom T is not even valid for p-serial  models. .2 Plausibility, Knowledge, and Beliefs First, we investigate the relationship between knowledge and plausibility/physicality operators. Then, we look at the interaction between knowledge and beliefs. Proposition 10. Let ϕ be a CTLKP formula, and M be a CTLKP model. We have the following strong validities: (i) |≡ Pl aKaϕ ↔ Kaϕ (ii) |≡ Ph Kaϕ ↔ KaPh ϕ and |≡ KaPh ϕ ↔ Kaϕ We now want to examine the relationship between  knowledge and belief. For instance, if agent a believes in  something, he knows that he believes it. Or, if he knows a fact, he also believes that he knows it. On the other hand, for instance, an agent does not necessarily believe in all the things he knows. For example, we may know that an  invasion from another galaxy is in principle possible (KaE♦ invasion), but if we do not take this possibility as plausible (¬Pl aE♦ invasion), then we reject the corresponding belief in consequence (¬BaE♦ invasion). Note that this property reflects the strong connection between belief and plausibility in our framework. Proposition 11. The following formulae are strongly valid: (i) Baϕ → KaBaϕ, (ii) KaBaϕ → Baϕ, (iii) Kaϕ → BaKaϕ. The following formulae are not valid: (iv) Baϕ → BaKaϕ, (v) Kaϕ → Baϕ The last invalidity is especially important: it is not the case that knowing something implies believing in it. This emphasizes that we study a specific concept of beliefs here. Note that its specific is not due to the plausibility-based  definition of beliefs. The reason lies rather in the fact that we investigate knowledge, beliefs and plausibility in a temporal framework, as Proposition 12 shows. Proposition 12. Let ϕ be a CTLKP formula that does not include any temporal operators. Then Kaϕ → Baϕ is strongly valid, and in the class of p-serial models we have even that |≡ Kaϕ ↔ Baϕ. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 587 Moreover, it is important that we use branching time with explicit quantification over paths; this observation is  formalized in Proposition 13. Definition 1. We define the universal sublanguage of CTLK in a way similar to [21]: ϕu ::= p | ¬p | ϕu ∧ ϕu | ϕu ∨ ϕu | Aγu | Kaϕu, γu ::= fϕu | 2 ϕu | ϕuU ϕu. We call such ϕu universal formulae, and γu universal path formulae. Proposition 13. Let ϕu be a universal CTLK formula. Then |≡ Kaϕu → Baϕu. The following two theorems characterize the relationship between knowledge and beliefs: first for the class of p-serial models, and then, finally, for all models. Theorem 14. The following formulae are strongly valid in the class of plausibly serial CTLKP models: (i) Baϕ ↔ KaPl aϕ, (ii) Kaϕ ↔ BaPh ϕ. Theorem 15. Formula Baϕ ↔ KaPl a(E f → ϕ) is strongly valid. Note that this characterization has a strong commonsense reading: believing in ϕ is knowing that ϕ plausibly holds in all plausibly imaginable situations. .3 Properties of the Update The first notable property of plausibility update is that it influences only formulae in which plausibility plays a role, i.e. ones in which belief or plausibility modalities occur. Proposition 16. Let ϕ be a CTLKP formula that does not include operators Pl a and Ba, and γ be a CTLKP path formula. Then, we have |≡ ϕ ↔ (set-pla γ)ϕ. What can be said about the result of an update? At first sight, formula (set-pla γ)Pl aAγ seems a natural  characterization; however, it is not valid. This is because, by leaving the other (implausible) paths out of scope, we may leave out of |γ| some paths that were needed to satisfy γ (see the  example in Section 4.2). We propose two alternative ways out: the first one restricts the language of the update similarly to [21]; the other refers to physical possibilities, in a way analogous to [13]. Proposition 17. The CTLKP formula (set-pla γ)Pl aAγ is not valid. However, we have the following validities: (i) |≡ (set-pla γu)Pl aAγu, where γu is a universal CTLK path formula from Definition 1. (ii) If ϕ, ϕ1, ϕ2 are arbitrary CTLK formulae, then: |≡ (set-pla fϕ)Pl aA f(Ph ϕ), |≡ (set-pla 2 ϕ)Pl aA2 (Ph ϕ), and |≡ (set-pla ϕ1U ϕ2)Pl aA(Ph ϕ1)U (Ph ϕ2). . VERIFICATION OF PLAUSIBILITY, TIME AND BELIEFS In this section we report preliminary results on model checking CTLKP formulae. Clearly, verifying CTLKP properties directly against models with plausibility does not make much sense, since these models are inherently infinite; what we need is a finite representation of plausibility sets. One such representation has been discussed in Section 3.3: plausibility sets can be defined by path formulae and the update operator (set-pla γ). We follow this idea here, studying the complexity of model checking CTLKP formulae against CTLK models (which can be seen as a compact representation of CTLKP  models in which all the paths are assumed plausible), with the underlying idea that plausibility sets, when needed, must be defined explicitly in the object language. Below we sketch an algorithm that model-checks CTLKP formulae in time linear wrt the size of the model and the length of the  formula. This means that we have extended CTLK to a more expressive language with no computational price to pay. First of all, we get rid of the belief operators (due to  Theorem 15), replacing every occurrence of Baϕ with KaPl a(E f → ϕ). Now, let −→γ = γ1, ..., γk be a vector of vanilla path formulae (one per agent), with the initial vector −→γ0 = , ..., , and −→γ [γ /a] denoting vector −→γ , in which −→γ [a] is replaced with γ . Additionally, we define −→γ [0] = . We translate the resulting CTLKP formulae to ones without plausibility via function tr(ϕ) = tr−→γ0,0(ϕ), defined as  follows: tr−→γ ,i(p) = p, tr−→γ ,i(ϕ1 ∧ ϕ2) = tr−→γ ,i(ϕ1) ∧ tr−→γ ,i(ϕ2), tr−→γ ,i(¬ϕ) = ¬tr−→γ ,i(ϕ), tr−→γ ,i(Kaϕ) = Ka tr−→γ ,0(ϕ), tr−→γ ,i(Pla ϕ) = tr−→γ ,a(ϕ), tr−→γ ,i((set-pla γ )ϕ) = tr−→γ [γ /a],i(ϕ), tr−→γ ,i(Ph ϕ) = tr−→γ ,0(ϕ), tr−→γ ,i( fϕ) = ftr−→γ ,i(ϕ), tr−→γ ,i(2 ϕ) = 2 tr−→γ ,i(ϕ), tr−→γ ,i(ϕ1U ϕ2) = tr−→γ ,i(ϕ1)U tr−→γ ,i(ϕ2), tr−→γ ,i(Eγ ) = E(−→γ [i] ∧ tr−→γ ,i(γ )). Note that the resulting sentences belong to the logic of CTLK+, that is CTL+ (where each path quantifier can be followed by a Boolean combination of vanilla path  formulae)9 with epistemic modalities. The following proposition justifies the translation. Proposition 18. For any CTLKP formula ϕ without Ba, we have that M, q |=CTLKP ϕ iff M, q |=CTLK+ tr(ϕ). In general, model checking CTL+ (and also CTLK+) is ΔP  -complete. However, in our case, the Boolean  combinations of path subformulae are always conjunctions of at most two non-negated elements, which allows us to propose the following model checking algorithm. First, subformulae are evaluated recursively: for every subformula ψ of ϕ, the set of states in M that satisfy ψ is computed and labeled with a new proposition pψ. Now, it is enough to define checking M, q |= ϕ for ϕ in which all (state) subformulae are propositions, with the following cases: Case M, q |= E(2 p ∧ γ): If M, q |= p, then return no.  Otherwise, remove from M all the states that do not satisfy p (yielding a sparser model M ), and check the CTL formula Eγ in M , q with any CTL model-checker. Case M, q |= E( fp ∧ γ): Create M by adding a copy q of state q, in which only the transitions to states  satisfying p are kept (i.e., M, q |= r iff M, q |= r; and q Rq iff qRq and M, q |= p). Then, check Eγ in M , q .  For the semantics of CTL+, and discussion of model checking complexity, cf. [17]. 88 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Case M, q |= E(p1U p2 ∧ p3U p4): Note that this is  equivalent to checking E(p1 ∧ p3)U (p2 ∧ Ep3U p4) ∨ E(p1 ∧ p3)U (p4 ∧ Ep1U p2), which is a CTL formula. Other cases: The above cases cover all possible formulas that begin with a path quantifier. For other cases, standard CTLK model checking can be used. Theorem 19. Model checking CTLKP against CTLK models is PTIME-complete, and can be done in time O(ml), where m is the number of transitions in the model, and l is the length of the formula to be checked. That is, the  complexity is no worse than for CTLK itself. . CONCLUSIONS In this paper a notion of plausible behavior is considered, with the underlying idea that implausible options should be usually ignored in practical reasoning about possible future courses of action. We add the new notion of plausibility to the logic of CTLK [19], and obtain a language which  enables reasoning about what can (or must) plausibly happen. As a technical device to define the semantics of the resulting logic, we use a non-standard satisfaction relation |=P that allows to propagate the current set of plausible paths into subformulae. Furthermore, we propose a non-standard  notion of beliefs, defined in terms of indistinguishability and plausibility. We also propose how plausibility assumptions can be specified in the object language via a plausibility  update operator (in a way similar to [13]). We use this new framework to investigate some important properties of plausibility, knowledge, beliefs, and updates. In particular, we show that knowledge is an S5 modality, and that beliefs satisfy axioms K45 in general, and KD45 for the class of plausibly serial models. We also prove that believing in ϕ is knowing that ϕ plausibly holds in all  plausibly possible situations. That is, the relationship between knowledge and beliefs is very natural and reflects the  initial intuition precisely. Moreover, the model checking  results from Section 5 show that verification for CTLKP is no more complex than for CTL and CTLK. We would like to stress that we do not see this contribution as a mere technical exercise in formal logic. Human agents use a similar concept of plausibility and practical beliefs in their everyday reasoning in order to reduce the search space and make the reasoning feasible. As a consequence, we suggest that the framework we propose may prove suitable for modeling, design, and analysis resource-bounded agents in general. We would like to thank Juergen Dix for fruitful  discussions, useful comments and improvements. . REFERENCES [1] R. Alur, T. A. Henzinger, and O. Kupferman. Alternating-time Temporal Logic. Journal of the ACM, 49:672-713, 2002. [2] N. Bulling and W. Jamroga. Agents, beliefs and plausible behavior in a temporal setting. Technical Report IfI-06-05, Clausthal Univ. of Technology, 2006. [3] E. A. Emerson. Temporal and modal logic. In J. van Leeuwen, editor, Handbook of Theoretical Computer Science, volume B, pages 995-1072. Elsevier, 1990. [4] E.A. Emerson and J.Y. Halpern. sometimes and not never revisited: On branching versus linear time temporal logic. Journal of the ACM, 33(1):151-178, 986. [5] R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning about Knowledge. MIT Press: Cambridge, MA, 1995. [6] R. Fagin and J.Y. Halpern. Reasoning about knowledge and probability. Journal of ACM, 1(2):340-367, 1994. [7] N. Friedman and J.Y. Halpern. A knowledge-based framework for belief change, Part I: Foundations. In Proceedings of TARK, pages 44-64, 1994. [8] N. Friedman and J.Y. Halpern. A knowledge-based framework for belief change, Part II: Revision and update. In Proceedings of KR"94, 1994. [9] J.Y. Halpern. Reasoning about knowledge: a survey. In Handbook of Logic in Artificial Intelligence and Logic Programming. Vol. 4: Epistemic and Temporal Reasoning, pages 1-34. Oxford University Press, Oxford, 1995. [10] J.Y. Halpern and R. Fagin. Modelling knowledge and action in distributed systems. Distributed Computing, (4):159-177, 1989. [11] W. Jamroga and N. Bulling. A general framework for reasoning about rational agents. In Proceedings of AAMAS"07, 2007. Short paper. [12] W. Jamroga and W. van der Hoek. Agents that know how to play. Fundamenta Informaticae, 3(2-3):185-219, 2004. [13] W. Jamroga, W. van der Hoek, and M. Wooldridge. Intentions and strategies in game-like scenarios. In Progress in Artificial Intelligence: Proceedings of EPIA 2005, volume 3808 of LNAI, pages 512-523. Springer Verlag, 2005. [14] W. Jamroga and Thomas ˚Agotnes. Constructive knowledge: What agents can achieve under incomplete information. Technical Report IfI-05-10, Clausthal University of Technology, 2005. [15] B.P. Kooi. Probabilistic dynamic epistemic logic. Journal of Logic, Language and Information, 2(4):381-408, 2003. [16] P. Lamarre and Y. Shoham. Knowledge, certainty, belief, and conditionalisation (abbreviated version). In Proceedings of KR"94, pages 415-424, 1994. [17] F. Laroussinie, N. Markey, and Ph. Schnoebelen. Model checking CTL+ and FCTL is hard. In Proceedings of FoSSaCS"01, volume 2030 of LNCS, pages 318-331. Springer, 2001. [18] Y. Moses and Y. Shoham. Belief as defeasible knowledge. Artificial Intelligence, 64(2):299-321, 1993. [19] W. Penczek and A. Lomuscio. Verifying epistemic properties of multi-agent systems via bounded model checking. In Proceedings of AAMAS"03, pages 09-216, New York, NY, USA, 2003. ACM Press. [20] K. Su, A. Sattar, G. Governatori, and Q. Chen. A computationally grounded logic of knowledge, belief and certainty. In Proceedings of AAMAS"05, pages 49-156. ACM Press, 2005. [21] W. van der Hoek, M. Roberts, and M. Wooldridge. Social laws in alternating time: Effectiveness, feasibility and synthesis. Synthese, 2005. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 589
Bid Expressiveness and Clearing Algorithms in Multiattribute Double Auctions Yagil Engel, Michael P. Wellman, and Kevin M. Lochner University of Michigan, Computer Science & Engineering 260 Hayward St, Ann Arbor, MI 48109-2121, USA {yagil,wellman,klochner}@umich.edu ABSTRACT We investigate the space of two-sided multiattribute auctions,  focusing on the relationship between constraints on the offers traders can express through bids, and the resulting computational problem of determining an optimal set of trades. We develop a formal  semantic framework for characterizing expressible offers, and show conditions under which the allocation problem can be separated into first identifying optimal pairwise trades and subsequently  optimizing combinations of those trades. We analyze the bilateral matching problem while taking into consideration relevant results from multiattribute utility theory. Network flow models we  develop for computing global allocations facilitate classification of the problem space by computational complexity, and provide  guidance for developing solution algorithms. Experimental trials help distinguish tractable problem classes for proposed solution  techniques. Categories and Subject Descriptors: F.2 [Theory of  Computation]: Analysis Of Algorithms And Problem Complexity; J.4 [Computer Applications]: Social and Behavioral  Sciences-Economics General Terms: Algorithms, Economics . BACKGROUND A multiattribute auction is a market-based mechanism where goods are described by vectors of features, or attributes [3, 5, 8, 9]. Such mechanisms provide traders with the ability to negotiate over a multidimensional space of potential deals, delaying  commitment to specific configurations until the most promising candidates are identified. For example, in a multiattribute auction for  computers, the good may be defined by attributes such as processor speed, memory, and hard disk capacity. Agents have varying preferences (or costs) associated with the possible configurations. For example, a buyer may be willing to purchase a computer with a 2 GHz  processor, 500 MB of memory, and a 50 GB hard disk for a price no greater than $500, or the same computer with 1GB of memory for a price no greater than $600. Existing research in multiattribute auctions has focused  primarily on one-sided mechanisms, which automate the process whereby a single agent negotiates with multiple potential trading partners [8, 7, 19, 5, 23, 22]. Models of procurement typically assume the buyer has a value function, v, ranging over the possible  configurations, X, and that each seller i can similarly be associated with a cost function ci over this domain. The role of the auction is to elicit these functions (possibly approximate or partial versions), and identify the surplus-maximizing deal. In this case, such an  outcome would be arg maxi,x v(x) − ci(x). This problem can be translated into the more familiar auction for a single good without attributes by computing a score for each attribute vector based on the seller valuation function, and have buyers bid scores. Analogs of the classic first- and second-price auctions correspond to  firstand second-score auctions [8, 7]. In the absence of a published buyer scoring function, agents on both sides may provide partial specifications of the deals they are willing to engage. Research on such auctions has, for example,  produced iterative mechanisms for eliciting cost functions  incrementally [19]. Other efforts focus on the optimization problem facing the bid taker, for example considering side constraints on the  combination of trades comprising an overall deal [4]. Side constraints have also been analyzed in the context of combinatorial auctions [6, 20]. Our emphasis is on two-sided multiattribute auctions, where  multiple buyers and sellers submit bids, and the objective is to construct a set of deals maximizing overall surplus. Previous research on such auctions includes works by Fink et al. [12] and Gong [14], both of which consider a matching problem for continuous double auctions (CDAs), where deals are struck whenever a pair of  compatible bids is identified. In a call market, in contrast, bids accumulate until designated times (e.g., on a periodic or scheduled basis) at which the auction clears by determining a comprehensive match over the entire set of bids. Because the optimization is performed over an aggregated scope, call markets often enjoy liquidity and efficiency advantages over CDAs [10].1 Clearing a multiattribute CDA is much like clearing a one-sided multiattribute auction. Because nothing happens between bids, the problem is to match a given new bid (say, an offer to buy) with the existing bids on the other (sell) side. Multiattribute call markets are potentially much more complex. Constructing an optimal overall matching may require consideration of many different  combina1 In the interim between clears, call markets may also disseminate price quotes providing summary information about the state of the auction [24]. Such price quotes are often computed based on  hypothetical clears, and so the clearing algorithm may be invoked more frequently than actual market clearing operations. 10 tions of trades, among the various potential trading-partner  pairings. The problem can be complicated by restrictions on overall assignments, as expressed in side constraints [16]. The goal of the present work is to develop a general framework for multiattribute call markets, to enable investigation of design  issues and possibilities. In particular, we use the framework to  explore tradeoffs between expressive power of agent bids and  computational properties of auction clearing. We conduct our  exploration independent of any consideration of strategic issues bearing on mechanism design. As with analogous studies of combinatorial auctions [18], we intend that tradeoffs quantified in this work can be combined with incentive factors within a comprehensive overall approach to multiattribute auction design. We provide the formal semantics of multiattribute offers in our framework in the next section. We abstract, where appropriate, from the specific language used to express offers, characterizing expressiveness semantically in terms of what deals may be offered. This enables us to identify some general conditions under which the problem of multilateral matching can be decomposed into  bilateral matching problems. We then develop a family of network flow problems that capture corresponding classes of multiattribute call market optimizations. Experimental trials provide preliminary confirmation that the network formulations provide useful structure for implementing clearing algorithms. . MULTIATTRIBUTE OFFERS .1 Basic Definitions The distinguishing feature of a multiattribute auction is that the goods are defined by vectors of attributes, x = (x1, . . . , xm), xj ∈ Xj . A configuration is a particular attribute vector, x ∈ X = Qm j=1 Xj . The outcome of the auction is a set of bilateral trades. Trade t takes the form t = (x, q, b, s, π), signifying that agent b buys q > 0 units of configuration x from seller s, for  payment π > 0. For convenience, we use the notation xt to denote the configuration associated with trade t (and similarly for other  elements of t). For a set of trades T, we denote by Ti that subset of T involving agent i (i.e., b = i or s = i). Let T denote the set of all possible trades. A bid expresses an agent"s willingness to participate in trades. We specify the semantics of a bid in terms of offer sets. Let OT i ⊆ Ti denote agent i"s trade offer set. Intuitively, this represents the trades in which i is willing to participate. However, since the  outcome of the auction is a set of trades, several of which may involve agent i, we must in general consider willingness to engage in trade combinations. Accordingly, we introduce the combination offer set of agent i, OC i ⊆ 2Ti . .2 Specifying Offer Sets A fully expressive bid language would allow specification of  arbitrary combination offer sets. We instead consider a more limited class which, while restrictive, still captures most forms of  multiattribute bidding proposed in the literature. Our bids directly specify part of the agent"s trade offer set, and include further directives  controlling how this can be extended to the full trade and combination offer sets. For example, one way to specify a trade (buy) offer set would be to describe a set of configurations and quantities, along with the maximal payment one would exchange for each (x, q) specified. This description could be by enumeration, or any available means of defining such a mapping. An explicit set of trades in the offer set generally entails inclusion of many more implicit trades. We assume payment monotonicity, which means that agents always prefer more money. That is, for π > π > 0, (x, q, i, s, π) ∈ OT i ⇒ (x, q, i, s, π ) ∈ OT i , (x, q, b, i, π ) ∈ OT i ⇒ (x, q, b, i, π) ∈ OT i . We also assume free disposal, which dictates that for all i, q > q > 0, (x, q , i, s, π) ∈ OT i ⇒ (x, q, i, s, π) ∈ OT i , (x, q, b, i, π) ∈ OT i ⇒ (x, q , b, i, π) ∈ OT i . Note that the conditions for agents in the role of buyers and sellers are analogous. Henceforth, for expository simplicity, we present all definitions with respect to buyers only, leaving the definition for sellers as understood. Allowing agents" bids to comprise offers from both buyer and seller perspectives is also straightforward. An assertion that offers are divisible entails further implicit  members in the trade offer set. DEFINITION 1 (DIVISIBLE OFFER). Agent i"s offer is  divisible down to q iff ∀q < q < q. (x, q, i, s, π) ∈ OT i ⇒ (x, q , i, s, q q π) ∈ OT i . We employ the shorthand divisible to mean divisible down to 0. The definition above specifies arbitrary divisibility. It would  likewise be possible to define divisibility with respect to integers, or to any given finite granularity. Note that when offers are divisible, it suffices to specify one offer corresponding to the maximal quantity one is willing to trade for any given configuration, trading partner, and per-unit payment (called the price). At the extreme of indivisibility are all-or-none offers. DEFINITION 2 (AON OFFER). Agent i"s offer is all-or-none (AON) iff (x, q, i, s, π) ∈ OT i ∧ (x, q , i, s, π ) ∈ OT i ⇒ [q = q ∨ π = π ]. In many cases, the agent will be indifferent with respect to  different trading partners. In that event, it may omit the partner element from trades directly specified in its offer set, and simply assert that its offer is anonymous. DEFINITION 3 (ANONYMITY). Agent i"s offer is anonymous iff ∀s, s , b, b . (x, q, i, s, π) ∈ OT i ⇔ (x, q, i, s , π) ∈ OT i ∧ (x, q, b, i, π) ∈ OT i ⇔ (x, q, b , i, π) ∈ OT i . Because omitting trading partner qualifications simplifies the  exposition, we generally assume in the following that all offers are anonymous unless explicitly specified otherwise. Extending to the non-anonymous case is conceptually straightforward. We employ the wild-card symbol ∗ in place of an agent identifier to indicate that any agent is acceptable. To specify a trade offer set, a bidder directly specifies a set of willing trades, along with any regularity conditions (e.g.,  divisibility, anonymity) that implicitly extend the set. The full trade offer set is then defined by the closure of this direct set with respect to payment monotonicity, free disposal, and any applicable  divisibility assumptions. We next consider the specification of combination offer sets. Without loss of generality, we restrict each trade set T ∈ OC i to include at most one trade for any combination of configuration and trading partner (multiple such trades are equivalent to one net trade aggregating the quantities and payments). The key question is to what extent the agent is willing to aggregate deals across  configurations or trading partners. One possibility is disallowing any  aggregation. 11 DEFINITION 4 (NO AGGREGATION). The no-aggregation  combinations are given by ONA i = {∅} ∪ {{t} | t ∈ OT i }. Agent i"s offer exhibits non-aggregation iff OC i = ONA i . We require in general that OC i ⊇ ONA i . A more flexible policy is to allow aggregation across trading partners, keeping configuration constant. DEFINITION 5 (PARTNER AGGREGATION). Suppose a  particular trade is offered in the same context (set of additional trades, T) with two different sellers, s and s . That is, {(x, q, i, s, π)} ∪ T ∈ OC i ∧ {(x, q, i, s , π)} ∪ T ∈ OC i . Agent i"s offer allows seller aggregation iff in all such cases, {(x, q , i, s, π ), (x, q − q , i, s , π − π )} ∪ T ∈ OC i . In other words, we may create new trade offer combinations by splitting the common trade (quantity and payment, not necessarily proportionately) between the two sellers. In some cases, it might be reasonable to form combinations by aggregating different configurations. DEFINITION 6 (CONFIGURATION AGGREGATION). Suppose agent i offers, in the same context, the same quantity of two (not necessarily different) configurations, x and x . That is, {(x, q, i, ∗, π)} ∪ T ∈ OC i ∧ {(x , q, i, ∗, π )} ∪ T ∈ OC i . Agent i"s offer allows configuration aggregation iff in all such cases (and analogously when it is a seller), {(x, q , i, ∗, q q π), (x , q − q , i, ∗, q − q q π )} ∪ T ∈ OC i . Note that combination offer sets can accommodate offerings of configuration bundles. However, classes of bundles formed by  partner or configuration aggregation are highly regular, covering only a specific type of bundle formed by splitting a desired quantity across configurations. This is quite restrictive compared to the general combinatorial case. .3 Willingness to Pay An agent"s offer trade set implicitly defines the agent"s  willingness to pay for any given configuration and quantity. We assume anonymity to avoid conditioning our definitions on trading partner. DEFINITION 7 (WILLINGNESS TO PAY). Agent i"s willingness to pay for quantity q of configuration x is given by ˆuB i (x, q) = max π s.t. (x, q, i, ∗, π) ∈ OT i . We use the symbol ˆu to recognize that willingness to pay can be viewed as a proxy for the agent"s utility function, measured in  monetary units. The superscript B distinguishes the buyer"s  willingnessto-pay function from, a seller"s willingness to accept, ˆuS i (x, q),  defined as the minimum payment seller i will accept for q units of configuration x. We omit the superscript where the distinction is inessential or clear from context. DEFINITION 8 (TRADE QUANTITY BOUNDS). Agent i"s  minimum trade quantity for configuration x is given by qi(x) = min q s.t. ∃π. (x, q, i, ∗, π) ∈ OT i . The agent"s maximum trade quantity for x is ¯qi(x) = max q s.t. ∃π. (x, q, i, ∗, π) ∈ OT i ∧ ¬∃q < q. (x, q , i, ∗, π) ∈ OT i . When the agent has no offers involving x, we take qi(x) = ¯qi(x) = . It is useful to define a special case where all configurations are offered in the same quantity range. DEFINITION 9 (CONFIGURATION PARITY). Agent i"s offers exhibit configuration parity iff qi(x) > 0 ∧ qi(x ) > 0 ⇒ qi(x) = qi(x ) ∧ ¯qi(x) = ¯qi(x ). Under configuration parity we drop the arguments from trade  quantity bounds, yielding the constants ¯q and q which apply to all offers. DEFINITION 10 (LINEAR PRICING). Agent i"s offers exhibit linear pricing iff for all qi(x) ≤ q ≤ ¯qi(x), ˆui(x, q) = q ¯qi(x) ˆui(x, ¯qi(x)). Note that linear pricing assumes divisibility down to qi(x). Given linear pricing, we can define the unit willingness to pay, ˆui(x) = ˆui(x, ¯qi(x))/¯qi(x), and take ˆui(x, q) = qˆui(x) for all qi(x) ≤ q ≤ ¯qi(x). In general, an agent"s willingness to pay may depend on a context of other trades the agent is engaging in. DEFINITION 11 (WILLINGNESS TO PAY IN CONTEXT). Agent i"s willingness to pay for quantity q of configuration x in the  context of other trades T is given by ˆuB i (x, q; T) = max π s.t. {(x, q, i, s, π)} ∪ Ti ∈ OC i . LEMMA 1. If OC i is either non aggregating, or exhibits linear pricing, then ˆuB i (x, q; T) = ˆuB i (x, q). . MULTIATTRIBUTE ALLOCATION DEFINITION 12 (TRADE SURPLUS). The surplus of trade t = (x, q, b, s, π) is given by σ(t) = ˆuB b (x, q) − ˆuS s (x, q). Note that the trade surplus does not depend on the payment, which is simply a transfer from buyer to seller. DEFINITION 13 (TRADE UNIT SURPLUS). The unit surplus of trade t = (x, q, b, s, π) is given by σ1 (t) = σ(t)/q. Under linear pricing, we can equivalently write σ1 (t) = ˆuB b (x) − ˆuS s (x). DEFINITION 14 (SURPLUS OF A TRADE IN CONTEXT). The surplus of trade t = (x, q, b, s, π) in the context of other trades T, σ(t; T), is given by ˆuB b (x, q; T) − ˆuS s (x, q; T). DEFINITION 15 (GMAP). The Global Multiattribute  Allocation Problem (GMAP) is to find the set of acceptable trades  maximizing total surplus, max T ∈2T X t∈T σ(t; T \ {t}) s.t. ∀i. Ti ∈ OC i . DEFINITION 16 (MMP). The Multiattribute Matching  Problem (MMP) is to find a best trade for a given pair of traders, MMP(b, s) = arg max t∈OT b ∩OT s σ(t). If OT b ∩ OT s is empty, we say that MMP has no solution. 12 Proofs of all the following results are provided in an extended  version of this paper available from the authors. THEOREM 2. Suppose all agents" offers exhibit no aggregation (Definition 4). Then the solution to GMAP consists of a set of trades, each of which is a solution to MMP for its specified pair of traders. THEOREM 3. Suppose that each agent"s offer set satisfies one of the following (not necessarily the same) sets of conditions. . No aggregation and configuration parity (Definitions 4 and 9). . Divisibility, linear pricing, and configuration parity  (Definitions 1, 10, and 9), with combination offer set defined as the minimal set consistent with configuration aggregation  (Definition 6).2 Then the solution to GMAP consists of a set of trades, each of which employs a configuration that solves MMP for its specified pair of traders. Let MMPd (b, s) denote a modified version of MMP, where OT b and OT s are extended to assume divisibility (i.e., the offer sets are taken to be their closures under Definition 1). Then we can extend Theorem 3 to allow aggregating agents to maintain AON or  minquantity offers as follows. THEOREM 4. Suppose offer sets as in Theorem 3, except that agents i satisfying configuration aggregation need be divisible only down to qi, rather than down to 0. Then the solution to GMAP consists of a set of trades, each of which employs the same  configuration as a solution to MMPd for its specified pair of traders. THEOREM 5. Suppose agents b and s exhibit configuration  parity, divisibility, and linear pricing, and there exists configuration x such that ˆub(x) − ˆus(x) > 0. Then t ∈ MMPd (b, s) iff xt = arg max x {ˆub(x) − ˆus(x)} qt = min(¯qb, ¯qs). (1) The preceding results signify that under certain conditions, we can divide the global optimization problem into two parts: first find a bilateral trade that maximizes unit surplus for each pair of traders (or total surplus in the non-aggregation case), and then use the  results to find a globally optimal set of trades. In the following two sections we investigate each of these subproblems. . UTILITY REPRESENTATION AND MMP We turn next to consider the problem of finding a best deal  between pairs of traders. The complexity of MMP depends pivotally on the representation by bids of offer sets, an issue we have  postponed to this point. Note that issues of utility representation and MMP apply to a broad class of multiattribute mechanisms, beyond the multiattribute call markets we emphasize. For example, the complexity results contained in this section apply equally to the bidding problem faced by sellers in reverse auctions, given a published buyer scoring  function. The simplest representation of an offer set is a direct  enumeration of configurations and associated quantities and payments. This approach treats the configurations as atomic entities, making no use  That is, for such an agent i, OC i is the closure under configuration aggregation of ONA i . of attribute structure. A common and inexpensive enhancement is to enable a trader to express sets of configurations, by specifying subsets of the domains of component attributes. Associating a  single quantity and payment with a set of configurations expresses indifference among them; hence we refer to such a set as an  indifference range.3 Indifference ranges include the case of attributes with a natural ordering, in which a bid specifies a minimum or maximum acceptable attribute level. The use of indifference ranges can be convenient for MMP. The compatibility of two indifference ranges is simply found by testing set intersection for each attribute, as demonstrated by the decision-tree algorithm of Fink et al. [12]. Alternatively, bidders may specify willingness-to-pay functions ˆu in terms of compact functional forms. Enumeration based  representations, even when enhanced with indifference ranges, are  ultimately limited by the exponential size of attribute space.  Functional forms may avoid this explosion, but only if ˆu reflects  structure among the attributes. Moreover, even given a compact  specification of ˆu, we gain computational benefits only if we can  perform the matching without expanding the ˆu values of an  exponential number of configuration points. .1 Additive Forms One particularly useful multiattribute representation is known as the additive scoring function. Though this form is widely used in practice and in the academic literature, it is important to stress the assumptions behind it. The theory of multiattribute representation is best developed in the context where ˆu is interpreted as a  utility function representing an underlying preference order [17]. We present the premises of additive utility theory in this section, and discuss some generalizations in the next. DEFINITION 17. A set of attributes Y ⊂ X is preferentially independent (PI) of its complement Z = X \ Y if the conditional preference order over Y given a fixed level Z0 of Z is the same regardless of the choice of Z0 . In other words, the preference order over the projection of X on the attributes in Y is the same for any instantiation of the attributes in Z. DEFINITION 18. X = {x1, . . . , xm} is mutually preferentially independent (MPI) if any subset of X is preferentially independent of its complement. THEOREM 6 ([9]). A preference order over set of attributes X has an additive utility function representation u(x1, . . . , xm) = mX i=1 ui(xi) iff X is mutually preferential independent. A utility function over outcomes including money is quasi-linear if the function can be represented as a function over non-monetary attributes plus payments, π. Interpreting ˆu as a utility function over non-monetary attributes is tantamount to assuming quasi-linearity. Even when quasi-linearity is assumed, however, MPI over  nonmonetary attributes is not sufficient for the quasi-linear utility  function to be additive. For this, we also need that each of the pairs (π, Xi) for any attribute Xi would be PI of the rest of the attributes.  These should not be mistaken with indifference curves, which  express dependency between the attributes. Indifference curves can be expressed by the more elaborate utility representations discussed below. 13 This (by MAUT) in turn implies that the set of attributes including money is MPI and the utility function can be represented as u(x1, . . . , xm, π) = mX i=1 ui(xi) + π. Given that form, a willingness-to-pay function reflecting u can be represented additively, as ˆu(x) = mX i=1 ui(xi) In many cases the additivity assumption provides practically  crucial simplification of offer set elicitation. In addition to  compactness, additivity dramatically simplifies MMP. If both sides provide additive ˆu representations, the globally optimal match reduces to finding the optimal match separately for each attribute. A common scenario in procurement has the buyer define an  additive scoring function, while suppliers submit enumerated offer points or indifference ranges. This model is still very amenable to MMP: for each element in a supplier"s enumerated set, we optimize each attribute by finding the point in the supplier"s allowable range that is most preferred by the buyer. A special type of scoring (more particularly, cost) function was defined by Bichler and Kalagnanam [4] and called a configurable offer. This idea is geared towards procurement auctions: assuming suppliers are usually comfortable with expressing their preferences in terms of cost that is quasi-linear in every attribute, they can  specify a price for a base offer, and additional cost for every change in a specific attribute level. This model is essentially a pricing out approach [17]. For this case, MMP can still be optimized on a per-attribute basis. A similar idea has been applied to one-sided iterative mechanisms [19], in which sellers refine prices on a  perattribute basis at each iteration. .2 Multiattribute Utility Theory Under MPI, the tradeoffs between the attributes in each subset cannot be affected by the value of other attributes. For example, when buying a PC, a weaker CPU may increase the importance of the RAM compared to, say, the type of keyboard. Such  relationships cannot be expressed under an additive model. Multiattribute utility theory (MAUT) develops various compact representations of utility functions that are based on weaker  structural assumptions [17, 2]. There are several challenges in adapting these techniques to multiattribute bidding. First, as noted above, the theory is developed for utility functions, which may behave  differently from willingness-to-pay functions. Second, computational efficiency of matching has not been an explicit goal of most work in the area. Third, adapting such representations to iterative  mechanisms may be more challenging. One representation that employs somewhat weaker assumptions than additivity, yet retains the summation structure is the  generalized additive (GA) decomposition: u(x) = JX j=1 fj(xj ), xj ∈ Xj , (2) where the Xj are potentially overlapping sets of attributes, together exhausting the space X. A key point from our perspective is that the complexity of the matching is similar to the complexity of optimizing a single  function, since the sum function is in the form (2) as well. Recent work by Gonzales and Perny [15] provides an elicitation process for GA decomposable preferences under certainty, as well as an  optimization algorithm for the GA decomposed function. The complexity of exact optimization is exponential in the induced width of the graph. However, to become operational for multiattribute bidding this  decomposition must be detectable and verifiable by statements over preferences with respect to price outcomes. We are exploring this topic in ongoing work [11]. . SOLVING GMAP UNDER ALLOCATION CONSTRAINTS Theorems 2, 3, and 4 establish conditions under which GMAP solutions must comprise elements from constituent MMP solutions. In Sections 5.1 and 5.2, we show how to compute these GMAP  solutions, given the MMP solutions, under these conditions. In these settings, traders that aggregate partners also aggregate  configurations; hence we refer to them simply as aggregating or  nonaggregating. Section 5.3 suggests a means to relax the linear  pricing restriction employed in these constructions. Section 5.4  provides strategies for allowing traders to aggregate partners and  restrict configuration aggregation at the same time. .1 Notation and Graphical Representation Our clearing algorithms are based on network flow formulations of the underlying optimization problem [1]. The network model is based on a bipartite graph, in which nodes on the left side represent buyers, and nodes on the right represent sellers. We denote the sets of buyers and sellers by B and S, respectively. We define two graph families, one for the case of non-aggregating traders (called single-unit), and the other for the case of  aggregating traders (called multi-unit).4 For both types, a single directed arc is placed from a buyer i ∈ B to a seller j ∈ S if and only if MMP(i, j) is nonempty. We denote by T(i) the set of potential trading partners of trader i (i.e., the nodes connected to buyer or seller i in the bipartite graph. In the single-unit case, we define the weight of an arc (i, j) as wij = σ(MMP(i, j)). Note that free disposal lets a buy offer receive a larger quantity than desired (and similarly for sell offers). For the multi-unit case, the weights are wij = σ1 (MMP(i, j)), and we associate the quantity ¯qi with the node for trader i. We also use the notation qij for the mathematical formulations to denote partial fulfillment of qt for t = MMP(i, j). .2 Handling Indivisibility and Aggregation Constraints Under the restrictions of Theorems 2, 3, or 4, and when the  solution to MMP is given, GMAP exhibits strong similarity to the problem of clearing double auctions with assignment constraints [16]. A match in our bipartite representation corresponds to a  potential trade in which assignment constraints are satisfied. Network flow formulations have been shown to model this problem under the assumption of indivisibility and aggregation for all traders. The novelty in this part of our work is the use of generalized network flow formulations for more complex cases where aggregation and divisibility may be controlled by traders. Initially we examine the simple case of no aggregation  (Theorem 2). Observe that the optimal allocation is simply the solution to the well known weighted assignment problem [1] on the  singleunit bipartite graph described above. The set of matches that  maximizes the total weight of arcs corresponds to the set of trades that maximizes total surplus. Note that any form of (in)divisibility can  In the next section, we introduce a hybrid form of graph  accommodating mixes of the two trader categories. 14 also be accommodated in this model via the constituent MMP  subproblems. The next formulation solves the case in which all traders fall under case 2 of Theorem 3-that is, all traders are aggregating and divisible, and exhibit linear pricing. This case can be represented using the following linear program, corresponding to our multi-unit graph: max X i∈B,j∈S wij qij s.t. X i∈T (j) qij ≤ ¯qj j ∈ S X j∈T (i) qij ≤ ¯qi i ∈ B qij ≥ 0 j ∈ S, i ∈ B Recall that the qij variables in the solution represent the number of units that buyer i procures from seller j. This formulation is known as the network transportation problem with inequality  constraints, for which efficient algorithms are available [1]. It is a well known property of the transportation problem (and flow  problems on pure networks in general) that given integer input values, the optimal solution is guaranteed to be integer as well. Figure 1 demonstrates the transformation of a set of bids to a transportation problem instance. Figure 1: Multi-unit matching with two boolean attributes. (a) Bids, with offers to buy in the left column and offers to sell at right. q@p indicates an offer to trade q units at price p per unit. Configurations are described in terms of constraints on attribute values. (b) Corresponding multi-unit assignment model. W represents arc weights (unit surplus), s represents source (exogenous) flow, and t represents sink quantity. The problem becomes significantly harder when aggregation is given as an option to bidders, requiring various enhancements to the basic multi-unit bipartite graph described above. In general, we consider traders that are either aggregating or not, with either divisible or AON offers. Initially we examine a special case, which at the same time  demonstrates the hardness of the problem but still carries computational advantages. We designate one side (e.g., buyers) as restrictive (AON and non-aggregating), and the other side (sellers) as unrestrictive (divisible and aggregating). This problem can be represented using the following integer programming formulation: max X i∈B,j∈S wij qij s.t. X i∈T (j) ¯qiqij ≤ ¯qj j ∈ S X j∈T (i) qij ≤ 1 i ∈ B qij ∈ {0, 1} j ∈ S, i ∈ B (3) This formulation is a restriction of the generalized assignment  problem (GAP) [13]. Although GAP is known to be NP-hard, it can be solved relatively efficiently by exact or approximate algorithms. GAP is more general than the formulation above as it allows  buyside quantities (¯qi above) to be different for each potential seller. That this formulation is NP-hard as well (even the case of a single seller corresponds to the knapsack problem), illustrates the drastic increase in complexity when traders with different constraints are admitted to the same problem instance. Other than the special case above, we found no advantage in  limiting AON constraints when traders may specify aggregation  constraints. Therefore, the next generalization allows any combination of the two boolean constraints, that is, any trader chooses among four bid types: NI Bid AON and not aggregating. AD Bid allows aggregation and divisibility. AI Bid AON, allows aggregation (quantity can be aggregated across configurations, as long as it sums to the whole amount). ND No aggregation, divisibility (one trade, but smaller quantities are acceptable). To formulate an integer programming representation for the  problem, we introduce the following variables. Boolean (0/1) variables ri and rj indicate whether buyer i and seller j participate in the solution (used for AON traders). Another indicator variable, yij , applied to non-aggregating buyer i and seller j, is one iff i trades with j. For aggregating traders, yij is not constrained. max X i∈B,j∈S Wij qij (4a) s.t. X j∈T (i) qij = ¯qiri i ∈ AIb (4b) X j∈T (i) qij ≤ ¯qiri i ∈ ADb (4c) X i∈T (j) qij = ¯qirj j ∈ AIs (4d) X i∈T (j) qij ≤ qj rj j ∈ ADs (4e) xij ≤ ¯qiyij i ∈ NDb , j ∈ T(i) (4f) xij ≤ ¯qj yij j ∈ NIs , i ∈ T(j) (4g) X j∈T (i) yij ≤ ri i ∈ NIb ∪ NDb (4h) X i∈T (j) yij ≤ rj j ∈ NIs ∪ NDs (4i) int qij (4j) yij , rj, ri ∈ {0, 1} (4k) 15 Figure 2: Generalized network flow model. B1 is a buyer in AD, B2 ∈ NI, B3 ∈ AI, B4 ∈ ND. V 1 is a seller in ND, V 2 ∈ AI, V 4 ∈ AD. The g values represent arc gains. Problem (4) has additional structure as a generalized min-cost flow problem with integral flow.5 A generalized flow network is a network in which each arc may have a gain factor, in addition to the pure network parameters (which are flow limits and costs). Flow in an arc is then multiplied by its gain factor, so that the flow that enters the end node of an arc equals the flow that entered from its start node, multiplied by the gain factor of the arc. The network model can in turn be translated into an IP formulation that captures such structure. The generalized min-cost flow problem is well-studied and has a multitude of efficient algorithms [1]. The faster algorithms are polynomial in the number of arcs and the logarithm of the maximal gain, that is, performance is not strongly polynomial but is  polynomial in the size of the input. The main benefit of this graphical formulation to our matching problem is that it provides a very  efficient linear relaxation. Integer programming algorithms such as branch-and-bound use solutions to the linear relaxation instance to bound the optimal integer solution. Since network flow algorithms are much faster than arbitrary linear programs (generalized network flow simplex algorithms have been shown to run in practice only 2 or 3 times slower than pure network min-cost flow [1]), we expect a branch-and-bound solver for the matching problem to show  improved performance when taking advantage of network flow  modeling. The network flow formulation is depicted in Figure 2.  Nonrestrictive traders are treated as in Figure 1. For a non-aggregating buyer, a single unit from the source will saturate up to one of the yij for all j, and be multiplied by ¯qi. If i ∈ ND, the end node of yij will function as a sink that may drain up to ¯qi of the entering flow. For i ∈ NI we use an indicator (0/1) arc ri, on which the flow is multiplied by ¯qi. Trader i trades the full quantity iff ri = 1. At the seller side, the end node of a qij arc functions as a source for sellers j ∈ ND, in order to let the flow through yij arcs be 0 or ¯qj. The flow is then multiplied by 1 ¯qj so 0/1 flows enter an end node which can drain either 1 or 0 units. for sellers j ∈ NI arcs rj ensure AON similarly to arcs rj for buyers. Having established this framework, we are ready to  accommo5 Constraint (4j) could be omitted (yielding computational savings) if non-integer quantities are allowed. Here and henceforth we  assume the harder problem, where divisibility is with respect to  integers. date more flexible versions of side constraints. The first  generalization is to replace the boolean AON constraint with divisibility down to q, the minimal quantity. In our network flow instance we simply need to turn the node of the constrained trader i (e.g., the node B3 in Figure 2) to a sink that can drain up to ¯qi − qi units of flow. The integer program (4) can be also easily changed to accommodate this extension. Using gains, we can also apply batch size constraints. If a trader specifies a batch size β, we change the gain on the r arcs to β, and set the available flow of its origin to the maximal number of batches ¯qi/β. .3 Nonlinear Pricing A key assumption in handling aggregation up to this point is linear pricing, which enables us to limit attention to a single unit price. Divisibility without linear pricing allows expression of  concave willingness-to-pay functions, corresponding to convex  preference relations. Bidders may often wish to express non-convex offer sets, for example, due to fixed costs or switching costs in  production settings [21]. We consider nonlinear pricing in the form of enumerated  payment schedules-that is, defining values ˆu(x, q) for a select set of quantities q. For the indivisible case, these points are distinguished in the offer set by satisfying the following: ∃π. (x, q, i, ∗, π) ∈ OT i ∧ ¬∃q < q. (x, q , i, ∗, π) ∈ OT i . (cf. Definition 8, which defines the maximum quantity, ¯q, as the largest of these.) For the divisible case, the distinguished quantities are those where the unit price changes, which can be formalized similarly. To handle nonlinear pricing, we augment the network to include flow possibilities corresponding to each of the enumerated  quantities, plus additional structure to enforce exclusivity among them. In other words, the network treats the offer for a given quantity as in Section 5.2, and embeds this in an XOR relation to ensure that each trader picks only one of these quantities. Since for each such quantity choice we can apply Theorem 3 or 4, the solution we get is in fact the solution to GMAP. The network representation of the XOR relation (which can be embedded into the network of Figure 2) is depicted in Figure 3. For a trader i with K XOR quantity points, we define dummy variables, zk i , k = 1, . . . , K. Since we consider trades between every pair of quantity points we also have qk ij , k = 1, . . . , K. For buyer i ∈ AI with XOR points at quantities ¯qk i , we replace (4b) with the following constraints: X j∈T (i) qk ij = ¯qk i zk i k = 1, . . . , K KX k=1 zk i = ri zk i ∈ {0, 1} k = 1, . . . , K (5) .4 Homogeneity Constraints The model (4) handles constraints over the aggregation of  quantities from different trading partners. When aggregation is allowed, the formulation permits trades involving arbitrary combinations of configurations. A homogeneity constraint [4] restricts such  combinations, by requiring that configurations aggregated in an overall deal must agree on some or all attributes. 16 Figure 3: Extending the network flow model to express an XOR over quantities. B2 has 3 XOR points for 6, 3, or 5 units. In the presence of homogeneity constraints, we can no longer apply the convenient separation of GMAP into MMP plus global bipartite optimization, as the solution to GMAP may include trades not part of any MMP solution. For example, let buyer b specify an offer for maximum quantity 10 of various acceptable  configurations, with a homogeneity constraint over the attribute color. This means b is willing to aggregate deals over different trading partners and configurations, as long as all are the same color. If seller s can provide 5 blue units or 5 green units, and seller s can provide only 5 green units, we may prefer that b and s trade on green units, even if the local surplus of a blue trade is greater. Let {x1, . . . , xH} be attributes that some trader constrains to be homogeneous. To preserve the network flow framework, we need to consider, for each trader, every point in the product domain of these homogeneous attributes. Thus, for every assignment ˆx to the homogeneous attributes, we compute MMP(b, s) under the constraint that configurations are consistent with ˆx. We apply the same approach as in Section 5.3: solve the global optimization, such that the alternative ˆx assignments for each trader are combined under XOR semantics, thus enforcing homogeneity constraints. The size of this network is exponential in the number of  homogeneous attributes, since we need a node for each point in the product domain of all the homogeneous attributes of each trader.6 Hence this solution method will only be tractable in applications were the traders can be limited to a small number of homogeneous attributes. It is important to note that the graph needs to include a node only for each point that potentially matches a point of the other side. It is therefore possible to make the problem tractable by limiting one of the sides to a less expressive bidding language, and by that limit the set of potential matches. For example, if sellers submit bounded sets of XOR points, we only need to consider the points in the  combined set offered by the sellers, and the reduction to network flow is polynomial regardless of the number of homogeneous attributes. If such simplifications do not apply, it may be preferable to solve the global problem directly as a single optimization problem. We provide the formulation for the special case of divisibility (with  respect to integers) and configuration parity. Let i index buyers, j sellers, and H homogeneous attributes. Variable xh ij ∈ Xh  represents the value of attribute Xh in the trade between buyer i and seller j. Integer variable qij represents the quantity of the trade (zero for no trade) between i and j.  If traders differ on which attributes they express such constraints, we can limit consideration to the relevant alternatives. The  complexity will still be exponential, but in the maximum number of homogeneous attributes for any pair of traders. max X i∈B,j∈S [ˆuB i (xij , qij ) − ˆuS j (xij , qij )] X j∈S qij ≤ ¯qi i ∈ B X i∈B qij ≤ ¯qj j ∈ S xh j = xh j = · · · = x|B|j j ∈ S, h ∈ {1, . . . , H} xh i1 = xh i2 = · · · = xi|S| i ∈ B, h ∈ {1, . . . , H} (6) Table 1 summarizes the mapping we presented from allocation constraints to the complexity of solving GMAP. Configuration  parity is assumed for all cases but the first. . EXPERIMENTAL RESULTS We approach the experimental aspect of this work with two  objectives. First, we seek a general idea of the sizes and types of  clearing problems that can be solved under given time constraints. We also look to compare the performance of a straightforward integer program as in (4) with an integer program that is based on the  network formulations developed here. Since we used CPLEX, a  commercial optimization tool, the second objective could be achieved to the extent that CPLEX can take advantage of network structure present in a model. We found that in addition to the problem size (in terms of number of traders), the number of aggregating traders plays a crucial role in determining complexity. When most of the traders are aggregating, problems of larger sizes can be solved quickly. For example, our IP model solved instances with 600 buyers and 500 sellers, where 0% of them are aggregating, in less than two minutes. When the aggregating ratio was reduced to 80% for the same data, solution time was just under five minutes. These results motivated us to develop a new network model. Rather than treat non-aggregating traders as a special case, the new model takes advantage of the single-unit nature of non-aggregating trades (treating the aggregating traders as a special case). This new model outperformed our other models on most problem instances, exceptions being those where aggregating traders constitute a vast majority (at least 80%). This new model (Figure 4) has a single node for each non  aggregating trader, with a single-unit arc designating a match to another non-aggregating trader. An aggregating trader has a node for each potential match, connected (via y arcs) to a mutual source node. Unlike the previous model we allow fractional flow for this case, representing the traded fraction of the buyer"s total quantity.7 We tested all three models on random data in the form of  bipartite graphs encoding MMP solutions. In our experiments, each trader has a maximum quantity uniformly distributed over [30, 70], and minimum quantity uniformly distributed from zero to maximal quantity. Each buyer/seller pair is selected as matching with  probability 0.75, with matches assigned a surplus uniformly distributed over [10, 70]. Whereas the size of the problem is defined by the number of traders on each side, the problem complexity depends on the product |B| × |S|. The tests depicted in Figures 5-7 are for the worst case |B| = |S|, with each data point averaged over six samples. In the figures, the direct IP (4) is designated SW, our first network model (Figure 2) NW, and our revised network model (Figure 4) NW 2.  Traded quantity remains integer. 17 Aggregation Hom. attr. Divisibility linear pricing Technique Complexity No aggregation N/A Any Not required Assignment problem Polynomial All aggregate None Down to 0 Required Transpor. problem Polynomial One side None Aggr side div. Aggr. side GAP NP-hard Optional None Down to q, batch Required Generalized ntwrk flow NP-hard Optional Bounded Down to q, batch Bounded size schdl. Generalized ntwrk flow NP-hard Optional Not bounded Down to q, batch Not required Nonlinear opt Depends on ˆu(x, q) Table 1: Mapping from combinations of allocation constraints to the solution methods of GMAP. One Side means that one side aggregates and divisible, and the other side is restrictive. Batch means that traders may submit batch sizes. Figure 4: Generalized network flow model. B1 is a buyer in AD, B2 ∈ AI, B3 ∈ NI, B4 ∈ ND. V 1 is a seller in AD, V 2 ∈ AI, V 4 ∈ ND. The g values represent arc gains, and W values represent weights. Figure 5: Average performance of models when 30% of traders aggregate. Figure 6: Average performance of models when 50% of traders aggregate. Figure 7: Average performance of models when 70% of traders aggregate. 18 Figure 8: Performance of models when varying percentage of aggregating traders Figure 8 shows how the various models are affected by a change in the percentage of aggregating traders, holding problem size fixed.8 Due to the integrality constraints, we could not test available  algorithms specialized for network-flow problems on our test  problems. Thus, we cannot fully evaluate the potential gain attributable to network structure. However, the model we built based on the insight from the network structure clearly provided a significant speedup, even without using a special-purpose algorithm. Model NW 2 provided speedups of a factor of 4-10 over the model SW. This was consistent throughout the problem sizes, including the smaller sizes for which the speedup is not visually apparent on the chart. . CONCLUSIONS The implementation and deployment of market exchanges  requires the development of bidding languages, information feedback policies, and clearing algorithms that are suitable for the target  domain, while paying heed to the incentive properties of the resulting mechanisms. For multiattribute exchanges, the space of feasible such mechanisms is constrained by computational limitations  imposed by the clearing process. The extent to which the space of feasible mechanisms may be quantified a priori will facilitate the search for such exchanges in the full mechanism design problem. In this work, we investigate the space of two-sided multiattribute auctions, focusing on the relationship between constraints on the offers traders can express through bids, and the resulting  computational problem of determining an optimal set of trades. We  developed a formal semantic framework for characterizing expressible offers, and introduced some basic classes of restrictions. Our key technical results identify sets of conditions under which the  overall matching problem can be separated into first identifying  optimal pairwise trades and subsequently optimizing combinations of those trades. Based on these results, we developed network flow models for the overall clearing problem, which facilitate  classification of problem versions by computational complexity, and provide guidance for developing solution algorithms and relaxing bidding constraints. . ACKNOWLEDGMENTS This work was supported in part by NSF grant IIS-0205435, and the STIET program under NSF IGERT grant 0114368. We are  All tests were performed on Intel 3.4 GHz processors with 2048 KB cache. Test that did not complete by the one-hour time limit were recorded as 4000 seconds. grateful to comments from an anonymous reviewer. Some of the underlying ideas were developed while the first two authors worked at TradingDynamics Inc. and Ariba Inc. in 1999-2001 (cf. US Patent 6,952,682). We thank Yoav Shoham, Kumar Ramaiyer, and Gopal Sundaram for fruitful discussions about multiattribute  auctions in that time frame. . REFERENCES [1] R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows. Prentice-Hall, 1993. [2] F. Bacchus and A. Grove. Graphical models for preference and utility. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 3-10, Montreal, 1995. [3] M. Bichler. The Future of e-Markets: Multi-Dimensional Market Mechanisms. Cambridge U. Press, New York, NY, USA, 2001. [4] M. Bichler and J. Kalagnanam. Configurable offers and winner determination in multi-attribute auctions. European Journal of Operational Research, 160:380-394, 2005. [5] M. Bichler, M. Kaukal, and A. Segev. Multi-attribute auctions for electronic procurement. In Proceedings of the 1st IBM IAC Workshop on Internet Based Negotiation Technologies, 1999. [6] C. Boutilier, T. Sandholm, and R. Shields. Eliciting bid taker non-price preferences in (combinatorial) auctions. In Nineteenth Natl. Conf. on Artificial Intelligence, pages 204-211, San Jose, 2004. [7] F. Branco. The design of multidimensional auctions. RAND Journal of Economics, 28(1):63-81, 1997. [8] Y.-K. Che. Design competition through multidimensional auctions. RAND Journal of Economics, 24(4):668-680, 1993. [9] G. Debreu. Topological methods in cardinal utility theory. In K. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Methods in the Social Sciences. Stanford University Press, 1959. [10] N. Economides and R. A. Schwartz. Electronic call market trading. Journal of Portfolio Management, 21(3), 1995. [11] Y. Engel and M. P. Wellman. Multiattribute utility representation for willingness-to-pay functions. Tech. report, Univ. of Michigan, 2006. [12] E. Fink, J. Johnson, and J. Hu. Exchange market for complex goods: Theory and experiments. Netnomics, 6(1):21-42, 2004. [13] M. L. Fisher, R. Jaikumar, and L. N. Van Wassenhove. A multiplier adjustment method for the generalized assignment problem. Management Science, 32(9):1095-1103, 1986. [14] J. Gong. Exchanges for complex commodities: Search for optimal matches. Master"s thesis, University of South Florida, 2002. [15] C. Gonzales and P. Perny. GAI networks for decision making under certainty. In IJCAI-05 workshop on preferences, Edinburgh, 2005. [16] J. R. Kalagnanam, A. J. Davenport, and H. S. Lee. Computational aspects of clearing continuous call double auctions with assignment constraints and indivisible demand. Electronic Commerce Research, (3):221-238, 2001. [17] R. L. Keeney and H. Raiffa. Decisions with Multiple Objectives: Preferences and Value Tradeoffs. Wiley, 1976. [18] N. Nisan. Bidding and allocation in combinatorial auctions. In Second ACM Conference on Electronic Commerce, pages 1-12, Minneapolis, MN, 2000. [19] D. C. Parkes and J. Kalagnanam. Models for iterative multiattribute procurement auctions. Management Science, 51:435-451, 2005. [20] T. Sandholm and S. Suri. Side constraints and non-price attributes in markets. In IJCAI-01 Workshop on Distributed Constraint Reasoning, Seattle, 2001. [21] L. J. Schvartzman and M. P. Wellman. Market-based allocation with indivisible bids. In AAMAS-05 Workshop on Agent-Mediated Electronic Commerce, Utrecht, 2005. [22] J. Shachat and J. T. Swarthout. Procurement auctions for differentiated goods. Technical Report 0310004, Economics Working Paper Archive at WUSTL, Oct. 2003. [23] A. V. Sunderam and D. C. Parkes. Preference elicitation in proxied multiattribute auctions. In Fourth ACM Conference on Electronic Commerce, pages 214-215, San Diego, 2003. [24] P. R. Wurman, M. P. Wellman, and W. E. Walsh. A parametrization of the auction design space. Games and Economic Behavior, 5:304-338, 2001. 19
(In)Stability Properties of Limit Order Dynamics Eyal Even-Dar ∗ Sham M. Kakade † Michael Kearns ‡ Yishay Mansour § ABSTRACT We study the stability properties of the dynamics of the standard continuous limit-order mechanism that is used in modern equity markets. We ask whether such mechanisms are susceptible to butterfly effects - the infliction of large changes on common measures of market activity by only small perturbations of the order sequence. We show that the answer depends strongly on whether the market consists of absolute traders (who determine their prices independent of the current order book state) or relative traders (who determine their prices relative to the current bid and ask). We prove that while the absolute trader model enjoys  provably strong stability properties, the relative trader model is vulnerable to great instability. Our theoretical results are supported by large-scale experiments using limit order data from INET, a large electronic exchange for NASDAQ stocks. Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics General Terms Economics, Theory . INTRODUCTION In recent years there has been an explosive increase in the automation of modern equity markets. This increase has taken place both in the exchanges, which are  increasingly computerized and offer sophisticated interfaces for  order placement and management, and in the trading  activity itself, which is ever more frequently undertaken by  software. The so-called Electronic Communication Networks (or ECNs) that dominate trading in NASDAQ stocks are a  common example of the automation of the exchanges. On the trading side, computer programs now are entrusted not only with the careful execution of large block trades for clients (sometimes referred to on Wall Street as program trading), but with the autonomous selection of stocks, direction (long or short) and volumes to trade for profit (commonly referred to as statistical arbitrage). The vast majority of equity trading is done via the  standard limit order market mechanism. In this mechanism, continuous trading takes place via the arrival of limit  orders specifying whether the party wishes to buy or sell, the volume desired, and the price offered. Arriving limit orders that are entirely or partially executable with the best offers on the other side are executed immediately, with any  volume not immediately executable being placed in an queue (or book) ordered by price on the appropriate side (buy or sell). (A detailed description of the limit order mechanism is given in Section 3.) While traders have always been able to view the prices at the top of the buy and sell books (known as the bid and ask), a relatively recent development in  certain exchanges is the real-time revelation of the entire order book - the complete distribution of orders, prices and  volumes on both sides of the exchange. With this revelation has come the opportunity - and increasingly, the  needfor modeling and exploiting limit order data and  dynamics. It is fair to say that market microstructure, as this area is generally known, is a topic commanding great interest both in the real markets and in the academic finance  literature. The opportunities and needs span the range from the optimized execution of large trades to the creation of stand-alone proprietary strategies that attempt to profit from high-frequency microstructure signals. In this paper we investigate a previously unexplored but fundamental aspect of limit order microstructure: the  stability properties of the dynamics. Specifically, we are  interested in the following natural question: To what extent are simple models of limit order markets either susceptible or immune to butterfly effects - that is, the infliction of large changes in important activity statistics (such as the 20 number of shares traded or the average price per share) by only minor perturbations of the order sequence? To examine this question, we consider two stylized but natural models of the limit order arrival process. In the  absolute price model, buyers and sellers arrive with limit order prices that are determined independently of the current state of the market (as represented by the order books), though they may depend on all manner of exogenous information or shocks, such as time, news events, announcements from the company whose shares are being traded, private signals or state of the individual traders, etc. This process models traditional fundamentals-based trading, in which market participants each have some inherent but possibly varying valuation for the good that in turn determines their limit price. In contrast, in the relative price model, traders express their limit order prices relative to the best price offered in their respective book (buy or sell). Thus, a buyer would encode their limit order price as an offset ∆ (which may be positive, negative, or zero) from the current bid pb, which is then translated to the limit price pb +∆. Again, in addition to now depending on the state of the order books, prices may also depend on all manner of exogenous information. The relative price model can be viewed as modeling traders who, in addition to perhaps incorporating fundamental  external information on the stock, may also position their  orders strategically relative to the other orders on their side of the book. A common example of such strategic  behavior is known as penny-jumping on Wall Street, in which a trader who has in interest in buying shares quickly, but still at a discount to placing a market order, will  deliberately position their order just above the current bid. More generally, the entire area of modern execution optimization [9, 10, 8] has come to rely heavily on the careful positioning of limit orders relative to the current order book state. Note that such positioning may depend on more complex features of the order books than just the current bid and ask, but the relative model is a natural and simplified starting point. We remark that an alternate view of the two models is that all traders behave in a relative manner, but with absolute traders able to act only on a considerably slower time scale than the faster relative traders. How do these two models differ? Clearly, given any fixed sequence of arriving limit order prices, we can choose to  express these prices either as their original (absolute) values, or we can run the order book dynamical process and  transform each order into a relative difference with the top of its book, and obtain identical results. The differences arise when we consider the stability question introduced above. Intuitively, in the absolute model a small perturbation in the arriving limit price sequence should have limited (but still some) effects on the subsequent evolution of the order books, since prices are determined independently. For the relative model this intuition is less clear. It seems possible that a small perturbation could (for example) slightly  modify the current bid, which in turn could slightly modify the price of the next arriving order, which could then slightly modify the price of the subsequent order, and so on, leading to an amplifying sequence of events. Our main results demonstrate that these two models do indeed have dramatically different stability properties. We first show that for any fixed sequence of prices in the  absolute model, the modification of a single order has a bounded and extremely limited impact on the subsequent evolution of the books. In particular, we define a natural notion of distance between order books and show that small  modifications can result in only constant distance to the original books for all subsequent time steps. We then show that this implies that for almost any standard statistic of market  activity - the executed volume, the average price execution price, and many others - the statistic can be influenced only infinitesimally by small perturbations. In contrast, we show that the relative model enjoys no such stability properties. After giving specific (worst-case) relative price sequences in which small perturbations  generate large changes in basic statistics (for example, altering the number of shares traded by a factor of two), we proceed to demonstrate that the difference in stability properties of the two models is more than merely theoretical. Using  extensive INET (a major ECN for NASDAQ stocks) limit order data and order book reconstruction code, we investigate the empirical stability properties when the data is interpreted as containing either absolute prices, relative prices, or  mixtures of the two. The theoretical predictions of stability and instability are strongly borne out by the subsequent  experiments. In addition to stability being of fundamental interest in any important dynamical system, we believe that the  results described here provide food for thought on the  topics of market impact and the backtesting of quantitative trading strategies (the attempt to determine hypothetical past performance using historical data). They suggest that one"s confidence that trading quietly and in small  volumes will have minimal market impact is linked to an  implicit belief in an absolute price model. Our results and the fact that in the real markets there is a large and increasing amount of relative behavior such as penny-jumping would seem to cast doubts on such beliefs. Similarly, in a purely or largely relative-price world, backtesting even low-frequency, low-volume strategies could result in historical estimates of performance that are not only unrelated to future  performance (the usual concern), but are not even accurate  measures of a hypothetical past. The outline of the paper follows. In Section 2 we briefly review the large literature on market microstructure. In Section 3 we describe the limit order mechanism and our formal models. Section 4 presents our most important  theoretical results, the 1-Modification Theorem for the absolute price model. This theorem is applied in Section 5 to derive a number of strong stability properties in the absolute model. Section 6 presents specific examples establishing the  worstcase instability of the relative model. Section 7 contains the simulation studies that largely confirm our theoretical findings on INET market data. . RELATED WORK As was mentioned in the Introduction, market  microstructure is an important and timely topic both in academic  finance and on Wall Street, and consequently has a large and varied recent literature. Here we have space only to  summarize the main themes of this literature and to provide pointers to further readings. To our knowledge the stability properties of detailed limit order microstructure dynamics have not been previously considered. (However, see Farmer and Joshi [6] for an example and survey of other price  dynamic stability studies.) 21 On the more theoretical side, there is a rich line of work  examining what might be considered the game-theoretic  properties of limit order markets. These works model traders and market-makers (who provide liquidity by offering both buy and sell quotes, and profit on the difference) by utility functions incorporating tolerance for risks of price  movement, large positions and other factors, and examine the resulting equilibrium prices and behaviors. Common  findings predict negative price impacts for large trades, and price effects for large inventory holdings by market-makers. An excellent and comprehensive survey of results in this area can be found in [2]. There is a similarly large body of empirical work on  microstructure. Major themes include the measurement of price impacts, statistical properties of limit order books, and attempts to establish the informational value of order books [4]. A good overview of the empirical work can be found in [7]. Of particular note for our interests is [3], which  empirically studies the distribution of arriving limit order prices in several prominent markets. This work takes a view of  arriving prices analogous to our relative model, and establishes a power-law form for the resulting distributions. There is also a small but growing number of works  examining market microstructure topics from a computer  science perspective, including some focused on the use of  microstructure in algorithms for optimized trade execution. Kakade et al. [9] introduced limit order dynamics in  competitive analysis for one-way and volume-weighted average price (VWAP) trading. Some recent papers have applied  reinforcement learning methods to trade execution using order book properties as state variables [1, 5, 10]. . MICROSTRUCTURE PRELIMINARIES The following expository background material is adapted from [9]. The market mechanism we examine in this paper is driven by the simple and standard concept of a limit  order. Suppose we wish to purchase 1000 shares of Microsoft (MSFT) stock. In a limit order, we specify not only the desired volume (1000 shares), but also the desired price. Suppose that MSFT is currently trading at roughly $24.07 a share (see Figure 1, which shows an actual snapshot of an MSFT order book on INET), but we are only willing to buy the 1000 shares at $24.04 a share or lower. We can choose to submit a limit order with this specification, and our order will be placed in a queue called the buy order book, which is ordered by price, with the highest offered unexecuted buy price at the top (often referred to as the bid). If there are multiple limit orders at the same price, they are ordered by time of arrival (with older orders higher in the book). In the example provided by Figure 1, our order would be placed immediately after the extant order for 5,503 shares at $24.04; though we offer the same price, this order has arrived before ours. Similarly, a sell order book for sell limit orders is maintained, this time with the lowest sell price offered (often referred to as the ask) at its top. Thus, the order books are sorted from the most  competitive limit orders at the top (high buy prices and low sell prices) down to less competitive limit orders. The bid and ask prices together are sometimes referred to as the inside market, and the difference between them as the spread. By definition, the order books always consist exclusively of  unexecuted orders - they are queues of orders hopefully  waiting for the price to move in their direction. Figure 1: Sample INET order books for MSFT. How then do orders get (partially) executed? If a buy (sell, respectively) limit order comes in above the ask  (below the bid, respectively) price, then the order is matched with orders on the opposing books until either the incoming order"s volume is filled, or no further matching is possible, in which case the remaining incoming volume is placed in the books. For instance, suppose in the example of Figure 1 a buy order for 2000 shares arrived with a limit price of $24.08. This order would be partially filled by the two 500-share sell orders at $24.069 in the sell books, the 500-share sell order at $24.07, and the 200-share sell order at $24.08, for a total of 1700 shares executed. The remaining 300 shares of the incoming buy order would become the new bid of the buy book at $24.08. It is important to note that the prices of executions are the prices specified in the limit orders already in the books, not the prices of the incoming order that is immediately executed. Thus in this example, the 700 executed shares would be at different prices. Note that this also means that in a pure limit order exchange such as INET, market orders can be simulated by limit orders with extreme price values. In exchanges such as INET, any order can be withdrawn or canceled by the party that placed it any time prior to execution. Every limit order arrives atomically and instantaneously - there is a strict temporal sequence in which orders arrive, and two orders can never arrive simultaneously. This gives rise to the definition of the last price of the exchange, which is simply the last price at which the exchange executed an order. It is this quantity that is usually meant when people casually refer to the (ticker) price of a stock. .1 Formal Definitions We now provide a formal model for the limit order  pro122 cess described above. In this model, limit orders arrive in a temporal sequence, with each order specifying its limit price and an indication of its type (buy or sell). Like the actual exchanges, we also allow cancellation of a standing  (unexecuted) order in the books any time prior to its execution. Without loss of generality we limit attention to a model in which every order is for a single share; large order volumes can be represented by 1-share sequences. Definition 3.1. Let Σ = σ1, ...σn be a sequence of limit orders, where each σi has the form ni, ti, vi . Here ni is an order identifier, ti is the order type (buy, sell, or cancel), and vi is the limit order value. In the case that ti is a cancel, ni matches a previously placed order and vi is ignored. We have deliberately called vi in the definition above the limit order value rather than price, since our two models will differ in their interpretation of vi (as being absolute or relative). In the absolute model, we do indeed interpret vi as simply being the price of the limit order. In the  relative model, if the current order book configuration is (A, B) (where A is the sell and B the buy book), the price of the order is ask(A) + vi if ti is sell, and bid(B) + vi if ti is buy, where by ask(X) and bid(X) we denote the price of the order at the top of the book X. (Note vi can be negative.) Our main interest in this paper is the effects that the  modification of a small number of limit orders can have on the resulting dynamics. For simplicity we consider only  modifications to the limit order values, but our results generalize to any modification. Definition 3.2. A k-modification of Σ is a sequence Σ such that for exactly k indices i1, ..., ik vij = vij , tij = tij , and nij = nij . For every = ij , j ∈ {1, . . . , k} σ = σ . We now define the various quantities whose stability  properties we examine in the absolute and relative models. All of these are standard quantities of common interest in financial markets. • volume(Σ): Number of shares executed (traded) in the sequence Σ. • average(Σ): Average execution price. • close(Σ): Price of the last (closing) execution. • lastbid(Σ): Bid at the end of the sequence. • lastask(Σ): Ask at end of the sequence. . THE 1-MODIFICATION THEOREM In this section we provide our most important technical result. It shows that in the absolute model, the effects that the modification of a single order has on the resulting  evolution of the order books is extremely limited. We then apply this result to derive strong stability results for all of the aforementioned quantities in the absolute model. Throughout this section, we consider an arbitrary order sequence Σ in the absolute model, and any 1-modification Σ of Σ. At any point (index) i in the two sequences we shall use (A1, B1) to denote the sell and buy books (respectively) in Σ, and (A2, B2) to denote the sell and buy books in Σ ; for notational convenience we omit explicitly superscripting by the current index i. We will shortly establish that at all times i, (A1, B1) and (A2, B2) are very close. Although the order books are sorted by price, we will use (for example) A1 ∪ {a2} = A2 to indicate that A2 contains an order at some price a2 that is not present in A1, but that otherwise A1 and A2 are identical; thus deleting the order at a2 in A2 would render the books the same. Similarly, B1 ∪ {b2} = B2 ∪ {b1} means B1 contains an order at price b1 not present in B2, B2 contains an order at price b2 not present in B1, and that otherwise B1 and B2 are identical. Using this notation, we now define a set of stable system states, where each state is composed from the order books of the original and the modified sequences. Shortly we show that if we change only one order"s value (price), we remain in this set for any sequence of limit orders. Definition 4.1. Let ab be the set of all states (A1, B1) and (A2, B2) such that A1 = A2 and B1 = B2. Let ¯ab be the set of states such that A1 ∪ {a2} = A2 ∪ {a1}, where a1 = a2, and B1 = B2. Let a¯b be the set of states such that B1∪{b2} = B2∪{b1}, where b1 = b2, and A1 = A2. Let ¯a¯b be the set of states in which A1 = A2∪{a1} and B1 = B2∪{b1}, or in which A2 = A1 ∪ {a2} and B2 = B1 ∪ {b2}. Finally we define S = ab ∪ ¯ab ∪ ¯ba ∪ ¯a¯b as the set of stable states. Theorem 4.1. (1-Modification Theorem) Consider any sequence of orders Σ and any 1-modification Σ of Σ. Then the order books (A1, B1) and (A2, B2) determined by Σ and Σ lie in the set S of stable states at all times. ab ¯a¯b a¯b¯ab Figure 2: Diagram representing the set S of stable states and the possible movements transitions in it after the change. The idea of the proof of this theorem is contained in  Figure 2, which shows a state transition diagram labeled by the categories of stable states. This diagram describes all  transitions that can take place after the arrival of the order on which Σ and Σ differ. The following establishes that  immediately after the arrival of this differing order, the state lies in S. Lemma 4.2. If at any time the current books (A1, B1) and (A2, B2) are in the set ab (and thus identical), then  modifying the price of the next order keeps the state in S. Proof. Suppose the arriving order is a sell order and we change it from a1 to a2; assume without loss of generality that a1 > a2. If neither order is executed immediately, then we move to state ¯ab; if both of them are executed then we stay in state ab; and if only a2 is executed then we move to state ¯a¯b. The analysis of an arriving buy order is similar. Following the arrival of their only differing order, Σ and Σ are identical. We now give a sequence of lemmas showing 23 Executed with two orders Not executed in both Arrivng buy order Arriving buy order Arriving buy order Arriving sell order ¯ab ab ¯a¯b Executed only with a1 (not a1 and a2) Executed with a1 and a2 Figure 3: The state diagram when starting at state ¯ab. This diagram provides the intuition of Lemma .3 that following the initial difference covered by Lemma 4.2, the state remains in S forever on the remaining (identical) sequence. We first show that from state ¯ab we remain in S regardless the next order. The intuition of this lemma is demonstrated in Figure 3. Lemma 4.3. If the current state is in the set ¯ab, then for any order the state will remain in S. Proof. We first provide the analysis for the case of an  arriving sell order. Note that in ¯ab the buy books are identical (B1 = B2). Thus either the arriving sell order is executed with the same buy order in both buy books, or it is not executed in both buy books. For the first case, the buy books remain identical (the bid is executed in both) and the sell books remain unchanged. For the second case, the buy books remain unchanged and identical, and the sell books have the new sell order added to both of them (and thus still differ by one order). Next we provide an analysis of the more subtle case where the arriving item is a buy order. For this case we need to take care of several different scenarios. The first is when the top of both sell books (the ask) is identical. Then  regardless of whether the new buy order is executed or not, the state remains in ¯ab (the analysis is similar to an arriving sell order). We are left to deal with case where ask(A1) and ask(A2) are different. Here we discuss two subcases: (a) ask(A1) = a1 and ask(A2) = a2, and (b) ask(A1) = a1 and ask(A2) = a . Here a1 and a2 are as in the definition of ¯ab in  Definition 4.1, and a is some other price. For subcase (a), by our assumption a1 < a2, then either (1) both asks get executed, the sell books become identical, and we move to state ab; (2) neither ask is executed and we remain in state ¯ab; or (3) only ask(A1) = a1 is executed, in which case we move to state ¯a¯b with A2 = A1 ∪ {a2} and B2 = B1 ∪ {b2}, where b2 is the arriving buy order price. For subcase (b), either (1) buy order is executed in neither sell book we remain in state ¯ab; or (2) the buy order is executed in both sell books and stay in state ¯ab with A1 ∪ {a } = A2 ∪ {a2}; or (3) only ask(A1) = a1 is executed and we move to state ¯a¯b. Lemma 4.4. If the current state is in the set a¯b, then for any order the state will remain in S. Lemma 4.5. If the current configuration is in the set ¯a¯b, then for any order the state will remain in S The proofs of these two lemmas are omitted, but are  similar in spirit to that of Lemma 4.3. The next and final lemma deals with cancellations. Lemma 4.6. If the current order book state lies in S, then following the arrival of a cancellation it remains in S. Proof. When a cancellation order arrives, one of the  following possibilities holds: (1) the order is still in both sets of books, (2) it is not in either of them and (3) it is only in one of them. For the first two cases it is easy to see that the  cancellation effect is identical on both sets of books, and thus the state remains unchanged. For the case when the order appears only in one set of books, without loss of generality we assume that the cancellation cancels a buy order at b1. Rather than removing b1 from the book we can change it to have price 0, meaning this buy order will never be executed and is effectively canceled. Now regardless the state that we were in, b1 is still only in one buy book (but with a different price), and thus we remain in the same state in S. The proof of Theorem 4.1 follows from the above lemmas. . ABSOLUTE MODEL STABILITY In this section we apply the 1-Modification Theorem to show strong stability properties for the absolute model. We begin with an examination of the executed volume. Lemma 5.1. Let Σ be any sequence and Σ be any  modification of Σ. Then the set of the executed orders (ID numbers) generated by the two sequences differs by at most . Proof. By Theorem 4.1 we know that at each stage the books differ by at most two orders. Now since the union of the IDs of the executed orders and the order books is always identical for both sequences, this implies that the executed orders can differ by at most two. Corollary 5.2. Let Σ be any sequence and Σ be any  kmodification of Σ. Then the set of the executed orders (ID numbers) generated by the two sequences differs by at most k. An order sequence Σ is a k-extension of Σ if Σ can be obtained by deleting any k orders in Σ . Lemma 5.3. Let Σ be any sequence and let Σ be any  kextension of Σ. Then the set of the executed orders generated by Σ and Σ differ by at most 2k. This lemma is the key to obtain our main absolute model volume result below. We use edit(Σ, Σ ) to denote the  standard edit distance between the sequences Σ and Σ - the minimal number of substitutions, insertions and deletions or orders needed to change Σ to Σ . Theorem 5.4. Let Σ and Σ be any absolute model order sequences. Then if edit(Σ, Σ ) ≤ k, the set of the executed orders generated by Σ and Σ differ by at most 4k. In  particular, |volume(Σ) − volume(Σ )| ≤ 4k. Proof. We first define the sequence ˜Σ which is the  intersection of Σ and Σ . Since Σ and Σ are at most k apart,we have that by k insertions we change ˜Σ to either Σ or Σ , and by Lemma 5.3 its set of executed orders is at most 2k from each. Thus the set of executed orders in Σ and Σ is at most k apart. 24 .1 Spread Bounds Theorem 5.4 establishes strong stability for executed  volume in the absolute model. We now turn to the quantities that involve execution prices as opposed to volume alone - namely, average(Σ), close(Σ), lastbid(Σ) and lastask(Σ). For these results, unlike executed volume, a condition must hold on Σ in order for stability to occur. This condition is expressed in terms of a natural measure of the spread of the market, or the gap between the buyers and sellers. We motivate this condition by first showing that without it, by changing one order, we can change average(Σ) by any  positive value x. Lemma 5.5. There exists Σ such that for any x ≥ 0, there is a 1-modification Σ of Σ such that average(Σ ) = average(Σ) + x. Proof. Let Σ be a sequence of alternating sell and buy orders in which each seller offers p and each buyer p + x, and the first order is a sell. Then all executions take place at the ask, which is always p, and thus average(Σ) = p. Now suppose we modify only the first sell order to be at price p+1+x. This initial sell order will never be executed, and now all executions take place at the bid, which is always p + x. Similar instability results can be shown to hold for the other price-based quantities. This motivates the  introduction of a quantity we call the second spread of the order books, which is defined as the difference between the prices of the second order in the sell book and the second order in the buy book (as opposed to the bid-ask difference, which is commonly called the spread). We note that in a liquid stock, such as those we examine experimentally in Section 7, the second spread will typically be quite small and in fact almost always equal to the spread. In this subsection we consider changes in the sequence only after an initialization period, and sequences such that the second spread is always defined after the time we make a change. We define s2(Σ) to be the maximum second spread in the sequence Σ following the change. Theorem 5.6. Let Σ be a sequence and let Σ be any  modification of Σ. Then . |lastbid(Σ) − lastbid(Σ )| ≤ s2(Σ) . |lastask(Σ) − lastask(Σ )| ≤ s2(Σ) where s2(Σ) is the maximum over the second spread in Σ following the 1-modification. Proof. We provide the proof for the last bid; the proof for the last ask is similar. The proof relies on Theorem 4.1 and considers states in the stable set S. For states ab and ¯ab, we have that the bid is identical. Let bid(X), sb(X), ask(X), be the bid, the second highest buy order, and the ask of a sequence X. Now recall that in state a¯b we have that the sell books are identical, and that the two buy books are identical except one different order. Thus bid(Σ)+s2(Σ) ≥ sb(Σ)+s2(Σ) ≥ ask(Σ) = ask(Σ ) ≥ bid(Σ ). Now it remains to bound bid(Σ). Here we use the fact that the bid of the modified sequence is at least the second  highest buy order in the original sequence, due to the fact that the books are different only in one order. Since bid(Σ ) ≥ sb(Σ) ≥ ask(Σ) − s2(Σ) ≥ bid(Σ) − s2(Σ) we have that |bid(Σ) − bid(Σ )| ≤ s2(Σ) as desired. In state ¯a¯b we have that for one sequence the books  contain an additional buy order and an additional sell order. First suppose that the books containing the additional  orders are the original sequence Σ. Now if the bid is not the additional order we are done, otherwise we have the  following: bid(Σ) ≤ ask(Σ) ≤ sb(Σ) + s2(Σ) = bid(Σ ) + s2(Σ), where sb(Σ) ≤ bid(Σ ) since the original buy book has only one additional order. Now assume that the books with the additional orders are for the modified sequence Σ . We have bid(Σ) + s2(Σ) ≥ ask(Σ) ≥ ask(Σ ) ≥ bid(Σ ), where we used the fact that ask(Σ) ≥ ask(Σ ) since the modified sequence has an additional order. Similarly we have that bid(Σ) ≤ bid(Σ ) since the modified buy book contains an additional order. We note that the proof of Theorem 5.6 actually establishes that the bid and ask of the original and modified sequences are within s2(Σ) at all times. Next we provide a technical lemma which relates the (first) spread of the modified sequence to the second spread of the original sequence. Lemma 5.7. Let Σ be a sequence and let Σ be any  modification of Σ. Then the spread of Σ is bounded by s2(Σ). Proof. By the 1-Modification Theorem, we know that the books of the modified sequence and the original sequence can differ by at most one order in each book (buy and sell). Therefore, the second-highest buy order in the original  sequence is always at most the bid in the modified sequence, and the second-lowest sell order in the original sequence is always at least the ask of the modified sequence. We are now ready to state a stability result for the average execution price in the absolute model. It establishes that in highly liquid markets, where the executed volume is large and the spread small, the average price is highly stable. Theorem 5.8. Let Σ be a sequence and let Σ be any  modification of Σ. Then |average(Σ) − average(Σ )| ≤ (pmax + s2(Σ)) volume(Σ) + s2(Σ) where pmax is the highest execution price in Σ. Proof. The proof will show that every execution in Σ besides the execution of the modified order and the last  execution has a matching execution in Σ with a price different by at most s2(Σ), and will use the fact that pmax + s2(Σ) is a bound on the price in Σ . Referring to the proof of the 1-Modification Theorem,  suppose we are in state ¯a¯b, where we have in one sequence (which can be either Σ or Σ ) an additional buy order b and an additional sell order a. Without loss of generality we assume that the sequence with the additional orders is Σ. If the next execution does not involve a or b then clearly we have the same execution in both Σ and Σ . Suppose that it involves a; there are two possibilities. Either a is the modified order, in which case we change the average price 25 difference by (pmax +s2(Σ))/volume(Σ), and this can happen only once; or a was executed before in Σ and the executions both involve an order whose limit price is a. By Lemma 5.7 the spread of both sequences is bounded by s2(Σ), which implies that the price of the execution in Σ was at most a + s2(Σ), while execution is in Σ is at price a, and thus the prices are different by at most s2(Σ). In states ¯ab, a¯b as long as we have concurrent executions in the two sequences, we know that the prices can differ by at most s2(Σ). If we have an execution only in one sequence, we either match it in state ¯a¯b, or charge it by (pmax + s2(Σ))/volume(Σ) if we end at state ¯a¯b. If we end in state ab, ¯ab or a¯b, then every execution in states ¯ab or a¯b were matched to an execution in state ¯a¯b. If we end up in state ¯a¯b, we have the one execution that is not matched and thus we charge it (pmax +s2(Σ))/volume(Σ). We next give a stability result for the closing price. We first provide a technical lemma regarding the prices of  consecutive executions. Lemma 5.9. Let Σ be any sequence. Then the prices of two consecutive executions in Σ differ by at most s2(Σ). Proof. Suppose the first execution is taken at time t; its price is bounded below by the current bid and above by the current ask. Now after this execution the bid is at least the second highest buy order at time t, if the former bid was executed and no higher buy orders arrived, and higher otherwise. Similarly, the ask is at most the second lowest sell order at time t. Therefore, the next execution price is at least the second bid at time t and at most the second ask at time t, which is at most s2(Σ) away from the bid/ask at time t. Lemma 5.10. Let Σ be any sequence and let Σ be a  modification of Σ. If the volume(Σ) ≥ 2, then |close(Σ) − close(Σ )| ≤ s2(Σ) Proof. We first deal with case where the last execution occurs in both sequences simultaneously. By Theorem 5.6, both the ask and the bid of Σ and Σ are at most s2(Σ) apart at every time t. Since the price of the last execution is their asks (bids) at time t we are done. Next we deal with the case where the last execution among the two sequences occurs only in Σ. In this case we know that either the previous execution happened simultaneously in both sequences at time t, and thus all three executions are within the second spread of Σ at time t (the first execution in Σ by definition, the execution at Σ from identical  arguments as in the former case, and the third by Lemma 5.9). Otherwise the previous execution happened only in Σ at time t, in which case the two executions are within the the spread of Σ at time t (the execution of Σ from the same arguments as before, and the execution in Σ must be inside its spread in time t). If the last execution happens only in Σ we know that the next execution of Σ will be at most s2(Σ) away from its previous execution by Lemma 5.9. Together with the fact that if an execution happens only in one sequence it implies that the order is in the spread of the second sequence as long as the sequences are 1-modification, the proof is completed. .2 Spread Bounds for k-Modifications As in the case of executed volume, we would like to extend the absolute model stability results for price-based  quantities to the case where multiple orders are modified. Here our results are weaker and depend on the k-spread, the distance between the kth highest buy order and the kth lowest sell order, instead of the second spread. (Looking ahead to  Section 7, we note that in actual market data for liquid stocks, this quantity is often very small as well.) We use sk(Σ) to denote the k-spread. As before, we assume that the k-spread is always defined after an initialization period. We first state the following generalization of Lemma 5.7. Lemma 5.11. Let Σ be a sequence and let Σ be any  modification of Σ. For ≥ 1, if s +1(Σ) is always defined after the change, then s (Σ ) ≤ s +1(Σ). The proof is similar to the proof of Lemma 5.7 and  omitted. A simple application of this lemma is the following: Let Σ be any sequence which is an -modification of Σ. Then we have s2(Σ ) ≤ s +2(Σ). Now using the above lemma and by simple induction we can obtain the following theorem. Theorem 5.12. Let Σ be a sequence and let Σ be any k-modification of Σ. Then . |lastbid(Σ) − lastbid(Σ )| ≤ Pk =1 s +1(Σ) ≤ ksk+1(Σ) . |lastask(Σ)−lastask(Σ )| ≤ Pk =1 s +1(Σ) ≤ ksk+1(Σ) . |close(Σ) − close(Σ )| ≤ Pk =1 s +1(Σ) ≤ ksk+1(Σ) . |average(Σ) − average(Σ )| ≤ Pk =1  (pmax +s +1(Σ)) volume(Σ) + s +1(Σ)  where s (Σ) is the maximum over the -spread in Σ following the first modification. We note that while these bounds depend on deeper  measures of spread for more modifications, we are working in a 1-share order model. Thus in an actual market, where single orders contain hundreds or thousands of shares, the k-spread even for large k might be quite small and close to the standard 1-spread in liquid stocks. . RELATIVE MODEL INSTABILITY In the relative model the underlying assumption is that traders try to exploit their knowledge of the books to  strategically place their orders. Thus if a trader wants her buy order to be executed quickly, she may position it above the current bid and be the first in the queue; if the trader is  patient and believes that the price trend is going to be  downward she will place orders deeper in the buy book, and so on. While in the previous sections we showed stability results for the absolute model, here we provide simple examples which show instability in the relative model for the  executed volume, last bid, last ask, average execution price and the last execution price. In Section 7 we provide many  simulations on actual market data that demonstrate that this instability is inherent to the relative model, and not due to artificial constructions. In the relative model we assume that for every sequence the ask and bid are always defined, so the books have a non-empty initial configuration. 26 We begin by showing that in the relative model, even a single modification can double the number of shares  executed. Theorem 6.1. There is a sequence Σ and a 1-modification Σ of Σ such that volume(Σ ) ≥ 2volume(Σ). Proof. For concreteness we assume that at the  beginning the ask is 10 and the bid is 8. The sequence Σ is composed from n buy orders with ∆ = 0, followed by n sell orders with ∆ = 0, and finally an alternating sequence of buy orders with ∆ = +1 and sell orders with ∆ = −1 of length 2n. Since the books before the alternating sequence contain n + 1 sell orders at 10 and n + 1 buy orders at 8, we have that each pair of buy sell order in the alternating part is matched and executed, but none of the initial 2n orders is executed, and thus volume(Σ) = n. Now we change the first buy order to have ∆ = +1. After the first 2n orders there are still no executions; however, the books are  different. Now there are n + 1 sell orders at 10, n buy orders at 9 and one buy order at 8. Now each order in the alternating sequence is executed with one of the former orders and we have volume(Σ ) = 2n. The next theorem shows that the spread-based stability results of Section 5.1 do not also hold in the relative model. Before providing the proof, we give its intuition. At the  beginning the sell book contains only two prices which are far apart and both contain only two orders, now several buy orders arrive, at the original sequence they are not being executed, while in the modified sequence they will be  executed and leave the sell book with only the orders at the high price. Now many sell orders followed by many buy orders will arrive, such that in the original sequence they will be executed only at the low price and in the modified sequence they will executed at the high price. Theorem 6.2. For any positive numbers s and x, there is sequence Σ such that s2(Σ) = s and a 1-modification Σ of Σ such that • |close(Σ) − close(Σ )| ≥ x • |average(Σ) − average(Σ )| ≥ x • |lastbid(Σ) − lastbid(Σ )| ≥ x • |lastask(Σ) − lastask(Σ )| ≥ x Proof. Without loss of generality let us consider sequences in which all prices are integer-valued, in which case the smallest possible value for the second spread is 1; we provide the proof for the case s2(Σ) = 2, but the s2(Σ) = 1 case is similar. We consider a sequence Σ such that after an initialization period there have been no executions, the buy book has  orders at price 10, and the sell book has two orders at price 12 and 2 orders with value 12+y, where y is a positive integer that will be determined by the analysis. The original sequence Σ is a buy order with ∆ = 0, followed by two buy orders with ∆ = +1, then 2y sell orders with ∆ = 0, and then 2y buy orders with ∆ = +1. We first note that s2(Σ) = 2, there are 2y executions, all at price 12, the last bid is 11 and the last ask is 12. Next we analyze a modified sequence. We change the first buy order from ∆ = 0 to ∆ = +1. Therefore, the next two buy orders with ∆ = +1 are executed, and afterwards we have that the bid is 11 and the ask is 12 + y. Now the 2y sell orders are accumulated at 2+y, and after the next y buy orders the bid is at 12+y−1. Therefore, at the end we have that lastbid(Σ ) = 12 + y − 1, lastask(Σ ) = 12 + y, close(Σ ) = 12 + y, and average(Σ ) = y y+2 (12 + y) + 2 y+2 (12). Setting y = x + 2, we obtain the lemma for every property. We note that while this proof was based on the fact that there are two consecutive orders in the books which are far (y) apart, we can provide a slightly more complicated  example in which all orders are close (at most 2 apart), yet still one change results in large differences. . SIMULATION STUDIES The results presented so far paint a striking contrast  between the absolute and relative price models: while the  absolute model enjoys provably strong stability over any fixed event sequence, there exist at least specific sequences  demonstrating great instability in the relative model. The  worstcase nature of these results raises the question of the extent to which such differences could actually occur in real  markets. In this section we provide indirect evidence on this question by presenting simulation results exploiting a rich source of real-market historical limit order sequence data. By interpreting arriving limit order prices as either  absolute values, or by transforming them into differences with the current bid and ask (relative model), we can perform small modifications on the sequences and examine how  different various outcomes (volume traded, average price, etc.) would be from what actually occurred in the market. These simulations provide an empirical counterpart to the theory we have developed. We emphasize that all such simulations interpret the actual historical data as falling into either the absolute or relative model, and are meaningful only within the confines of such an interpretation. Nevertheless, we feel they provide valuable empirical insight into the potential (in)stability properties of modern equity limit order  markets, and demonstrate that one"s belief or hope in stability largely relies on an absolute model interpretation. We also investigate the empirical behavior of mixtures of absolute and relative prices. .1 Data The historical data used in our simulations is  commercially available limit order data from INET, the previously mentioned electronic exchange for NASDAQ stocks. Broadly speaking, this data consists of practically every single event on INET regarding the trading of an individual  stockevery arriving limit order (price, volume, and sequence ID number), every execution, and every cancellation of a  standing order - all timestamped in milliseconds. It is data  sufficient to recreate the precise INET order book in a given stock on a given day and time. We will report stability properties for three stocks:  Amazon, Nvidia, and Qualcomm (identified in the sequel by their tickers, AMZN, NVDA and QCOM). These three provide some range of liquidities (with QCOM having the greatest and NVDA the least liquidity on INET) and other trading properties. We note that the qualitative results of our  simulations were similar for several other stocks we examined. 27 .2 Methodology For our simulations we employed order-book  reconstruction code operating on the underlying raw data. The basic format of each experiment was the following: . Run the order book reconstruction code on the  original INET data and compute the quantity of interest (volume traded, average price, etc.) . Make a small modification to a single order, and  recompute the resulting value of the quantity of interest. In the absolute model case, Step 2 is as simple as  modifying the order in the original data and re-running the order book reconstruction. For the relative model, we must first pre-process the raw data and convert its prices to relative values, then make the modification and re-run the order book reconstruction on the relative values. The type of modification we examined was extremely small compared to the volume of orders placed in these stocks: namely, the deletion of a single randomly chosen order from the sequence. Although a deletion is not 1-modification, its edit distance is 1 and we can apply Theorem 5.4. For each trading day examined,this single deleted order was  selected among those arriving between 10 AM and 3 PM, and the quantities of interest were measured and compared at 3 PM. These times were chosen to include the busiest part of the trading day but avoid the half hour around the opening and closing of the official NASDAQ market (9:30 AM and :30 PM respectively), which are known to have different dynamics than the central portion of the day. We run the absolute and relative model simulations on both the raw INET data and on a cleaned version of this data. In the cleaned we remove all limit orders that were canceled in the actual market prior to their execution (along with the cancellations themselves). The reason is that such cancellations may often be the first step in the repositioning of orders - that is, cancellations of the  order that are followed by the submission of a replacement order at a different price. Not removing canceled orders allows the possibility of modified simulations in which the same order 1 is executed twice, which may magnify  instability effects. Again, it is clear that neither the raw nor the cleaned data can perfectly reflect what would have happened under the deleted orders in the actual market. However, the results both from the raw data and the clean data are qualitatively similar. The results mainly differ, as expected, in the executed volume, where the instability  results for the relative model are much more dramatic in the raw data. .3 Results We begin with summary statistics capturing our overall stability findings. Each row of the tables below contains a ticker (e.g. AMZN) followed by either -R (for the uncleaned or raw data) or -C (for the data with canceled orders  removed). For each of the approximately 250 trading days in 2003, 1000 trials were run in which a randomly selected order was deleted from the INET event sequence. For each quantity of interest (volume executed, average price, closing price and last bid), we show for the both the absolute and  Here same is in quotes since the two orders will actually have different sequence ID numbers, which is what makes such repositioning activity impossible to reliably detect in the data. relative model the average percentage change in the quantity induced by the deletion. The results confirm rather strikingly the qualitative  conclusions of the theory we have developed. In virtually every case (stock, raw or cleaned data, and quantity) the  percentage change induced by a single deletion in the relative model is many orders of magnitude greater than in the  absolute model, and shows that indeed butterfly effects may occur in a relative model market. As just one specific  representative example, notice that for QCOM on the cleaned data, the relative model effect of just a single deletion on the closing price is in excess of a full percentage point. This is a variety of market impact entirely separate from the more traditional and expected kind generated by trading a large volume of shares. Stock Date volume average Rel Abs Rel Abs AMZN-R 2003 15.1% 0.04% 0.3% 0.0002% AMZN-C 2003 0.69% 0.087% 0.36% 0.0007% NVDA-R 2003 9.09% 0.05 % 0.17% 0.0003% NVDA-C 2003 0.73% 0.09 % 0.35% 0.001% QCOM-R 2003 16.94% 0.035% 0.21% 0.0002% QCOM-C 2003 0.58% 0.06% 0.35% 0.0005% Stock Date close lastbid Rel Abs Rel Abs AMZN-R 2003 0.78% 0.0001% 0.78% 0.0007% AMZN-C 2003 1.10% 0.077% 1.11% 0.001% NVDA-R 2003 1.17% 0.002 % 1.18 % 0.08% NVDA-C 2003 0.45% 0.0003% 0.45% 0.0006% QCOM-R 2003 0.58% 0.0001% 0.58% 0.0004% QCOM-C 2003 1.05% 0.0006% 1.05% 0.06% In Figure 4 we examine how the change to one the  quantities, the average execution price, grows with the  introduction of greater perturbations of the event sequence in the two models. Rather than deleting only a single order between 0 AM and 3 PM, in these experiments a growing number of randomly chosen deletions was performed, and the  percentage change to the average price measured. As suggested by the theory we have developed, for the absolute model the change to the average price grows linearly with the number of deletions and remains very small (note the vastly  different scales of the y-axis in the panels for the absolute and relative models in the figure). For the relative model, it is interesting to note that while small numbers of changes have large effects (often causing average execution price changes well in excess of 0.1 percent), the effects of large numbers of changes levels off quite rapidly and consistently. We conclude with an examination of experiments with a mixture model. Even if one accepts a world in which traders behave in either an absolute or relative manner, one would be likely to claim that the market contains a mixture of both. We thus ran simulations in which each arriving order in the INET event streams was treated as an absolute price with probability α, and as a relative price with probability 1−α. Representative results for the average execution price in this mixture model are shown in Figure 5 for AMZN and NVDA. Perhaps as expected, we see a monotonic decrease in the percentage change (instability) as the fraction of absolute traders increases, with most of the reduction already being realized by the introduction of just a small population of  absolute traders. Thus even in a largely relative-price world, a 28  10 20 30 40 50 60 70 80 90 100  .5  .5  .5 x 10 −3 QCOM−R June 2004: Absolute Number of changes Averageprice  10 20 30 40 50 60 70 80 90 100  .1 .2 .3 .4 .5 .6 .7 QCOM−R June 2004: Relative Number of changes Averageprice Figure 4: Percentage change to the average  execution price (y-axis) as a function of the number of deletions to the sequence (x-axis). The left panel is for the absolute model, the right panel for the  relative model, and each curve corresponds to a single day of QCOM trading in June 2004. Curves  represent averages over 1000 trials. small minority of absolute traders can have a greatly  stabilizing effect. Similar behavior is found for closing price and last bid.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  .1 .2 .3 .4 .5 .6 .7 AMZN−R Feburary 2004 α Averageprice  0.2 0.4 0.6 0.8 1  .05 .1 .15 .2 .25 .3 .35 .4 NVDA−R June 2004 α Averageprice Figure 5: Percentage change to the average  execution price (y-axis) vs. probability of treating  arriving INET orders as absolute prices (x-axis). Each curve corresponds to a single day of trading during a month of 2004. Curves represent averages over 000 trials. For the executed volume in the mixture model, however, the findings are more curious. In Figure 6, we show how the percentage change to the executed volume varies with the absolute trader fraction α, for NVDA data that is both raw and cleaned of cancellations. We first see that for this quantity, unlike the others, the difference induced by the cleaned and uncleaned data is indeed dramatic, as already suggested by the summary statistics table above. But most intriguing is the fact that the stability is not monotonically increasing with α for either the cleaned or uncleaned  datathe market with maximum instability is not a pure relative price market, but occurs at some nonzero value for α. It was in fact not obvious to us that sequences with this property could even be artificially constructed, much less that they would occur as actual market data. We have yet to find a satisfying explanation for this phenomenon and leave it to future research. . ACKNOWLEDGMENTS We are grateful to Yuriy Nevmyvaka of Lehman Brothers in New York for the use of his INET order book  reconstruction code, and for valuable comments on the work presented  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  .5  .5  .5  .5  NVDA−C June 2004 α Volume  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1      0 2 4 6 8 NVDA−R June 2004 α Volume Figure 6: Percentage change to the executed volume (y-axis) vs. probability of treating arriving INET orders as absolute prices (x-axis). The left panel is for NVDA using the raw data that includes  cancellations, while the right panel is on the cleaned data. Each curve corresponds to a single day of trading during June 2004. Curves represent averages over 000 trials. here. Yishay Mansour was supported in part by the IST  Programme of the European Community, under the PASCAL Network of Excellence, IST-2002-506778, by a grant from the Israel Science Foundation and an IBM faculty award. . REFERENCES [1] D. Bertsimas and A. Lo. Optimal control of execution costs. Journal of Financial Markets, 1:1-50, 1998. [2] B. Biais, L. Glosten, and C. Spatt. Market microstructure: a survey of microfoundations, empirical results and policy implications. Journal of Financial Markets, 8:217-264, 2005. [3] J.-P. Bouchaud, M. Mezard, and M. Potters. Statistical properties of stock order books: empirical results and models. Quantitative Finance, 2:251-256, 002. [4] C. Cao, O.Hansch, and X. Wang. The informational content of an open limit order book, 2004. AFA 2005 Philadelphia Meetings, EFA Maastricht Meetings Paper No. 4311. [5] R. Coggins, A. Blazejewski, and M. Aitken. Optimal trade execution of equities in a limit order market. In International Conference on Computational Intelligence for Financial Engineering, pages 371-378, March 2003. [6] D. Farmer and S. Joshi. The price dynamics of common trading strategies. Journal of Economic Behavior and Organization, 29:149-171, 2002. [7] J. Hasbrouck. Empirical market microstructure: Economic and statistical perspectives on the dynamics of trade in securities markets, 2004. Course notes, Stern School of Business, New York University. [8] R. Kissell and M. Glantz. Optimal Trading Strategies. Amacom, 2003. [9] S.Kakade, M. Kearns, Y. Mansour, and L. Ortiz. Competitive algorithms for VWAP and limit order trading. In Proceedings of the ACM Conference on Electronic Commerce, pages 189-198, 2004. [10] Y.Nevmyvaka, Y. Feng, and M. Kearns. Reinforcement learning for optimized trade execution, 2006. Preprint. 29
Efficiency and Nash Equilibria in a Scrip System for P2P Networks Eric J. Friedman School of Operations Research and Industrial Engineering Cornell University ejf27@cornell.edu Joseph Y. Halpern Computer Science Dept. Cornell University halpern@cs.cornell.edu Ian Kash Computer Science Dept. Cornell University kash@cs.cornell.edu ABSTRACT A model of providing service in a P2P network is analyzed. It is shown that by adding a scrip system, a mechanism that admits a reasonable Nash equilibrium that reduces free  riding can be obtained. The effect of varying the total amount of money (scrip) in the system on efficiency (i.e., social  welfare) is analyzed, and it is shown that by maintaining the appropriate ratio between the total amount of money and the number of agents, efficiency is maximized. The work has implications for many online systems, not only P2P  networks but also a wide variety of online forums for which scrip systems are popular, but formal analyses have been lacking. Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; I.2.11 [Artificial Intelligence]: Distributed  Artificial Intelligence-Multiagent systems; J.4 [Social and  Behavioral Sciences]: Economics; K.4.4 [Computers and Society]: Electronic Commerce General Terms Economics, Theory . INTRODUCTION A common feature of many online distributed systems is that individuals provide services for each other.  Peer-topeer (P2P) networks (such as Kazaa [25] or BitTorrent [3]) have proved popular as mechanisms for file sharing, and  applications such as distributed computation and file storage are on the horizon; systems such as Seti@home [24] provide computational assistance; systems such as Slashdot [21]  provide content, evaluations, and advice forums in which people answer each other"s questions. Having individuals provide each other with service typically increases the social welfare: the individual utilizing the resources of the system derives a greater benefit from it than the cost to the individual  providing it. However, the cost of providing service can still be nontrivial. For example, users of Kazaa and BitTorrent may be charged for bandwidth usage; in addition, in some  filesharing systems, there is the possibility of being sued, which can be viewed as part of the cost. Thus, in many systems there is a strong incentive to become a free rider and  benefit from the system without contributing to it. This is not merely a theoretical problem; studies of the Gnutella [22] network have shown that almost 70 percent of users share no files and nearly 50 percent of responses are from the top  percent of sharing hosts [1]. Having relatively few users provide most of the service  creates a point of centralization; the disappearance of a small percentage of users can greatly impair the functionality of the system. Moreover, current trends seem to be leading to the elimination of the altruistic users on which these systems rely. These heavy users are some of the most  expensive customers ISPs have. Thus, as the amount of traffic has grown, ISPs have begun to seek ways to reduce this traffic. Some universities have started charging students for  excessive bandwidth usage; others revoke network access for it [5]. A number of companies have also formed whose service is to detect excessive bandwidth usage [19]. These trends make developing a system that encourages a more equal distribution of the work critical for the  continued viability of P2P networks and other distributed online systems. A significant amount of research has gone into designing reputation systems to give preferential treatment to users who are sharing files. Some of the P2P networks currently in use have implemented versions of these  techniques. However, these approaches tend to fall into one of two categories: either they are barter-like or reputational. By barter-like, we mean that each agent bases its decisions only on information it has derived from its own interactions. Perhaps the best-known example of a barter-like system is BitTorrent, where clients downloading a file try to find other clients with parts they are missing so that they can trade, thus creating a roughly equal amount of work. Since the barter is restricted to users currently interested in a  single file, this works well for popular files, but tends to have problems maintaining availability of less popular ones. An example of a barter-like system built on top of a more  traditional file-sharing system is the credit system used by eMule 40 [8]. Each user tracks his history of interactions with other users and gives priority to those he has downloaded from in the past. However, in a large system, the probability that a pair of randomly-chosen users will have interacted before is quite small, so this interaction history will not be  terribly helpful. Anagnostakis and Greenwald [2] present a more sophisticated version of this approach, but it still seems to suffer from similar problems. A number of attempts have been made at providing  general reputation systems (e.g. [12, 13, 17, 27]). The basic idea is to aggregate each user"s experience into a global number for each individual that intuitively represents the system"s view of that individual"s reputation. However, these  attempts tend to suffer from practical problems because they implicitly view users as either good or bad, assume that the good users will act according to the specified protocol, and that there are relatively few bad users. Unfortunately, if there are easy ways to game the system, once this  information becomes widely available, rational users are likely to make use of it. We cannot count on only a few users being bad (in the sense of not following the prescribed protocol). For example, Kazaa uses a measure of the ratio of the  number of uploads to the number of downloads to identify good and bad users. However, to avoid penalizing new users, they gave new users an average rating. Users discovered that they could use this relatively good rating to free ride for a while and, once it started to get bad, they could delete their stored information and effectively come back as a new user, thus circumventing the system (see [2] for a discussion and [11] for a formal analysis of this whitewashing). Thus Kazaa"s reputation system is ineffective. This is a simple case of a more general vulnerability of such systems to sybil attacks [6], where a single user  maintains multiple identities and uses them in a coordinated  fashion to get better service than he otherwise would. Recent work has shown that most common reputation systems are vulnerable (in the worst case)to such attacks [4]; however, the degree of this vulnerability is still unclear. The  analyses of the practical vulnerabilities and the existence of such systems that are immune to such attacks remains an area of active research (e.g., [4, 28, 14]). Simple economic systems based on a scrip or money seem to avoid many of these problems, are easy to implement and are quite popular (see, e.g., [13, 15, 26]). However, they have a different set of problems. Perhaps the most common involve determining the amount of money in the system. Roughly speaking, if there is too little money in the system relative to the number of agents, then relatively few users can afford to make request. On the other hand, if there is too much money, then users will not feel the need to  respond to a request; they have enough money already. A related problem involves handling newcomers. If newcomers are each given a positive amount of money, then the system is open to sybil attacks. Perhaps not surprisingly, scrip  systems end up having to deal with standard economic woes such as inflation, bubbles, and crashes [26]. In this paper, we provide a formal model in which to analyze scrip systems. We describe a simple scrip system and show that, under reasonable assumptions, for each fixed amount of money there is a nontrivial Nash equilibrium  involving threshold strategies, where an agent accepts a request if he has less than $k for some threshold k.1 An interesting aspect of our analysis is that, in equilibrium, the  distribution of users with each amount of money is the distribution that maximizes entropy (subject to the money supply  constraint). This allows us to compute the money supply that maximizes efficiency (social welfare), given the number of agents. It also leads to a solution for the problem of  dealing with newcomers: we simply assume that new users come in with no money, and adjust the price of service (which is equivalent to adjusting the money supply) to maintain the ratio that maximizes efficiency. While assuming that new users come in with no money will not work in all settings, we believe the approach will be widely applicable. In  systems where the goal is to do work, new users can acquire money by performing work. It should also work in  Kazaalike system where a user can come in with some resources (e.g., a private collection of MP3s). The rest of the paper is organized as follows. In Section 2, we present our formal model and observe that it can be used to understand the effect of altruists. In Section 3, we  examine what happens in the game under nonstrategic play, if all agents use the same threshold strategy. We show that, in this case, the system quickly converges to a situation where the distribution of money is characterized by maximum  entropy. Using this analysis, we show in Section 4 that, under minimal assumptions, there is a nontrivial Nash equilibrium in the game where all agents use some threshold strategy. Moreover, we show in Section 5 that the analysis leads to an understanding of how to choose the amount of money in the system (or, equivalently, the cost to fulfill a request) so as to maximize efficiency, and also shows how to handle new users. In Section 6, we discuss the extent to which our approach can handle sybils and collusion. We conclude in Section 7. . THE MODEL To begin, we formalize providing service in a P2P network as a non-cooperative game. Unlike much of the modeling in this area, our model will model the asymmetric interactions in a file sharing system in which the matching of players (those requesting a file with those who have that particular file) is a key part of the system. This is in contrast with much previous work which uses random matching in a  prisoner"s dilemma. Such models were studied in the economics literature [18, 7] and first applied to online reputations in [11]; an application to P2P is found in [9]. This random-matching model fails to capture some salient aspects of a number of important settings. When a request is made, there are typically many people in the network who can potentially satisfy it (especially in a large P2P network), but not all can. For example, some people may not have the time or resources to satisfy the request. The  randommatching process ignores the fact that some people may not be able to satisfy the request. Presumably, if the person matched with the requester could not satisfy the match, he would have to defect. Moreover, it does not capture the fact that the decision as to whether to volunteer to satisfy the request should be made before the matching process, not after. That is, the matching process does not capture  Although we refer to our unit of scrip as the dollar, these are not real dollars nor do we view them as convertible to dollars. 41 the fact that if someone is unwilling to satisfy the request, there will doubtless be others who can satisfy it. Finally, the actions and payoffs in the prisoner"s dilemma game do not obviously correspond to actual choices that can be made. For example, it is not clear what defection on the part of the requester means. In our model we try to deal with all these issues. Suppose that there are n agents. At each round, an agent is picked uniformly at random to make a request. Each other agent is able to satisfy this request with probability β > 0 at all times, independent of previous behavior. The term β is intended to capture the probability that an agent is busy, or does not have the resources to fulfill the request. Assuming that β is time-independent does not capture the intution that being an unable to fulfill a request at time t may well be correlated with being unable to fulfill it at time t+1. We believe that, in large systems, we should be able to drop the independence assumption, but we leave this for future work. In any case, those agents that are able to satisfy the request must choose whether or not to volunteer to satisfy it. If at least one agent volunteers, the requester gets a benefit of 1 util (the job is done) and one of volunteers is chosen at random to fulfill the request. The agent that fulfills the request pays a cost of α < 1. As is standard in the literature, we assume that agents discount future payoffs by a factor of δ per time unit. This captures the intuition that a util now is worth more than a util tomorrow, and allows us to compute the total utility derived by an agent in an infinite game. Lastly, we assume that with more players requests come more often. Thus we assume that the time between rounds is 1/n. This captures the fact that the systems we want to model are really processing many requests in parallel, so we would expect the number of concurrent requests to be proportional to the number of users.2 Let G(n, δ, α, β) denote this game with n agents, a  discount factor of δ, a cost to satisfy requests of α, and a  probability of being able to satisfy requests of β. When the latter two parameters are not relevant, we sometimes write G(n, δ). We use the following notation throughout the paper: • pt denotes the agent chosen in round t. • Bt i ∈ {0, 1} denotes whether agent i can satisfy the request in round t. Bt i = 1 with probability β > 0 and Bt i is independent of Bt i for all t = t. • V t i ∈ {0, 1} denotes agent i"s decision about whether to volunteer in round t; 1 indicates volunteering. V t i is determined by agent i"s strategy. • vt ∈ {j | V t j Bt j = 1} denotes the agent chosen to satisfy the request. This agent is chosen uniformly at random from those who are willing (V t j = 1) and able (Bt j = 1) to satisfy the request. • ut i denotes agent i"s utility in round t. A standard agent is one whose utility is determined as discussed in the introduction; namely, the agent gets  For large n, our model converges to one in which players make requests in real time, and the time between a player"s requests are exponentially distributed with mean 1. In  addition, the time between requests served by a single player is also exponentially distributed. a utility of 1 for a fulfilled request and utility −α for fulfilling a request. Thus, if i is a standard agent, then ut i =  < :  if i = pt and P j=i V t j Bt j > 0 −α if i = vt  otherwise. • Ui = P∞ t=0 δt/n ut i denotes the total utility for agent i. It is the discounted total of agent i"s utility in each round. Note that the effective discount factor is δ1/n since an increase in n leads to a shortening of the time between rounds. Now that we have a model of making and satisfying  requests, we use it to analyze free riding. Take an altruist to be someone who always fulfills requests. Agent i might  rationally behave altruistically if agent i"s utility function has the following form, for some α > 0: ut i =  < :  if i = pt and P j=i V t j Bt j > 0 α if i = vt  otherwise. Thus, rather than suffering a loss of utility when satisfying a request, an agent derives positive utility from satisfying it. Such a utility function is a reasonable representation of the pleasure that some people get from the sense that they provide the music that everyone is playing. For such  altruistic agents, playing the strategy that sets V t i = 1 for all t is dominant. While having a nonstandard utility function might be one reason that a rational agent might use this strategy, there are certainly others. For example a naive user of filesharing software with a good connection might well follow this strategy. All that matters for the  following discussion is that there are some agents that use this strategy, for whatever reason. As we have observed, such users seem to exist in some large systems. Suppose that our system has a altruists.  Intuitively, if a is moderately large, they will manage to satisfy most of the requests in the system even if other agents do no work. Thus, there is little incentive for any other agent to volunteer, because he is already getting full advantage of participating in the system. Based on this intuition, it is a relatively straightforward calculation to determine a value of a that depends only on α, β, and δ, but not the number n of players in the system, such that the dominant strategy for all standard agents i is to never volunteer to satisfy any requests (i.e., V t i = 0 for all t). Proposition 2.1. There exists an a that depends only on α, β, and δ such that, in G(n, δ, α, β) with at least a altruists, not volunteering in every round is a dominant strategy for all standard agents. Proof. Consider the strategy for a standard player j in the presence of a altruists. Even with no money, player j will get a request satisfied with probability 1 − (1 − β)a just through the actions of these altruists. Thus, even if j is chosen to make a request in every round, the most additional expected utility he can hope to gain by having money isP∞ k=1(1 − β)a δk = (1 − β)a /(1 − δ). If (1 − β)a /(1 − δ) > α or, equivalently, if a > log1−β(α(1 − δ)), never volunteering is a dominant strategy. Consider the following reasonable values for our  parameters: β = .01 (so that each player can satisfy 1% of the  requests), α = .1 (a low but non-negligible cost), δ = .9999/day 42 (which corresponds to a yearly discount factor of  approximately 0.95), and an average of 1 request per day per player. Then we only need a > 1145. While this is a large number, it is small relative to the size of a large P2P network. Current systems all have a pool of users behaving like our altruists. This means that attempts to add a reputation system on top of an existing P2P system to influence users to cooperate will have no effect on rational users. To have a fair distribution of work, these systems must be  fundamentally redesigned to eliminate the pool of altruistic users. In some sense, this is not a problem at all. In a system with altruists, the altruists are presumably happy, as are the standard agents, who get almost all their requests  satisfied without having to do any work. Indeed, current P2P network work quite well in terms of distributing content to people. However, as we said in the introduction, there is some reason to believe these altruists may not be around forever. Thus, it is worth looking at what can be done to make these systems work in their absence. For the rest of this paper we assume that all agents are standard, and try to maximize expected utility. We are interested in equilibria based on a scrip system. Each time an agent has a request satisfied he must pay the person who satisfied it some amount. For now, we assume that the payment is fixed; for simplicity, we take the amount to be $1. We denote by M the total amount of money in the system. We assume that M > 0 (otherwise no one will ever be able to get paid). In principle, agents are free to adopt a very wide  variety of strategies. They can make decisions based on the names of other agents or use a strategy that is heavily  history dependant, and mix these strategies freely. To aid our analysis, we would like to be able to restrict our attention to a simpler class of strategies. The class of strategies we are interested in is easy to motivate. The intuitive reason for wanting to earn money is to cater for the possibility that an agent will run out before he has a chance to earn more. On the other hand, a rational agent with plenty of mone would not want to work, because by the time he has managed to spend all his money, the util will have less value than the present cost of working. The natural balance between these two is a threshold strategy. Let Sk be the strategy where an agent volunteers whenever he has less than k dollars and not otherwise. Note that S0 is the strategy where the agent never volunteers. While everyone playing S0 is a Nash  equilibrium (nobody can do better by volunteering if no one else is willing to), it is an uninteresting one. As we will show in Section 4, it is sufficient to restrict our attention to this class of strategies. We use Kt i to denote the amount of money agent i has at time t. Clearly Kt+1 i = Kt i unless agent i has a request satisfied, in which case Kt+1 i = Kt+1 i − 1 or agent i fulfills a request, in which case Kt+1 i = Kt+1 i + 1. Formally, Kt+1 i =  < : Kt i − 1 if i = pt , P j=i V t j Bt j > 0, and Kt i > 0 Kt i + 1 if i = vt and Kt pt > 0 Kt i otherwise. The threshold strategy Sk is the strategy such that V t i =   if Kt pt > 0 and Kt i < k  otherwise. . THE GAME UNDER NONSTRATEGIC PLAY Before we consider strategic play, we examine what  happens in the system if everyone just plays the same strategy Sk. Our overall goal is to show that there is some  distribution over money (i.e., the fraction of people with each amount of money) such that the system converges to this distribution in a sense to be made precise shortly. Suppose that everyone plays Sk. For simplicity, assume that everyone has at most k dollars. We can make this assumption with essentially no loss of generality, since if someone has more than k dollars, he will just spend money until he has at most k dollars. After this point he will never acquire more than k. Thus, eventually the system will be in such a state. If M ≥ kn, no agent will ever be willing to work. Thus, for the purposes of this section we assume that M < kn. From the perspective of a single agent, in (stochastic) equilibrium, the agent is undergoing a random walk.  However, the parameters of this random walk depend on the  random walks of the other agents and it is quite complicated to solve directly. Thus we consider an alternative analysis based on the evolution of the system as a whole. If everyone has at most k dollars, then the amount of money that an agent has is an element of {0, . . . , k}. If there are n agents, then the state of the game can be described by identifying how much money each agent has, so we can represent it by an element of Sk,n = {0, . . . , k}{1,...,n} . Since the total amount of money is constant, not all of these states can arise in the game. For example the state where each player has $0 is impossible to reach in any game with money in the system. Let mS(s) = P i∈{1...n} s(i) denote the total mount of money in the game at state s, where s(i) is the number of dollars that agent i has in state s. We want to consider only those states where the total money in the system is M, namely Sk,n,M = {s ∈ Sk,n | mS(s) = M}. Under the assumption that all agents use strategy Sk, the evolution of the system can be treated as a Markov chain Mk,n,M over the state space Sk,n,M . It is possible to move from one state to another in a single round if by choosing a particular agent to make a request and a particular agent to satisfy it, the amounts of money possesed by each agent become those in the second state. Therefore the  probability of a transition from a state s to t is 0 unless there exist two agents i and j such that s(i ) = t(i ) for all i /∈ {i, j}, t(i) = s(i) + 1, and t(j) = s(j) − 1. In this case the  probability of transitioning from s to t is the probability of j being chosen to spend a dollar and has someone willing and able to satisfy his request ((1/n)(1 − (1 − β)|{i |s(i )=k}|−Ij ) multiplied by the probability of i being chosen to satisfy his request (1/(|({i | s(i ) = k}| − Ij )). Ij is 0 if j has k dollars and 1 otherwise (it is just a correction for the fact that j cannot satisfy his own request.) Let ∆k denote the set of probability distributions on {0, . . . , k}. We can think of an element of ∆k as describing the fraction of people with each amount of money. This is a useful way of looking at the system, since we typically don"t care who has each amount of money, but just the fraction of people that have each amount. As before, not all elements of ∆k are possible, given our constraint that the total amount of 43 money is M. Rather than thinking in terms of the total amount of money in the system, it will prove more useful to think in terms of the average amount of money each player has. Of course, the total amount of money in a system with n agents is M iff the average amount that each player has is m = M/n. Let ∆k m denote all distributions d ∈ ∆k such that E(d) = m (i.e., Pk j=0 d(j)j = m). Given a state s ∈ Sk,n,M , let ds ∈ ∆k m denote the distribution of money in s. Our goal is to show that, if n is large, then there is a distribution d∗ ∈ ∆k m such that, with high probability, the Markov chain Mk,n,M will almost always be in a state s such that ds is close to d∗ . Thus, agents can base their decisions about what strategy to use on the assumption that they will be in such a state. We can in fact completely characterize the distribution d∗ . Given a distribution d ∈ ∆k , let H(d) = − X {j:d(j)=0} d(j) log(d(j)) denote the entropy of d. If ∆ is a closed convex set of  distributions, then it is well known that there is a unique  distribution in ∆ at which the entropy function takes its maximum value in ∆. Since ∆k m is easily seen to be a closed convex set of distributions, it follows that there is a unique distribution in ∆k m that we denote d∗ k,m whose entropy is greater than that of all other distributions in ∆k m. We now show that, for n sufficiently large, the Markov chain Mk,n,M is almost surely in a state s such that ds is close to d∗ k,M/n. The statement is correct under a number of senses of close. For definiteness, we consider the Euclidean distance. Given > 0, let Sk,n,m, denote the set of states s in Sk,n,mn such that Pk j=0 |ds (j) − d∗ k,m|2 < . Given a Markov chain M over a state space S and S ⊆ S, let Xt,s,S be the random variable that denotes that M is in a state of S at time t, when started in state s. Theorem 3.1. For all > 0, all k, and all m, there exists n such that for all n > n and all states s ∈ Sk,n,mn, there exists a time t∗ (which may depend on k, n, m, and ) such that for t > t∗ , we have Pr(Xt,s,Sk,n,m, ) > 1 − . Proof. (Sketch) Suppose that at some time t, Pr(Xt,s,s ) is uniform for all s . Then the probability of being in a set of states is just the size of the set divided by the total number of states. A standard technique from statistical mechanics is to show that there is a concentration phenomenon around the maximum entropy distribution [16]. More precisely, using a straightforward combinatorial argument, it can be shown that the fraction of states not in Sk,n,m, is bounded by p(n)/ecn , where p is a polynomial. This fraction clearly goes to 0 as n gets large. Thus, for sufficiently large n, Pr(Xt,s,Sk,n,m, ) > 1 − if Pr(Xt,s,s ) is uniform. It is relatively straightforward to show that our Markov Chain has a limit distribution π over Sk,n,mn, such that for all s, s ∈ Sk,n,mn, limt→∞ Pr(Xt,s,s ) = πs . Let Pij denote the probability of transitioning from state i to state j. It is easily verified by an explicit computation of the  transition probabilities that Pij = Pji for all states i and j. It immediatly follows from this symmetry that πs = πs , so π is uniform. After a sufficient amount of time, the  distribution will be close enough to π, that the probabilities are again bounded by constant, which is sufficient to complete the theorem.  0.002 0.004 0.006 0.008 0.01 Euclidean Distance 000 500 000 500 000 NumberofSteps Figure 1: Distance from maximum-entropy  distribution with 1000 agents. 000 10000 15000 20000 25000 Number of Agents .001 .002 .003 .004 .005 MaximumDistance Figure 2: Maximum distance from  maximumentropy distribution over 106 timesteps.  5000 10000 15000 20000 25000 Number of Agents  0000 0000 0000 TimetoDistance.001 Figure 3: Average time to get within .001 of the maximum-entropy distribution. 44 We performed a number of experiments that show that the maximum entropy behavior described in Theorem 3.1 arises quickly for quite practical values of n and t. The first experiment showed that, even if n = 1000, we reach the maximum-entropy distribution quickly. We averaged 10 runs of the Markov chain for k = 5 where there is enough money for each agent to have $2 starting from a very extreme distribution (every agent has either $0 or $5) and considered the average time needed to come within various distances of the maximum entropy distribution. As Figure 1 shows, after 2,000 steps, on average, the Euclidean distance from the average distribution of money to the maximum-entropy distribution is .008; after 3,000 steps, the distance is down to .001. Note that this is really only 3 real time units since with 1000 players we have 1000 transactions per time unit. We then considered how close the distribution stays to the maximum entropy distribution once it has reached it. To simplify things, we started the system in a state whose distribution was very close to the maximum-entropy  distribution and ran it for 106 steps, for various values of n. As Figure 2 shows, the system does not move far from the maximum-entropy distribution once it is there. For  example, if n = 5000, the system is never more than distance .001 from the maximum-entropy distribution; if n = 25, 000, it is never more than .0002 from the maximum-entropy  distribution. Finally, we considered how more carefully how quickly the system converges to the maximum-entropy distribution for various values of n. There are approximately kn  possible states, so the convergence time could in principle be quite large. However, we suspect that the Markov chain that arises here is rapidly mixing, which means that it will converge significantly faster (see [20] for more details about rapid mixing). We believe that the actually time needed is O(n). This behavior is illustrated in Figure 3, which shows that for our example chain (again averaged over 10 runs),  after 3n steps, the Euclidean distance between the actual  distribution of money in the system and the maximum-entropy distribution is less than .001. . THE GAME UNDER STRATEGIC PLAY We have seen that the system is well behaved if the agents all follow a threshold strategy; we now want to show that there is a nontrivial Nash equilibrium where they do so (that is, a Nash equilibrium where all the agents use Sk for some k > 0.) This is not true in general. If δ is small, then agents have no incentive to work. Intuitively, if future utility is sufficiently discounted, then all that matters is the present, and there is no point in volunteering to work. With small δ, S0 is the only equilibrium. However, we show that for δ sufficiently large, there is another equilibrium in threshold strategies. We do this by first showing that, if every other agent is playing a threshold strategy, then there is a best response that is also a threshold strategy (although not  necessarily the same one). We then show that there must be some (mixed) threshold strategy for which this best response is the same strategy. It follows that this tuple of threshold strategies is a Nash equilibrium. As a first step, we show that, for all k, if everyone other than agent i is playing Sk, then there is a threshold  strategy Sk that is a best response for agent i. To prove this, we need to assume that the system is close to the  steadystate distribution (i.e., the maximum-entropy distribution). However, as long as δ is sufficiently close to 1, we can ignore what happens during the period that the system is not in steady state.3 We have thus far considered threshold strategies of the form Sk, where k is a natural number; this is a discrete set of strategies. For a later proof, it will be helpful to have a continuous set of strategies. If γ = k + γ , where k is a natural number and 0 ≤ γ < 1, let Sγ be the strategy that performs Sk with probability 1 − γ and Sk+1 with probability γ. (Note that we are not considering arbitrary mixed threshold strategies here, but rather just mixing  between adjacent strategies for the sole purpose of making out strategies continuous in a natural way.) Theorem 3.1  applies to strategies Sγ (the same proof goes through without change), where γ is an arbitrary nonnegative real number. Theorem 4.1. Fix a strategy Sγ and an agent i. There exists δ∗ < 1 and n∗ such that if δ > δ∗ , n > n∗ , and every agent other than i is playing Sγ in game G(n, δ), then there is an integer k such that the best response for agent i is Sk . Either k is unique (that is, there is a unique best response that is also a threshold strategy), or there exists an integer k such that Sγ is a best response for agent i for all γ in the interval [k , k +1] (and these are the only best responses among threshold strategies). Proof. (Sketch:) If δ is sufficiently large, we can ignore what happens before the system converges to the  maximumentropy distribution. If n is sufficiently large, then the  strategy played by one agent will not affect the distribution of money significantly. Thus, the probability of i moving from one state (dollar amount) to another depends only on i"s strategy (since we can take the probability that i will be chosen to make a request and the probability that i will be chosen to satisfy a request to be constant). Thus, from i"s point of view, the system is a Markov decision process (MDP), and i needs to compute the optimal policy  (strategy) for this MDP. It follows from standard results [23,  Theorem 6.11.6] that there is an optimal policy that is a  threshold policy. The argument that the best response is either unique or there is an interval of best responses follows from a more careful analysis of the value function for the MDP. We remark that there may be best responses that are not threshold strategies. All that Theorem 4.1 shows is that, among best responses, there is at least one that is a threshold strategy. Since we know that there is a best response that is a threshold strategy, we can look for a Nash equilibrium in the space of threshold strategies. Theorem 4.2. For all M, there exists δ∗ < 1 and n∗ such that if δ > δ∗ and n > n∗ , there exists a Nash equilibrium in the game G(n, δ) where all agents play Sγ for some integer γ > 0. Proof. It follows easily from the proof Theorem 4.1 that if br(δ, γ) is the minimal best response threshold strategy if all the other agents are playing Sγ and the discount factor is δ then, for fixed δ, br(δ, ·) is a step function. It also follows  Formally, we need to define the strategies when the system is far from equilibrium. However, these far from (stochastic) equilibrium strategies will not affect the equilibrium  behavior when n is large and deviations from stochastic  equilibrium are extremely rare. 45 from the theorem that if there are two best responses, then a mixture of them is also a best response. Therefore, if we can join the steps by a vertical line, we get a best-response curve. It is easy to see that everywhere that this  bestresponse curve crosses the diagonal y = x defines a Nash equilibrium where all agents are using the same threshold strategy. As we have already observed, one such  equilibrium occurs at 0. If there are only $M in the system, we can restrict to threshold strategies Sk where k ≤ M + 1. Since no one can have more than $M, all strategies Sk for k > M are equivalent to SM ; these are just the strategies where the agent always volunteers in response to request made by someone who can pay. Clearly br(δ, SM ) ≤ M for all δ, so the best response function is at or below the equilibrium at M. If k ≤ M/n, every player will have at least k dollars and so will be unwilling to work and the best response is just 0. Consider k∗ , the smallest k such that k > M/n. It is not hard to show that for k∗ there exists a δ∗ such that for all δ ≥ δ∗ , br(δ, k∗ ) ≥ k∗ . It follows by continuity that if δ ≥ δ∗ , there must be some γ such that br(δ, γ) = γ. This is the desired Nash equilibrium. This argument also shows us that we cannot in general expect fixed points to be unique. If br(δ, k∗ ) = k∗ and br(δ, k + 1) > k + 1 then our argument shows there must be a second fixed point. In general there may be multiple fixed points even when br(δ, k∗ ) > k∗ , as illustrated in the Figure  with n = 1000 and M = 3000.  5 10 15 20 25 Strategy of Rest of Agents   0 5 0 5 BestResponse Figure 4: The best response function for n = 1000 and M = 3000. Theorem 4.2 allows us to restrict our design to agents using threshold strategies with the confidence that there will be a nontrivial equilibrium. However, it does not rule out the possibility that there may be other equilibria that do not involve threshold stratgies. It is even possible (although it seems unlikely) that some of these equilibria might be better. . SOCIAL WELFARE AND SCALABITY Our theorems show that for each value of M and n, for sufficiently large δ, there is a nontrivial Nash equilibrium where all the agents use some threshold strategy Sγ(M,n). From the point of view of the system designer, not all  equilibria are equally good; we want an equilibrium where as few as possible agents have $0 when they get a chance to make a request (so that they can pay for the request) and relatively few agents have more than the threshold amount of money (so that there are always plenty of agents to fulfill the  request). There is a tension between these objectives. It is not hard to show that as the fraction of agents with $0 increases in the maximum entropy distribution, the fraction of agents with the maximum amount of money decreases. Thus, our goal is to understand what the optimal amount of money should be in the system, given the number of agents. That is, we want to know the amount of money M that maximizes efficiency, i.e., the total expected utility if all the agents use Sγ(M,n). 4 We first observe that the most efficient equilibrium  depends only on the ratio of M to n, not on the actual values of M and n. Theorem 5.1. There exists n∗ such that for all games G(n1, δ) and G(n2, δ) where n1, n2 > n∗ , if M1/n1 = M2/n2, then Sγ(M1,n1) = Sγ(M2,n2). Proof. Fix M/n = r. Theorem 3.1 shows that the maximum-entropy distribution depends only on k and the ratio M/n, not on M and n separately. Thus, given r, for each choice of k, there is a unique maximum entropy  distribution dk,r. The best response br(δ, k) depends only on the distribution dk,r, not M or n. Thus, the Nash equilibrium depends only on the ratio r. That is, for all choices of M and n such that n is sufficiently large (so that Theorem 3.1 applies) and M/n = r, the equilibrium strategies are the same. In light of Theorem 5.1, the system designer should ensure that there is enough money M in the system so that the ratio between M/n is optimal. We are currently exploring exactly what the optimal ratio is. As our very preliminary results for β = 1 show in Figure 5, the ratio appears to be monotone increasing in δ, which matches the intuition that we should provide more patient agents with the opportunity to save more money. Additionally, it appears to be relatively smooth, which suggests that it may have a nice analytic solution. .9 0.91 0.92 0.93 0.94 0.95 Discount Rate ∆  .5  .5  OptimalRatioofMn Figure 5: Optimal average amount of money to the nearest .25 for β = 1 We remark that, in practice, it may be easier for the  designer to vary the price of fulfilling a request rather than  If there are multiple equilibria, we take Sγ(M,n) to be the Nash equilibrium that has highest efficiency for fixed M and n. 46 injecting money in the system. This produces the same  effect. For example, changing the cost of fulfilling a request from $1 to $2 is equivalent to halving the amount of money that each agent has. Similarly, halving the the cost of  fulfilling a request is equivalent to doubling the amount of money that everyone has. With a fixed amount of money M, there is an optimal product nc of the number of agents and the cost c of fulfilling a request. Theorem 5.1 also tells us how to deal with a dynamic pool of agents. Our system can handle newcomers relatively  easily: simply allow them to join with no money. This gives existing agents no incentive to leave and rejoin as  newcomers. We then change the price of fulfilling a request so that the optimal ratio is maintained. This method has the nice feature that it can be implemented in a distributed fashion; if all nodes in the system have a good estimate of n then they can all adjust prices automatically. (Alternatively, the number of agents in the system can be posted in a  public place.) Approaches that rely on adjusting the amount of money may require expensive system-wide computations (see [26] for an example), and must be carefully tuned to avoid creating incentives for agents to manipulate the  system by which this is done. Note that, in principle, the realization that the cost of fulfilling a request can change can affect an agent"s  strategy. For example, if an agent expects the cost to increase, then he may want to defer volunteering to fulfill a request. However, if the number of agents in the system is always increasing, then the cost always decreases, so there is never any advantage in waiting. There may be an advantage in delaying a request, but it is far more costly, in terms of waiting costs than in  providing service, since we assume the need for a service is often subject to real waiting costs, while the need to supply the service is merely to augment a money supply. (Related  issues are discussed in [10].) We ultimately hope to modify the mechanism so that the price of a job can be set endogenously within the system (as in real-world economies), with agents bidding for jobs rather than there being a fixed cost set externally. However, we have not yet explored the changes required to implement this change. Thus, for now, we assume that the cost is set as a function of the number of agents in the system (and that there is no possibility for agents to satisfy a request for less than the official cost or for requesters to offer to pay more than it). . SYBILS AND COLLUSION In a naive sense, our system is essentially sybil-proof. To get d dollars, his sybils together still have to perform d units of work. Moreover, since newcomers enter the system with $0, there is no benefit to creating new agents simply to take advantage of an initial endowment. Nevertheless, there are some less direct ways that an agent could take advantage of sybils. First, by having more identities he will have a greater probability of getting chosen to make a request. It is easy to see that this will lead to the agent having higher total utility. However, this is just an artifact of our model. To make our system simple to analyze, we have assumed that request opportunities came uniformly at random. In practice, requests are made to satisfy a desire. Our model implicitly assumed that all agents are equally likely to have a desire at any particular time. Having sybils should not  increase the need to have a request satisfied. Indeed, it would be reasonable to assume that sybils do not make requests at all. Second, having sybils makes it more likely that one of the sybils will be chosen to fulfill a request. This can allow a user to increase his utility by setting a lower threshold; that is, to use a strategy Sk where k is smaller than the k used by the Nash equilibrium strategy. Intuitively, the need for money is not as critical if money is easier to obtain.  Unlike the first concern, this seems like a real issue. It seems reasonable to believe that when people make a decision  between a number of nodes to satisfy a request they do so at random, at least to some extent. Even if they look for advertised node features to help make this decision, sybils would allow a user to advertise a wide range of features. Third, an agent can drive down the cost of fulfilling a request by introducing many sybils. Similarly, he could  increase the cost (and thus the value of his money) by making a number of sybils leave the system. Concievably he could alternate between these techniques to magnify the effects of work he does. We have not yet calculated the exact effect of this change (it interacts with the other two effects of having sybils that we have already noted). Given the number of sybils that would be needed to cause a real change in the perceived size of a large P2P network, the practicality of this attack depends heavily on how much sybils cost an attacker and what resources he has available. The second point raised regarding sybils also applies to collusion if we allow money to be loaned. If k agents  collude, they can agree that, if one runs out of money, another in the group will loan him money. By pooling their money in this way, the k agents can again do better by setting a higher threshold. Note that the loan mechanism doesn"t need to be built into the system; the agents can simply use a fake transaction to transfer the money. These appear to be the main avenues for collusive attacks, but we are still exploring this issue. . CONCLUSION We have given a formal analysis of a scrip system and have shown that the existence of a Nash equilibrium where all agents use a threshold strategy. Moreover, we can  compute efficiency of equilibrium strategy and optimize the price (or money supply) to maximize efficiency. Thus, our  analysis provides a formal mechanisms for solving some important problems in implementing scrip systems. It tells us that with a fixed population of rational users, such systems are very unlikely to become unstable. Thus if this stability is  common belief among the agents we would not expect inflation, bubbles, or crashes because of agent speculation. However, we cannot rule out the possibility that that agents may have other beliefs that will cause them to speculate. Our  analysis also tells us how to scale the system to handle an influx of new users without introducing these problems: scale the money supply to keep the average amount of money constant (or equivalently adjust prices to achieve the same goal). There are a number of theoretical issues that are still open, including a characterization of the multiplicity of  equilibria - are there usually 2? In addition, we expect that one should be able to compute analytic estimates for the best response function and optimal pricing which would allow us to understand the relationship between pricing and various parameters in the model. 47 It would also be of great interest to extend our analysis to handle more realistic settings. We mention a few possible extensions here: • We have assumed that the world is homogeneous in a number of ways, including request frequency, utility, and ability to satisfy requests. It would be  interesting to examine how relaxing any of these assumptions would alter our results. • We have assumed that there is no cost to an agent to be a member of the system. Suppose instead that we imposed a small cost simply for being present in the system to reflect the costs of routing messages and overlay maintainance. This modification could have a significant impact on sybil attacks. • We have described a scrip system that works when there are no altruists and have shown that no system can work once there there are sufficiently many  altruists. What happens between these extremes? • One type of irrational behavior encountered with scrip systems is hoarding. There are some similarities between hoarding and altruistic behavior. While an altruist provide service for everyone, a hoarder will volunteer for all jobs (in order to get more money) and rarely request service (so as not to spend money). It would be interesting to investigate the extent to which our system is robust against hoarders. Clearly with too many hoarders, there may not be enough money remaining among the non-hoarders to guarantee that, typically, a non-hoarder would have enough money to satisfy a request. • Finally, in P2P filesharing systems, there are  overlapping communities of various sizes that are significantly more likely to be able to satisfy each other"s requests. It would be interesting to investigate the effect of such communities on the equilibrium of our system. There are also a number of implementation issues that would have to be resolved in a real system. For example, we need to worry about the possibility of agents counterfeiting money or lying about whether service was actually provided. Karma [26] provdes techniques for dealing with both of these issues and a number of others, but some of Karma"s  implementation decisions point to problems for our model. For example, it is prohibitively expensive to ensure that bank  account balances can never go negative, a fact that our model does not capture. Another example is that Karma has nodes serve as bookkeepers for other nodes account balances. Like maintaining a presence in the network, this imposes a cost on the node, but unlike that, responsibility it can be easily shirked. Karma suggests several ways to incentivize nodes to perform these duties. We have not investigated whether these mechanisms be incorporated without disturbing our equilibrium. . ACKNOWLEDGEMENTS We would like to thank Emin Gun Sirer, Shane  Henderson, Jon Kleinberg, and 3 anonymous referees for helpful suggestions. EF, IK and JH are supported in part by NSF under grant ITR-0325453. JH is also supported in part by NSF under grants CTC-0208535 and IIS-0534064, by ONR under grant N00014-01-10-511, by the DoD  Multidisciplinary University Research Initiative (MURI) program  administered by the ONR under grants N00014-01-1-0795 and N00014-04-1-0725, and by AFOSR under grant  F49620-021-0101. . REFERENCES [1] E. Adar and B. A. Huberman. Free riding on Gnutella. First Monday, 5(10), 2000. [2] K. G. Anagnostakis and M. Greenwald. Exchange-based incentive mechanisms for peer-to-peer file sharing. In International Conference on Distributed Computing Systems (ICDCS), pages 524-533, 2004. [3] BitTorrent Inc. BitTorrent web site. http://www.bittorent.com. [4] A. Cheng and E. Friedman. Sybilproof reputation mechanisms. In Workshop on Economics of Peer-to-Peer Systems (P2PECON), pages 128-132, 005. [5] Cornell Information Technologies. Cornell"s ccommodity internet usage statistics. http://www.cit.cornell.edu/computer/students/  bandwidth/charts.html. [6] J. R. Douceur. The sybil attack. In International Workshop on Peer-to-Peer Systems (IPTPS), pages 51-260, 2002. [7] G. Ellison. Cooperation in the prisoner"s dilemma with anonymous random matching. Review of Economic Studies, 61:567-588, 1994. [8] eMule Project. eMule web site. http://www.emule-project.net/. [9] M. Feldman, K. Lai, I. Stoica, and J. Chuang. Robust incentive techniques for peer-to-peer networks. In ACM Conference on Electronic Commerce (EC), pages 102-111, 2004. [10] E. J. Friedman and D. C. Parkes. Pricing wifi at starbucks: issues in online mechanism design. In EC "03: Proceedings of the 4th ACM Conference on Electronic Commerce, pages 240-241. ACM Press, 003. [11] E. J. Friedman and P. Resnick. The social cost of cheap pseudonyms. Journal of Economics and Management Strategy, 10(2):173-199, 2001. [12] R. Guha, R. Kumar, P. Raghavan, and A. Tomkins. Propagation of trust and distrust. In Conference on the World Wide Web(WWW), pages 403-412, 2004. [13] M. Gupta, P. Judge, and M. H. Ammar. A reputation system for peer-to-peer networks. In Network and Operating System Support for Digital Audio and Video(NOSSDAV), pages 144-152, 2003. [14] Z. Gyongi, P. Berkhin, H. Garcia-Molina, and J. Pedersen. Link spam detection based on mass estimation. Technical report, Stanford University, 005. [15] J. Ioannidis, S. Ioannidis, A. D. Keromytis, and V. Prevelakis. Fileteller: Paying and getting paid for file storage. In Financial Cryptography, pages 282-299, 002. [16] E. T. Jaynes. Where do we stand on maximum entropy? In R. D. Levine and M. Tribus, editors, The Maximum Entropy Formalism, pages 15-118. MIT Press, Cambridge, Mass., 1978. 48 [17] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina. The Eigentrust algorithm for reputation management in P2P networks. In Conference on the World Wide Web (WWW), pages 640-651, 2003. [18] M. Kandori. Social norms and community enforcement. Review of Economic Studies, 59:63-80, 992. [19] LogiSense Corporation. LogiSense web site. http://www.logisense.com/tm p2p.html. [20] L. Lovasz and P. Winkler. Mixing of random walks and other diffusions on a graph. In Surveys in Combinatorics, 1993, Walker (Ed.), London Mathematical Society Lecture Note Series 187, Cambridge University Press. 1995. [21] Open Source Technology Group. Slashdot  FAQcomments and moderation. http://slashdot.org/faq/com-mod.shtml#cm700. [22] OSMB LLC. Gnutella web site. http://www.gnutella.com/. [23] M. L. Puterman. Markov Decision Processes. Wiley, 994. [24] SETI@home. SETI@home web page. http://setiathome.ssl.berkeley.edu/. [25] Sharman Networks Ltd. Kazaa web site. http://www.kazaa.com/. [26] V. Vishnumurthy, S. Chandrakumar, and E. Sirer. Karma: A secure economic framework for peer-to-peer resource sharing. In Workshop on Economics of Peer-to-Peer Systems (P2PECON), 2003. [27] L. Xiong and L. Liu. Building trust in decentralized peer-to-peer electronic communities. In Internation Conference on Electronic Commerce Research (ICECR), 2002. [28] H. Zhang, A. Goel, R. Govindan, K. Mason, and B. V. Roy. Making eigenvector-based reputation systems robust to collusion. In Workshop on Algorithms and Models for the Web-Graph(WAW), pages 92-104, 004. 49
Playing Games in Many Possible Worlds Matt Lepinski∗ , David Liben-Nowell† , Seth Gilbert∗ , and April Rasala Lehman‡ (∗ ) Computer Science and Artificial Intelligence Laboratory, MIT; Cambridge, MA 02139 († ) Department of Computer Science, Carleton College; Northfield, MN 55057 (‡ ) Google, Inc.; Mountain View, CA 94043 lepinski,sethg@theory.lcs.mit.edu, dlibenno@carleton.edu, alehman@google.com ABSTRACT In traditional game theory, players are typically endowed with exogenously given knowledge of the structure of the game-either full omniscient knowledge or partial but fixed information. In real life, however, people are often unaware of the utility of taking a particular action until they perform research into its consequences. In this paper, we model this phenomenon. We imagine a player engaged in a  questionand-answer session, asking questions both about his or her own preferences and about the state of reality; thus we call this setting Socratic game theory. In a Socratic game, players begin with an a priori probability distribution over many possible worlds, with a different utility function for each world. Players can make queries, at some cost, to learn partial information about which of the possible worlds is the actual world, before choosing an action. We consider two query models: (1) an unobservable-query model, in which players learn only the response to their own queries, and (2) an observable-query model, in which players also learn which queries their opponents made. The results in this paper consider cases in which the  underlying worlds of a two-player Socratic game are either constant-sum games or strategically zero-sum games, a class that generalizes constant-sum games to include all games in which the sum of payoffs depends linearly on the interaction between the players. When the underlying worlds are  constant sum, we give polynomial-time algorithms to find Nash equilibria in both the observable- and unobservable-query models. When the worlds are strategically zero sum, we give efficient algorithms to find Nash equilibria in  unobservablequery Socratic games and correlated equilibria in  observablequery Socratic games. Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of algorithms and problem complexity; J.4 [Social and Behavioral  Sciences]: Economics General Terms Algorithms, Economics, Theory . INTRODUCTION Late October 1960. A smoky room. Democratic Party strategists huddle around a map. How should the Kennedy campaign allocate its remaining advertising budget? Should it focus on, say, California or New York? The Nixon  campaign faces the same dilemma. Of course, neither campaign knows the effectiveness of its advertising in each state.  Perhaps Californians are susceptible to Nixon"s advertising, but are unresponsive to Kennedy"s. In light of this uncertainty, the Kennedy campaign may conduct a survey, at some cost, to estimate the effectiveness of its advertising. Moreover, the larger-and more expensive-the survey, the more accurate it will be. Is the cost of a survey worth the information that it provides? How should one balance the cost of acquiring more information against the risk of playing a game with higher uncertainty? In this paper, we model situations of this type as Socratic games. As in traditional game theory, the players in a  Socratic game choose actions to maximize their payoffs, but we model players with incomplete information who can make costly queries to reduce their uncertainty about the state of the world before they choose their actions. This approach contrasts with traditional game theory, in which players are usually modeled as having fixed, exogenously given  information about the structure of the game and its payoffs. (In traditional games of incomplete and imperfect information, there is information that the players do not have; in Socratic games, unlike in these games, the players have a chance to acquire the missing information, at some cost.) A number of related models have been explored by economists and  computer scientists motivated by similar situations, often with a focus on mechanism design and auctions; a sampling of this research includes the work of Larson and Sandholm [41, 2, 43, 44], Parkes [59], Fong [22], Compte and Jehiel [12], Rezende [63], Persico and Matthews [48, 60], Cr´emer and Khalil [15], Rasmusen [62], and Bergemann and V¨alim¨aki [4, ]. The model of Bergemann and V¨alim¨aki is similar in many regards to the one that we explore here; see Section 7 for some discussion. A Socratic game proceeds as follows. A real world is  cho150 sen randomly from a set of possible worlds according to a common prior distribution. Each player then selects an  arbitrary query from a set of available costly queries and  receives a corresponding piece of information about the real world. Finally each player selects an action and receives a payoff-a function of the players" selected actions and the identity of the real world-less the cost of the query that he or she made. Compared to traditional game theory, the distinguishing feature of our model is the introduction of explicit costs to the players for learning arbitrary partial  information about which of the many possible worlds is the real world. Our research was initially inspired by recent results in  psychology on decision making, but it soon became clear that Socratic game theory is also a general tool for understanding the exploitation versus exploration tradeoff, well studied in machine learning, in a strategic multiplayer environment. This tension between the risk arising from uncertainty and the cost of acquiring information is ubiquitous in economics, political science, and beyond. Our results. We consider Socratic games under two  models: an unobservable-query model where players learn only the response to their own queries and an observable-query model where players also learn which queries their opponents made. We give efficient algorithms to find Nash  equilibriai.e., tuples of strategies from which no player has unilateral incentive to deviate-in broad classes of two-player Socratic games in both models. Our first result is an efficient  algorithm to find Nash equilibria in unobservable-query  Socratic games with constant-sum worlds, in which the sum of the players" payoffs is independent of their actions. Our techniques also yield Nash equilibria in unobservable-query Socratic games with strategically zero-sum worlds.  Strategically zero-sum games generalize constant-sum games by allowing the sum of the players" payoffs to depend on  individual players" choices of strategy, but not on any interaction of their choices. Our second result is an efficient algorithm to find Nash equilibria in observable-query Socratic games with constant-sum worlds. Finally, we give an efficient  algorithm to find correlated equilibria-a weaker but  increasingly well-studied solution concept for games [2, 3, 32, 56, 7]-in observable-query Socratic games with strategically zero-sum worlds. Like all games, Socratic games can be viewed as a  special case of extensive-form games, which represent games by trees in which internal nodes represent choices made by chance or by the players, and the leaves represent outcomes that correspond to a vector of payoffs to the players.  Algorithmically, the generality of extensive-form games makes them difficult to solve efficiently, and the special cases that are known to be efficiently solvable do not include even  simple Socratic games. Every (complete-information) classical game is a trivial Socratic game (with a single possible world and a single trivial query), and efficiently finding Nash  equilibria in classical games has been shown to be hard [10, 11, 3, 16, 17, 27, 54, 55]. Therefore we would not expect to find a straightforward polynomial-time algorithm to  compute Nash equilibria in general Socratic games. However, it is well known that Nash equilibria can be found efficiently via an LP for two-player constant-sum games [49, 71] (and strategically zero-sum games [51]). A Socratic game is itself a classical game, so one might hope that these results can be applied to Socratic games with constant-sum (or  strategically zero-sum) worlds. We face two major obstacles in extending these  classical results to Socratic games. First, a Socratic game with constant-sum worlds is not itself a constant-sum classical game-rather, the resulting classical game is only  strategically zero sum. Worse yet, a Socratic game with  strategically zero-sum worlds is not itself classically strategically zero sum-indeed, there are no known efficient  algorithmic techniques to compute Nash equilibria in the resulting class of classical games. (Exponential-time algorithms like Lemke/Howson, of course, can be used [45].) Thus even when it is easy to find Nash equilibria in each of the worlds of a Socratic game, we require new techniques to solve the Socratic game itself. Second, even when the Socratic game itself is strategically zero sum, the number of possible  strategies available to each player is exponential in the natural representation of the game. As a result, the standard linear programs for computing equilibria have an exponential  number of variables and an exponential number of constraints. For unobservable-query Socratic games with strategically zero-sum worlds, we address these obstacles by  formulating a new LP that uses only polynomially many variables (though still an exponential number of constraints) and then use ellipsoid-based techniques to solve it. For  observablequery Socratic games, we handle the exponentiality by  decomposing the game into stages, solving the stages  separately, and showing how to reassemble the solutions  efficiently. To solve the stages, it is necessary to find Nash equilibria in Bayesian strategically zero-sum games, and we give an explicit polynomial-time algorithm to do so. . GAMES AND SOCRATIC GAMES In this section, we review background on game theory and formally introduce Socratic games. We present these  models in the context of two-player games, but the multiplayer case is a natural extension. Throughout the paper,  boldface variables will be used to denote a pair of variables (e.g., a = ai, aii ). Let Pr[x ← π] denote the probability that a particular value x is drawn from the distribution π, and let Ex∼π[g(x)] denote the expectation of g(x) when x is drawn from π. .1 Background on Game Theory Consider two players, Player I and Player II, each of whom is attempting to maximize his or her utility (or payoff). A (two-player) game is a pair A, u , where, for i ∈ {i,ii}, • Ai is the set of pure strategies for Player i, and A = Ai, Aii ; and • ui : A → R is the utility function for Player i, and u = ui, uii . We require that A and u be common knowledge. If each Player i chooses strategy ai ∈ Ai, then the payoffs to  Players I and II are ui(a) and uii(a), respectively. A game is  constant sum if, for all a ∈ A, we have that ui(a) + uii(a) = c for some fixed c independent of a. Player i can also play a mixed strategy αi ∈ Ai, where Ai denotes the space of probability measures over the set Ai. Payoff functions are generalized as ui (α) = ui (αi, αii) := Ea∼α[ui (a)] = P a∈A α(a)ui (a), where the quantity α(a) = 51 αi(ai) · αii(aii) denotes the joint probability of the  independent events that each Player i chooses action ai from the distribution αi. This generalization to mixed strategies is known as von Neumann/Morgenstern utility [70], in which players are indifferent between a guaranteed payoff x and an expected payoff of x. A Nash equilibrium is a pair α of mixed strategies so that neither player has an incentive to change his or her strategy unilaterally. Formally, the strategy pair α is a Nash  equilibrium if and only if both ui(αi, αii) = maxαi∈Ai ui(αi, αii) and uii(αi, αii) = maxαii∈Aii uii(αi, αii); that is, the  strategies αi and αii are mutual best responses. A correlated equilibrium is a distribution ψ over A that obeys the following: if a ∈ A is drawn randomly according to ψ and Player i learns ai, then no Player i has incentive to deviate unilaterally from playing ai. (A Nash equilibrium is a correlated equilibrium in which ψ(a) = αi(ai) · αii(aii) is a product distribution.) Formally, in a correlated equilibrium, for every a ∈ A we must have that ai is a best response to a randomly chosen ˆaii ∈ Aii drawn according to ψ(ai, ˆaii), and the analogous condition must hold for Player II. .2 Socratic Games In this section, we formally define Socratic games. A Socratic game is a 7-tuple A, W, u, S, Q, p, δ , where, for i ∈ {i,ii}: • Ai is, as before, the set of pure strategies for Player i. • W is a set of possible worlds, one of which is the real world wreal. • ui = {uw i : A → R | w ∈ W} is a set of payoff functions for Player i, one for each possible world. • S is a set of signals. • Qi is a set of available queries for Player i. When Player i makes query qi : W → S, he or she receives the signal qi(wreal). When Player i receives signal qi(wreal) in response to query qi, he or she can infer that wreal ∈ {w : qi(w) = qi(wreal)}, i.e., the set of possible worlds from which query qi cannot distinguish wreal. • p : W → [0, 1] is a probability distribution over the possible worlds. • δi : Qi → R≥0 gives the query cost for each available query for Player i. Initially, the world wreal is chosen according to the  probability distribution p, but the identity of wreal remains  unknown to the players. That is, it is as if the players are playing the game A, uwreal but do not know wreal. The players make queries q ∈ Q, and Player i receives the signal qi(wreal). We consider both observable queries and  unobservable queries. When queries are observable, each player learns which query was made by the other player, and the results of his or her own query-that is, each Player i learns qi, qii, and qi(wreal). For unobservable queries, Player i learns only qi and qi(wreal). After learning the results of the queries, the players select strategies a ∈ A and receive as payoffs u wreal i (a) − δi(qi). In the Socratic game, a pure strategy for Player i consists of a query qi ∈ Qi and a response function mapping any  result of the query qi to a strategy ai ∈ Ai to play. A player"s state of knowledge after a query is a point in R := Q × S or Ri := Qi × S for observable or unobservable queries,  respectively. Thus Player i"s response function maps R or Ri to Ai. Note that the number of pure strategies is  exponential, as there are exponentially many response  functions. A mixed strategy involves both randomly choosing a query qi ∈ Qi and randomly choosing an action ai ∈ Ai in response to the results of the query. Formally, we will consider a mixed-strategy-function profile f = fquery , fresp to have two parts: • a function fquery i : Qi → [0, 1], where fquery i (qi) is the probability that Player i makes query qi. • a function fresp i that maps R or Ri to a  probability distribution over actions. Player i chooses an  action ai ∈ Ai according to the probability distribution fresp i (q, qi(w)) for observable queries, and according to fresp i (qi, qi(w)) for unobservable queries. (With  unobservable queries, for example, the probability that Player I plays action ai conditioned on making query qi in world w is given by Pr[ai ← fresp i (qi, qi(w))].) Mixed strategies are typically defined as probability  distributions over the pure strategies, but here we represent a mixed strategy by a pair fquery , fresp , which is commonly referred to as a behavioral strategy in the game-theory literature. As in any game with perfect recall, one can  easily map a mixture of pure strategies to a behavioral strategy f = fquery , fresp that induces the same probability of  making a particular query qi or playing a particular action after making a query qi in a particular world. Thus it suffices to consider only this representation of mixed strategies. For a strategy-function profile f for observable queries, the (expected) payoff to Player i is given by X q∈Q,w∈W,a∈A     fquery i (qi) · fquery ii (qii) · p(w) · Pr[ai ← fresp i (q, qi(w))] · Pr[aii ← fresp ii (q, qii(w))] · (uw i (a) − δi(qi))     . The payoffs for unobservable queries are analogous, with fresp j (qj, qj(w)) in place of fresp j (q, qj(w)). . STRATEGICALLY ZERO-SUM GAMES We can view a Socratic game G with constant-sum worlds as an exponentially large classical game, with pure  strategies make query qi and respond according to fi.  However, this classical game is not constant sum. The sum of the players" payoffs varies depending upon their strategies, because different queries incur different costs. However, this game still has significant structure: the sum of payoffs varies only because of varying query costs. Thus the sum of  payoffs does depend on players" choice of strategies, but not on the interaction of their choices-i.e., for fixed functions gi and gii, we have ui(q, f) + uii(q, f) = gi(qi, fi) + gii(qii, fii) for all strategies q, f . Such games are called strategically zero sum and were introduced by Moulin and Vial [51], who describe a notion of strategic equivalence and define  strategically zero-sum games as those strategically equivalent to zero-sum games. It is interesting to note that two Socratic games with the same queries and strategically equivalent worlds are not necessarily strategically equivalent. A game A, u is strategically zero sum if there exist labels (i, ai) for every Player i and every pure strategy ai ∈ Ai 52 such that, for all mixed-strategy profiles α, we have that the sum of the utilities satisfies ui(α)+uii(α) = X ai∈Ai αi(ai)· (i, ai)+ X aii∈Aii αii(aii)· (ii, aii). Note that any constant-sum game is strategically zero sum as well. It is not immediately obvious that one can efficiently  decide if a given game is strategically zero sum. For  completeness, we give a characterization of classical strategically zero-sum games in terms of the rank of a simple matrix  derived from the game"s payoffs, allowing us to efficiently  decide if a given game is strategically zero sum and, if it is, to compute the labels (i, ai). Theorem 3.1. Consider a game G = A, u with Ai = {a1 i , . . . , ani i }. Let MG be the ni-by-nii matrix whose i, j th entry MG (i,j) satisfies log2 MG (i,j) = ui(ai i , aj ii) + uii(ai i , aj ii). Then the following are equivalent: (i) G is strategically zero sum; (ii) there exist labels (i, ai) for every player i ∈ {i,ii} and every pure strategy ai ∈ Ai such that, for all pure strategies a ∈ A, we have ui(a) + uii(a) = (i, ai) + (ii, aii); and (iii) rank(MG ) = 1. Proof Sketch. (i ⇒ ii) is immediate; every pure  strategy is a trivially mixed strategy. For (ii ⇒ iii), let ci be the n-element column vector with jth component 2 (i,a j i ) ; then ci · cii T = MG . For (iii ⇒ i), if rank(MG ) = 1, then MG = u · vT . We can prove that G is strategically zero sum by choosing labels (i, aj i ) := log2 uj and (ii, aj ii) := log2 vj. . SOCRATIC GAMES WITH UNOBSERVABLE QUERIES We begin with Socratic games with unobservable queries, where a player"s choice of query is not revealed to her  opponent. We give an efficient algorithm to solve  unobservablequery Socratic games with strategically zero-sum worlds. Our algorithm is based upon the LP shown in Figure 1, whose feasible points are Nash equilibria for the game. The LP has polynomially many variables but exponentially many constraints. We give an efficient separation oracle for the LP, implying that the ellipsoid method [28, 38] yields an efficient algorithm. This approach extends the techniques of Koller and Megiddo [39] (see also [40]) to solve constant-sum games represented in extensive form. (Recall that their result does not directly apply in our case; even a Socratic game with constant-sum worlds is not a constant-sum classical game.) Lemma 4.1. Let G = A, W, u, S, Q, p, δ be an arbitrary unobservable-query Socratic game with strategically zero-sum worlds. Any feasible point for the LP in Figure 1 can be  efficiently mapped to a Nash equilibrium for G, and any Nash equilibrium for G can be mapped to a feasible point for the program. Proof Sketch. We begin with a description of the  correspondence between feasible points for the LP and Nash equilibria for G. First, suppose that strategy profile f = fquery , fresp forms a Nash equilibrium for G. Then the  following setting for the LP variables is feasible: yi qi = fquery i (qi) xi ai,qi,w = Pr[ai ← fresp i (qi, qi(w))] · yi qi ρi = P w,q∈Q,a∈A p(w) · xi ai,qi,w · xii aii,qii,w · [uw i (a) − δi(qi)]. (We omit the straightforward calculations that verify  feasibility.) Next, suppose xi ai,qi,w, yi qi , ρi is feasible for the LP. Let f be the strategy-function profile defined as fquery i : qi → yi qi fresp i (qi, qi(w)) : ai → xi ai,qi,w/yi qi . Verifying that this strategy profile is a Nash equilibrium requires checking that fresp i (qi, qi(w)) is a well-defined  function (from constraint VI), that fquery i and fresp i (qi, qi(w)) are probability distributions (from constraints III and IV), and that each player is playing a best response to his or her  opponent"s strategy (from constraints I and II). Finally, from constraints I and II, the expected payoff to Player i is at most ρi. Because the right-hand side of constraint VII is equal to the expected sum of the payoffs from f and is at most ρi + ρii, the payoffs are correct and imply the lemma. We now give an efficient separation oracle for the LP in Figure 1, thus allowing the ellipsoid method to solve the LP in polynomial time. Recall that a separation oracle is a function that, given a setting for the variables in the LP, either returns feasible or returns a particular constraint of the LP that is violated by that setting of the variables. An efficient, correct separation oracle allows us to solve the LP efficiently via the ellipsoid method. Lemma 4.2. There exists a separation oracle for the LP in Figure 1 that is correct and runs in polynomial time. Proof. Here is a description of the separation oracle SP. On input xi ai,qi,w, yi qi , ρi : . Check each of the constraints (III), (IV), (V), (VI), and (VII). If any one of these constraints is violated, then return it. . Define the strategy profile f as follows: fquery i : qi → yi qi fresp i (qi, qi(w)) : ai → xi ai,qi,w/yi qi For each query qi, we will compute a pure best-response function ˆf qi i for Player I to strategy fii after making query qi. More specifically, given fii and the result qi(wreal) of the query qi, it is straightforward to compute the  probability that, conditioned on the fact that the result of query qi is qi(w), the world is w and Player II will play action aii ∈ Aii. Therefore, for each query qi and  response qi(w), Player I can compute the expected utility of each pure response ai to the induced mixed strategy over Aii for Player II. Player I can then select the ai maximizing this expected payoff. Let ˆfi be the response function such that ˆfi(qi, qi(w)) = ˆf qi i (qi(w)) for every qi ∈ Qi. Similarly, compute ˆfii. 53 Player i does not prefer ‘make query qi, then play according to the function fi" : ∀qi ∈ Qi, fi : Ri → Ai : ρi ≥ P w∈W,aii∈Aii,qii∈Qii,ai=fi(qi,qi(w)) ` p(w) · xii aii,qii,w · [uw i (a) − δi(qi)] ´ (I) ∀qii ∈ Qii, fii : Rii → Aii : ρii ≥ P w∈W,ai∈Ai,qi∈Qi,aii=fii(qii,qii(w)) ` p(w) · xi ai,qi,w · [uw ii (a) − δii(qii)] ´ (II) Every player"s choices form a probability distribution in every world: ∀i ∈ {i,ii}, w ∈ W : 1 = P ai∈Ai,qi∈Qi xi ai,qi,w (III) ∀i ∈ {i,ii}, w ∈ W : 0 ≤ xi ai,qi,w (IV) Queries are independent of the world, and actions depend only on query output: ∀i ∈ {i,ii}, qi ∈ Qi, w ∈ W, w ∈ W such that qi(w) = qi(w ) : yi qi = P ai∈Ai xi ai,qi,w (V) xi ai,qi,w = xi ai,qi,w (VI) The payoffs are consistent with the labels (i, ai, w): ρi + ρii = P i∈{i,ii} P w∈W,qi∈Qi,ai∈Ai ` p(w) · xi ai,qi,w · [ (i, ai, w) − δi(qi)] ´ (VII) Figure 1: An LP to find Nash equilibria in unobservable-query Socratic games with strategically zero-sum worlds. The input is a Socratic game A, W, u, S, Q, p, δ so that world w is strategically zero sum with labels (i, ai, w). Player i makes query qi ∈ Qi with probability yi qi and, when the actual world is w ∈ W, makes query qi and plays action ai with probability xi ai,qi,w. The expected payoff to Player i is given by ρi. . Let ˆρ qi i be the expected payoff to Player I using the strategy make query qi and play response function ˆfi if Player II plays according to fii. Let ˆρi = maxqi∈Qq ˆρ qi i and let ˆqi = arg maxqi∈Qq ˆρ qi i . Similarly, define ˆρ qii ii , ˆρii, and ˆqii. . For the ˆfi and ˆqi defined in Step 3, return constraint (I-ˆqi- ˆfi) or (II-ˆqii- ˆfii) if either is violated. If both are satisfied, then return feasible. We first note that the separation oracle runs in polynomial time and then prove its correctness. Steps 1 and 4 are clearly polynomial. For Step 2, we have described how to compute the relevant response functions by examining every action of Player I, every world, every query, and every action of Player II. There are only polynomially many queries, worlds, query results, and pure actions, so the running time of Steps 2 and  is thus polynomial. We now sketch the proof that the separation oracle works correctly. The main challenge is to show that if any  constraint (I-qi-fi ) is violated then (I-ˆqi- ˆfi) is violated in Step 4. First, we observe that, by construction, the function ˆfi  computed in Step 3 must be a best response to Player II playing fii, no matter what query Player I makes. Therefore the strategy make query ˆqi, then play response function ˆfi must be a best response to Player II playing fii, by definition of ˆqi. The right-hand side of each constraint (I-qi-fi ) is equal to the expected payoff that Player I receives when playing the pure strategy make query qi and then play response function fi  against Player II"s strategy of fii. Therefore, because the pure strategy make query ˆqi and then play response function ˆfi is a best response to Player II  playing fii, the right-hand side of constraint (I-ˆqi- ˆfi) is at least as large as the right hand side of any constraint (I-ˆqi-fi ). Therefore, if any constraint (I-qi-fi ) is violated, constraint (I-ˆqi- ˆfi) is also violated. An analogous argument holds for Player II. These lemmas and the well-known fact that Nash  equilibria always exist [52] imply the following theorem: Theorem 4.3. Nash equilibria can be found in  polynomial time for any two-player unobservable-query Socratic game with strategically zero-sum worlds. . SOCRATIC GAMES WITH OBSERVABLE QUERIES In this section, we give efficient algorithms to find (1) a Nash equilibrium for observable-query Socratic games with constant-sum worlds and (2) a correlated equilibrium in the broader class of Socratic games with strategically zero-sum worlds. Recall that a Socratic game G = A, W, u, S, Q, p, δ with observable queries proceeds in two stages: Stage 1: The players simultaneously choose queries q ∈ Q. Player i receives as output qi, qii, and qi(wreal). Stage 2: The players simultaneously choose strategies a ∈ A. The payoff to Player i is u wreal i (a) − δi(qi). Using backward induction, we first solve Stage 2 and then proceed to the Stage-1 game. For a query q ∈ Q, we would like to analyze the Stage-2 game ˆGq resulting from the players making queries q in Stage 1. Technically, however, ˆGq is not actually a game, because at the beginning of Stage 2 the players have different information about the world: Player I knows qi(wreal), and 54 Player II knows qii(wreal). Fortunately, the situation in which players have asymmetric private knowledge has been well studied in the game-theory literature. A Bayesian game is a quadruple A, T, r, u , where: • Ai is the set of pure strategies for Player i. • Ti is the set of types for Player i. • r is a probability distribution over T; r(t) denotes the probability that Player i has type ti for all i. • ui : A × T → R is the payoff function for Player i. If the players have types t and play pure strategies a, then ui(a, t) denotes the payoff for Player i. Initially, a type t is drawn randomly from T according to the distribution r. Player i learns his type ti, but does not learn any other player"s type. Player i then plays a mixed strategy αi ∈ Ai-that is, a probability distribution over Ai-and receives payoff ui(α, t). A strategy function is a function hi : Ti → Ai; Player i plays the mixed strategy hi(ti) ∈ Ai when her type is ti. A strategy-function profile h is a Bayesian Nash equilibrium if and only if no Player i has  unilateral incentive to deviate from hi if the other players play according to h. For a two-player Bayesian game, if α = h(t), then the profile h is a Bayesian Nash equilibrium exactly when the following condition and its analogue for Player II hold: Et∼r[ui(α, t)] = maxhi Et∼r[ui( hi(ti), αii , t)]. These conditions hold if and only if, for all ti ∈ Ti occurring with positive probability, Player i"s expected utility conditioned on his type being ti is maximized by hi(ti). A Bayesian game is constant sum if for all a ∈ A and all t ∈ T, we have ui(a, t) + uii(a, t) = ct, for some constant ct  independent of a. A Bayesian game is strategically zero sum if the classical game A, u(·, t) is strategically zero sum for every t ∈ T. Whether a Bayesian game is strategically zero sum can be determined as in Theorem 3.1. (For further  discussion of Bayesian games, see [25, 31].) We now formally define the Stage-2 game as a Bayesian game. Given a Socratic game G = A, W, u, S, Q, p, δ and a query profile q ∈ Q, we define the Stage-2 Bayesian game Gstage2(q) := A, Tq , pstage2(q) , ustage2(q) , where: • Ai, the set of pure strategies for Player i, is the same as in the original Socratic game; • Tq i = {qi(w) : w ∈ W}, the set of types for Player i, is the set of signals that can result from query qi; • pstage2(q) (t) = Pr[q(w) = t | w ← p]; and • u stage2(q) i (a, t) = P w∈W Pr[w ← p | q(w) = t] · uw i (a). We now define the Stage-1 game in terms of the payoffs for the Stage-2 games. Fix any algorithm alg that finds a Bayesian Nash equilibrium hq,alg := alg(Gstage2(q)) for each Stage-2 game. Define valuealg i (Gstage2(q)) to be the expected payoff received by Player i in the Bayesian game Gstage2(q) if each player plays according to hq,alg , that is, valuealg i (Gstage2(q)) := P w∈W p(w) · u stage2(q) i (hq,alg (q(w)), q(w)). Define the game Galg stage1 := Astage1 , ustage1(alg) , where: • Astage1 := Q, the set of available queries in the Socratic game; and • u stage1(alg) i (q) := valuealg i (Gstage2(q)) − δi(qi). I.e., players choose queries q and receive payoffs  corresponding to valuealg (Gstage2(q)), less query costs. Lemma 5.1. Consider an observable-query Socratic game G = A, W, u, S, Q, p, δ . Let Gstage2(q) be the Stage-2 games for all q ∈ Q, let alg be an algorithm finding a Bayesian Nash equilibrium in each Gstage2(q), and let Galg stage1 be the Stage-1 game. Let α be a Nash equilibrium for Galg stage1, and let hq,alg := alg(Gstage2(q)) be a Bayesian Nash equilibrium for each Gstage2(q). Then the following strategy profile is a Nash equilibrium for G: • In Stage 1, Player i makes query qi with probability αi(qi). (That is, set fquery (q) := α(q).) • In Stage 2, if q is the query in Stage 1 and qi(wreal) denotes the response to Player i"s query, then Player i chooses action ai with probability hq,alg i (qi(wreal)). (In other words, set fresp i (q, qi(w)) := hq,alg i (qi(w)).) We now find equilibria in the stage games for Socratic games with constant- or strategically zero-sum worlds. We first show that the stage games are well structured in this setting: Lemma 5.2. Consider an observable-query Socratic game G = A, W, u, S, Q, p, δ with constant-sum worlds. Then the Stage-1 game Galg stage1 is strategically zero sum for every algorithm alg, and every Stage-2 game Gstage2(q) is Bayesian constant sum. If the worlds of G are strategically zero sum, then every Gstage2(q) is Bayesian strategically zero sum. We now show that we can efficiently compute equilibria for these well-structured stage games. Theorem 5.3. There exists a polynomial-time algorithm BNE finding Bayesian Nash equilibria in strategically  zerosum Bayesian (and thus classical strategically zero-sum or Bayesian constant-sum) two-player games. Proof Sketch. Let G = A, T, r, u be a strategically zero-sum Bayesian game. Define an unobservable-query  Socratic game G∗ with one possible world for each t ∈ T, one available zero-cost query qi for each Player i so that qi  reveals ti, and all else as in G. Bayesian Nash equilibria in G correspond directly to Nash equilibria in G∗ , and the worlds of G∗ are strategically zero sum. Thus by Theorem 4.3 we can compute Nash equilibria for G∗ , and thus we can  compute Bayesian Nash equilibria for G. (LP"s for zero-sum two-player Bayesian games have been previously developed and studied [61].) Theorem 5.4. We can compute a Nash equilibrium for an arbitrary two-player observable-query Socratic game G = A, W, u, S, Q, p, δ with constant-sum worlds in polynomial time. Proof. Because each world of G is constant sum, Lemma .2 implies that the induced Stage-2 games Gstage2(q) are all Bayesian constant sum. Thus we can use algorithm BNE to compute a Bayesian Nash equilibrium hq,BNE := BNE(Gstage2(q)) for each q ∈ Q, by Theorem 5.3.  Furthermore, again by Lemma 5.2, the induced Stage-1 game GBNE stage1 is classical strategically zero sum. Therefore we can again use algorithm BNE to compute a Nash equilibrium α := BNE(GBNE stage1), again by Theorem 5.3. Therefore, by Lemma 5.1, we can assemble α and the hq,BNE "s into a Nash equilibrium for the Socratic game G. 55 We would like to extend our results on observable-query Socratic games to Socratic games with strategically  zerosum worlds. While we can still find Nash equilibria in the Stage-2 games, the resulting Stage-1 game is not in  general strategically zero sum. Thus, finding Nash equilibria in observable-query Socratic games with strategically  zerosum worlds seems to require substantially new techniques. However, our techniques for decomposing observable-query Socratic games do allow us to find correlated equilibria in this case. Lemma 5.5. Consider an observable-query Socratic game G = A, W, u, S, Q, p, δ . Let alg be an arbitrary algorithm that finds a Bayesian Nash equilibrium in each of the derived Stage-2 games Gstage2(q), and let Galg stage1 be the derived  Stage1 game. Let φ be a correlated equilibrium for Galg stage1, and let hq,alg := alg(Gstage2(q)) be a Bayesian Nash equilibrium for each Gstage2(q). Then the following distribution over pure strategies is a correlated equilibrium for G: ψ(q, f) := φ(q) Y i∈{i,ii} Y s∈S Pr h fi(q, s) ← hq,alg i (s) i . Thus to find a correlated equilibrium in an observable-query Socratic game with strategically zero-sum worlds, we need only algorithm BNE from Theorem 5.3 along with an  efficient algorithm for finding a correlated equilibrium in a  general game. Such an algorithm exists (the definition of  correlated equilibria can be directly translated into an LP [3]), and therefore we have the following theorem: Theorem 5.6. We can provide both efficient oracle  access and efficient sampling access to a correlated  equilibrium for any observable-query two-player Socratic game with strategically zero-sum worlds. Because the support of the correlated equilibrium may be exponentially large, providing oracle and sampling access is the natural way to represent the correlated equilibrium. By Lemma 5.5, we can also compute correlated equilibria in any observable-query Socratic game for which Nash  equilibria are computable in the induced Gstage2(q) games (e.g., when Gstage2(q) is of constant size). Another potentially interesting model of queries in  Socratic games is what one might call public queries, in which both the choice and outcome of a player"s query is  observable by all players in the game. (This model might be most appropriate in the presence of corporate espionage or media leaks, or in a setting in which the queries-and thus their results-are done in plain view.) The techniques that we have developed in this section also yield exactly the same results as for observable queries. The proof is actually  simpler: with public queries, the players" payoffs are common knowledge when Stage 2 begins, and thus Stage 2 really is a complete-information game. (There may still be uncertainty about the real world, but all players use the observed  signals to infer exactly the same set of possible worlds in which wreal may lie; thus they are playing a complete-information game against each other.) Thus we have the same results as in Theorems 5.4 and 5.6 more simply, by solving Stage 2 using a (non-Bayesian) Nash-equilibrium finder and solving Stage 1 as before. Our results for observable queries are weaker than for  unobservable: in Socratic games with worlds that are  strategically zero sum but not constant sum, we find only a  correlated equilibrium in the observable case, whereas we find a Nash equilibrium in the unobservable case. We might hope to extend our unobservable-query techniques to observable queries, but there is no obvious way to do so. The  fundamental obstacle is that the LP"s payoff constraint becomes nonlinear if there is any dependence on the probability that the other player made a particular query. This dependence arises with observable queries, suggesting that observable Socratic games with strategically zero-sum worlds may be harder to solve. . RELATED WORK Our work was initially motivated by research in the social sciences indicating that real people seem (irrationally)  paralyzed when they are presented with additional options. In this section, we briefly review some of these social-science experiments and then discuss technical approaches related to Socratic game theory. Prima facie, a rational agent"s happiness given an added option can only increase. However, recent research has found that more choices tend to decrease happiness: for  example, students choosing among extra-credit options are more likely to do extra credit if given a small subset of the choices and, moreover, produce higher-quality work [35]. (See also [19].) The psychology literature explores a number of  explanations: people may miscalculate their opportunity cost by comparing their choice to a component-wise maximum of all other options instead of the single best alternative [65], a new option may draw undue attention to aspects of the other options [67], and so on. The present work explores an economic explanation of this phenomenon: information is not free. When there are more options, a decision-maker must spend more time to achieve a satisfactory outcome. See, e.g., the work of Skyrms [68] for a philosophical  perspective on the role of deliberation in strategic situations. Finally, we note the connection between Socratic games and modal logic [34], a formalism for the logic of possibility and necessity. The observation that human players typically do not play rational strategies has inspired some attempts to model partially rational players. The typical model of this  socalled bounded rationality [36, 64, 66] is to postulate bounds on computational power in computing the consequences of a strategy. The work on bounded rationality [23, 24, 53, 58] differs from the models that we consider here in that instead of putting hard limitations on the computational power of the agents, we instead restrict their a priori knowledge of the state of the world, requiring them to spend time (and therefore money/utility) to learn about it. Partially observable stochastic games (POSGs) are a  general framework used in AI to model situations of multi-agent planning in an evolving, unknown environment, but the  generality of POSGs seems to make them very difficult [6].  Recent work has been done in developing algorithms for  restricted classes of POSGs, most notably classes of  cooperative POSGs-e.g., [20, 30]-which are very different from the competitive strategically zero-sum games we address in this paper. The fundamental question in Socratic games is deciding on the comparative value of making a more costly but more informative query, or concluding the data-gathering phase and picking the best option, given current information. This tradeoff has been explored in a variety of other contexts; a sampling of these contexts includes aggregating results 56 from delay-prone information sources [8], doing approximate reasoning in intelligent systems [72], deciding when to take the current best guess of disease diagnosis from a  beliefpropagation network and when to let it continue inference [33], among many others. This issue can also be viewed as another perspective on the general question of exploration versus exploitation that arises often in AI: when is it better to actively seek  additional information instead of exploiting the knowledge one already has? (See, e.g., [69].) Most of this work differs significantly from our own in that it considers single-agent planning as opposed to the game-theoretic setting. A  notable exception is the work of Larson and Sandholm [41, 42, 3, 44] on mechanism design for interacting agents whose computation is costly and limited. They present a model in which players must solve a computationally intractable valuation problem, using costly computation to learn some hidden parameters, and results for auctions and bargaining games in this model. . FUTURE DIRECTIONS Efficiently finding Nash equilibria in Socratic games with non-strategically zero-sum worlds is probably difficult  because the existence of such an algorithm for classical games has been shown to be unlikely [10, 11, 13, 16, 17, 27, 54, 5]. There has, however, been some algorithmic success in finding Nash equilibria in restricted classical settings (e.g., [21, 46, 47, 57]); we might hope to extend our results to analogous Socratic games. An efficient algorithm to find correlated equilibria in  general Socratic games seems more attainable. Suppose the players receive recommended queries and responses. The difficulty is that when a player considers a deviation from his recommended query, he already knows his recommended response in each of the Stage-2 games. In a correlated  equilibrium, a player"s expected payoff generally depends on his recommended strategy, and thus a player may deviate in Stage 1 so as to land in a Stage-2 game where he has been given a better than average recommended response.  (Socratic games are succinct games of superpolynomial type, so Papadimitriou"s results [56] do not imply correlated  equilibria for them.) Socratic games can be extended to allow players to make adaptive queries, choosing subsequent queries based on  previous results. Our techniques carry over to O(1) rounds of unobservable queries, but it would be interesting to  compute equilibria in Socratic games with adaptive observable queries or with ω(1) rounds of unobservable queries.  Special cases of adaptive Socratic games are closely related to single-agent problems like minimum latency [1, 7, 26],  determining strategies for using priced information [9, 29, 37], and an online version of minimum test cover [18, 50].  Although there are important technical distinctions between adaptive Socratic games and these problems, approximation techniques from this literature may apply to Socratic games. The question of approximation raises interesting questions even in non-adaptive Socratic games. An -approximate Nash equilibrium is a strategy profile α so that no player can increase her payoff by an additive by deviating from α. Finding approximate Nash equilibria in both adaptive and non-adaptive Socratic games is an interesting direction to pursue. Another natural extension is the model where query  results are stochastic. In this paper, we model a query as deterministically partitioning the possible worlds into  subsets that the query cannot distinguish. However, one could instead model a query as probabilistically mapping the set of possible worlds into the set of signals. With this  modification, our unobservable-query model becomes equivalent to the model of Bergemann and V¨alim¨aki [4, 5], in which the result of a query is a posterior distribution over the worlds. Our techniques allow us to compute equilibria in such a stochastic-query model provided that each query is represented as a table that, for each world/signal pair, lists the probability that the query outputs that signal in that world. It is also interesting to consider settings in which the game"s queries are specified by a compact representation of the relevant probability distributions. (For example, one might consider a setting in which the algorithm has only a sampling oracle for the posterior distributions envisioned by Bergemann and V¨alim¨aki.) Efficiently finding equilibria in such settings remains an open problem. Another interesting setting for Socratic games is when the set Q of available queries is given by Q = P(Γ)-i.e., each player chooses to make a set q ∈ P(Γ) of queries from a specified groundset Γ of queries. Here we take the query cost to be a linear function, so that δ(q) = P γ∈q δ({γ}). Natural groundsets include comparison queries (if my  opponent is playing strategy aii, would I prefer to play ai or ˆai?), strategy queries (what is my vector of payoffs if I play strategy ai?), and world-identity queries (is the world w ∈ W the real world?). When one can infer a polynomial bound on the number of queries made by a rational player, then our results yield efficient solutions. (For example, we can efficiently solve games in which every groundset element γ ∈ Γ has δ({γ}) = Ω(M − M), where M and M denote the maximum and minimum payoffs to any player in any world.) Conversely, it is NP-hard to compute a Nash  equilibrium for such a game when every δ({γ}) ≤ 1/|W|2 , even when the worlds are constant sum and Player II has only a single available strategy. Thus even computing a best response for Player I is hard. (This proof proceeds by  reduction from set cover; intuitively, for sufficiently low query costs, Player I must fully identify the actual world through his queries. Selecting a minimum-sized set of these queries is hard.) Computing Player I"s best response can be viewed as maximizing a submodular function, and thus a best  response can be (1 − 1/e) ≈ 0.63 approximated greedily [14]. An interesting open question is whether this approximate best-response calculation can be leveraged to find an  approximate Nash equilibrium. . ACKNOWLEDGEMENTS Part of this work was done while all authors were at MIT CSAIL. We thank Erik Demaine, Natalia Hernandez  Gardiol, Claire Monteleoni, Jason Rennie, Madhu Sudan, and Katherine White for helpful comments and discussions. . REFERENCES [1] Aaron Archer and David P. Williamson. Faster approximation algorithms for the minimum latency problem. In Proceedings of the Symposium on Discrete Algorithms, pages 88-96, 2003. [2] R. J. Aumann. Subjectivity and correlation in randomized strategies. J. Mathematical Economics, :67-96, 1974. 57 [3] Robert J. Aumann. Correlated equilibrium as an expression of Bayesian rationality. Econometrica, 5(1):1-18, January 1987. [4] Dick Bergemann and Juuso V¨alim¨aki. Information acquisition and efficient mechanism design. Econometrica, 70(3):1007-1033, May 2002. [5] Dick Bergemann and Juuso V¨alim¨aki. Information in mechanism design. Technical Report 1532, Cowles Foundation for Research in Economics, 2005. [6] Daniel S. Bernstein, Shlomo Zilberstein, and Neil Immerman. The complexity of decentralized control of Markov Decision Processes. Mathematics of Operations Research, pages 819-840, 2002. [7] Avrim Blum, Prasad Chalasani, Don Coppersmith, Bill Pulleyblank, Prabhakar Raghavan, and Madhu Sudan. The minimum latency problem. In Proceedings of the Symposium on the Theory of Computing, pages 63-171, 1994. [8] Andrei Z. Broder and Michael Mitzenmacher. Optimal plans for aggregation. In Proceedings of the Principles of Distributed Computing, pages 144-152, 2002. [9] Moses Charikar, Ronald Fagin, Venkatesan Guruswami, Jon Kleinberg, Prabhakar Raghavan, and Amit Sahai. Query strategies for priced information. J. Computer and System Sciences, 64(4):785-819, June 2002. [10] Xi Chen and Xiaotie Deng. 3-NASH is PPAD-complete. In Electronic Colloquium on Computational Complexity, 2005. [11] Xi Chen and Xiaotie Deng. Settling the complexity of -player Nash-equilibrium. In Electronic Colloquium on Computational Complexity, 2005. [12] Olivier Compte and Philippe Jehiel. Auctions and information acquisition: Sealed-bid or dynamic formats? Technical report, Centre d"Enseignement et de Recherche en Analyse Socio-´economique, 2002. [13] Vincent Conitzer and Tuomas Sandholm. Complexity results about Nash equilibria. In Proceedings of the International Joint Conference on Artificial Intelligence, pages 765-771, 2003. [14] Gerard Cornuejols, Marshall L. Fisher, and George L. Nemhauser. Location of bank accounts to optimize float: An analytic study of exact and approximate algorithms. Management Science, 23(8), April 1977. [15] Jacques Cr´emer and Fahad Khalil. Gathering information before signing a contract. American Economic Review, 82:566-578, 1992. [16] Constantinos Daskalakis, Paul W. Goldberg, and Christos H. Papadimitriou. The complexity of computing a Nash equilbrium. In Electronic Colloquium on Computational Complexity, 2005. [17] Konstantinos Daskalakis and Christos H. Papadimitriou. Three-player games are hard. In Electronic Colloquium on Computational Complexity, 005. [18] K. M. J. De Bontridder, B. V. Halld´orsson, M. M. Halld´orsson, C. A. J. Hurkens, J. K. Lenstra, R. Ravi, and L. Stougie. Approximation algorithms for the test cover problem. Mathematical Programming, 8(1-3):477-491, September 2003. [19] Ap Dijksterhuis, Maarten W. Bos, Loran F. Nordgren, and Rick B. van Baaren. On making the right choice: The deliberation-without-attention effect. Science, 11:1005-1007, 17 February 2006. [20] Rosemary Emery-Montemerlo, Geoff Gordon, Jeff Schneider, and Sebastian Thrun. Approximate solutions for partially observable stochastic games with common payoffs. In Autonomous Agents and Multi-Agent Systems, 2004. [21] Alex Fabrikant, Christos Papadimitriou, and Kunal Talwar. The complexity of pure Nash equilibria. In Proceedings of the Symposium on the Theory of Computing, 2004. [22] Kyna Fong. Multi-stage Information Acquisition in Auction Design. Senior thesis, Harvard College, 2003. [23] Lance Fortnow and Duke Whang. Optimality and domination in repeated games with bounded players. In Proceedings of the Symposium on the Theory of Computing, pages 741-749, 1994. [24] Yoav Freund, Michael Kearns, Yishay Mansour, Dana Ron, Ronitt Rubinfeld, and Robert E. Schapire. Efficient algorithms for learning to play repeated games against computationally bounded adversaries. In Proceedings of the Foundations of Computer Science, pages 332-341, 1995. [25] Drew Fudenberg and Jean Tirole. Game Theory. MIT, 991. [26] Michel X. Goemans and Jon Kleinberg. An improved approximation ratio for the minimum latency problem. Mathematical Programming, 82:111-124, 1998. [27] Paul W. Goldberg and Christos H. Papadimitriou. Reducibility among equilibrium problems. In Electronic Colloquium on Computational Complexity, 005. [28] M. Grotschel, L. Lovasz, and A. Schrijver. The ellipsoid method and its consequences in combinatorial optimization. Combinatorica, 1:70-89, 1981. [29] Anupam Gupta and Amit Kumar. Sorting and selection with structured costs. In Proceedings of the Foundations of Computer Science, pages 416-425, 001. [30] Eric A. Hansen, Daniel S. Bernstein, and Shlomo Zilberstein. Dynamic programming for partially observable stochastic games. In National Conference on Artificial Intelligence (AAAI), 2004. [31] John C. Harsanyi. Games with incomplete information played by Bayesian players. Management Science, 4(3,5,7), 1967-1968. [32] Sergiu Hart and David Schmeidler. Existence of correlated equilibria. Mathematics of Operations Research, 14(1):18-25, 1989. [33] Eric Horvitz and Geoffrey Rutledge. Time-dependent utility and action under uncertainty. In Uncertainty in Artificial Intelligence, pages 151-158, 1991. [34] G. E. Hughes and M. J. Cresswell. A New Introduction to Modal Logic. Routledge, 1996. [35] Sheena S. Iyengar and Mark R. Lepper. When choice is demotivating: Can one desire too much of a good thing? J. Personality and Social Psychology, 9(6):995-1006, 2000. [36] Ehud Kalai. Bounded rationality and strategic complexity in repeated games. Game Theory and Applications, pages 131-157, 1990. 58 [37] Sampath Kannan and Sanjeev Khanna. Selection with monotone comparison costs. In Proceedings of the Symposium on Discrete Algorithms, pages 10-17, 2003. [38] L.G. Khachiyan. A polynomial algorithm in linear programming. Dokklady Akademiia Nauk SSSR, 244, 979. [39] Daphne Koller and Nimrod Megiddo. The complexity of two-person zero-sum games in extensive form. Games and Economic Behavior, 4:528-552, 1992. [40] Daphne Koller, Nimrod Megiddo, and Bernhard von Stengel. Efficient computation of equilibria for extensive two-person games. Games and Economic Behavior, 14:247-259, 1996. [41] Kate Larson. Mechanism Design for Computationally Limited Agents. PhD thesis, CMU, 2004. [42] Kate Larson and Tuomas Sandholm. Bargaining with limited computation: Deliberation equilibrium. Artificial Intelligence, 132(2):183-217, 2001. [43] Kate Larson and Tuomas Sandholm. Costly valuation computation in auctions. In Proceedings of the Theoretical Aspects of Rationality and Knowledge, July 2001. [44] Kate Larson and Tuomas Sandholm. Strategic deliberation and truthful revelation: An impossibility result. In Proceedings of the ACM Conference on Electronic Commerce, May 2004. [45] C. E. Lemke and J. T. Howson, Jr. Equilibrium points of bimatrix games. J. Society for Industrial and Applied Mathematics, 12, 1964. [46] Richard J. Lipton, Evangelos Markakis, and Aranyak Mehta. Playing large games using simple strategies. In Proceedings of the ACM Conference on Electronic Commerce, pages 36-41, 2003. [47] Michael L. Littman, Michael Kearns, and Satinder Singh. An efficient exact algorithm for singly connected graphical games. In Proceedings of Neural Information Processing Systems, 2001. [48] Steven A. Matthews and Nicola Persico. Information acquisition and the excess refund puzzle. Technical Report 05-015, Department of Economics, University of Pennsylvania, March 2005. [49] Richard D. McKelvey and Andrew McLennan. Computation of equilibria in finite games. In H. Amman, D. A. Kendrick, and J. Rust, editors, Handbook of Compututational Economics, volume 1, pages 87-142. Elsevier, 1996. [50] B.M.E. Moret and H. D. Shapiro. On minimizing a set of tests. SIAM J. Scientific Statistical Computing, :983-1003, 1985. [51] H. Moulin and J.-P. Vial. Strategically zero-sum games: The class of games whose completely mixed equilibria cannot be improved upon. International J. Game Theory, 7(3/4), 1978. [52] John F. Nash, Jr. Equilibrium points in n-person games. Proceedings of the National Academy of Sciences, 36:48-49, 1950. [53] Abraham Neyman. Finitely repeated games with finite automata. Mathematics of Operations Research, 3(3):513-552, August 1998. [54] Christos Papadimitriou. On the complexity of the parity argument and other inefficient proofs of existence. J. Computer and System Sciences, 8:498-532, 1994. [55] Christos Papadimitriou. Algorithms, games, and the internet. In Proceedings of the Symposium on the Theory of Computing, pages 749-753, 2001. [56] Christos H. Papadimitriou. Computing correlated equilibria in multi-player games. In Proceedings of the Symposium on the Theory of Computing, 2005. [57] Christos H. Papadimitriou and Tim Roughgarden. Computing equilibria in multiplayer games. In Proceedings of the Symposium on Discrete Algorithms, 005. [58] Christos H. Papadimitriou and Mihalis Yannakakis. On bounded rationality and computational complexity. In Proceedings of the Symposium on the Theory of Computing, pages 726-733, 1994. [59] David C. Parkes. Auction design with costly preference elicitation. Annals of Mathematics and Artificial Intelligence, 44:269-302, 2005. [60] Nicola Persico. Information acquisition in auctions. Econometrica, 68(1):135-148, 2000. [61] Jean-Pierre Ponssard and Sylvain Sorin. The LP formulation of finite zero-sum games with incomplete information. International J. Game Theory, (2):99-105, 1980. [62] Eric Rasmussen. Strategic implications of uncertainty over one"s own private value in auctions. Technical report, Indiana University, 2005. [63] Leonardo Rezende. Mid-auction information acquisition. Technical report, University of Illinois, 005. [64] Ariel Rubinstein. Modeling Bounded Rationality. MIT, 988. [65] Barry Schwartz. The Paradox of Choice: Why More is Less. Ecco, 2004. [66] Herbert Simon. Models of Bounded Rationality. MIT, 982. [67] I. Simonson and A. Tversky. Choice in context: Tradeoff contrast and extremeness aversion. J. Marketing Research, 29:281-295, 1992. [68] Brian Skyrms. Dynamic models of deliberation and the theory of games. In Proceedings of the Theoretical Aspects of Rationality and Knowledge, pages 185-200, 990. [69] Richard Sutton and Andrew Barto. Reinforcement Learning: An Introduction. MIT, 1998. [70] John von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior. Princeton, 1957. [71] Bernhard von Stengel. Computing equilibria for two-person games. In R. J. Aumann and S. Hart, editors, Handbook of Game Theory with Econonic Applications, volume 3, pages 1723-1759. Elsevier, 002. [72] S. Zilberstein and S. Russell. Approximate reasoning using anytime algorithms. In S. Natarajan, editor, Imprecise and Approximate Computation. Kluwer, 995. 59
Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of  imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games. To address this, we introduce the ordered game  isomorphism and the related ordered game isomorphic  abstraction transformation. For a multi-player sequential game of imperfect information with observable actions and an  ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more  applications of the transformation, can be easily converted into a Nash equilibrium in the original game. We present an  algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively. Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree. Using GameShrink, we find an equilibrium to a poker game with .1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously. We discuss several electronic commerce applications for GameShrink. To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies. Categories and Subject Descriptors: I.2 [Artificial  Intelligence], F. [Theory of Computation], J.4 [Social and  Behavioral Sciences]: Economics. General Terms: Algorithms, Economics, Theory. . INTRODUCTION In environments with more than one agent, an agent"s outcome is generally affected by the actions of the other agent(s). Consequently, the optimal action of one agent can depend on the others. Game theory provides a normative framework for analyzing such strategic situations. In  particular, it provides solution concepts that define what rational behavior is in such settings. The most famous and  important solution concept is that of Nash equilibrium [36]. It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.  However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium. Games can be classified as either games of perfect  information or imperfect information. Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type. To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes. If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with  αβ-pruning to reduce the search tree size and thus enhance speed). Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect  information, such as poker, is that they are not fully observable: when it is an agent"s turn to move, she does not have access to all of the information about the world. In such games, the decision of what to do at a point in time cannot  generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of  being at different states at the current point in time. Thus the algorithms for perfect information games do not solve games of imperfect information. For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies  This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45].  This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating  intermediate nodes using a heuristic evaluation and then treating those nodes as leaves.  An -equilibrium in a normal form game with any 60 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52]. By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables. Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. .1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation. Instead of developing an equilibrium-finding method per se, we  instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game. Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game. The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game. To this end, we introduce games with ordered signals  (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes. Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the  information each player receives. They are used in our analysis and abstraction algorithm. By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium  finding. We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game  isomorphic abstraction transformation to take advantange of such symmetries (Section 3). As our main equilibrium  result we have the following: constant number of agents can be constructed in  quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8]. The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44]. For a survey of equilibrium  computation in 2-player games, see [53]. Recently,  equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43]. For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40].  There were also early techniques that capitalized in  different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23].  Recently this approach was extended to handle  computing sequential equilibria [26] as well [35]. Theorem 2 Let Γ be a game with ordered  signals, and let F be an information filter for Γ. Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ). If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF . The proof of the theorem uses an equivalent  characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players" beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes" rule. We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game. We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4). Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree. We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our  algorithm yields an approximation algorithm (Section 5). .2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions. Often aspects of a player"s knowledge are not pertinent for deciding what action the player should take at a given point in the game. On the trivial end, some aspects of a player"s knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification. However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.  Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game. Our algorithm  automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation. One broad application area that has this property is  sequential negotiation (potentially over multiple issues).  Another broad application area is sequential auctions  (potentially over multiple goods). For example, in those states of a 1-object auction where bidder A can infer that his  valuation is greater than that of bidder B, bidder A can ignore all his other information about B"s signals, although that  information would be relevant for inferring B"s exact valuation. Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other  bidders in aggregate (ignoring their identities). Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42]. Our techniques are in no way specific to an application. The main experiment that we present in this paper is on 61 a recreational game. We chose a particular poker game as the benchmark problem because it yields an extremely  complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge  problem instances have been proposed for electronic commerce applications that require solving sequential games). .3 Rhode Island Hold"em poker Poker is an enormously popular card game played around the world. The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event. Increasingly, poker players compete in online casinos, and television stations regularly  broadcast poker tournaments. Poker has been identified as an important research area in AI due to the uncertainty  stemming from opponents" cards, opponents" future actions, and chance moves, among other reasons [5]. Almost since the field"s founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 86-219]. However, this work was limited to tiny games that could be solved by hand. More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games. Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear  programming [25]. Large-scale approximations have been  developed [4], but those methods do not provide any  guarantees about the performance of the computed strategies. Furthermore, the approximations were designed manually by a human expert. Our approach yields an automated  abstraction mechanism along with theoretical guarantees on the strategies" performance. Rhode Island Hold"em was invented as a testbed for  computational game playing [47]. It was designed so that it was similar in style to Texas Hold"em, yet not so large that  devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Hold"em, as well as a discussion of how Rhode Island Hold"em can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].) We applied the techniques developed in this paper to find an exact  (minimax) solution to Rhode Island Hold"em, which has a game tree exceeding 3.1 billion nodes. Applying the sequence form to Rhode Island Hold"em directly without abstraction yields a linear program with 1,224,226 rows, and the same number of columns. This is much too large for (current) linear programming algorithms to handle. We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients. We then applied iterated elimination of  dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated  elimination of dominated strategies without GameShrink yielded 9,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.) GameShrink  required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations). Using a 1.65GHz IBM eServer p5 570 with 4 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version .1.2. We recently demonstrated our optimal Rhode Island Hold"em poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html. While others have worked on computer programs for  playing Rhode Island Hold"em [47], no optimal strategy has been found before. This is the largest poker game solved to date by over four orders of magnitude. . GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as  compared to the full generality of the extensive form. This class, which we call games with ordered signals, is highly  structured, but still general enough to capture a wide range of strategic situations. A game with ordered signals consists of a finite number of rounds. Within a round, the players play a game on a directed tree (the tree can be different in different rounds). The only uncertainty players face stems from private signals the other players have received and from the unknown future signals. In other words, players observe each others" actions, but potentially not nature"s actions. In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players). For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed). We also assume that the legal actions that a player has are independent of the signals received. For example, in poker, the legal  betting actions are independent of the cards received. Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not  necessarily strictly) in these signals. For example, in poker, this partial ordering corresponds exactly to the ranking of card hands. Definition 1. A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: . I = {1, . . . , n} is a finite set of players. . G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej . Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j . Gj is the stage game for round j. . L = L1 , . . . , Lr , Lj : V j \ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. . Θ is a finite set of signals. . κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the  number of public and private signals (per player),  respectively, revealed in round j. Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we  require Pr j=1 κj + nγj ≤ |Θ|. The public information revealed in round j is αj ∈ Θκj and the public  information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ . The private information  revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ . We 62 also write ˜βj =  ˜βj , . . . , ˜βj n  to represent all private information up through round j, and  ˜β j i , ˜βj −i  =  ˜βj , . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n  is ˜βj with ˜βj i replaced with ˜β j i . The total information revealed up through round j,  ˜αj , ˜βj  , is said to be legal if no signals are repeated. . p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ. Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X  if x ∈ X. . is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. . ω : rS j=1 Zj → {over, continue} is a mapping of  terminal nodes within a stage game to one of two  values: over, in which case the game ends, or continue, in which case the game continues to the next round. Clearly, we require ω(z) = over for all z ∈ Zr . Note that ω is independent of the signals. Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. . u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a player"s utility is increasing in her private signals, everything else equal:  ˜αj , ˜βj i   ˜αj , ˜β j i  =⇒ ui  ˜z, ˜αj ,  ˜βj i , ˜βj −i  ≥ ui  ˜z, ˜αj ,  ˜β j i , ˜βj −i  . We will use the term game with ordered signals and the term ordered game interchangeably. .1 Information filters In this subsection, we define an information filter for  ordered games. Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player. By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact. We will use this when designing our abstraction techniques. Formally, an information filter is as follows. Definition 2. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game. Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j. An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: . (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). . (Independence) The range of Fj is a partition of Sj . . (Information preservation) If two values of a signal are distinguishable in round k, then they are  distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl . We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF . We refer to such games as filtered ordered games. We are left with the original game if we use the identity filter Fj  ˜αj , ˜βj i  = n ˜αj , ˜βj i o . We have the following simple (but important) result: Proposition 1. A filtered ordered game is an extensive form game satisfying perfect recall. A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall. In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. .2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the  context of filtered ordered games. Definition 3. A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range  Fj  → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.) A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \ Zj where Lj (vk) = i. A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ . A strategy profile is σ = (σ1, . . . , σn). A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ. Strategy σi is said to be player i"s best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i. A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29]. Using these observations, we have the following corollary to Proposition 1: 63 Corollary 1. For any filtered ordered game, a Nash  equilibrium exists in behavior strateges. . EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games. We begin by defining a filtered signal tree which represents all of the chance moves in the game. The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game. Definition 4. Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a  filtered signal tree, a directed tree in which each node  corresponds to some revealed (filtered) signals and edges  correspond to revealing specific (filtered) signals. The nodes in the filtered signal tree represent the set of all possible revealed  filtered signals (public and private) at some point in time. The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk . We denote children of a node x as N(x). In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached. In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game. By melding these situations together, it is possible to arrive at a strategically  equivalent smaller game. The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction  transformation. Definition 5. Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game  isomorphic if x and y have the same parent and there is a  bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic. Two leaves  (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ). Definition 6. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ. Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j. The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j  ˜αj , ˜βj i  =  < : Fj  ˜αj , ˜βj i  if  ˜αj , ˜βj i  /∈ ϑ ∪ ϑ ϑ ∪ ϑ if  ˜αj , ˜βj i  ∈ ϑ ∪ ϑ . Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.  Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster. Theorem 2. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ. Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation. Let σ be a Nash equilibrium of the induced game ΓF . If we take σj i,v  ˜z, Fj  ˜αj , ˜βj i  = σ j i,v  ˜z, F j  ˜αj , ˜βj i  , σ is a Nash equilibrium of ΓF . Proof. For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF . Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium. Fix some player i ∈ I. Each of i"s information sets in some round j corresponds to filtered signals Fj  ˜α∗j , ˜β∗j i  , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and  history so far in round j, v ∈ V j \ Zj . Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this  information set. Thus, we can uniquely specify this information set using the information  Fj  ˜α∗j , ˜β∗j i  , ˜z  . Each node in an information set corresponds to the  possible private signals the other players have received. Denote by ˜β some legal (Fj (˜αj , ˜βj ), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). In other words, there exists (˜αj , ˜βj , . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated. Using such a set of signals (˜αj , ˜βj , . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj ), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i  ˆβ  = ˆβ .) We can now compute μ directly from μ : μ  ˆβ | Fj  ˜αj , ˜βj i  , ˜z  =  >>>>>>< >>>>>>: μ  ˆβ | F j  ˜αj , ˜βj i  , ˜z  if Fj  ˜αj , ˜βj i  = F j  ˜αj , ˜βj i  or ˆβ = ˆβ p∗ μ  ˆβ | F j  ˜αj , ˜βj i  , ˜z  if Fj  ˜αj , ˜βj i  = F j  ˜αj , ˜βj i  and ˆβ = ˆβ 64 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b  0 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0   0   0  -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1   1   1   1   J1 K1 K2 J1 J2 K2 J1 J2 K1     1  1          {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2   c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2     J1,J2 K2 J1,J2 K1  0 -1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2       -1 -1-1 -1  0     -1 -1-1 -1  0     c b C B F B f b -1 -10 0  c b B F B f b -1 -1-1 -2 -2 c b C BF B f b  0 -1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1        {{J1,J2}, {K1,K2}}   1  /4 1/4 1/4 1/4 /3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 /4 /41/2 /3 1/3 1/3 /32/3 1/32/3 /2 1/2 /3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game. Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player. Open circles are chance nodes with the indicated transition probabilities. The root node is the chance node for player 1"s card, and the next level is for player 2"s card. The payment from player 2 to player 1 is given below each leaf. In this example, the algorithm reduces the game tree from 3 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . The following three claims show that μ as calculated above supports σ as a Nash  equilibrium. Claim 1. μ is a valid belief system for ΓF . Claim 2. For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3. For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ. The proofs of Claims 1-3 are in an extended version of this paper [13]. By Claims 1 and 2, we know that condition C2 holds. By Claim 3, we know that condition C1 holds. Thus, σ is a Nash equilibrium. .1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure  connecting the player actions and the chance actions (for one, the players are assumed to observe each others" actions, but nature"s actions might not be publicly observable), and 2) there is a common ordering of signals. In this subsection we show that removing either of these conditions can make our technique invalid. First, we demonstrate a failure when removing the first assumption. Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same  payoffs, and nodes c and d also have similar structural  properties. By merging the subtrees beginning at a and b, we get the game on the right in Figure 2. In this game, player "s only Nash equilibrium strategy is to play left. But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. /4 /4 1/4 /4  2 2    2 1 2 3 0 3 0 -10 10 /2 1/4 1/4  2 2   2 3 0 3 0 a b  2 2 10-10 c d Figure 2: Example illustrating difficulty in  developing a theory of equilibrium-preserving abstractions for general extensive form games. Removing the second assumption (that the utility  functions are based on a common ordering of signals) can also cause failure. Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1"s utility function is based on the ordering  We thank Albert Xin Jiang for providing this example. 65 K J1 ∼ J2 but player 2"s utility function is based on the ordering J2 K J1. It is easy to check that in the  abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 . GAMESHRINK: AN EFFICIENT  ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for  conducting the abstractions. It only needs to analyze the signal tree discussed above, rather than the entire game tree. We first present a subroutine that GameShrink uses. It is a dynamic program for computing the ordered game  isomorphic relation. Again, it operates on the signal tree. Algorithm 1. OrderedGameIsomorphic? (Γ, ϑ, ϑ ) . If ϑ and ϑ have different parents, then return false. . If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. . Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). . For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) . Return true if Gϑ,ϑ has a perfect matching; otherwise, return false. By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic. We can  further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game  isomorphic. The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game. Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals). Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time. Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Hold"em, S = 4 because each of the two players has one card in the hand plus there are two cards on the table). The number of nodes, n, in the signal tree is O(|Θ|S ). The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine. So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation. While this is exponential in the number of revealed  signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree  We thank an anonymous person for this example. because the signal tree is smaller than the game tree. The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.) The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S ! S! which is a lower bound on the number of nodes. For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S ! S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ). Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can  indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree. The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is  significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.) See Figure 1. In  general, if an ordered game has r rounds, and each round"s stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree. For example, in Rhode Island Hold"em, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705. Given the OrderedGameIsomorphic? routine for  determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink. Algorithm 2. GameShrink (Γ) . Initialize F to be the identity filter for Γ. . For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic?(Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). . Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as  possible. Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2. Thus, we have the following result: Theorem 3. GameShrink finds all ordered game  isomorphisms and applies the associated ordered game isomorphic abstraction transformations. Furthermore, for any Nash  equilibrium, σ , of the abstracted game, the strategy profile  constructed for the original game from σ is a Nash equilibrium. The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop. There are at most 66 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game. Thus, the inner for-loop executes O „`|Θ| S ´ S!  « times. As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each  iteration of the inner for-loop possibly performs a union  operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermann"s function [1, 49] (which grows  extremely slowly). Thus, the total time for GameShrink is O „`|Θ| S ´ S!  α „`|Θ| S ´ S!  , |Θ|S «« . By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Again,  although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree. Furthermore,  GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is  significantly smaller than the game tree in most nontrivial games, as discussed above. .1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our  implementation. One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of  operations [49]. Initially each node in the signalling tree is its own set (this corresponds to the identity information  filter); when two nodes are contracted they are joined into a new set. Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure. This is an efficient method of recording contractions within the game tree, and the memory  requirements are only linear in the size of the signal tree. Determining whether two nodes are ordered game  isomorphic requires us to determine if a bipartite graph has a  perfect matching. We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold. One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents. We can precompute these  frequencies for every game tree node. This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section). The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database  entry. This makes the database significantly more compact. (For example in Texas Hold"em, the database is reduced by a factor `50  ´`47  ´`46  ´ / `50  ´ = 20.) We store the histograms in a 2-dimensional database. The first dimension is indexed by the private signals, the second by the public signals. The problem of computing the index in (either) one of the  dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and  integers in ˆ , . . . , `n r ´ − 1 ˜ . We efficiently compute this using the subsets" colexicographical ordering [6]. Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1. We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . . APPROXIMATION METHODS Some games are too large to compute an exact  equilibrium, even after using the presented abstraction technique. This section discusses general techniques for computing  approximately optimal strategy profiles. For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy. To illustrate this, suppose we know player 2"s planned strategy for some game. We can then fix the probabilities of player 2"s actions in the game tree as if they were chance moves. Then player 1 is faced with a single-agent decision problem, which can be solved  bottomup, maximizing expected payoff at every node. Thus, we can objectively determine the expected worst-case performance of player 2"s strategy. This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A  variation of this technique may also be applied in n-person games where only one player"s strategies are held fixed.) This  technique provides ex post guarantees about the worst-case  performance of a strategy, and can be used independently of the method that is used to compute the strategies. .1 State-space approximations By slightly modifying GameShrink, we can obtain an  algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2. Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the  difference in utility between two nodes increases. There are many ways in which the penalty function could be defined and implemented. One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the  unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold). Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal  abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict  players to ignoring all signals, but still observing actions). This knob also begets an anytime algorithm. One can solve  increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. .2 Algorithmic approximations In the case of two-player zero-sum games, the  equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method. This approach has inherent features which we can leverage into desirable properties in the context of solving games. In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player . There are two versions of the simplex method: the primal simplex and the dual simplex. The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 67 at which point optimality has been reached. Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.) Thus, the primal and dual simplex  methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively. At any point in time, they can output the best strategies found so far. Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.) Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57]. Thus, without requiring further computation, we get lower bounds on the expected utility of each agent"s strategy against that agent"s worst-case opponent. One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both  primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.) In contrast, there are interior-point methods for linear programming that maintain primal and dual  feasibility throughout the execution. For example, many  interiorpoint path-following algorithms have this property [55, Ch. ]. We observe that running such a linear programming method yields a method for finding -equilibria (i.e.,  strategy profiles in which no agent can increase her expected  utility by more than by deviating). A threshold on can also be used as a termination criterion for using the method as an anytime algorithm. Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. . RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11]. In contrast to our work, those  approaches were not for making the game smaller and easier to solve. The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form. The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of  strategies [27]. An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21]. Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10]. The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game  isomorphism. The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations. Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms. However, that definition requires that the games to be tested for weak isomorphism are of the same size. Our focus is totally  different: we find strategically equivalent smaller games. Also, their paper does not provide algorithms. Abstraction techniques have been used in artificial  intelligence research before. In contrast to our work, most (but not all) research involving abstraction has been for  singleagent problems (e.g. [20, 32]). Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield  optimal solutions. A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2]. However, a significant difference to our work is that Sprouts is a game of perfect information. One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the world"s first  expertlevel computer bridge player [17, 18]. In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.) Partition search can lead to substantial speed improvements over α-β-search. However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of  imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically. There has been some research on the use of abstraction for imperfect information games. Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Hold"em poker, and include promising results against expert players. However, this approach has significant drawbacks. First, it is highly specialized for Texas Hold"em. Second, a large amount of expert knowledge and effort was used in constructing the abstraction. Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium. Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. . CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for  abstracting the game using the isomorphism exhaustively. We proved that in games with ordered signals, any Nash  equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game. The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in  Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either. Instead, partition search is used in  conjunction with statistical sampling to simulate the uncertainty in bridge. There are also other bridge programs that use search techniques for perfect information games in  conjunction with statistical sampling and expert-defined  abstraction [48]. Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 68 the size of the game tree. Using GameShrink, we found a minimax equilibrium to Rhode Island Hold"em, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously. To further improve scalability, we introduced an  approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction. We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately  optimal strategies of increasing quality. The method also yields bounds on the suboptimality of the resulting strategies. We are currently working on using these techniques for full-scale -player limit Texas Hold"em poker, a highly popular card game whose game tree has about 1018 nodes. That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. . REFERENCES [1] W. Ackermann. Zum Hilbertschen Aufbau der reellen Zahlen. Math. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator. Computer analysis of sprouts. Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell. Some two-person games involving bluffing. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron. Approximating game-theoretic optimal strategies for full-scale poker. In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron. The challenge of poker. Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as. Combinatorics. Cambridge University Press, 1986. [7] A. Casajus. Weak isomorphism of extensive games. Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng. Settling the complexity of 2-player Nash equilibrium. ECCC, Report No. 150, 2005. [9] V. Chv´atal. Linear Programming. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. Game transformations and game equivalence. Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny. On the strategic equivalence of extensive form games. J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson. Flows in Networks. Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm. Finding equilibria in large sequential games of imperfect information. Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm. Optimal Rhode Island Hold"em poker. In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm. A competitive Texas Hold"em poker player via automated abstraction and real-time equilibrium computation. Mimeo, 2006. [16] A. Gilpin and T. Sandholm. A Texas Hold"em poker player based on automated abstraction and real-time equilibrium computation. In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg. Partition search. In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg. GIB: Steps toward an expert-level bridge-playing program. In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson. A global Newton method to compute Nash equilibria. J. of Econ. Theory, 110:65-86, 2003. [20] C. A. Knoblock. Automatically generating abstractions for planning. Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens. On the strategic stability of equilibria. Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo. The complexity of two-person zero-sum games in extensive form. Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo. Finding mixed strategies with small supports in extensive form games. International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel. Efficient computation of equilibria for extensive two-person games. Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer. Representations and solutions for game-theoretic problems. Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson. Sequential equilibria. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Extensive games. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. A simplified two-person poker. In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103. Princeton University Press, 1950. [29] H. W. Kuhn. Extensive games and the problem of information. In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216. Princeton University Press, 1953. [30] C. Lemke and J. Howson. Equilibrium points of bimatrix games. Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta. Playing large games using simple strategies. In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman. On state-space abstraction for anytime evaluation of Bayesian networks. SIGART Bulletin, (2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green. Microeconomic Theory. Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan. Computation of equilibria in finite games. In Handbook of Computational Economics, volume 1, pages 87-142. Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen. Computing sequential equilibria for two-player games. In SODA, pages 107-116, 2006. [36] J. Nash. Equilibrium points in n-person games. Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley. A simple three-person poker game. In Contributions to the Theory of Games, volume 1, pages 105-116. Princeton University Press, 1950. [38] A. Perea. Rationality in extensive form games. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa. State-space approximations for extensive form games, July 2000. Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham. Simple search methods for finding a Nash equilibrium. In AAAI, pages 64-669, San Jose, CA, USA, 2004. [41] I. Romanovskii. Reduction of a game with complete memory to a matrix game. Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin. Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation. In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer. Mixed-integer programming methods for finding Nash equilibria. In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel. Exponentially many steps for finding a Nash equilibrium in a bimatrix game. In FOCS, pages 58-267, 2004. [45] R. Selten. Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit. Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten. Evolutionary stability in extensive two-person games - correction and further development. Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman. Abstraction methods for game theoretic poker. In Computers and Games, pages 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop. Computer bridge: A big win for AI planning. AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan. Efficiency of a good but not linear set union algorithm. Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalence of games in extensive form. RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern. Theory of games and economic behavior. Princeton University Press, 1947. [52] B. von Stengel. Efficient computation of behavior strategies. Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel. Computing equilibria for two-person games. In Handbook of Game Theory, volume 3. North Holland, Amsterdam, 2002. [54] R. Wilson. Computing equilibria of two-person games from the extensive form. Management Science, 18(7):448-460, 1972. [55] S. J. Wright. Primal-Dual Interior-Point Methods. SIAM, 997. 69
Multi-Attribute Coalitional Games∗ Samuel Ieong † Computer Science Department Stanford University Stanford, CA 94305 sieong@cs.stanford.edu Yoav Shoham Computer Science Department Stanford University Stanford, CA 94305 shoham@cs.stanford.edu ABSTRACT We study coalitional games where the value of cooperation among the agents are solely determined by the attributes the agents possess, with no assumption as to how these  attributes jointly determine this value. This framework  allows us to model diverse economic interactions by picking the right attributes. We study the computational  complexity of two coalitional solution concepts for these  gamesthe Shapley value and the core. We show how the positive results obtained in this paper imply comparable results for other games studied in the literature. Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent systems; J.4 [Social and Behavioral Sciences]:  Economics; F.2 [Analysis of Algorithms and Problem  Complexity] General Terms Algorithms, Economics . INTRODUCTION When agents interact with one another, the value of their contribution is determined by what they can do with their skills and resources, rather than simply their identities.  Consider the problem of forming a soccer team. For a team to be successful, a team needs some forwards, midfielders,  defenders, and a goalkeeper. The relevant attributes of the players are their skills at playing each of the four positions. The value of a team depends on how well its players can play these positions. At a finer level, we can extend the model to consider a wider range of skills, such as passing,  shooting, and tackling, but the value of a team remains solely a function of the attributes of its players. Consider an example from the business world.  Companies in the metals industry are usually vertically-integrated and diversified. They have mines for various types of ores, and also mills capable of processing and producing  different kinds of metal. They optimize their production profile according to the market prices for their products. For  example, when the price of aluminum goes up, they will  allocate more resources to producing aluminum. However, each company is limited by the amount of ores it has, and its capacities in processing given kinds of ores. Two or more companies may benefit from trading ores and processing  capacities with one another. To model the metal industry, the relevant attributes are the amount of ores and the  processing capacities of the companies. Given the exogenous input of market prices, the value of a group of companies will be determined by these attributes. Many real-world problems can be likewise modeled by picking the right attributes. As attributes apply to both individual agents and groups of agents, we propose the use of coalitional game theory to understand what groups may form and what payoffs the agents may expect in such models. Coalitional game theory focuses on what groups of agents can achieve, and thus connects strongly with e-commerce, as the Internet economies have significantly enhanced the abilities of business to identify and capitalize on profitable opportunities of cooperation. Our goal is to understand the computational aspects of computing the solution  concepts (stable and/or fair distribution of payoffs, formally defined in Section 3) for coalitional games described using attributes. Our contributions can be summarized as follows: • We define a formal representation for coalitional games based on attributes, and relate this representation to others proposed in the literature. We show that when compared to other representations, there exists games for which a multi-attribute description can be  exponentially more succinct, and for no game it is worse. • Given the generality of the model, positive results carry over to other representations. We discuss two positive results in the paper, one for the Shapley value and one for the core, and show how these imply related results in the literature. 70 • We study an approximation heuristic for the Shapley value when its exact values cannot be found efficiently. We provide an explicit bound on the maximum error of the estimate, and show that the bound is  asymptotically tight. We also carry out experiments to evaluate how the heuristic performs on random instances.1 . RELATED WORK Coalitional game theory has been well studied in  economics [9, 10, 14]. A vast amount of literature have focused on defining and comparing solution concepts, and  determining their existence and properties. The first algorithmic study of coalitional games, as far as we know, is performed by Deng and Papadimitriou in [5]. They consider coalitional games defined on graphs, where the players are the vertices and the value of coalition is determined by the sum of the weights of the edges spanned by these players. This can be efficiently modeled and generalized using attributes. As a formal representation, multi-attribute coalitional games is closely related to the multi-issue representation of Conitzer and Sandholm [3] and our work on marginal contribution networks [7]. Both of these representations are based on dividing a coalitional game into subgames (termed issues in [3] and rules in [7]), and aggregating the subgames via linear combination. The key difference in our work is the unrestricted aggregation of subgames: the aggregation could be via a polynomial function of the attributes, or even by treating the subgames as input to another computational problem such as a min-cost flow problem. The relationship of these models will be made clear after we define the  multiattribute representation in Section 4. Another representation proposed in the literature is one specialized for superadditive games by Conitzer and  Sandholm [2]. This representation is succinct, but to find the values of some coalitions may require solving an NP-hard problem. While it is possible for multi-attribute coalitional games to efficiently represent these games, it necessarily  requires the solution to an NP-hard problem in order to find out the values of some coalitions. In this paper, we stay within the boundary of games that admits efficient  algorithm for determining the value of coalitions. We will  therefore not make further comparisons with [2]. The model of coalitional games with attributes has been considered in the works of Shehory and Kraus. They model the agents as possessing capabilities that indicates their  proficiencies in different areas, and consider how to efficiently allocate tasks [12] and the dynamics of coalition formation [13]. Our work differs significantly as our focus is on  reasoning about solution concepts. Our model also covers a wider scope as attributes generalize the notion of capabilities. Yokoo et al. have also considered a model of coalitional games where agents are modeled by sets of skills, and these skills in turn determine the value of coalitions [15]. There are two major differences between their work and ours. Firstly, Yokoo et al. assume that each skill is fundamentally different from another, hence no two agents may possess the same skill. Also, they focus on developing new solution concepts that are robust with respect to manipulation by agents. Our focus is on reasoning about traditional solution concepts.  We acknowledge that random instances may not be typical of what happens in practice, but given the generality of our model, it provides the most unbiased view. Our work is also related to the study of cooperative games with committee control [4]. In these games, there is usually an underlying set of resources each controlled by a  (possibly overlapping) set of players known as the committee, engaged in a simple game (defined in Section 3).  multiattribute coalitional games generalize these by considering relationship between the committee and the resources  beyond simple games. We note that when restricted to simple games, we derive similar results to that in [4]. . PRELIMINARIES In this section, we will review the relevant concepts of coalitional game theory and its two most important solution concepts - the Shapley value and the core. We will then define the computational questions that will be studied in the second half of the paper. .1 Coalitional Games Throughout this paper, we assume that payoffs to groups of agents can be freely distributed among its members. This transferable utility assumption is commonly made in  coalitional game theory. The canonical representation of a  coalitional game with transferable utility is its characteristic form. Definition 1. A coalition game with transferable utility in characteristic form is denoted by the pair N, v , where • N is the set of agents; and • v : 2N → R is a function that maps each group of agents S ⊆ N to a real-valued payoff. A group of agents in a game is known as a coalition, and the entire set of agents is known as the grand coalition. An important class of coalitional games is the class of monotonic games. Definition 2. A coalitional game is monotonic if for all S ⊂ T ⊆ N, v(S) ≤ v(T). Another important class of coalitional games is the class of simple games. In a simple game, a coalition either wins, in which case it has a value of 1, or loses, in which case it has a value of 0. It is often used to model voting situations. Simple games are often assumed to be monotonic, i.e., if S wins, then for all T ⊇ S, T also wins. This coincides with the notion of using simple games as a model for voting. If a simple game is monotonic, then it is fully described by the set of minimal winning coalitions, i.e., coalitions S for which v(S) = 1 but for all coalitions T ⊂ S, v(T) = 0. An outcome in a coalitional game specifies the utilities the agents receive. A solution concept assigns to each  coalitional game a set of reasonable outcomes. Different  solution concepts attempt to capture in some way outcomes that are stable and/or fair. Two of the best known solution concepts are the Shapley value and the core. The Shapley value is a normative solution concept that prescribes a fair way to divide the gains from cooperation when the grand coalition is formed. The division of payoff to agent i is the average marginal contribution of agent i over all possible permutations of the agents. Formally, Definition 3. The Shapley value of agent i, φi(v), in game N, v is given by the following formula φi(v) = S⊆N\{i} |S|!(|N| − |S| − 1)! |N|! (v(S ∪ {i}) − v(S)) 71 The core is a descriptive solution concept that focuses on outcomes that are stable. Stability under core means that no set of players can jointly deviate to improve their payoffs. Definition 4. An outcome x ∈ R|N| is in the core of the game N, v if for all S ⊆ N, i∈S xi ≥ v(S) Note that the core of a game may be empty, i.e., there may not exist any payoff vector that satisfies the stability  requirement for the given game. .2 Computational Problems We will study the following three problems related to  solution concepts in coalitional games. Problem 1. (Shapley Value) Given a description of the coalitional game and an agent i, compute the Shapley value of agent i. Problem 2. (Core Membership) Given a description of the coalitional game and a payoff vector x such that È i∈N xi = v(N), determine if È i∈S xi ≥ v(S) for all S ⊆ N. Problem 3. (Core Non-emptiness) Given a description of the coalitional game, determine if there exists any payoff vector x such that È i∈S xi ≥ V (S) for all S ⊆ N, andÈ i∈N xi = v(N). Note that the complexity of the above problems depends on the how the game is described. All these problems will be easy if the game is described by its characteristic form, but only so because the description takes space  exponential in the number of agents, and hence simple brute-force approach takes time polynomial to the input description. To properly understand the computational complexity  questions, we have to look at compact representation. . FORMAL MODEL In this section, we will give a formal definition of  multiattribute coalitional games, and show how it is related to some of the representations discussed in the literature. We will also discuss some limitations to our proposed approach. .1 Multi-Attribute Coalitional Games A multi-attribute coalitional game (MACG) consists of two parts: a description of the attributes of the agents, which we termed an attribute model, and a function that assigns values to combination of attributes. Together, they induce a coalitional game over the agents. We first define the attribute model. Definition 5. An attribute model is a tuple N, M, A , where • N denotes the set of agents, of size n; • M denotes the set of attributes, of size m; • A ∈ Rm×n , the attribute matrix, describes the values of the attributes of the agents, with Aij denoting the value of attribute i for agent j. We can directly define a function that maps combinations of attributes to real values. However, for many problems, we can describe the function more compactly by computing it in two steps: we first compute an aggregate value for each attribute, then compute the values of combination of attributes using only the aggregated information. Formally, Definition 6. An aggregating function (or aggregator) takes as input a row of the attribute matrix and a coalition S, and summarizes the attributes of the agents in S with a single number. We can treat it as a mapping from Rn × 2N → R. Aggregators often perform basic arithmetic or logical  operations. For example, it may compute the sum of the  attributes, or evaluate a Boolean expression by treating the agents i ∈ S as true and j /∈ S as false. Analogous to the notion of simple games, we call an aggregator simple if its range is {0, 1}. For any aggregator, there is a set of relevant agents, and a set of irrelevant agents. An agent i is  irrelevant to aggregator aj if aj (S ∪ {i}) = aj (S) for all S ⊆ N. A relevant agent is one not irrelevant. Given the attribute matrix, an aggregator assigns a value to each coalition S ⊆ N. Thus, each aggregator defines a game over N. For aggregator aj , we refer to this induced game as the game of attribute j, and denote it with aj (A). When the attribute matrix is clear from the context, we may drop A and simply denote the game as aj . We may refer to the game as the aggregator when no ambiguities arise. We now define the second step of the computation with the help of aggregators. Definition 7. An aggregate value function takes as input the values of the aggregators and maps these to a real value. In this paper, we will focus on having one aggregator per attribute. Therefore, in what follows, we will refer to the aggregate value function as a function over the attributes. Note that when all aggregators are simple, the aggregate value function implicitly defines a game over the attributes, as it assigns a value to each set of attributes T ⊆ M. We refer to this as the game among attributes. We now define multi-attribute coalitional game. Definition 8. A multi-attribute coalitional game is defined by the tuple N, M, A, a, w , where • N, M, A is an attribute model; • a is a set of aggregators, one for each attribute; we can treat the set together as a vector function, mapping Rm×n × 2N → Rm • w : Rm → R is an aggregate value function. This induces a coalitional game with transferable payoffs N, v with players N and the value function defined by v(S) = w(a(A, S)) Note that MACG as defined is fully capable of  representing any coalitional game N, v . We can simply take the set of attributes as equal to the set of agents, i.e., M = N, an identity matrix for A, aggregators of sums, and the  aggregate value function w to be v. 72 .2 An Example Let us illustrate how MACG can be used to represent a game with a simple example. Suppose there are four types of resources in the world: gold, silver, copper, and iron, that each agent is endowed with some amount of these resources, and there is a fixed price for each of the resources in the market. This game can be described using MACG with an attribute matrix A, where Aij denote the amount of resource i that agent j is endowed. For each resource, the  aggregator sums together the amount of resources the agents have. Finally, the aggregate value function takes the dot product between the market price vector and the aggregate vector. Note the inherent flexibility in the model: only limited work would be required to update the game as the market price changes, or when a new agent arrives. .3 Relationship with Other Representations As briefly discussed in Section 2, MACG is closely related to two other representations in the literature, the  multiissue representation of Conitzer and Sandholm [3], and our work on marginal contribution nets [7]. To make their  relationships clear, we first review these two representations. We have changed the notations from the original papers to highlight their similarities. Definition 9. A multi-issue representation is given as a vector of coalitional games, (v1, v2, . . . vm), each possibly with a varying set of agents, say N1, . . . , Nm. The  coalitional game N, v induced by multi-issue representation has player set N = Ëm i=1 Ni, and for each coalition S ⊆ N, v(S) = Èm i=1 v(S ∩ Ni). The games vi are assumed to be represented in characteristic form. Definition 10. A marginal contribution net is given as a set of rules (r1, r2, . . . , rm), where rule ri has a weight wi, and a pattern pi that is a conjunction over literals  (positive or negative). The agents are represented as literals. A coalition S is said to satisfy the pattern pi, if we treat the agents i ∈ S as true, an agent j /∈ S as false, pi(S)  evaluates to true. Denote the set of literals involved in rule i by Ni. The coalitional game N, v induced by a marginal contribution net has player set N = Ëm i=1 Ni, and for each coalition S ⊆ N, v(S) = È i:pi(S)=true wi. From these definitions, we can see the relationships among these three representations clearly. An issue of a multi-issue representation corresponds to an attribute in MACG.  Similarly, a rule of a marginal contribution net corresponds to an attribute in MACG. The aggregate value functions are simple sums and weighted sums for the respective  representations. Therefore, it is clear that MACG will be no less succinct than either representation. However, MACG differs in two important way. Firstly, there is no restriction on the operations performed by the aggregate value function over the attributes. This is an  important generalization over the linear combination of issues or rules in the other two approaches. In particular, there are games for which MACG can be exponentially more compact. The proof of the following proposition can be found in the Appendix. Proposition 1. Consider the parity game N, v where coalition S ⊆ N has value v(S) = 1 if |S| is odd, and v(S) =  otherwise. MACG can represent the game in O(n) space. Both multi-issue representation and marginal contribution nets requires O(2n ) space. A second important difference of MACG is that the  attribute model and the value function is cleanly separated. As suggested in the example in Section 4.2, this often  allows us more efficient update of the values of the game as it changes. Also, the same attribute model can be evaluated using different value functions, and the same value function can be used to evaluate different attribute model. Therefore, MACG is very suitable for representing multiple games. We believe the problems of updating games and representing multiple games are interesting future directions to explore. .4 Limitation of One Aggregator per Attribute Before focusing on one aggregator per attribute for the rest of the paper, it is natural to wonder if any is lost per such restriction. The unfortunate answer is yes, best  illustrated by the following. Consider again the problem of forming a soccer team discussed in the introduction, where we model the attributes of the agents as their ability to take the four positions of the field, and the value of a team  depends on the positions covered. If we first aggregate each of the attribute individually, we will lose the distributional information of the attributes. In other words, we will not be able to distinguish between two teams, one of which has a player for each position, the other has one player who can play all positions, but the rest can only play the same one position. This loss of distributional information can be recovered by using aggregators that take as input multiple rows of the attribute matrix rather than just a single row.  Alternatively, if we leave such attributes untouched, we can leave the burden of correctly evaluating these attributes to the  aggregate value function. However, for many problems that we found in the literature, such as the transportation domain of [12] and the flow game setting of [4], the distribution of attributes does not affect the value of the coalitions. In  addition, the problem may become unmanageably complex as we introduce more complicated aggregators. Therefore, we will focus on the representation as defined in Definition 8. . SHAPLEY VALUE In this section, we focus on computational issues of  finding the Shapley value of a player in MACG. We first set up the problem with the use of oracles to avoid  complexities arising from the aggregators. We then show that when attributes are linearly separable, the Shapley value can be efficiently computed. This generalizes the proofs of related results in the literature. For the non-linearly separable case, we consider a natural heuristic for estimating the Shapley value, and study the heuristic theoretically and empirically. .1 Problem Setup We start by noting that computing the Shapley value for simple aggregators can be hard in general. In particular, we can define aggregators to compute weighted majority over its input set of agents. As noted in [6], finding the Shapley value of a weighted majority game is #P-hard. Therefore, discussion of complexity of Shapley value for MACG with unrestricted aggregators is moot. Instead of placing explicit restriction on the aggregator, we assume that the Shapley value of the aggregator can be 73 answered by an oracle. For notation, let φi(u) denote the Shapley value for some game u. We make the following assumption: Assumption 1. For each aggregator aj in a MACG, there is an associated oracle that answers the Shapley value of the game of attribute j. In other words, φi(aj ) is known. For many aggregators that perform basic operations over its input, polynomial time oracle for Shapley value exists. This include operations such as sum, and symmetric  functions when the attributes are restricted to {0, 1}. Also, when only few agents have an effect on the aggregator, brute-force computation for Shapley value is feasible. Therefore, the above assumption is reasonable for many settings. In any case, such abstraction allows us to focus on the aggregate value function. .2 Linearly Separable Attributes When the aggregate value function can be written as a linear function of the attributes, the Shapley value of the game can be efficiently computed. Theorem 1. Given a game N, v represented as a MACG N, M, A, a, w , if the aggregate value function can be  written as a linear function of its attributes, i.e., w(a(A, S)) = m j=1 cj aj (A, S) The Shapley value of agent i in N, v is given by φi(v) = m j=1 cj φi(aj ) (1) Proof. First, we note that Shapley value satisfies an  additivity axiom [11]. The Shapley value satisfies additivity, namely, φi(a + b) = φi(a) + φi(b), where N, a + b is a game defined to be (a + b)(S) = a(S) + b(S) for all S ⊆ N. It is also clear that Shapley value satisfies scaling, namely φi(αv) = αφi(v) where (αv)(S) = αv(S) for all S ⊆ N. Since the aggregate value function can be expressed as a weighted sum of games of attributes, φi(v) = φi(w(a)) = φi( m j=1 cjaj ) = m j=1 cjφi(aj ) Many positive results regarding efficient computation of Shapley value in the literature depends on some form of  linearity. Examples include the edge-spanning game on graphs by Deng and Papadimitriou [5], the multi-issue  representation of [3], and the marginal contribution nets of [7]. The key to determine if the Shapley value can be efficiently  computed depends on the linear separability of attributes. Once this is satisfied, as long as the Shapley value of the game of attributes can be efficiently determined, the Shapley value of the entire game can be efficiently computed. Corollary 1. The Shapley value for the edge-spanning game of [5], games in multi-issue representation [3], and games in marginal contribution nets [7], can be computed in polynomial time. .3 Polynomial Combination of Attributes When the aggregate value function cannot be expressed as a linear function of its attributes, computing the Shapley value exactly is difficult. Here, we will focus on aggregate value function that can be expressed as some polynomial of its attributes. If we do not place a limit on the degree of the polynomial, and the game N, v is not necessarily monotonic, the problem is #P-hard. Theorem 2. Computing the Shapley value of a MACG N, M, A, a, w , when w can be an arbitrary polynomial of the aggregates a, is #P-hard, even when the Shapley value of each aggregator can be efficiently computed. The proof is via reduction from three-dimensional matching, and details can be found in the Appendix. Even if we restrict ourselves to monotonic games, and non-negative coefficients for the polynomial aggregate value function, computing the exact Shapley value can still be hard. For example, suppose there are two attributes. All agents in some set B ⊆ N possess the first attribute, and all agents in some set C ⊆ N possess the second, and B and C are disjoint. For a coalition S ⊆ N, the aggregator for the first evaluates to 1 if and only if |S ∩ B| ≥ b , and similarly, the aggregator for the second evaluates to 1 if and only if |S ∩ C| ≥ c . Let the cardinality of the sets B and C be b and c. We can verify that the Shapley value of an agent i in B equals φi =  b b −1 i=0  b i ¡  c c −1 ¡   b+c c +i−1 ¡ c − c + 1 b + c − c − i + 1 The equation corresponds to a weighted sum of probability values of hypergeometric random variables. The  correspondence with hypergeometric distribution is due to sampling without replacement nature of Shapley value. As far as we know, there is no close-form formula to evaluate the sum above. In addition, as the number of attributes involved increases, we move to multi-variate hypergeometric random variables, and the number of summands grow exponentially in the number of attributes. Therefore, it is highly unlikely that the exact Shapley value can be determined efficiently. Therefore, we look for approximation. .3.1 Approximation First, we need a criteria for evaluating how well an  estimate, ˆφ, approximates the true Shapley value, φ. We  consider the following three natural criteria: • Maximum underestimate: maxi φi/ˆφi • Maximum overestimate: maxi ˆφi/φi • Total variation: 1  È i |φi − ˆφi|, or alternatively maxS | È i∈S φi − È i∈S ˆφi| The total variation criterion is more meaningful when we normalize the game to having a value of 1 for the grand coalition, i.e., v(N) = 1. We can also define additive  analogues of the under- and overestimates, especially when the games are normalized. 74 We will assume for now that the aggregate value  function is a polynomial over the attributes with non-negative coefficients. We will also assume that the aggregators are simple. We will evaluate a specific heuristic that is  analogous to Equation (1). Suppose the aggregate function can be written as a polynomial with p terms w(a(A, S)) = p j=1 cj aj(1) (A, S)aj(2) (A, S) · · · aj(kj ) (A, S) (2) For term j, the coefficient of the term is cj , its degree kj , and the attributes involved in the term are j(1), . . . , j(kj ). We compute an estimate ˆφ to the Shapley value as ˆφi = p j=1 kj l=1 cj kj φi(aj(l) ) (3) The idea behind the estimate is that for each term, we divide the value of the term equally among all its attributes. This is represented by the factor cj kj . Then for for each attribute of an agent, we assign the player a share of value from the attribute. This share is determined by the Shapley value of the simple game of that attribute. Without considering the details of the simple games, this constitutes a fair (but blind) rule of sharing. .3.2 Theoretical analysis of heuristic We can derive a simple and tight bound for the maximum (multiplicative) underestimate of the heuristic estimate. Theorem 3. Given a game N, v represented as a MACG N, M, A, a, w , suppose w can be expressed as a  polynomial function of its attributes (cf Equation (2)). Let K = maxjkj, i.e., the maximum degree of the polynomial. Let ˆφ denote the estimated Shapley value using Equation (3), and φ denote the true Shapley value. For all i ∈ N, φi ≥ K ˆφi. Proof. We bound the maximum underestimate  term-byterm. Let tj be the j-th term of the polynomial. We note that the term can be treated as a game among attributes, as it assigns a value to each coalition S ⊆ N. Without loss of generality, renumber attributes j(1) through j(kj ) as 1 through kj. tj (S) = cj kj l=1 al (A, S) To make the equations less cluttered, let B(N, S) = |S|!(|N| − |S| − 1)! |N|! and for a game a, contribution of agent i to group S : i /∈ S, ∆i(a, S) = a(S ∪ {i}) − a(S) The true Shapley value of the game tj is φi(tj) = cj S⊆N\{i} B(N, S)∆i(tj, S) For each coalition S, i /∈ S, ∆i(tj , S) = 1 if and only if for at least one attribute, say l∗ , ∆i(al∗ , S) = 1. Therefore, if we sum over all the attributes, we would have included l∗ for sure. φi(tj) ≤ cj kj j=1 S⊆N\{i} B(N, S)∆i(aj , S) = kj kj j=1 cj kj φi(aj ) = kj ˆφi(T) Summing over the terms, we see that the worst case  underestimate is by the maximum degree. Without loss of generality, since the bound is  multiplicative, we can normalize the game to having v(N) = 1. As a corollary, because we cannot overestimate any set by more than K times, we obtain a bound on the total variation: Corollary 2. The total variation between the estimated Shapley value and the true Shapley value, for K-degree bounded polynomial aggregate value function, is K−1 K . We can show that this bound is tight. Example 1. Consider a game with n players and K  attributes. Let the first (n−1) agents be a member of the first (K − 1) attributes, and that the corresponding aggregator returns 1 if any one of the first (K − 1) agents is present. Let the n-th agent be the sole member of the K-th attribute. The estimated Shapley will assign a value of K−1 K  n−1 to the first (n − 1) agents and 1 K to the n-th agent. However, the true Shapley value of the n-th agent tends to 1 as n → ∞, and the total variation approaches K−1 K . In general, we cannot bound how much ˆφ may  overestimate the true Shapley value. The problem is that ˆφi may be non-zero for agent i even though may have no influence over the outcome of a game when attributes are multiplied together, as illustrated by the following example. Example 2. Consider a game with 2 players and 2  attributes, and let the first agent be a member of both  attributes, and the other agent a member of the second  attribute. For a coalition S, the first aggregator evaluates to  if agent 1 ∈ S, and the second aggregator evaluates to 1 if both agents are in S. While agent 2 is not a dummy with respect to the second attribute, it is a dummy with respect to the product of the attributes. Agent 2 will be assigned a value of 1  by the estimate. As mentioned, for simple monotonic games, a game is fully described by its set of minimal winning coalitions. When the simple aggregators are represented as such, it is possible to check, in polynomial time, for agents turning dummies after attributes are multiplied together. Therefore, we can improve the heuristic estimate in this special case. .3.3 Empirical evaluation Due to a lack of benchmark problems for coalitional games, we have tested the heuristic on random instances. We  believe more meaningful results can be obtained when we have real instances to test this heuristic on. Our experiment is set up as follows. We control three  parameters of the experiment: the number of players (6 − 10), 75  .025 .05 .075 .1 .125 .15 .175 .2  7 8 9 10 No. of Players TotalVariationDistance     (a) Effect of Max Degree  .025 .05 .075 .1 .125 .15 .175 .2  7 8 9 10 No. of Players TotalVariationDistance    (b) Effect of Number of Attributes Figure 1: Experimental results the number of attributes (3 − 8), and the maximum degree of the polynomial (2 − 5). For each attribute, we randomly sample one to three minimal winning coalitions. We then randomly generate a polynomial of the desired maximum degree with a random number (3 − 12) of terms, each with a random positive weight. We normalize each game to have v(N) = 1. The results of the experiments are shown in  Figure 1. The y-axis of the graphs shows the total variation, and the x-axis the number of players. Each datapoint is an average of approximately 700 random samples. Figure 1(a) explores the effect of the maximum degree and the number of players when the number of attributes is fixed (at six). As expected, the total variation increases as the maximum degree increases. On the other hand, there is only a very small increase in error as the number of players increases. The error is nowhere near the theoretical  worstcase bound of 1  to 4  for polynomials of degrees 2 to 5. Figure 1(b) explores the effect of the number of attributes and the number of players when the maximum degree of the polynomial is fixed (at three). We first note that these three lines are quite tightly clustered together, suggesting that the number of attributes has relatively little effect on the error of the estimate. As the number of attributes increases, the total variation decreases. We think this is an interesting phenomenon. This is probably due to the precise construct required for the worst-case bound, and so as more attributes are available, we have more diverse terms in the polynomial, and the diversity pushes away from the worst-case bound. . CORE-RELATED QUESTIONS In this section, we look at the complexity of the two computational problems related to the core: Core  Nonemptiness and Core Membership. We show that the  nonemptiness of core of the game among attributes and the cores of the aggregators imply non-emptiness of the core of the game induced by the MACG. We also show that there appears to be no such general relationship that relates the core memberships of the game among attributes, games of attributes, and game induced by MACG. .1 Problem Setup There are many problems in the literature for which the questions of Core Non-emptiness and Core  Membership are known to be hard [1]. For example, for the  edgespanning game that Deng and Papadimitriou studied [5], both of these questions are coNP-complete. As MACG can model the edge-spanning game in the same amount of space, these hardness results hold for MACG as well. As in the case for computing Shapley value, we attempt to find a way around the hardness barrier by assuming the existence of oracles, and try to build algorithms with these oracles. First, we consider the aggregate value function. Assumption 2. For a MACG N, M, A, a, w , we assume there are oracles that answers the questions of Core  Nonemptiness, and Core Membership for the aggregate value function w. When the aggregate value function is a non-negative linear function of its attributes, the core is always non-empty, and core membership can be determined efficiently. The concept of core for the game among attributes makes the most sense when the aggregators are simple games. We will further assume that these simple games are monotonic. Assumption 3. For a MACG N, M, A, a, w , we assume all aggregators are monotonic and simple. We also assume there are oracles that answers the questions of Core  Nonemptiness, and Core Membership for the aggregators. We consider this a mild assumption. Recall that monotonic simple games are fully described by their set of minimal  winning coalitions (cf Section 3). If the aggregators are  represented as such, Core Non-emptiness and Core  Membership can be checked in polynomial time. This is due to the following well-known result regarding simple games: Lemma 1. A simple game N, v has a non-empty core if and only if it has a set of veto players, say V , such that v(S) = 0 for all S ⊇ V . Further, A payoff vector x is in the core if and only if xi = 0 for all i /∈ V . .2 Core Non-emptiness There is a strong connection between the non-emptiness of the cores of the games among attributes, games of the attributes, and the game induced by a MACG. Theorem 4. Given a game N, v represented as a MACG N, M, A, a, w , if the core of the game among attributes, 76 M, w , is non-empty, and the cores of the games of  attributes are non-empty, then the core of N, v is non-empty. Proof. Let u be an arbitrary payoff vector in the core of the game among attributes, M, w . For each attribute j, let θj be an arbitrary payoff vector in the core of the game of attribute j. By Lemma 1, each attribute j must have a set of veto players; let this set be denoted by Pj . For each agent i ∈ N, let yi = È j ujθj i . We claim that this vector y is in the core of N, v . Consider any coalition S ⊆ N, v(S) = w(a(A, S)) ≤ j:S⊇P j uj (4) This is true because an aggregator cannot evaluate to 1  without all members of the veto set. For any attribute j, by Lemma 1, È i∈P j θj i = 1. Therefore, j:S⊇P j uj = j:S⊇P j uj i∈P j θj i = i∈S j:S⊇P j ujθj i ≤ i∈S yi Note that the proof is constructive, and hence if we are given an element in the core of the game among attributes, we can construct an element of the core of the coalitional game. From Theorem 4, we can obtain the following  corollaries that have been previously shown in the literature. Corollary 3. The core of the edge-spanning game of [5] is non-empty when the edge weights are non-negative. Proof. Let the players be the vertices, and their  attributes the edges incident on them. For each attribute, there is a veto set - namely, both endpoints of the edges. As previously observed, an aggregate value function that is a non-negative linear function of its aggregates has non-empty core. Therefore, the precondition of Theorem 4 is satisfied, and the edge-spanning game with non-negative edge weights has a non-empty core. Corollary 4 (Theorem 1 of [4]). The core of a flow game with committee control, where each edge is controlled by a simple game with a veto set of players, is non-empty. Proof. We treat each edge of the flow game as an  attribute, and so each attribute has a veto set of players. The core of a flow game (without committee) has been shown to be non-empty in [8]. We can again invoke Theorem 4 to show the non-emptiness of core for flow games with  committee control. However, the core of the game induced by a MACG may be non-empty even when the core of the game among  attributes is empty, as illustrated by the following example. Example 3. Suppose the minimal winning coalition of all aggregators in a MACG N, M, A, a, w is N, then v(S) = 0 for all coalitions S ⊂ N. As long as v(N) ≥ 0, any  nonnegative vector x that satisfies È i∈N xi = v(N) is in the core of N, v . Complementary to the example above, when all the  aggregators have empty cores, the core of N, v is also empty. Theorem 5. Given a game N, v represented as a MACG N, M, A, a, w , if the cores of all aggregators are empty, v(N) > 0, and for each i ∈ N, v({i}) ≥ 0, then the core of N, v is empty. Proof. Suppose the core of N, v is non-empty. Let x be a member of the core, and pick an agent i such that xi > . However, for each attribute, since the core is empty, by Lemma 1, there are at least two disjoint winning coalitions. Pick the winning coalition Sj that does not include i for each attribute j. Let S∗ = Ë j Sj . Because S∗ is winning for all coalitions, v(S∗ ) = v(N). However, v(N) = j∈N xj = xi + j /∈N xj ≥ xi + j∈S∗ xj > j∈S∗ xj Therefore, v(S∗ ) > È j∈S∗ xj, contradicting the fact that x is in the core of N, v . We do not have general results regarding the problem of Core Non-emptiness when some of the aggregators have non-empty cores while others have empty cores. We suspect knowledge about the status of the cores of the aggregators alone is insufficient to decide this problem. .3 Core Membership Since it is possible for the game induced by the MACG to have a non-empty core when the core of the aggregate value function is empty (Example 3), we try to explore the problem of Core Membership assuming that the core of both the game among attributes, M, w , and the underlying game, N, v , is known to be non-empty, and see if there is any relationship between their members. One reasonable requirement is whether a payoff vector x in the core of N, v can be decomposed and re-aggregated to a payoff vector y in the core of M, w . Formally, Definition 11. We say that a vector x ∈ Rn ≥0 can be  decomposed and re-aggregated into a vector y ∈ Rm ≥0 if there exists Z ∈ Rm×n ≥0 , such that yi = n j=1 Zij for all i xj = m i=1 Zij for all j We may refer Z as shares. When there is no restriction on the entries of Z, it is  always possible to decompose a payoff vector x in the core of N, v to a payoff vector y in the core of M, w . However, it seems reasonable to restrict that if an agent j is irrelevant to the aggregator i, i.e., i never changes the outcome of  aggregator j, then Zij should be restricted to be 0. Unfortunately, this restriction is already too strong. Example 4. Consider a MACG N, M, A, a, w with two players and three attributes. Suppose agent 1 is irrelevant to attribute 1, and agent 2 is irrelevant to attributes 2 and . For any set of attributes T ⊆ M, let w be defined as w(T) =  if |T| = 0 or 1  if |T| = 2 0 if |T| = 3 77 Since the core of a game with a finite number of players forms a polytope, we can verify that the set of vectors (4, 4, 2), (4, 2, 4), and (2, 4, 4), fully characterize the core C of M, w . On the other hand, the vector (10, 0) is in the core of N, v . This vector cannot be decomposed and re-aggregated to a vector in C under the stated restriction. Because of the apparent lack of relationship among  members of the core of N, v and that of M, w , we believe an algorithm for testing Core Membership will require more input than just the veto sets of the aggregators and the  oracle of Core Membership for the aggregate value function. . CONCLUDING REMARKS Multi-attribute coalitional games constitute a very  natural way of modeling problems of interest. Its space  requirement compares favorably with other representations discussed in the literature, and hence it serves well as a prototype to study computational complexity of coalitional game theory for a variety of problems. Positive results  obtained under this representation can easily be translated to results about other representations. Some of these corollary results have been discussed in Sections 5 and 6. An important direction to explore in the future is the question of efficiency in updating a game, and how to  evaluate the solution concepts without starting from scratch. As pointed out at the end of Section 4.3, MACG is very  naturally suited for updates. Representation results regarding efficiency of updates, and algorithmic results regarding how to compute the different solution concepts from updates, will both be very interesting. Our work on approximating the Shapley value when the aggregate value function is a non-linear function of the  attributes suggests more work to be done there as well. Given the natural probabilistic interpretation of the Shapley value, we believe that a random sampling approach may have  significantly better theoretical guarantees. . REFERENCES [1] J. M. Bilbao, J. R. Fern´andez, and J. J. L´opez. Complexity in cooperative game theory. http://www.esi.us.es/~mbilbao. [2] V. Conitzer and T. Sandholm. Complexity of determining nonemptiness of the core. In Proc. 18th Int. Joint Conf. on Artificial Intelligence, pages 13-618, 2003. [3] V. Conitzer and T. Sandholm. Computing Shapley values, manipulating value division schemes, and checking core membership in multi-issue domains. In Proc. 19th Nat. Conf. on Artificial Intelligence, pages 19-225, 2004. [4] I. J. Curiel, J. J. Derks, and S. H. Tijs. On balanced games and games with committee control. OR Spectrum, 11:83-88, 1989. [5] X. Deng and C. H. Papadimitriou. On the complexity of cooperative solution concepts. Math. Oper. Res., 9:257-266, May 1994. [6] M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman, New York, 1979. [7] S. Ieong and Y. Shoham. Marginal contribution nets: A compact representation scheme for coalitional games. In Proc. 6th ACM Conf. on Electronic Commerce, pages 193-202, 2005. [8] E. Kalai and E. Zemel. Totally balanced games and games of flow. Math. Oper. Res., 7:476-478, 1982. [9] A. Mas-Colell, M. D. Whinston, and J. R. Green. Microeconomic Theory. Oxford University Press, New York, 1995. [10] M. J. Osborne and A. Rubinstein. A Course in Game Theory. The MIT Press, Cambridge, Massachusetts, 994. [11] L. S. Shapley. A value for n-person games. In H. W. Kuhn and A. W. Tucker, editors, Contributions to the Theory of Games II, number 28 in Annals of Mathematical Studies, pages 307-317. Princeton University Press, 1953. [12] O. Shehory and S. Kraus. Task allocation via coalition formation among autonomous agents. In Proc. 14th Int. Joint Conf. on Artificial Intelligence, pages 31-45, 995. [13] O. Shehory and S. Kraus. A kernel-oriented model for autonomous-agent coalition-formation in general environments: Implentation and results. In Proc. 13th Nat. Conf. on Artificial Intelligence, pages 134-140, 996. [14] J. von Neumann and O. Morgenstern. Theory of Games and Economic Behvaior. Princeton University Press, 1953. [15] M. Yokoo, V. Conitzer, T. Sandholm, N. Ohta, and A. Iwasaki. Coalitional games in open anonymous environments. In Proc. 20th Nat. Conf. on Artificial Intelligence, pages 509-515, 2005. Appendix We complete the missing proofs from the main text here. To prove Proposition 1, we need the following lemma. Lemma 2. Marginal contribution nets when all coalitions are restricted to have values 0 or 1 have the same  representation power as an AND/OR circuit with negation at the literal level (i.e., AC0 circuit) of depth two. Proof. If a rule assigns a negative value in the marginal contribution nets, we can write the rule by a corresponding set of at most n rules, where n is the number of agents, such that each of which has positive values through application of De Morgan"s Law. With all values of the rules non-negative, we can treat the weighted summation step of marginal  contribution nets can be viewed as an OR, and each rule as a conjunction over literals, possibly negated. This exactly match up with an AND/OR circuit of depth two. Proof (Proposition 1). The parity game can be  represented with a MACG using a single attribute, aggregator of sum, and an aggregate value function that evaluates that sum modulus two. As a Boolean function, parity is known to require an  exponential number of prime implicants. By Lemma 2, a prime implicant is the exact analogue of a pattern in a rule of  marginal contribution nets. Therefore, to represent the parity function, a marginal contribution nets must be an  exponential number of rules. Finally, as shown in [7], a marginal contribution net is at worst a factor of O(n) less compact than multi-issue  representation. Therefore, multi-issue representation will also 78 take exponential space to represent the parity game. This is assuming that each issue in the game is represented in characteristic form. Proof (Theorem 2). An instance of three-dimensional matching is as follows [6]: Given set P ⊆ W × X × Y , where W , X, Y are disjoint sets having the same number q of elements, does there exist a matching P ⊆ P such that |P | = q and no two elements of P agree in any  coordinate. For notation, let P = {p1, p2, . . . , pK}. We construct a MACG N, M, A, a, w as follows: • M: Let attributes 1 to q correspond to elements in W , (q+1) to 2q correspond to elements in X, (2q+1) to 3q corresponds to element in Y , and let there be a special attribute (3q + 1). • N: Let player i corresponds to pi, and let there be a special player . • A: Let Aji = 1 if the element corresponding to  attribute j is in pi. Thus, for the first K columns, there are exactly three non-zero entries. We also set A(3q+1) = 1. • a: for each aggregator j, aj (A(S)) = 1 if and only if sum of row j of A(S) equals 1. • w: product over all aj . In the game N, v that corresponds to this construction, v(S) = 1 if and only if all attributes are covered exactly once. Therefore, for /∈ T ⊆ N, v(T ∪ { }) − v(T) = 1 if and only if T covers attributes 1 to 3q exactly once. Since all such T, if exists, must be of size q, the number of  threedimensional matchings is given by φ (v) (K + 1)! q!(K − q)! 79
The Sequential Auction Problem on eBay: An Empirical Analysis and a Solution ∗ Adam I. Juda Division of Engineering and Applied Sciences Harvard University, Harvard Business School ajuda@hbs.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University parkes@eecs.harvard.edu ABSTRACT Bidders on eBay have no dominant bidding strategy when faced with multiple auctions each offering an item of  interest. As seen through an analysis of 1,956 auctions on eBay for a Dell E193FP LCD monitor, some bidders win auctions at prices higher than those of other available  auctions, while others never win an auction despite placing bids in losing efforts that are greater than the closing prices of other available auctions. These misqueues in strategic  behavior hamper the efficiency of the system, and in so doing limit the revenue potential for sellers. This paper proposes a novel options-based extension to eBay"s proxy-bidding  system that resolves this strategic issue for buyers in  commoditized markets. An empirical analysis of eBay provides a basis for computer simulations that investigate the market effects of the options-based scheme, and demonstrates that the options-based scheme provides greater efficiency than eBay, while also increasing seller revenue. Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral  Sciences-Economics General Terms Algorithms, Design, Economics . INTRODUCTION Electronic markets represent an application of information systems that has generated significant new trading  opportunities while allowing for the dynamic pricing of goods. In  addition to marketplaces such as eBay, electronic marketplaces are increasingly used for business-to-consumer auctions (e.g. to sell surplus inventory [19]). Many authors have written about a future in which  commerce is mediated by online, automated trading agents [10, 5, 1]. There is still little evidence of automated trading in e-markets, though. We believe that one leading place of resistance is in the lack of provably optimal bidding  strategies for any but the simplest of market designs. Without this, we do not expect individual consumers, or firms, to be confident in placing their business in the hands of an automated agent. One of the most common examples today of an electronic marketplace is eBay, where the gross merchandise volume (i.e., the sum of all successfully closed listings) during 2005 was $44B. Among items listed on eBay, many are essentially identical. This is especially true in the Consumer  Electronics category [9], which accounted for roughly $3.5B of eBay"s gross merchandise volume in 2005. This presence of  essentially identical items can expose bidders, and sellers, to risks because of the sequential auction problem. For example, Alice may want an LCD monitor, and could potentially bid in either a 1 o"clock or 3 o"clock eBay  auction. While Alice would prefer to participate in whichever auction will have the lower winning price, she cannot  determine beforehand which auction that may be, and could end up winning the wrong auction. This is a problem of multiple copies. Another problem bidders may face is the exposure  problem. As investigated by Bykowsky et al. [6], exposure  problems exist when buyers desire a bundle of goods but may only participate in single-item auctions.1 For example, if Alice values a video game console by itself for $200, a video game by itself for $30, and both a console and game for $250, Alice must determine how much of the $20 of synergy value she might include in her bid for the console alone. Both problems arise in eBay as a result of sequential auctions of single items coupled with patient bidders with substitutes or complementary valuations. Why might the sequential auction problem be bad?  Complex games may lead to bidders employing costly strategies and making mistakes. Potential bidders who do not wish to bear such costs may choose not to participate in the  The exposure problem has been primarily investigated by Bykowsky et al. in the context of simultaneous single-item auctions. The problem is also a familiar one of online  decision making. 80 market, inhibiting seller revenue opportunities.  Additionally, among those bidders who do choose to participate, the mistakes made may lead to inefficient allocations, further limiting revenue opportunities. We are interested in creating modifications to eBay-style markets that simplify the bidder problem, leading to simple equilibrium strategies, and preferably better efficiency and revenue properties. .1 Options + Proxies: A Proposed Solution Retail stores have developed policies to assist their  customers in addressing sequential purchasing problems.  Return policies alleviate the exposure problem by allowing  customers to return goods at the purchase price. Price  matching alleviates the multiple copies problem by allowing buyers to receive from sellers after purchase the difference between the price paid for a good and a lower price found elsewhere for the same good [7, 15, 18]. Furthermore, price matching can reduce the impact of exactly when a seller brings an item to market, as the price will in part be set by others selling the same item. These two retail policies provide the basis for the scheme proposed in this paper.2 We extend the proxy bidding technology currently  employed by eBay. Our super-proxy extension will take  advantage of a new, real options-based, market infrastructure that enables simple, yet optimal, bidding strategies. The extensions are computationally simple, handle temporal  issues, and retain seller autonomy in deciding when to enter the market and conduct individual auctions. A seller sells an option for a good, which will ultimately lead to either a sale of the good or the return of the option. Buyers interact through a proxy agent, defining a value on all possible bundles of goods in which they have interest together with the latest time period in which they are  willing to wait to receive the good(s). The proxy agents use this information to determine how much to bid for options, and follow a dominant bidding strategy across all relevant auctions. A proxy agent exercises options held when the buyer"s patience has expired, choosing options that  maximize a buyer"s payoff given the reported valuation. All other options are returned to the market and not exercised. The options-based protocol makes truthful and immediate  revelation to a proxy a dominant strategy for buyers, whatever the future auction dynamics. We conduct an empirical analysis of eBay, collecting data on over four months of bids for Dell LCD screens (model E193FP) starting in the Summer of 2005. LCD screens are a high-ticket item, for which we demonstrate evidence of the sequential bidding problem. We first infer a  conservative model for the arrival time, departure time and value of bidders on eBay for LCD screens during this period. This model is used to simulate the performance of the  optionsbased infrastructure, in order to make direct comparisons to the actual performance of eBay in this market. We also extend the work of Haile and Tamer [11] to  estimate an upper bound on the distribution of value of eBay bidders, taking into account the sequential auction  problem when making the adjustments. Using this estimate, one can approximate how much greater a bidder"s true value is  Prior work has shown price matching as a potential  mechanism for colluding firms to set monopoly prices. However, in our context, auction prices will be matched, which are not explicitly set by sellers but rather by buyers" bids. from the maximum bid they were observed to have placed on eBay. Based on this approximation, revenue generated in a simulation of the options-based scheme exceeds  revenue on eBay for the comparable population and sequence of auctions by 14.8%, while the options-based scheme  demonstrates itself as being 7.5% more efficient. .2 Related Work A number of authors [27, 13, 28, 29] have analyzed the multiple copies problem, often times in the context of  categorizing or modeling sniping behavior for reasons other than those first brought forward by Ockenfels and Roth [20]. These papers perform equilibrium analysis in simpler settings, assuming bidders can participate in at most two auctions. Peters & Severinov [21] extend these models to  allow buyers to consider an arbitrary number of auctions, and characterize a perfect Bayesian equilibrium. However, their model does not allow auctions to close at distinct times and does not consider the arrival and departure of bidders. Previous work have developed a data-driven approach  toward developing a taxonomy of strategies employed by  bidders in practice when facing multi-unit auctions, but have not considered the sequential bidding problem [26, 2].  Previous work has also sought to provide agents with smarter bidding strategies [4, 3, 5, 1]. Unfortunately, it seems hard to design artificial agents with equilibrium bidding  strategies, even for a simple simultaneous ascending price auction. Iwasaki et al. [14] have considered the role of options in the context of a single, monolithic, auction design to help bidders with marginal-increasing values avoid exposure in a multi-unit, homogeneous item auction problem. In other contexts, options have been discussed for selling coal mine leases [23], or as leveled commitment contracts for use in a decentralized market place [24]. Most similar to our work, Gopal et al. [9] use options for reducing the risks of buyers and sellers in the sequential auction problem. However, their work uses costly options and does not remove the sequential bidding problem completely. Work on online mechanisms and online auctions [17, 12, 2] considers agents that can dynamically arrive and depart across time. We leverage a recent price-based  characterization by Hajiaghayi et al. [12] to provide a dominant strategy equilibrium for buyers within our options-based protocol. The special case for single-unit buyers is equivalent to the protocol of Hajiaghayi et al., albeit with an options-based interpretation. Jiang and Leyton-Brown [16] use machine learning  techniques for bid identification in online auctions. . EBAY AND THE DELL E193FP The most common type of auction held on eBay is a  singleitem proxy auction. Auctions open at a given time and  remain open for a set period of time (usually one week).  Bidders bid for the item by giving a proxy a value ceiling. The proxy will bid on behalf of the bidder only as much as is  necessary to maintain a winning position in the auction, up to the ceiling received from the bidder. Bidders may  communicate with the proxy multiple times before an auction closes. In the event that a bidder"s proxy has been outbid, a bidder may give the proxy a higher ceiling to use in the auction. eBay"s proxy auction implements an incremental version of a Vickrey auction, with the item sold to the highest bidder for the second-highest bid plus a small increment. 81 0  0  0  0  0  0  0  0  0  0  Number of Auctions NumberofBidders Auctions Available Auctions in Which Bid Figure 1: Histogram of number of LCD auctions  available to each bidder and number of LCD auctions in which a bidder participates. The market analyzed in this paper is that of a specific model of an LCD monitor, a 19 Dell LCD model E193FP. This market was selected for a variety of reasons including: • The mean price of the monitor was $240 (with  standard deviation $32), so we believe it reasonable to  assume that bidders on the whole are only interested in acquiring one copy of the item on eBay.3 • The volume transacted is fairly high, at approximately 00 units sold per month. • The item is not usually bundled with other items. • The item is typically sold as new, and so suitable for the price-matching of the options-based scheme. Raw auction information was acquired via a PERL script. The script accesses the eBay search engine,4 and returns all auctions containing the terms ‘Dell" and ‘LCD" that have closed within the past month.5 Data was stored in a text file for post-processing. To isolate the auctions in the  domain of interest, queries were made against the titles of eBay auctions that closed between 27 May, 2005 through 1  October, 2005.6 Figure 1 provides a general sense of how many LCD  auctions occur while a bidder is interested in pursuing a  monitor.7 ,746 bidders (86%) had more than one auction  available between when they first placed a bid on eBay and the  For reference, Dell"s October 2005 mail order catalogue quotes the price of the monitor as being $379 without a desktop purchase, and $240 as part of a desktop purchase upgrade.  http://search.ebay.com  The search is not case-sensitive.  Specifically, the query found all auctions where the title contained all of the following strings: ‘Dell," ‘LCD" and ‘E193FP," while excluding all auctions that contained any of the following strings: ‘Dimension," ‘GHZ," ‘desktop," ‘p4" and ‘GB." The exclusion terms were incorporated so that the only auctions analyzed would be those selling exclusively the LCD of interest. For example, the few bundled auctions  selling both a Dell Dimension desktop and the E193FP LCD are excluded.  As a reference, most auctions close on eBay between noon and midnight EDT, with almost two auctions for the Dell LCD monitor closing each hour on average during peak time periods. Bidders have an average observed patience of 3.9 days (with a standard deviation of 11.4 days). latest closing time of an auction in which they bid (with an average of 78 auctions available). Figure 1 also illustrates the number of auctions in which each bidder participates. Only 32.3% of bidders who had more than one auction  available are observed to bid in more than one auction (bidding in 3.6 auctions on average). A simple regression analysis shows that bidders tend to submit maximal bids to an  auction that are $1.22 higher after spending twice as much time in the system, as well as bids that are $0.27 higher in each subsequent auction. Among the 508 bidders that won exactly one monitor and participated in multiple auctions, 201 (40%) paid more than $10 more than the closing price of another auction in which they bid, paying on average $35 more (standard deviation $21) than the closing price of the cheapest auction in which they bid but did not win. Furthermore, among the 2,216 bidders that never won an item despite participating in  multiple auctions, 421 (19%) placed a losing bid in one auction that was more than $10 higher than the closing price of  another auction in which they bid, submitting a losing bid on average $34 more (standard deviation $23) than the  closing price of the cheapest auction in which they bid but did not win. Although these measures do not say a bidder that lost could have definitively won (because we only consider the final winning price and not the bid of the winner to her proxy), or a bidder that won could have secured a better price, this is at least indicative of some bidder mistakes. . MODELING THE SEQUENTIAL AUCTION PROBLEM While the eBay analysis was for simple bidders who  desire only a single item, let us now consider a more general scenario where people may desire multiple goods of different types, possessing general valuations over those goods. Consider a world with buyers (sometimes called bidders) B and K different types of goods G1...GK . Let T = {0, 1, ...} denote time periods. Let L denote a bundle of goods,  represented as a vector of size K, where Lk ∈ {0, 1} denotes the quantity of good type Gk in the bundle.8 The type of a buyer i ∈ B is (ai, di, vi), with arrival time ai ∈ T, departure time di ∈ T, and private valuation vi(L) ≥ 0 for each bundle of goods L received between ai and di, and zero value  otherwise. The arrival time models the period in which a buyer first realizes her demand and enters the market, while the departure time models the period in which a buyer loses  interest in acquiring the good(s). In settings with general  valuations, we need an additional assumption: an upper bound on the difference between a buyer"s arrival and departure, denoted ΔMax. Buyers have quasi-linear utilities, so that the utility of buyer i receiving bundle L and paying p, in some period no later than di, is ui(L, p) = vi(L) − p. Each seller j ∈ S brings a single item kj to the market, has no intrinsic value and wants to maximize revenue. Seller j has an arrival time, aj, which models the period in which she is first interested in listing the item, while the departure time, dj, models the latest period in which she is willing to consider having an auction for the item close. A seller will receive payment by the end of the reported departure of the winning buyer.  We extend notation whereby a single item k of type Gk refers to a vector L : Lk = 1. 82 We say an individual auction in a sequence is locally  strategyproof (LSP) if truthful bidding is a dominant strategy for a buyer that can only bid in that auction. Consider the following example to see that LSP is insufficient for the  existence of a dominant bidding strategy for buyers facing a sequence of auctions. Example 1. Alice values one ton of Sand with one ton of Stone at $2, 000. Bob holds a Vickrey auction for one ton of Sand on Monday and a Vickrey auction for one ton of Stone on Tuesday. Alice has no dominant bidding strategy because she needs to know the price for Stone on Tuesday to know her maximum willingness to pay for Sand on Monday. Definition 1. The sequential auction problem. Given a sequence of auctions, despite each auction being locally strategyproof, a bidder has no dominant bidding strategy. Consider a sequence of auctions. Generally, auctions  selling the same item will be uncertainly-ordered, because a buyer will not know the ordering of closing prices among the auctions. Define the interesting bundles for a buyer as all bundles that could maximize the buyer"s profit for some combination of auctions and bids of other buyers.9 Within the interesting bundles, say that an item has uncertain  marginal value if the marginal value of an item depends on the other goods held by the buyer.10 Say that an item is  oversupplied if there is more than one auction offering an item of that type. Say two bundles are substitutes if one of those bundles has the same value as the union of both bundles.11 Proposition 1. Given locally strategyproof single-item auctions, the sequential auction problem exists for a bidder if and only if either of the following two conditions is true: (1) within the set of interesting bundles (a) there are two  bundles that are substitutes, (b) there is an item with uncertain marginal value, or (c) there is an item that is over-supplied; (2) a bidder faces competitors" bids that are conditioned on the bidder"s past bids. Proof. (Sketch.)(⇐) A bidder does not have a dominant strategy when (a) she does not know which bundle among substitutes to pursue, (b) she faces the exposure problem, or (c) she faces the multiple copies problem. Additionally, a bidder does not have a dominant strategy when she does not how to optimally influence the bids of competitors.(⇒) By contradiction. A bidder has a dominant strategy to bid its constant marginal value for a given item in each auction available when conditions (1) and (2) are both false. For example, the following buyers all face the sequential auction problem as a result of condition (a), (b) and (c) respectively: a buyer who values one ton of Sand for $1,000, or one ton of Stone for $2,000, but not both Sand and Stone; a buyer who values one ton of Sand for $1,000, one ton of Stone for $300, and one ton of Sand and one ton of Stone for $1,500, and can participate in an auction for Sand before an auction for Stone; a buyer who values one ton of Sand for $1,000 and can participate in many auctions selling Sand.  Assume that the empty set is an interesting bundle. 0 Formally, an item k has uncertain marginal value if |{m : m = vi(Q) − vi(Q − k), ∀Q ⊆ L ∈ InterestingBundle, Q ⊇ k}| > 1. 1 Formally, two bundles A and B are substitutes if vi(A ∪ B) = max(vi(A), vi(B)), where A ∪ B = L where Lk = max(Ak, Bk). . SUPER PROXIES AND OPTIONS The novel solution proposed in this work to resolve the sequential auction problem consists of two primary  components: richer proxy agents, and options with price matching. In finance, a real option is a right to acquire a real good at a certain price, called the exercise price. For instance, Alice may obtain from Bob the right to buy Sand from him at an exercise price of $1, 000. An option provides the right to purchase a good at an exercise price but not the obligation. This flexibility allows buyers to put together a collection of options on goods and then decide which to exercise. Options are typically sold at a price called the option price. However, options obtained at a non-zero option price cannot generally support a simple, dominant bidding  strategy, as a buyer must compute the expected value of an  option to justify the cost [8]. This computation requires a model of the future, which in our setting requires a model of the bidding strategies and the values of other bidders. This is the very kind of game-theoretic reasoning that we want to avoid. Instead, we consider costless options with an option price of zero. This will require some care as buyers are weakly better off with a costless option than without one, whatever its exercise price. However, multiple bidders pursuing  options with no intention of exercising them would cause the efficiency of an auction for options to unravel. This is the role of the mandatory proxy agents, which intermediate between buyers and the market. A proxy agent forces a link between the valuation function used to acquire options and the valuation used to exercise options. If a buyer tells her proxy an inflated value for an item, she runs the risk of  having the proxy exercise options at a price greater than her value. .1 Buyer Proxies .1.1 Acquiring Options After her arrival, a buyer submits her valuation ˆvi  (perhaps untruthfully) to her proxy in some period ˆai ≥ ai, along with a claim about her departure time ˆdi ≥ ˆai. All transactions are intermediated via proxy agents. Each  auction is modified to sell an option on that good to the  highest bidding proxy, with an initial exercise price set to the second-highest bid received.12 When an option in which a buyer is interested becomes available for the first time, the proxy determines its bid by computing the buyer"s maximum marginal value for the item, and then submits a bid in this amount. A proxy does not bid for an item when it already holds an option. The bid price is: bidt i(k) = max L [ˆvi(L + k) − ˆvi(L)] (1) By having a proxy compute a buyer"s maximum marginal value for an item and then bidding only that amount, a buyer"s proxy will win any auction that could possibly be of benefit to the buyer and only lose those auctions that could never be of value to the buyer. 2 The system can set a reserve price for each good, provided that the reserve is universal for all auctions selling the same item. Without a universal reserve price, price matching is not possible because of the additional restrictions on prices that individual sellers will accept. 83 Buyer Type Monday Tuesday Molly (Mon, Tues, $8) 6Nancy 6Nancy → 4Polly Nancy (Mon, Tues, $6) - 4Polly Polly (Mon, Tues, $4)  -Table 1: Three-buyer example with each wanting a  single item and one auction occurring on Monday and  Tuesday. XY  implies an option with exercise price X and bookkeeping that a proxy has prevented Y from  currently possessing an option. → is the updating of  exercise price and bookkeeping. When a proxy wins an auction for an option, the proxy will store in its local memory the identity (which may be a pseudonym) of the proxy not holding an option because of the proxy"s win (i.e., the proxy that it ‘bumped" from winning, if any). This information will be used for price matching. .1.2 Pricing Options Sellers agree by joining the market to allow the proxy representing a buyer to adjust the exercise price of an option that it holds downwards if the proxy discovers that it could have achieved a better price by waiting to bid in a later auction for an option on the same good. To assist in the implementation of the price matching scheme each proxy tracks future auctions for an option that it has already won and will determine who would be bidding in that auction had the proxy delayed its entry into the market until this later auction. The proxy will request price matching from the seller that granted it an option if the proxy discovers that it could have secured a lower price by waiting. To reiterate, the proxy does not acquire more than one option for any good. Rather, it reduces the exercise price on its already issued option if a better deal is found. The proxy is able to discover these deals by asking each future auction to report the identities of the bidders in that auction together with their bids. This needs to be enforced by eBay, as the central authority. The highest bidder in this later auction, across those whose identity is not stored in the proxy"s memory for the given item, is exactly the bidder against whom the proxy would be competing had it delayed its entry until this auction. If this high bid is lower than the current option price held, the proxy price matches down to this high bid price. After price matching, one of two adjustments will be made by the proxy for bookkeeping purposes. If the winner of the auction is the bidder whose identity has been in the proxy"s local memory, the proxy will replace that local  information with the identity of the bidder whose bid it just price matched, as that is now the bidder the proxy has  prevented from obtaining an option. If the auction winner"s identity is not stored in the proxy"s local memory the  memory may be cleared. In this case, the proxy will simply price match against the bids of future auction winners on this item until the proxy departs. Example 2 (Table 1). Molly"s proxy wins the  Monday auction, submitting a bid of $8 and receiving an option for $6. Molly"s proxy adds Nancy to its local memory as Nancy"s proxy would have won had Molly"s proxy not bid. On Tuesday, only Nancy"s and Polly"s proxy bid (as Molly"s proxy holds an option), with Nancy"s proxy winning an  opBuyer Type Monday Tuesday Truth: Molly (Mon, Mon, $8)  NancyNancy (Mon, Tues, $6) - 4Polly Polly (Mon, Tues, $4)  -Misreport: Molly (Mon, Mon, $8)  -Nancy (Mon, Tues, $10) 8Molly 8Molly → 4φ Polly (Mon, Tues, $4) - 0φ Misreport & match low: Molly (Mon, Mon, $8)  -Nancy (Mon, Tues, $10) 8 8 → 0 Polly (Mon, Tues, $4) - 0 Table 2: Examples demonstrating why bookkeeping will lead to a truthful system whereas simply matching to the lowest winning price will not. tion for $4 and noting that it bumped Polly"s proxy. At this time, Molly"s proxy will price match its option down to $4 and replace Nancy with Polly in its local memory as per the price match algorithm, as Polly would be holding an option had Molly never bid. .1.3 Exercising Options At the reported departure time the proxy chooses which options to exercise. Therefore, a seller of an option must wait until period ˆdw for the option to be exercised and  receive payment, where w was the winner of the option.13 For bidder i, in period ˆdi, the proxy chooses the option(s) that maximize the (reported) utility of the buyer: θ∗ t = argmax θ⊆Θ (ˆvi(γ(θ)) − π(θ)) (2) where Θ is the set of all options held, γ(θ) are the goods corresponding to a set of options, and π(θ) is the sum of exercise prices for a set of options. All other options are returned.14 No options are exercised when no combination of options have positive utility. .1.4 Why bookkeep and not match winning price? One may believe that an alternative method for  implementing a price matching scheme could be to simply have proxies match the lowest winning price they observe after winning an option. However, as demonstrated in Table 2, such a simple price matching scheme will not lead to a  truthful system. The first scenario in Table 2 demonstrates the outcome if all agents were to truthfully report their types. Molly 3 While this appears restrictive on the seller, we believe it not significantly different than what sellers on eBay currently endure in practice. An auction on eBay closes at a specific time, but a seller must wait until a buyer relinquishes  payment before being able to realize the revenue, an amount of time that could easily be days (if payment is via a money order sent through courier) to much longer (if a buyer is slow but not overtly delinquent in remitting her payment). 4 Presumably, an option returned will result in the seller holding a new auction for an option on the item it still possesses. However, the system will not allow a seller to re-auction an option until ΔMax after the option had first been issued in order to maintain a truthful mechanism. 84 would win the Monday auction and receive an option with an exercise price of $6 (subsequently exercising that option at the end of Monday), and Nancy would win the Tuesday auction and receive an option with an exercise price of $4 (subsequently exercising that option at the end of Tuesday). The second scenario in Table 2 demonstrates the outcome if Nancy were to misreport her value for the good by  reporting an inflated value of $10, using the proposed bookkeeping method. Nancy would win the Monday auction and receive an option with an exercise price of $8. On Tuesday, Polly would win the auction and receive an option with an exercise price of $0. Nancy"s proxy would observe that the highest bid submitted on Tuesday among those proxies not stored in local memory is Polly"s bid of $4, and so Nancy"s proxy would price match the exercise price of its option down to $4. Note that the exercise price Nancy"s proxy has obtained at the end of Tuesday is the same as when she truthfully revealed her type to her proxy. The third scenario in Table 2 demonstrates the outcome if Nancy were to misreport her value for the good by reporting an inflated value of $10, if the price matching scheme were for proxies to simply match their option price to the  lowest winning price at any time while they are in the system. Nancy would win the Monday auction and receive an option with an exercise price of $8. On Tuesday, Polly would win the auction and receive an option with an exercise price of $0. Nancy"s proxy would observe that the lowest price on Tuesday was $0, and so Nancy"s proxy would price match the exercise price of its option down to $0. Note that the exercise price Nancy"s proxy has obtained at the end of  Tuesday is lower than when she truthfully revealed her type to the proxy. Therefore, a price matching policy of simply matching the lowest price paid may not elicit truthful information from buyers. .2 Complexity of Algorithm An XOR-valuation of size M for buyer i is a set of M terms, < L1 , v1 i > ...< LM , vM i >, that maps distinct  bundles to values, where i is interested in acquiring at most one such bundle. For any bundle S, vi(S) = maxLm⊆S(vm i ). Theorem 1. Given an XOR-valuation which possesses M terms, there is an O(KM2 ) algorithm for computing all maximum marginal values, where K is the number of  different item types in which a buyer may be interested. Proof. For each item type, recall Equation 1 which  defines the maximum marginal value of an item. For each bundle L in the M-term valuation, vi(L + k) may be found by iterating over the M terms. Therefore, the number of terms explored to determine the maximum marginal value for any item is O(M2 ), and so the total number of  bundle comparisons to be performed to calculate all maximum marginal values is O(KM2 ). Theorem 2. The total memory required by a proxy for implementing price matching is O(K), where K is the  number of distinct item types. The total work performed by a proxy to conduct price matching in each auction is O(1). Proof. By construction of the algorithm, the proxy stores one maximum marginal value for each item for bidding, of which there are O(K); at most one buyer"s identity for each item, of which there are O(K); and one current option  exercise price for each item, of which there are O(K). For each auction, the proxy either submits a precomputed bid or price matches, both of which take O(1) work. .3 Truthful Bidding to the Proxy Agent Proxies transform the market into a direct revelation  mechanism, where each buyer i interacts with the proxy only once,15 and does so by declaring a bid, bi, which is  defined as an announcement of her type, (ˆai, ˆdi, ˆvi), where the announcement may or may not be truthful. We  denote all received bids other than i"s as b−i. Given bids, b = (bi, b−i), the market determines allocations, xi(b), and payments, pi(b) ≥ 0, to each buyer (using an online  algorithm). A dominant strategy equilibrium for buyers requires that vi(xi(bi, b−i))−pi(bi, b−i) ≥ vi(xi(bi, b−i))−pi(bi, b−i), ∀bi = bi, ∀b−i. We now establish that it is a dominant strategy for a buyer to reveal her true valuation and true departure time to her proxy agent immediately upon arrival to the system. The proof builds on the price-based characterization of  strategyproof single-item online auctions in Hajiaghayi et al. [12]. Define a monotonic and value-independent price function psi(ai, di, L, v−i) which can depend on the values of other agents v−i. Price psi(ai, di, L, v−i) will represent the price available to agent i for bundle L in the mechanism if it announces arrival time ai and departure time di. The price is independent of the value vi of agent i, but can depend on ai, di and L as long as it satisfies a monotonicity condition. Definition 2. Price function psi(ai, di, L, v−i) is  monotonic if psi(ai, di, L , v−i) ≤ psi(ai, di, L, v−i) for all ai ≤ ai, all di ≥ di, all bundles L ⊆ L and all v−i. Lemma 1. An online combinatorial auction will be  strategyproof (with truthful reports of arrival, departure and value a dominant strategy) when there exists a monotonic and value-independent price function, psi(ai, di, L, v−i), such that for all i and all ai, di ∈ T and all vi, agent i is allocated  bundle L∗ = argmaxL [vi(L) − psi(ai, di, L, v−i)] in period di and makes payment psi(ai, di, L∗ , v−i). Proof. Agent i cannot benefit from reporting a later  departure ˆdi because the allocation is made in period ˆdi and the agent would have no value for this allocation. Agent i cannot benefit from reporting a later arrival ˆai ≥ ai or earlier departure ˆdi ≤ di because of price monotonicity.  Finally, the agent cannot benefit from reporting some ˆvi = vi because its reported valuation does not change the prices it faces and the mechanism maximizes its utility given its reported valuation and given the prices. Lemma 2. At any given time, there is at most one buyer in the system whose proxy does not hold an option for a given item type because of buyer i"s presence in the system, and the identity of that buyer will be stored in i"s proxy"s local memory at that time if such a buyer exists. Proof. By induction. Consider the first proxy that a buyer prevents from winning an option. Either (a) the 5 For analysis purposes, we view the mechanism as an opaque market so that the buyer cannot condition her bid on bids placed by others. 85 bumped proxy will leave the system having never won an option, or (b) the bumped proxy will win an auction in the future. If (a), the buyer"s presence prevented exactly that one buyer from winning an option, but will have not  prevented any other proxies from winning an option (as the buyer"s proxy will not bid on additional options upon  securing one), and will have had that bumped proxy"s identity in its local memory by definition of the algorithm. If (b), the buyer has not prevented the bumped proxy from  winning an option after all, but rather has prevented only the proxy that lost to the bumped proxy from winning (if any), whose identity will now be stored in the proxy"s local  memory by definition of the algorithm. For this new identity in the buyer"s proxy"s local memory, either scenario (a) or (b) will be true, ad infinitum. Given this, we show that the options-based  infrastructure implements a price-based auction with a monotonic and value-independent price schedule to every agent. Theorem 3. Truthful revelation of valuation, arrival and departure is a dominant strategy for a buyer in the  optionsbased market. Proof. First, define a simple agent-independent price function pk i (t, v−i) as the highest bid by the proxies not holding an option on an item of type Gk at time t, not including the proxy representing i herself and not  including any proxies that would have already won an option had i never entered the system (i.e., whose identity is stored in i"s proxy"s local memory)(∞ if no supply at t). This set of proxies is independent of any declaration i makes to its proxy (as the set explicitly excludes the at most one proxy (see Lemma 2) that i has prevented from holding an option), and each bid submitted by a proxy within this set is only a function of their own buyer"s declared  valuation (see Equation 1). Furthermore, i cannot influence the supply she faces as any options returned by bidders due to a price set by i"s proxy"s bid will be re-auctioned after i has departed the system. Therefore, pk i (t, v−i) is independent of i"s declaration to its proxy. Next, define psk i (ˆai, ˆdi, v−i) = minˆai≤τ≤ ˆdi [pk i (τ, v−i)] (possibly ∞) as the minimum price over pk i (t, v−i), which is clearly monotonic. By construction of price matching, this is exactly the price obtained by a proxy on any option that it holds at  departure. Define psi(ˆai, ˆdi, L, v−i) = Èk=K k=1 psk i (ˆai, ˆdi, v−i)Lk, which is monotonic in ˆai, ˆdi and L since psk i (ˆai, ˆdi, v−i) is monotonic in ˆai and ˆdi and (weakly) greater than zero for each k. Given the set of options held at ˆdi, which may be a subset of those items with non-infinite prices, the proxy exercises options to maximize the reported utility. Left to show is that all bundles that could not be obtained with options held are priced sufficiently high as to not be  preferred. For each such bundle, either there is an item priced at ∞ (in which case the bundle would not be desired) or there must be an item in that bundle for which the proxy does not hold an option that was available. In all auctions for such an item there must have been a distinct bidder with a bid greater than bidt i(k), which subsequently results in psk i (ˆai, ˆdi, v−i) > bidt i(k), and so the bundle without k would be preferred to the bundle. Theorem 4. The super proxy, options-based scheme is individually-rational for both buyers and sellers. Price σ(Price) Value Surplus eBay $240.24 $32 $244 $4 Options $239.66 $12 $263 $23 Table 3: Average price paid, standard deviation of prices paid, average bidder value among winners, and average winning bidder surplus on eBay for Dell E193FP LCD screens as well as the simulated options-based  market using worst-case estimates of bidders" true value. Proof. By construction, the proxy exercises the profit maximizing set of options obtained, or no options if no set of options derives non-negative surplus. Therefore, buyers are guaranteed non-negative surplus by participating in the scheme. For sellers, the price of each option is based on a non-negative bid or zero. . EVALUATING THE OPTIONS / PROXY INFRASTRUCTURE A goal of the empirical benchmarking and a reason to collect data from eBay is to try and build a realistic model of buyers from which to estimate seller revenue and other market effects under the options-based scheme. We simulate a sequence of auctions that match the timing of the Dell LCD auctions on eBay.16 When an auction  successfully closes on eBay, we simulate a Vickrey auction for an option on the item sold in that period. Auctions that do not successfully close on eBay are not simulated. We  estimate the arrival, departure and value of each bidder on eBay from their observed behavior.17 Arrival is estimated as the first time that a bidder interacts with the eBay proxy, while departure is estimated as the latest closing time among eBay auctions in which a bidder participates. We initially adopt a particularly conservative estimate for bidder value, estimating it as the highest bid a bidder was observed to make on eBay. Table 3 compares the  distribution of closing prices on eBay and in the simulated options scheme. While the average revenue in both schemes is  virtually the same ($239.66 in the options scheme vs. $240.24 on eBay), the winners in the options scheme tend to value the item won 7% more than the winners on eBay ($263 in the options scheme vs. $244 on eBay). .1 Bid Identification We extend the work of Haile and Tamer [11] to sequential auctions to get a better view of underlying bidder values. Rather than assume for bidders an equilibrium behavior as in standard econometric techniques, Haile and Tamer do not attempt to model how bidders" true values get mapped into a bid in any given auction. Rather, in the context of repeated 6 When running the simulations, the results of the first and final ten days of auctions are not recorded to reduce edge effects that come from viewing a discrete time window of a continuous process. 7 For the 100 bidders that won multiple times on eBay, we have each one bid a constant marginal value for each  additional item in each auction until the number of options held equals the total number of LCDs won on eBay, with each option available for price matching independently. This bidding strategy is not a dominant strategy (falling outside the type space possible for buyers on which the proof of truthfulness has been built), but is believed to be the most appropriate first order action for simulation. 86  100 200 300 400 500  .2 .4 .6 .8  Value ($) CDF Observed Max Bids Upper Bound of True Value Figure 2: CDF of maximum bids observed and upper bound estimate of the bidding population"s distribution for maximum willingness to pay. The true population distribution lies below the estimated upper bound. single-item auctions with distinct bidder populations, Haile and Tamer make only the following two assumptions when estimating the distribution of true bidder values: . Bidders do not bid more than they are willing to pay. . Bidders do not allow an opponent to win at a price they are willing to beat. From the first of their two assumptions, given the bids placed by each bidder in each auction, Haile and Tamer derive a method for estimating an upper bound of the bidding  population"s true value distribution (i.e., the bound that lies above the true value distribution). From the second of their two assumptions, given the winning price of each auction, Haile and Tamer derive a method for estimating a lower bound of the bidding population"s true value distribution. It is only the upper-bound of the distribution that we  utilize in our work. Haile and Tamer assume that bidders only participate in a single auction, and require independence of the bidding population from auction to auction. Neither assumption is valid here: the former because bidders are known to bid in more than one auction, and the latter because the set of bidders in an auction is in all likelihood not a true i.i.d. sampling of the overall bidding population. In particular, those who win auctions are less likely to bid in successive auctions, while those who lose auctions are more likely to remain bidders in future auctions. In applying their methods we make the following  adjustments: • Within a given auction, each individual bidder"s true willingness to pay is assumed weakly greater than the maximum bid that bidder submits across all auctions for that item (either past or future). • When estimating the upper bound of the value  distribution, if a bidder bids in more than one auction, randomly select one of the auctions in which the  bidder bid, and only utilize that one observation during the estimation.18 8 In current work, we assume that removing duplicate  bidders is sufficient to make the buying populations  independent i.i.d. draws from auction to auction. If one believes that certain portions of the population are drawn to  cerPrice σ(Price) Value Surplus eBay $240.24 $32 $281 $40 Options $275.80 $14 $302 $26 Table 4: Average price paid, standard deviation of prices paid, average bidder value among winners, and  average winning bidder surplus on eBay for Dell E193FP LCD screens as well as in the simulated options-based market using an adjusted Haile and Tamer estimate of bidders" true values being 15% higher than their  maximum observed bid. Figure 2 provides the distribution of maximum bids placed by bidders on eBay as well as the estimated upper bound of the true value distribution of bidders based on the extended Haile and Tamer method.19 As can be seen, the smallest  relative gap between the two curves meaningfully occurs near the 80th percentile, where the upper bound is 1.17 times the maximum bid. Therefore, adopted as a less  conservative model of bidder values is a uniform scaling factor of .15. We now present results from this less conservative  analysis. Table 4 shows the distribution of closing prices in  auctions on eBay and in the simulated options scheme. The mean price in the options scheme is now significantly higher, 5% greater, than the prices on eBay ($276 in the options scheme vs. $240 on eBay), while the standard deviation of closing prices is lower among the options scheme auctions ($14 in the options scheme vs. $32 on eBay). Therefore, not only is the expected revenue stream higher, but the lower variance provides sellers a greater likelihood of realizing that higher revenue. The efficiency of the options scheme remains higher than on eBay. The winners in the options scheme now have an average estimated value 7.5% higher at $302. In an effort to better understand this efficiency, we  formulated a mixed integer program (MIP) to determine a simple estimate of the allocative efficiency of eBay. The MIP computes the efficient value of the oﬄine problem with full hindsight on all bids and all supply.20 Using a scaling of 1.15, the total value allocated to eBay winners is  estimated at $551,242, while the optimal value (from the MIP) is $593,301. This suggests an allocative efficiency of 92.9%: while the typical value of a winner on eBay is $281, an  average value of $303 was possible.21 Note the options-based tain auctions, then further adjustments would be required in order to utilize these techniques. 9 The estimation of the points in the curve is a  minimization over many variables, many of which can have  smallnumbers bias. Consequently, Haile and Tamer suggest using a weighted average over all terms yi of È i yi exp(yiρ)Èj exp(yj ρ) to approximate the minimum while reducing the small  number effects. We used ρ = −1000 and removed observations of auctions with 17 bidders or more as they occurred very infrequently. However, some small numbers bias still  demonstrated itself with the plateau in our upper bound estimate around a value of $300. 0 Buyers who won more than one item on eBay are cloned so that they appear to be multiple bidders of identical type. 1 As long as one believes that every bidder"s true value is a constant factor α away from their observed maximum bid, the 92.9% efficiency calculation holds for any value of α. In practice, this belief may not be reasonable. For example, if losing bidders tend to have true values close to their observed 87 scheme comes very close to achieving this level of efficiency [at 99.7% efficient in this estimate] even though it operates without the benefit of hindsight. Finally, although the typical winning bidder surplus  decreases between eBay and the options-based scheme, some surplus redistribution would be possible because the total market efficiency is improved.22 . DISCUSSION The biggest concern with our scheme is that proxy agents who may be interested in many different items may acquire many more options than they finally exercise. This can lead to efficiency loss. Notice that this is not an issue when  bidders are only interested in a single item (as in our empirical study), or have linear-additive values on items. To fix this, we would prefer to have proxy agents use more caution in acquiring options and use a more adaptive bidding strategy than that in Equation 1. For instance, if a proxy is already holding an option with an exercise price of $3 on some item for which it has value of $10, and it values some substitute item at $5, the proxy could reason that in no circumstance will it be useful to acquire an option on the second item. We formulate a more sophisticated bidding strategy along these lines. Let Θt be the set of all options a proxy for bidder i already possesses at time t. Let θt ⊆ Θt, be a subset of those options, the sum of whose exercise prices are π(θt), and the goods corresponding to those options being γ(θt). Let Π(θt) = ˆvi(γ(θt)) − π(θt) be the (reported) available surplus associated with a set of options. Let θ∗ t be the set of options currently held that would maximize the buyer"s surplus; i.e., θ∗ t = argmaxθt⊆Θt Π(θt). Let the maximal willingness to pay for an item k represent a price above which the agent knows it would never exercise an option on the item given the current options held. This can be computed as follows: bidt i(k) = max L [0, min[ˆvi(L + k) − Π(θ∗ t ), ˆvi(L + k) − ˆvi(L)]] (3) where ˆvi(L+k)−Π(θ∗ t ) considers surplus already held, ˆvi(L+ k)−ˆvi(L) considers the marginal value of a good, and taking the max[0, .] considers the overall use of pursuing the good. However, and somewhat counter intuitively, we are not able to implement this bidding scheme without forfeiting truthfulness. The Π(θ∗ t ) term in Equation 3 (i.e., the amount of guaranteed surplus bidder i has already obtained) can be influenced by proxy j"s bid. Therefore, bidder j may have the incentive to misrepresent her valuation to her proxy if she believes doing so will cause i to bid differently in the future in a manner beneficial to j. Consider the following example where the proxy scheme is refined to bid the  maximum willingness to pay. Example 3. Alice values either one ton of Sand or one ton of Stone for $2,000. Bob values either one ton of Sand or one ton of Stone for $1,500. All bidders have a patience maximum bids while eBay winners have true values much greater than their observed maximum bids then downward bias is introduced in the efficiency calculation at present. 2 The increase in eBay winner surplus between Tables 3 and  is to be expected as the α scaling strictly increases the estimated value of the eBay winners while holding the prices at which they won constant. of 2 days. On day one, a Sand auction is held, where Alice"s proxy bids $2,000 and Bob"s bids $1,500. Alice"s proxy wins an option to purchase Sand for $1,500. On day two, a Stone auction is held, where Alice"s proxy bids $1,500 [as she has already obtained a guaranteed $500 of surplus from winning a Sand option, and so reduces her Stone bid by this amount], and Bob"s bids $1,500. Either Alice"s proxy or Bob"s proxy will win the Stone option. At the end of the second day, Alice"s proxy holds an option with an exercise price of $1,500 to obtain a good valued for $2,000, and so obtains $500 in surplus. Now, consider what would have happened had Alice  declared that she valued only Stone. Example 4. Alice declares valuing only Stone for $2,000. Bob values either one ton of Sand or one ton of Stone for $1,500. All bidders have a patience of 2 days. On day one, a Sand auction is held, where Bob"s proxy bids $1,500. Bob"s proxy wins an option to purchase Sand for $0. On day two, a Stone auction is held, where Alice"s proxy bids $2,000, and Bob"s bids $0 [as he has already obtained a guaranteed $1,500 of surplus from winning a Sand option, and so reduces his Stone bid by this amount]. Alice"s proxy wins the Stone option for $0. At the end of the second day, Alice"s proxy holds an option with an exercise price of $0 to obtain a good valued for $2,000, and so obtains $2,000 in surplus. By misrepresenting her valuation (i.e., excluding her value of Sand), Alice was able to secure higher surplus by guiding Bob"s bid for Stone to $0. An area of immediate further work by the authors is to develop a more sophisticated proxy agent that can allow for bidding of maximum willingness to pay (Equation 3) while maintaining truthfulness. An additional, practical, concern with our proxy scheme is that we assume an available, trusted, and well understood method to characterize goods (and presumably the quality of goods). We envision this happening in practice by  sellers defining a classification for their item upon entering the market, for instance via a UPC code. Just as in eBay, this would allow an opportunity for sellers to improve revenue by overstating the quality of their item (new vs. like new), and raises the issue of how well a reputation scheme could address this. . CONCLUSIONS We introduced a new sales channel, consisting of an  optionsbased and proxied auction protocol, to address the  sequential auction problem that exists when bidders face  multiple auctions for substitutes and complements goods. Our scheme provides bidders with a simple, dominant and  truthful bidding strategy even though the market remains open and dynamic. In addition to exploring more sophisticated proxies that bid in terms of maximum willingness to pay, future work should aim to better model seller incentives and resolve the strategic problems facing sellers. For instance, does the  options scheme change seller incentives from what they  currently are on eBay? Acknowledgments We would like to thank Pai-Ling Yin. Helpful comments have been received from William Simpson, attendees at  Har188 vard University"s EconCS and ITM seminars, and  anonymous reviewers. Thank you to Aaron L. Roth and  KangXing Jin for technical support. All errors and omissions remain our own. . REFERENCES [1] P. Anthony and N. R. Jennings. Developing a bidding agent for multiple heterogeneous auctions. ACM Trans. On Internet Technology, 2003. [2] R. Bapna, P. Goes, A. Gupta, and Y. Jin. User heterogeneity and its impact on electronic auction market design: An empirical exploration. MIS Quarterly, 28(1):21-43, 2004. [3] D. Bertsimas, J. Hawkins, and G. Perakis. Optimal bidding in on-line auctions. Working Paper, 2002. [4] C. Boutilier, M. Goldszmidt, and B. Sabata. Sequential auctions for the allocation of resources with complementarities. In Proc. 16th International Joint Conference on Artificial Intelligence (IJCAI-99), pages 527-534, 1999. [5] A. Byde, C. Preist, and N. R. Jennings. Decision procedures for multiple auctions. In Proc. 1st Int. Joint Conf. on Autonomous Agents and Multiagent Systems (AAMAS-02), 2002. [6] M. M. Bykowsky, R. J. Cull, and J. O. Ledyard. Mutually destructive bidding: The FCC auction design problem. Journal of Regulatory Economics, 7(3):205-228, 2000. [7] Y. Chen, C. Narasimhan, and Z. J. Zhang. Consumer heterogeneity and competitive price-matching guarantees. Marketing Science, 20(3):300-314, 2001. [8] A. K. Dixit and R. S. Pindyck. Investment under Uncertainty. Princeton University Press, 1994. [9] R. Gopal, S. Thompson, Y. A. Tung, and A. B. Whinston. Managing risks in multiple online auctions: An options approach. Decision Sciences, 6(3):397-425, 2005. [10] A. Greenwald and J. O. Kephart. Shopbots and pricebots. In Proc. 16th International Joint Conference on Artificial Intelligence (IJCAI-99), pages 506-511, 1999. [11] P. A. Haile and E. Tamer. Inference with an incomplete model of English auctions. Journal of Political Economy, 11(1), 2003. [12] M. T. Hajiaghayi, R. Kleinberg, M. Mahdian, and D. C. Parkes. Online auctions with re-usable goods. In Proc. ACM Conf. on Electronic Commerce, 2005. [13] K. Hendricks, I. Onur, and T. Wiseman. Preemption and delay in eBay auctions. University of Texas at Austin Working Paper, 2005. [14] A. Iwasaki, M. Yokoo, and K. Terada. A robust open ascending-price multi-unit auction protocol against false-name bids. Decision Support Systems, 39:23-40, 005. [15] E. G. James D. Hess. Price-matching policies: An empirical case. Managerial and Decision Economics, 2(4):305-315, 1991. [16] A. X. Jiang and K. Leyton-Brown. Estimating bidders" valuation distributions in online auctions. In Workshop on Game Theory and Decision Theory (GTDT) at IJCAI, 2005. [17] R. Lavi and N. Nisan. Competitive analysis of incentive compatible on-line auctions. In Proc. 2nd ACM Conf. on Electronic Commerce (EC-00), 2000. [18] Y. J. Lin. Price matching in a model of equilibrium price dispersion. Southern Economic Journal, 5(1):57-69, 1988. [19] D. Lucking-Reiley and D. F. Spulber. Business-to-business electronic commerce. Journal of Economic Perspectives, 15(1):55-68, 2001. [20] A. Ockenfels and A. Roth. Last-minute bidding and the rules for ending second-price auctions: Evidence from eBay and Amazon auctions on the Internet. American Economic Review, 92(4):1093-1103, 2002. [21] M. Peters and S. Severinov. Internet auctions with many traders. Journal of Economic Theory (Forthcoming), 2005. [22] R. Porter. Mechanism design for online real-time scheduling. In Proceedings of the 5th ACM conference on Electronic commerce, pages 61-70. ACM Press, 004. [23] M. H. Rothkopf and R. Engelbrecht-Wiggans. Innovative approaches to competitive mineral leasing. Resources and Energy, 14:233-248, 1992. [24] T. Sandholm and V. Lesser. Leveled commitment contracts and strategic breach. Games and Economic Behavior, 35:212-270, 2001. [25] T. W. Sandholm and V. R. Lesser. Issues in automated negotiation and electronic commerce: Extending the Contract Net framework. In Proc. 1st International Conference on Multi-Agent Systems (ICMAS-95), pages 328-335, 1995. [26] H. S. Shah, N. R. Joshi, A. Sureka, and P. R. Wurman. Mining for bidding strategies on eBay. Lecture Notes on Artificial Intelligence, 2003. [27] M. Stryszowska. Late and multiple bidding in competing second price Internet auctions. EuroConference on Auctions and Market Design: Theory, Evidence and Applications, 2003. [28] J. T.-Y. Wang. Is last minute bidding bad? UCLA Working Paper, 2003. [29] R. Zeithammer. An equilibrium model of a dynamic auction marketplace. Working Paper, University of Chicago, 2005. 89
Networks Preserving Evolutionary Equilibria and the Power of Randomization Michael Kearns mkearns@cis.upenn.edu Siddharth Suri ssuri@cis.upenn.edu Department of Computer and Information Science University of Pennsylvania Philadelphia, PA 19104 ABSTRACT We study a natural extension of classical evolutionary game theory to a setting in which pairwise interactions are  restricted to the edges of an undirected graph or network. We generalize the definition of an evolutionary stable strategy (ESS), and show a pair of complementary results that  exhibit the power of randomization in our setting: subject to degree or edge density conditions, the classical ESS of any game are preserved when the graph is chosen randomly and the mutation set is chosen adversarially, or when the graph is chosen adversarially and the mutation set is chosen randomly. We examine natural strengthenings of our  generalized ESS definition, and show that similarly strong results are not possible for them. Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics General Terms Economics, Theory . INTRODUCTION In this paper, we introduce and examine a natural  extension of classical evolutionary game theory (EGT) to a setting in which pairwise interactions are restricted to the edges of an undirected graph or network. This extension generalizes the classical setting, in which all pairs of organisms in an infinite population are equally likely to interact. The  classical setting can be viewed as the special case in which the underlying network is a clique. There are many obvious reasons why one would like to examine more general graphs, the primary one being in that many scenarios considered in evolutionary game theory, all interactions are in fact not possible. For example,  geographical restrictions may limit interactions to physically  proximate pairs of organisms. More generally, as evolutionary game theory has become a plausible model not only for  biological interaction, but also economic and other kinds of  interaction in which certain dynamics are more imitative than optimizing (see [2, 16] and chapter 4 of [19]), the network constraints may come from similarly more general sources. Evolutionary game theory on networks has been considered before, but not in the generality we will do so here (see Section 4). We generalize the definition of an evolutionary stable  strategy (ESS) to networks, and show a pair of complementary results that exhibit the power of randomization in our  setting: subject to degree or edge density conditions, the  classical ESS of any game are preserved when the graph is  chosen randomly and the mutation set is chosen adversarially, or when the graph is chosen adversarially and the mutation set is chosen randomly. We examine natural strengthenings of our generalized ESS definition, and show that similarly strong results are not possible for them. The work described here is part of recent efforts  examining the relationship between graph topology or structure and properties of equilibrium outcomes. Previous works in this line include studies of the relationship of topology to properties of correlated equilibria in graphical games [11], and studies of price variation in graph-theoretic market  exchange models [12]. More generally, this work contributes to the line of graph-theoretic models for game theory  investigated in both computer science [13] and economics [10]. . CLASSICAL EGT The fundamental concept of evolutionary game theory is the evolutionarily stable strategy (ESS). Intuitively, an ESS is a strategy such that if all the members of a population adopt it, then no mutant strategy could invade the  population [17]. To make this more precise, we describe the basic model of evolutionary game theory, in which the notion of an ESS resides. The standard model of evolutionary game theory  considers an infinite population of organisms, each of which plays a strategy in a fixed, 2-player, symmetric game. The game is defined by a fitness function F. All pairs of members of the infinite population are equally likely to interact with one another. If two organisms interact, one playing strategy s 00 and the other playing strategy t, the s-player earns a fitness of F(s|t) while the t-player earns a fitness of F(t|s). In this infinite population of organisms, suppose there is a  − fraction who play strategy s, and call these organisms incumbents; and suppose there is an fraction who play t, and call these organisms mutants. Assume two organisms are chosen uniformly at random to play each other. The strategy s is an ESS if the expected fitness of an  organism playing s is higher than that of an organism playing t, for all t = s and all sufficiently small . Since an  incumbent will meet another incumbent with probability 1 − and it will meet a mutant with probability , we can  calculate the expected fitness of an incumbent, which is simply (1 − )F(s|s) + F(s|t). Similarly, the expected fitness of a mutant is (1 − )F(t|s) + F(t|t). Thus we come to the formal definition of an ESS [19]. Definition 2.1. A strategy s is an evolutionarily stable strategy (ESS) for the 2-player, symmetric game given by fitness function F, if for every strategy t = s, there exists an t such that for all 0 < < t, (1 − )F(s|s) + F(s|t) > (1 − )F(t|s) + F(t|t). A consequence of this definition is that for s to be an ESS, it must be the case that F(s|s) ≥ F(t|s), for all strategies t. This inequality means that s must be a best response to itself, and thus any ESS strategy s must also be a Nash equilibrium. In general the notion of ESS is more  restrictive than Nash equilibrium, and not all 2-player, symmetric games have an ESS. In this paper our interest is to examine what kinds of  network structure preserve the ESS strategies for those games that do have a standard ESS. First we must of course  generalize the definition of ESS to a network setting. . EGT ON GRAPHS In our setting, we will no longer assume that two  organisms are chosen uniformly at random to interact. Instead, we assume that organisms interact only with those in their local neighborhood, as defined by an undirected graph or network. As in the classical setting (which can be viewed as the special case of the complete network or clique), we shall assume an infinite population, by which we mean we examine limiting behavior in a family of graphs of increasing size. Before giving formal definitions, some comments are in order on what to expect in moving from the classical to the graph-theoretic setting. In the classical (complete graph) setting, there exist many symmetries that may be broken in moving to the the network setting, at both the group and individual level. Indeed, such asymmetries are the primary interest in examining a graph-theoretic generalization. For example, at the group level, in the standard ESS  definition, one need not discuss any particular set of mutants of population fraction . Since all organisms are equally likely to interact, the survival or fate of any specific mutant set is identical to that of any other. In the network setting, this may not be true: some mutant sets may be better able to survive than others due to the specific topologies of their  interactions in the network. For instance, foreshadowing some of our analysis, if s is an ESS but F(t|t) is much larger than F(s|s) and F(s|t), a mutant set with a great deal of  internal interaction (that is, edges between mutants) may be able to survive, whereas one without this may suffer. At the level of individuals, in the classical setting, the assertion that one mutant dies implies that all mutants die, again by symmetry. In the network setting, individual fates may  differ within a group all playing a common strategy. These observations imply that in examining ESS on networks we face definitional choices that were obscured in the classical model. If G is a graph representing the allowed pairwise  interactions between organisms (vertices), and u is a vertex of G playing strategy su, then the fitness of u is given by F(u) = P v∈Γ(u) F(su|sv) |Γ(u)| . Here sv is the strategy being played by the neighbor v, and Γ(u) = {v ∈ V : (u, v) ∈ E}. One can view the fitness of u as the average fitness u would obtain if it played each if its neighbors, or the expected fitness u would obtain if it were assigned to play one of its neighbors chosen uniformly at random. Classical evolutionary game theory examines an infinite, symmetric population. Graphs or networks are inherently  finite objects, and we are specifically interested in their  asymmetries, as discussed above. Thus all of our definitions shall revolve around an infinite family G = {Gn}∞ n=0 of finite graphs Gn over n vertices, but we shall examine asymptotic (large n) properties of such families. We first give a definition for a family of mutant vertex sets in such an infinite graph family to contract. Definition 3.1. Let G = {Gn}∞ n=0 be an infinite family of graphs, where Gn has n vertices. Let M = {Mn}∞ n=0 be any family of subsets of vertices of the Gn such that |Mn| ≥ n for some constant > 0. Suppose all the vertices of Mn play a common (mutant) strategy t, and suppose the remaining vertices in Gn play a common (incumbent)  strategy s. We say that Mn contracts if for sufficiently large n, for all but o(n) of the j ∈ Mn, j has an incumbent neighbor i such that F(j) < F(i). A reasonable alternative would be to ask that the  condition above hold for all mutants rather than all but o(n). Note also that we only require that a mutant have one  incumbent neighbor of higher fitness in order to die; one might considering requiring more. In Sections 6.1 and 6.2 we  consider these stronger conditions and demonstrate that our results can no longer hold. In order to properly define an ESS for an infinite family of finite graphs in a way that recovers the classical definition asymptotically in the case of the family of complete graphs, we first must give a definition that restricts attention to  families of mutant vertices that are smaller than some invasion threshold n, yet remain some constant fraction of the  population. This prevents invasions that survive merely by constituting a vanishing fraction of the population. Definition 3.2. Let > 0, and let G = {Gn}∞ n=0 be an infinite family of graphs, where Gn has n vertices. Let M = {Mn}∞ n=0 be any family of (mutant) vertices in Gn. We say that M is -linear if there exists an , > > 0, such that for all sufficiently large n, n > |Mn| > n. We can now give our definition for a strategy to be  evolutionarily stable when employed by organisms interacting with their neighborhood in a graph. 01 Definition 3.3. Let G = {Gn}∞ n=0 be an infinite family of graphs, where Gn has n vertices. Let F be any 2-player, symmetric game for which s is a strategy. We say that s is an ESS with respect to F and G if for all mutant strategies t = s, there exists an t > 0 such that for any t-linear family of mutant vertices M = {Mn}∞ n=0 all playing t, for n sufficiently large, Mn contracts. Thus, to violate the ESS property for G, one must witness a family of mutations M in which each Mn is an arbitrarily small but nonzero constant fraction of the population of Gn, but does not contract (i.e. every mutant set has a subset of linear size that survives all of its incumbent interactions). In Section A.1 we show that the definition given coincides with the classical one in the case where G is the family of complete graphs, in the limit of large n. We note that even in the classical model, small sets of mutants were allowed to have greater fitness than the incumbents, as long as the size of the set was o(n) [18]. In the definition above there are three parameters: the game F, the graph family G and the mutation family M. Our main results will hold for any 2-player, symmetric game F. We will also study two rather general settings for G and M: that in which G is a family of random graphs and M is arbitrary, and that in which G is nearly arbitrary and M is randomly chosen. In both cases, we will see that, subject to conditions on degree or edge density (essentially forcing  connectivity of G but not much more), for any 2-player,  symmetric game, the ESS of the classical settings, and only those strategies, are always preserved. Thus a common theme of these results is the power of randomization: as long as either the network itself is chosen randomly, or the mutation set is chosen randomly, classical ESS are preserved. . RELATED WORK There has been previous work that analyzes which  strategies are resilient to mutant invasions with respect to various types of graphs. What sets our work apart is that the model we consider encompasses a significantly more general class of games and graph topologies. We will briefly survey this  literature and point out the differences in the previous models and ours. In [8], [3], and [4], the authors consider specific families of graphs, such as cycles and lattices, where players play specific games, such as 2 × 2-games or k × k-coordination games. In these papers the authors specify a simple, local dynamic for players to improve their payoffs by changing strategies, and analyze what type of strategies will grow to dominate the population. The model we propose is more general than both of these, as it encompasses a larger class of graphs as well as a richer set of games. Also related to our work is that of [14], where the authors propose two models. The first assumes organisms interact according to a weighted, undirected graph. However, the fitness of each organism is simply assigned and does not  depend on the actions of each organism"s neighborhood. The second model has organisms arranged around a directed  cycle, where neighbors play a 2 × 2-game. With probability proportional to its fitness, an organism is chosen to  reproduce by placing a replica of itself in its neighbors position, thereby killing the neighbor. We consider more general games than the first model and more general graphs than the second. Finally, the works most closely related to ours are [7], [15], and [6]. The authors consider 2-action, coordination games played by players in a general undirected graph. In these three works, the authors specify a dynamic for a strategy to reproduce, and analyze properties of the graph that allow a strategy to overrun the population. Here again, one can see that our model is more general than these, as it allows for organisms to play any 2-player, symmetric game. . NETWORKS PRESERVING ESS We now proceed to state and prove two complementary results in the network ESS model defined in Section 3. First, we consider a setting where the graphs are generated via the Gn,p model of Erd˝os and R´enyi [5]. In this model, every pair of vertices are joined by an edge independently and with probability p (where p may depend on n). The mutant set, however, will be constructed adversarially (subject to the linear size constraint given by Definition 3.3). For these settings, we show that for any 2-player, symmetric game, s is a classical ESS of that game, if and only if s is an ESS for {Gn,p}∞ n=0, where p = Ω(1/nc ) and 0 ≤ c < 1, and any mutant family {Mn}∞ n=0, where each Mn has linear size. We note that under these settings, if we let c = 1 − γ for small γ > 0, the expected number of edges in Gn is n1+γ or larger - that is, just superlinear in the number of vertices and potentially far smaller than O(n2 ). It is easy to convince oneself that once the graphs have only a linear number of edges, we are flirting with disconnectedness, and there may simply be large mutant sets that can survive in isolation due to the lack of any incumbent interactions in certain games. Thus in some sense we examine the minimum plausible edge density. The second result is a kind of dual to the first, considering a setting where the graphs are chosen arbitrarily (subject to conditions) but the mutant sets are chosen randomly. It states that for any 2-player, symmetric game, s is a  classical ESS for that game, if and only if s is an ESS for any {Gn = (Vn, En)}∞ n=0 in which for all v ∈ Vn, deg(v) = Ω(nγ ) (for any constant γ > 0), and a family of mutant sets {Mn}∞ n=0, that is chosen randomly (that is, in which each  organism is labeled a mutant with constant probability > 0). Thus, in this setting we again find that classical ESS are  preserved subject to edge density restrictions. Since the degree assumption is somewhat strong, we also prove another result which only assumes that |En| ≥ n1+γ , and shows that there must exist at least 1 mutant with an incumbent neighbor of higher fitness (as opposed to showing that all but o(n)  mutants have an incumbent neighbor of higher fitness). As will be discussed, this rules out stationary mutant invasions. .1 Random Graphs, Adversarial Mutations Now we state and prove a theorem which shows that if s is a classical ESS, then s will be an ESS for random graphs, where a linear sized set of mutants is chosen by an adversary. Theorem 5.1. Let F be any 2-player, symmetric game, and suppose s is a classical ESS of F. Let the infinite graph family {Gn}∞ n=0 be drawn according to Gn,p, where p = Ω(1/nc ) and 0 ≤ c < 1. Then with probability 1, s is an ESS. The main idea of the proof is to divide mutants into 2 categories, those with normal fitness and those with  ab202 normal fitness. First, we show all but o(n) of the  population (incumbent or mutant) have an incumbent neighbor of normal fitness. This will imply that all but o(n) of the  mutants of normal fitness have an incumbent neighbor of higher fitness. The vehicle for proving this is Theorem 2.15 of [5], which gives an upper bound on the number of vertices not connected to a sufficiently large set. This theorem assumes that the size of this large set is known with equality, which necessitates the union bound argument below. Secondly, we show that there can be at most o(n) mutants with abnormal fitness. Since there are so few of them, even if none of them have an incumbent neighbor of higher fitness, s will still be an ESS with respect to F and G. Proof. (Sketch) Let t = s be the mutant strategy. Since s is a classical ESS, there exists an t such that (1− )F(s|s)+ F(s|t) > (1 − )F(t|s) + F(t|t), for all 0 < < t. Let M be any mutant family that is t-linear. Thus for any fixed value of n that is sufficiently large, there exists an such that |Mn| = n and t > > 0. Also, let In = Vn \ Mn and let I ⊆ In be the set of incumbents that have fitness in the range (1 ± τ)[(1 − )F(s|s) + F(s|t)] for some constant τ,  < τ < 1/6. Lemma 5.1 below shows (1 − )n ≥ |I | ≥ (1 − )n − 24 log n τ2p . Finally, let TI = {x ∈ V \ I : Γ(x) ∩ I = ∅}. (For the sake of clarity we suppress the subscript n on the sets I and T.) The union bound gives us Pr(|TI | ≥ δn) ≤ (1− )n X i=(1− )n− 24 log n τ2p Pr(|TI | ≥ δn and |I | = i) (1) Letting δ = n−γ for some γ > 0 gives δn = o(n). We will apply Theorem 2.15 of [5] to the summand on the right hand side of Equation 1. If we let γ = (1−c)/2, and combine this with the fact that 0 ≤ c < 1, all of the requirements of this theorem will be satisfied (details omitted). Now when we apply this theorem to Equation 1, we get Pr(|TI | ≥ δn) ≤ (1− )n X i=(1− )n− 24 log n τ2p exp „ −   Cδn « (2) = o(1) This is because equation 2 has only 24 log n τ2p terms, and Theorem 2.15 of [5] gives us that C ≥ (1 − )n1−c − 24 log n τ2 . Thus we have shown, with probability tending to 1 as n → ∞, at most o(n) individuals are not attached to an  incumbent which has fitness in the range (1 ± τ)[(1 − )F(s|s) + F(s|t)]. This implies that the number of mutants of  approximately normal fitness, not attached to an incumbent of approximately normal fitness, is also o(n). Now those mutants of approximately normal fitness that are attached to an incumbent of approximately normal  fitness have fitness in the range (1±τ)[(1− )F(t|s)+ F(t|t)]. The incumbents that they are attached to have fitness in the range (1±τ)[(1− )F(s|s)+ F(s|t)]. Since s is an ESS of F, we know (1− )F(s|s)+ F(s|t) > (1− )F(t|s)+ F(t|t), thus if we choose τ small enough, we can ensure that all but o(n) mutants of normal fitness have a neighboring incumbent of higher fitness. Finally by Lemma 5.1, we know there are at most o(n)  mutants of abnormal fitness. So even if all of them are more fit than their respective incumbent neighbors, we have shown all but o(n) of the mutants have an incumbent neighbor of higher fitness. We now state and prove the lemma used in the proof above. Lemma 5.1. For almost every graph Gn,p with (1 − )n incumbents, all but 24 log n δ2p incumbents have fitness in the range (1±δ)[(1− )F(s|s)+ F(s|t)], where p = Ω(1/nc ) and , δ and c are constants satisfying 0 < < 1, 0 < δ < 1/6,  ≤ c < 1. Similarly, under the same assumptions, all but 24 log n δ2p mutants have fitness in the range (1 ± δ)[(1 − )F(t|s) + F(t|t)]. Proof. We define the mutant degree of a vertex to be the number of mutant neighbors of that vertex, and  incumbent degree analogously. Observe that the only way for an incumbent to have fitness far from its expected value of (1− )F(s|s)+ F(s|t) is if it has a fraction of mutant  neighbors either much higher or much lower than . Theorem .14 of [5] gives us a bound on the number of such  incumbents. It states that the number of incumbents with mutant degree outside the range (1 ± δ)p|M| is at most 12 log n δ2p . By the same theorem, the number of incumbents with  incumbent degree outside the range (1 ± δ)p|I| is at most 12 log n δ2p . From the linearity of fitness as a function of the fraction of mutant or incumbent neighbors, one can show that for those incumbents with mutant and incumbent degree in the expected range, their fitness is within a constant factor of (1 − )F(s|s) + F(s|t), where that constant goes to 1 as n tends to infinity and δ tends to 0. The proof for the mutant case is analogous. We note that if in the statement of Theorem 5.1 we let c = 0, then p = 1. This, in turn, makes G = {Kn}∞ n=0, where Kn is a clique of n vertices. Then for any Kn all of the incumbents will have identical fitness and all of the mutants will have identical fitness. Furthermore, since s was an ESS for G, the incumbent fitness will be higher than the mutant fitness. Finally, one can show that as n → ∞, the incumbent fitness converges to (1 − )F(s|s) + F(s|t), and the mutant fitness converges to (1 − )F(t|s) + F(t|t). In other words, s must be a classical ESS, providing a converse to Theorem 5.1. We rigorously present this argument in Section A.1. .2 Adversarial Graphs, Random Mutations We now move on to our second main result. Here we show that if the graph family, rather than being chosen randomly, is arbitrary subject to a minimum degree requirement, and the mutation sets are randomly chosen, classical ESS are again preserved. A modified notion of ESS allows us to considerably weaken the degree requirement to a minimum edge density requirement. Theorem 5.2. Let G = {Gn = (Vn, En)}∞ n=0 be an  infinite family of graphs in which for all v ∈ Vn, deg(v) = Ω(nγ ) (for any constant γ > 0). Let F be any 2-player, symmetric game, and suppose s is a classical ESS of F. Let t be any mutant strategy, and let the mutant family M = {Mn}∞ n=0 be chosen randomly by labeling each vertex a mutant with  constant probability , where t > > 0. Then with probability , s is an ESS with respect to F, G and M. 03 Proof. Let t = s be the mutant strategy and let X be the event that every incumbent has fitness within the range (1 ± τ)[(1 − )F(s|s) + F(s|t)], for some constant τ > 0 to be specified later. Similarly, let Y be the event that every mutant has fitness within the range (1 ± τ)[(1 − )F(t|s) + F(t|t)]. Since Pr(X ∩ Y ) = 1 − Pr(¬X ∪ ¬Y ), we proceed by showing Pr(¬X ∪ ¬Y ) = o(1). ¬X is the event that there exists an incumbent with fitness outside the range (1±τ)[(1− )F(s|s)+ F(s|t)]. If degM (v) denotes the number of mutant neighbors of v, similarly, degI (v) denotes the number of incumbent neighbors of v, then an incumbent i has fitness degI (i) deg(i) F(s|s)+ degM (i) deg(i) F(s|t). Since F(s|s) and F(s|t) are fixed quantities, the only  variation in an incumbents fitness can come from variation in the terms degI (i) deg(i) and degM (i) deg(i) . One can use the Chernoff bound followed by the union bound to show that for any incumbent i, Pr(F(i) /∈ (1 ± τ)[(1 − )F(s|s) + F(s|t)]) < 4 exp „ − deg(i)τ2  « . Next one can use the union bound again to bound the  probability of the event ¬X, Pr(¬X) ≤ 4n exp „ − diτ2  « where di = mini∈V \M deg(i), 0 < ≤ 1/2. An analogous argument can be made to show Pr(¬Y ) < 4n exp(− dj τ2  ), where dj = minj∈M deg(j) and 0 < ≤ 1/2. Thus, by the union bound, Pr(¬X ∪ ¬Y ) < 8n exp „ − dτ2  « where d = minv∈V deg(v), 0 < ≤ 1/2. Since deg(v) = Ω(nγ ), for all v ∈ V , and , τ and γ are all constants greater than 0, lim n→∞ n exp ( dτ2/3) = 0, so Pr(¬X∪¬Y ) = o(1). Thus, we can choose τ small enough such that (1 + τ)[(1 − )F(t|s) + F(t|t)] < (1 − τ)[(1 − )F(s|s)+ F(s|t)], and then choose n large enough such that with probability 1 − o(1), every incumbent will have fitness in the range (1±τ)[(1− )F(s|s)+F(s|t)], and every mutant will have fitness in the range (1 ± τ)[(1 − )F(t|s) + F(t|t)]. So with high probability, every incumbent will have a higher fitness than every mutant. By arguments similar to those following the proof of  Theorem 5.1, if we let G = {Kn}∞ n=0, each incumbent will have the same fitness and each mutant will have the same fitness. Furthermore, since s is an ESS for G, the incumbent fitness must be higher than the mutant fitness. Here again, one has to show show that as n → ∞, the incumbent fitness converges to (1 − )F(s|s) + F(s|t), and the mutant fitness converges to (1 − )F(t|s) + F(t|t). Observe that the exact fraction mutants of Vn is now a random variable. So to prove this convergence we use an argument similar to one that is used to prove that sequence of random variables that  converges in probability also converges in distribution (details omitted). This in turn establishes that s must be a classical ESS, and we thus obtain a converse to Theorem 5.2. This argument is made rigorous in Section A.2. The assumption on the degree of each vertex of  Theorem 5.2 is rather strong. The following theorem relaxes this requirement and only necessitates that every graph have n1+γ edges, for some constant γ > 0, in which case it shows there will alway be at least 1 mutant with an incumbent neighbor of higher fitness. A strategy that is an ESS in this weakened sense will essentially rule out stable, static sets of mutant invasions, but not more complex invasions. An example of more complex invasions are mutant sets that survive, but only by perpetually migrating through the graph under some natural evolutionary dynamics, akin to gliders in the well-known Game of Life [1]. Theorem 5.3. Let F be any game, and let s be a classical ESS of F, and let t = s be a mutant strategy. For any graph family G = {Gn = (Vn, En)}∞ n=0 in which |En| ≥ n1+γ (for any constant γ > 0), and any mutant family M = {Mn}∞ n=0 which is determined by labeling each vertex a mutant with probability , where t > > 0, the probability that there exists a mutant with an incumbent neighbor of higher fitness approaches 1 as n → ∞. Proof. (Sketch) The main idea behind the proof is to show that with high probability, over only the choice of  mutants, there will be an incumbent-mutant edge in which both vertices have high degree. If their degree is high enough, we can show that close to an fraction of their neighbors are mutants, and thus their fitnesses are very close to what we expect them to be in the classical case. Since s is an ESS, the fitness of the incumbent will be higher than the mutant. We call an edge (i, j) ∈ En a g(n)-barbell if deg(i) ≥ g(n) and deg(j) ≥ g(n). Suppose Gn has at most h(n) edges that are g(n)-barbells. This means there are at least |En| − h(n) edges in which at least one vertex has degree at most g(n). We call these vertices light vertices. Let (n) be the number of light vertices in Gn. Observe that |En|−h(n) ≤ (n)g(n). This is because each light vertex is incident on at most g(n) edges. This gives us that |En| ≤ h(n) + (n)g(n) ≤ h(n) + ng(n). So if we choose h(n) and g(n) such that h(n) + ng(n) = o(n1+γ ), then |En| = o(n1+γ ). This contradicts the  assumption that |En| = Ω(n1+γ ). Thus, subject to the above constraint on h(n) and g(n), Gn must contain at least h(n) edges that are g(n)-barbells. Now let Hn denote the subgraph induced by the barbell edges of Gn. Note that regardless of the structure of Gn, there is no reason that Hn should be connected. Thus, let m be the number of connected components of Hn, and let c1, c2, . . . , cm be the number of vertices in each of these  connected components. Note that since Hn is an edge-induced subgraph we have ck ≥ 2 for all components k. Let us choose the mutant set by first flipping the vertices in Hn only. We now show that the probability, with respect to the random mutant set, that none of the components of Hn have an incumbent-mutant edge is exponentially small in n. Let An be the event that every component of Hn contains only  mutants or only incumbents. Then algebraic manipulations can establish that Pr[An] = Πm k=1( ck + (1 − )ck ) ≤ (1 − )(1− β2  ) Pm k=1 ck 04 where β is a constant. Thus for sufficiently small the bound decreases exponentially with Pm k=1 ck. Furthermore, sincePm k=1 `ck  ´ ≥ h(n) (with equality achieved by making each component a clique), one can show that Pm k=1 ck ≥ p h(n). Thus, as long as h(n) → ∞ with n, the probability that all components are uniformly labeled will go to 0. Now assuming that there exists a non-uniformly labeled component, by construction that component contains an edge (i, j) where i is an incumbent and j is a mutant, that is a g(n)-barbell. We also assume that the h(n) vertices already labeled have been done so arbitrarily, but that the remaining g(n) − h(n) vertices neighboring i and j are  labeled mutants independently with probability . Then via a standard Chernoff bound argument, one can show that with high probability, the fraction of mutants neighboring i and the fraction of mutants neighboring j is in the range (1 ± τ)(g(n)−h(n)) g(n) . Similarly, one can show that the  fraction of incumbents neighboring i and the fraction of mutants neighboring j is in the range 1 − (1 ± τ)(g(n)−h(n)) g(n) . Since s is an ESS, there exists a ζ > 0 such that (1 − )F(s|s) + F(s|t) = (1 − )F(t|s) + F(t|t) + ζ. If we choose g(n) = nγ , and h(n) = o(g(n)), we can choose n large enough and τ small enough to force F(i) > F(j), as desired. . LIMITATIONS OF STRONGER MODELS In this section we show that if one tried to strengthen the model described in Section 3 in two natural ways, one would not be able to prove results as strong as Theorems 5.1 and 5.2, which hold for every 2-player, symmetric game. .1 Stronger Contraction for the Mutant Set In Section 3 we alluded to the fact that we made certain design decisions in arriving at Definitions 3.1, 3.2 and 3.3. One such decision was to require that all but o(n) mutants have incumbent neighbors of higher fitness. Instead, we could have required that all mutants have an incumbent neighbor of higher fitness. The two theorems in this  subsection show that if one were to strengthen our notion of contraction for the mutant set, given by Definition 3.1, in this way, it would be impossible to prove theorems analogous to Theorems 5.1 and 5.3. Recall that Definition 3.1 gave the notion of contraction for a linear sized subset of mutants. In what follows, we will say an edge (i, j) contracts if i is an incumbent, j is a mutant, and F(i) > F(j). Also, recall that Theorem 5.1 stated that if s is a classical ESS, then it is an ESS for random graphs with adversarial mutations. Next, we prove that if we instead required every incumbent-mutant edge to contract, this need not be the case. Theorem 6.1. Let F be a 2-player, symmetric game that has a classical ESS s for which there exists a mutant  strategy t = s with F(t|t) > F(s|s) and F(t|t) > F(s|t). Let G = {Gn}∞ n=0 be an infinite family of random graphs drawn according to Gn,p, where p = Ω(1/nc ) for any constant  ≤ c < 1. Then with probability approaching 1 as n → ∞, there exists a mutant family M = {Mn}∞ n=0, where tn > |Mn| > n and t, > 0, in which there is an edge that does not contract. Proof. (Sketch) With probability approaching 1 as n → ∞, there exists a vertex j where deg(j) is arbitrarily close to n. So label j mutant, label one of its neighbors  incumbent, denoted i, and label the rest of j"s neighborhood mutant. Also, label all of i"s neighbors incumbent, with the exception of j and j"s neighbors (which were already labeled mutant). In this setting, one can show that F(j) will be arbitrarily close to F(t|t) and F(i) will be a convex combination of F(s|s) and F(s|t), which are both strictly less than F(t|t). Theorem 5.3 stated that if s is a classical ESS, then for graphs where |En| ≥ n1+γ , for some γ > 0, and where each organism is labeled a mutant with probability , one edge must contract. Below we show that, for certain graphs and certain games, there will always exist one edge that will not contract. Theorem 6.2. Let F be a 2-player, symmetric game that has a classical ESS s, such that there exists a mutant  strategy t = s where F(t|s) > F(s|t). There exists an infinite family of graphs {Gn = (Vn, En)}∞ n=0, where |En| = Θ(n2 ), such that for a mutant family M = {Mn}∞ n=0, which is  determined by labeling each vertex a mutant with probability > 0, the probability there exists an edge in En that does not contract approaches 1 as n → ∞. Proof. (Sketch) Construct Gn as follows. Pick n/4  vertices u1, u2, . . . , un/4 and add edges such that they from a clique. Then, for each ui, i ∈ [n/4] add edges (ui, vi), (vi, wi) and (wi, xi). With probability 1 as n → ∞, there exists an i such that ui and wi are mutants and vi and xi are incumbents. Observe that F(vi) = F(xi) = F(s|t) and F(wi) = F(t|s). .2 Stronger Contraction for Individuals The model of Section 3 requires that for an edge (i, j) to contract, the fitness of i must be greater than the fitness of j. One way to strengthen this notion of contraction would be to require that the maximum fitness incumbent in the  neighborhood of j be more fit than the maximum fitness mutant in the neighborhood of j. This models the idea that each organism is trying to take over each place in its  neighborhood, but only the most fit organism in the neighborhood of a vertex gets the privilege of taking it. If we assume that we adopt this notion of contraction for individual mutants, and require that all incumbent-mutant edges contract, we will next show that Theorems 6.1 and 6.2 still hold, and thus it is still impossible to get results such as Theorems 5.1 and 5.3 which hold for every 2-player, symmetric game. In the proof of Theorem 6.1 we proved that F(i) is strictly less than F(j). Observe that maximum fitness mutant in the neighborhood of j must have fitness at least F(j). Also observe that there is only 1 incumbent in the neighborhood of j, namely i. So under this stronger notion of contraction, the edge (i, j) will not contract. Similarly, in the proof of Theorem 6.2, observe that the only mutant in the neighborhood of wi is wi itself, which has fitness F(t|s). Furthermore, the only incumbents in the neighborhood of wi are vi and xi, both of which have fitness F(s|t). By assumption, F(t|s) > F(s|t), thus, under this stronger notion of contraction, neither of the  incumbentmutant edges, (vi, wi) and (xi, wi), will contract. . REFERENCES [1] Elwyn R. Berlekamp, John Horton Conway, and Richard K. Guy. Winning Ways for Your 05 Mathematical Plays, volume 4. AK Peters, Ltd, March 004. [2] Jonas Bj¨ornerstedt and Karl H. Schlag. On the evolution of imitative behavior. Discussion Paper B-378, University of Bonn, 1996. [3] L. E. Blume. The statistical mechanics of strategic interaction. Games and Economic Behavior, :387-424, 1993. [4] L. E. Blume. The statistical mechanics of best-response strategy revision. Games and Economic Behavior, 11(2):111-145, November 1995. [5] B. Bollob´as. Random Graphs. Cambridge University Press, 2001. [6] Michael Suk-Young Chwe. Communication and coordination in social networks. Review of Economic Studies, 67:1-16, 2000. [7] Glenn Ellison. Learning, local interaction, and coordination. Econometrica, 61(5):1047-1071, Sept. 993. [8] I. Eshel, L. Samuelson, and A. Shaked. Altruists, egoists, and hooligans in a local interaction model. The American Economic Review, 88(1), 1998. [9] Geoffrey R. Grimmett and David R. Stirzaker. Probability and Random Processes. Oxford University Press, 3rd edition, 2001. [10] M. Jackson. A survey of models of network formation: Stability and efficiency. In Group Formation in Economics; Networks, Clubs and Coalitions. Cambridge University Press, 2004. [11] S. Kakade, M. Kearns, J. Langford, and L. Ortiz. Correlated equilibria in graphical games. ACM Conference on Electronic Commerce, 2003. [12] S. Kakade, M. Kearns, L. Ortiz, R. Pemantle, and S. Suri. Economic properties of social networks. Neural Information Processing Systems, 2004. [13] M. Kearns, M. Littman, and S. Singh. Graphical models for game theory. Conference on Uncertainty in Artificial Intelligence, pages 253-260, 2001. [14] E. Lieberman, C. Hauert, and M. A. Nowak. Evolutionary dynamics on graphs. Nature, 33:312-316, 2005. [15] S. Morris. Contagion. Review of Economic Studies, 7(1):57-78, 2000. [16] Karl H. Schlag. Why imitate and if so, how? Journal of Economic Theory, 78:130-156, 1998. [17] J. M. Smith. Evolution and the Theory of Games. Cambridge University Press, 1982. [18] William L. Vickery. How to cheat against a simple mixed strategy ESS. Journal of Theoretical Biology, 27:133-139, 1987. [19] J¨orgen W. Weibull. Evolutionary Game Theory. The MIT Press, 1995. APPENDIX A. GRAPHICAL AND CLASSICAL ESS In this section we explore the conditions under which a graphical ESS is also a classical ESS. To do so, we state and prove two theorems which provide converses to each of the major theorems in Section 3. A.1 Random Graphs, Adversarial Mutations Theorem 5.2 states that if s is a classical ESS and G = {Gn,p}, where p = Ω(1/nc ) and 0 ≤ c < 1, then with  probability 1 as n → ∞, s is an ESS with respect to G. Here we show that if s is an ESS with respect to G, then s is a  classical ESS. In order to prove this theorem, we do not need the full generality of s being an ESS for G when p = Ω(1/nc ) where 0 ≤ c < 1. All we need is s to be an ESS for G when p = 1. In this case there are no more probabilistic events in the theorem statement. Also, since p = 1 each graph in G is a clique, so if one incumbent has a higher fitness than one mutant, then all incumbents have higher fitness than all mutants. This gives rise to the following theorem. Theorem A.1. Let F be any 2-player, symmetric game, and suppose s is a strategy for F and t = s is a mutant strategy. Let G = {Kn}∞ n=0. If, as n → ∞, for any t-linear family of mutants M = {Mn}∞ n=0, there exists an incumbent i and a mutant j such that F(i) > F(j), then s is a classical ESS of F. The proof of this theorem analyzes the limiting behavior of the mutant population as the size of the cliques in G tends to infinity. It also shows how the definition of ESS given in Section 5 recovers the classical definition of ESS. Proof. Since each graph in G is a clique, every  incumbent will have the same number of incumbent and mutant neighbors, and every mutant will have the same number of incumbent and mutant neighbors. Thus, all incumbents will have identical fitness and all mutants will have identical  fitness. Next, one can construct an t-linear mutant family M, where the fraction of mutants converges to for any , where t > > 0. So for n large enough, the number of mutants in Kn will be arbitrarily close to n. Thus, any mutant subset of size n will result in all incumbents having fitness (1 − n n−1 )F(s|s) + n n−1 F(s|t), and all mutants  having fitness (1 − n−1 n−1 )F(t|s) + n−1 n−1 F(t|t). Furthermore, by assumption the incumbent fitness must be higher than the mutant fitness. This implies, lim n→∞ „ (1 − n n − 1 )F(s|s) + n n − 1 F(s|t) > (1 − n − 1 n − 1 )F(t|s) + n − 1 n − 1 F(t|t) « = 1. This implies, (1− )F(s|s)+ F(s|t) > (1− )F(t|s)+ F(t|t), for all , where t > > 0. A.2 Adversarial Graphs, Random Mutations Theorem 5.2 states that if s is a classical ESS for a  player, symmetric game F, where G is chosen adversarially subject to the constraint that the degree of each vertex is Ω(nγ ) (for any constant γ > 0), and mutants are chosen with probability , then s is an ESS with respect to F, G, and M. Here we show that if s is an ESS with respect to F, G, and M then s is a classical ESS. All we will need to prove this is that s is an ESS with  respect to G = {Kn}∞ n=0, that is when each vertex has degree n − 1. As in Theorem A.1, since the graphs are cliques, if one incumbent has higher fitness than one mutant, then all incumbents have higher fitness than all mutants. Thus, the theorem below is also a converse to Theorem 5.3. (Recall that Theorem 5.3 uses a weaker notion of contraction that 06 requires only one incumbent to have higher fitness than one mutant.) Theorem A.2. Let F be any 2-player symmetric game, and suppose s is an incumbent strategy for F and t = s is a mutant strategy. Let G = {Kn}∞ n=0. If with  probability 1 as n → ∞, s is an ESS for G and a mutant family M = {Mn}∞ n=0, which is determined by labeling each vertex a mutant with probability , where t > > 0, then s is a classical ESS of F. This proof also analyzes the limiting behavior of the  mutant population as the size of the cliques in G tends to  infinity. Since the mutants are chosen randomly we will use an argument similar to the proof that a sequence of random variables that converges in probability, also converge in  distribution. In this case the sequence of random variables will be actual fraction of mutants in each Kn. Proof. Fix any value of , where n > > 0, and  construct each Mn by labeling a vertex a mutant with  probability . By the same argument as in the proof of Theorem A.1, if the actual number of mutants in Kn is denoted by nn, any mutant subset of size nn will result in all incumbents having fitness (1 − nn n−1 )F(s|s) + nn n−1 F(s|t), and in all  mutants having fitness (1 − nn−1 n−1 )F(t|s) + nn−1 n−1 F(t|t). This implies lim n→∞ Pr(s is an ESS for Gn w.r.t. nn mutants) = 1 ⇒ lim n→∞ Pr „ (1 − nn n − 1 )F(s|s) + nn n − 1 F(s|t) > (1 − nn − 1 n − 1 )F(t|s) + nn − 1 n − 1 F(t|t) « = 1 ⇔ lim n→∞ Pr „ n > F(t|s) − F(s|s) F(s|t) − F(s|s) − F(t|t) + F(t|s) + F(s|s) − F(t|t) n « = 1 (3) By two simple applications of the Chernoff bound and an application of the union bound, one can show the sequence of random variables { n}∞ n=0 converges to in probability. Next, if we let Xn = − n, X = − , b = −F(s|s) + F(t|t), and a = − F (t|s)−F (s|s) F (s|t)−F (s|s)−F (t|t)+F (t|s) , by Theorem A.3  below, we get that limn→∞ Pr(Xn < a + b/n) = Pr(X < a). Combining this with equation 3, Pr( > −a) = 1. The proof of the following theorem is very similar to the proof that a sequence of random variables that converges in probability, also converge in distribution. A good  explanation of this can be found in [9], which is the basis for the argument below. Theorem A.3. If {Xn}∞ n=0 is a sequence of random  variables that converge in probability to the random variable X, and a and b are constants, then limn→∞ Pr(Xn < a+b/n) = Pr(X < a). Proof. By Lemma A.1 (see below) we have the following two inequalities, Pr(X < a + b/n − τ) ≤ Pr(Xn < a + b/n) + Pr(|X − Xn| > τ), Pr(Xn < a + b/n) ≤ Pr(X < a + b/n + τ) + Pr(|X − Xn| > τ). Combining these gives, Pr(X < a + b/n − τ) − Pr(|X − Xn| > τ) ≤ Pr(Xn < a + b/n) ≤ Pr(X < a + b/n + τ) + Pr(|X − Xn| > τ). There exists an n0 such that for all n > n0, |b/n| < τ, so the following statement holds for all n > n0. Pr(X < a − 2τ) − Pr(|X − Xn| > τ) ≤ Pr(Xn < a + b/n) ≤ Pr(X < a + 2τ) + Pr(|X − Xn| > τ). Take the limn→∞ of both sides of both inequalities, and since Xn converges in probability to X, Pr(X < a − 2τ) ≤ lim n→∞ Pr(Xn < a + b/n) (4) ≤ Pr(X < a + 2τ). (5) Recall that X is a continuous random variable representing the fraction of mutants in an infinite sized graph. So if we let FX (a) = Pr(X < a), we see that FX (a) is a cumulative distribution function of a continuous random variable, and is therefore continuous from the right. So lim τ↓0 FX (a − τ) = lim τ↓0 FX (a + τ) = FX (a). Thus if we take the limτ↓0 of inequalities 4 and 5 we get Pr(X < a) = lim n→∞ Pr(Xn < a + b/n). The following lemma is quite useful, as it expresses the cumulative distribution of one random variable Y , in terms of the cumulative distribution of another random variable X and the difference between X and Y . Lemma A.1. If X and Y are random variables, c ∈ and τ > 0, then Pr(Y < c) ≤ Pr(X < c + τ) + Pr(|Y − X| > τ). Proof. Pr(Y < c) = Pr(Y < c, X < c + τ) + Pr(Y < c, X ≥ c + τ) ≤ Pr(Y < c | X < c + τ) Pr(X < c + τ) + Pr(|Y − X| > τ) ≤ Pr(X < c + τ) + Pr(|Y − X| > τ) 07
An Analysis of Alternative Slot Auction Designs for Sponsored Search S´ebastien Lahaie ∗ Division of Engineering and Applied Sciences Harvard University, Cambridge, MA 02138 slahaie@eecs.harvard.edu ABSTRACT Billions of dollars are spent each year on sponsored search, a form of advertising where merchants pay for placement alongside web search results. Slots for ad listings are  allocated via an auction-style mechanism where the higher a merchant bids, the more likely his ad is to appear above other ads on the page. In this paper we analyze the  incentive, efficiency, and revenue properties of two slot  auction designs: rank by bid (RBB) and rank by revenue (RBR), which correspond to stylized versions of the  mechanisms currently used by Yahoo! and Google, respectively. We also consider first- and second-price payment rules  together with each of these allocation rules, as both have been used historically. We consider both the short-run  incomplete information setting and the long-run complete  information setting. With incomplete information, neither RBB nor RBR are truthful with either first or second pricing. We find that the informational requirements of RBB are much weaker than those of RBR, but that RBR is efficient whereas RBB is not. We also show that no revenue ranking of RBB and RBR is possible given an arbitrary distribution over bidder values and relevance. With complete information, we find that no equilibrium exists with first pricing using either RBB or RBR. We show that there typically exists a multitude of equilibria with second pricing, and we bound the divergence of (economic) value in such equilibria from the value obtained assuming all merchants bid truthfully. Categories and Subject Descriptors J.4 [Computer Applications]: Social and Behavioral  Sciences-Economics General Terms Economics, Theory . INTRODUCTION Today, Internet giants Google and Yahoo! boast a  combined market capitalization of over $150 billion, largely on the strength of sponsored search, the fastest growing  component of a resurgent online advertising industry.  PricewaterhouseCoopers estimates that 2004 industry-wide sponsored search revenues were $3.9 billion, or 40% of total  Internet advertising revenues.1 Industry watchers expect 2005 revenues to reach or exceed $7 billion.2 Roughly 80% of Google"s estimated $4 billion in 2005 revenue and roughly 5% of Yahoo!"s estimated $3.7 billion in 2005 revenue will likely be attributable to sponsored search.3 A number of other companies-including LookSmart, FindWhat,  InterActiveCorp (Ask Jeeves), and eBay (Shopping.com)-earn hundreds of millions of dollars of sponsored search revenue annually. Sponsored search is a form of advertising where merchants pay to appear alongside web search results. For example, when a user searches for used honda accord san diego in a web search engine, a variety of commercial entities (San Diego car dealers, Honda Corp, automobile information  portals, classified ad aggregators, eBay, etc...) may bid to to have their listings featured alongside the standard  algorithmic search listings. Advertisers bid for placement on the page in an auction-style format where the higher they bid the more likely their listing will appear above other ads on the page. By convention, sponsored search advertisers  generally pay per click, meaning that they pay only when a user clicks on their ad, and do not pay if their ad is displayed but not clicked. Though many people claim to systematically  ignore sponsored search ads, Majestic Research reports that  www.iab.net/resources/adrevenue/pdf/IAB PwC 2004full.pdf  battellemedia.com/archives/002032.php  These are rough back of the envelope estimates. Google and Yahoo! 2005 revenue estimates were obtained from  Yahoo! Finance. We assumed $7 billion in 2005 industry-wide sponsored search revenues. We used Nielsen/NetRatings  estimates of search engine market share in the US, the most monetized market: wired-vig.wired.com/news/technology/0,1282,69291,00.html Using comScore"s international search engine market share estimates would yield different estimates: www.comscore.com/press/release.asp?press=622 18 as many as 17% of Google searches result in a paid click, and that Google earns roughly nine cents on average for every search query they process.4 Usually, sponsored search results appear in a separate  section of the page designated as sponsored above or to the right of the algorithmic results. Sponsored search results are displayed in a format similar to algorithmic results: as a list of items each containing a title, a text description, and a hyperlink to a corresponding web page. We call each position in the list a slot. Generally, advertisements that appear in a higher ranked slot (higher on the page) garner more attention and more clicks from users. Thus, all else being equal, merchants generally prefer higher ranked slots to lower ranked slots. Merchants bid for placement next to particular search queries; for example, Orbitz and Travelocity may bid for las vegas hotel while Dell and HP bid for laptop  computer. As mentioned, bids are expressed as a maximum willingness to pay per click. For example, a forty-cent bid by HostRocket for web hosting means HostRocket is  willing to pay up to forty cents every time a user clicks on their ad.5 The auctioneer (the search engine6 ) evaluates the bids and allocates slots to advertisers. In principle, the  allocation decision can be altered with each new incoming search query, so in effect new auctions clear continuously over time as search queries arrive. Many allocation rules are plausible. In this paper, we  investigate two allocation rules, roughly corresponding to the two allocation rules used by Yahoo! and Google. The rank by bid (RBB) allocation assigns slots in order of bids, with higher ranked slots going to higher bidders. The rank by revenue (RBR) allocation assigns slots in order of the  product of bid times expected relevance, where relevance is the proportion of users that click on the merchant"s ad after viewing it. In our model, we assume that an ad"s expected relevance is known to the auctioneer and the advertiser (but not necessarily to other advertisers), and that clickthrough rate decays monotonically with lower ranked slots. In  practice, the expected clickthrough rate depends on a number of factors, including the position on the page, the ad text (which in turn depends on the identity of the bidder), the nature and intent of the user, and the context of other ads and algorithmic results on the page, and must be learned over time by both the auctioneer and the bidder [13]. As of this writing, to a rough first-order approximation, Yahoo! employs a RBB allocation and Google employs a RBR  allocation, though numerous caveats apply in both cases when it comes to the vagaries of real-world implementations.7 Even when examining a one-shot version of a slot  auction, the mechanism differs from a standard multi-item  auc4 battellemedia.com/archives/001102.php  Usually advertisers also set daily or monthly budget caps; in this paper we do not model budget constraints.  In the sponsored search industry, the auctioneer and search engine are not always the same entity. For example Google runs the sponsored search ads for AOL web search, with revenue being shared. Similarly, Yahoo! currently runs the sponsored search ads for MSN web search, though Microsoft will begin independent operations soon.  Here are two among many exceptions to the Yahoo! = RBB and Google = RBR assertion: (1) Yahoo! excludes ads deemed insufficiently relevant either by a human editor or due to poor historical click rate; (2) Google sets differing reserve prices depending on Google"s estimate of ad quality. tion in subtle ways. First, a single bid per merchant is used to allocate multiple non-identical slots. Second, the bid is communicated not as a direct preference over slots, but as a preference for clicks that depend stochastically on slot  allocation. We investigate a number of economic properties of RBB and RBR slot auctions. We consider the short-run  incomplete information case in Section 3, adapting and  extending standard analyses of single-item auctions. In Section 4 we turn to the long-run complete information case; our characterization results here draw on techniques from  linear programming. Throughout, important observations are highlighted as claims supported by examples. Our  contributions are as follows: • We show that with multiple slots, bidders do not reveal their true values with either RBB or RBR, and with either first- or second-pricing. • With incomplete information, we find that the  informational requirements of playing the equilibrium bid are much weaker for RBB than for RBR, because  bidders need not know any information about each others" relevance (or even their own) with RBB. • With incomplete information, we prove that RBR is efficient but that RBB is not. • We show via a simple example that no general revenue ranking of RBB and RBR is possible. • We prove that in a complete-information setting,  firstprice slot auctions have no pure strategy Nash  equilibrium, but that there always exists a pure-strategy equilibrium with second pricing. • We provide a constant-factor bound on the deviation from efficiency that can occur in the equilibrium of a second-price slot auction. In Section 2 we specify our model of bidders and the  various slot auction formats. In Section 3.1 we study the incentive properties of each format, asking in which cases agents would bid truthfully. There is possible confusion here because the second-price design for slot auctions is reminiscent of the Vickrey auction for a single item; we note that for slot auctions the Vickrey mechanism is in fact very different from the second-price mechanism, and so they have different incentive properties.8 In Section 3.2 we derive the Bayes-Nash equilibrium bids for the various auction formats. This is useful for the  efficiency and revenue results in later sections. It should  become clear in this section that slot auctions in our model are a straightforward generalization of single-item auctions. Sections 3.3 and 3.4 address questions of efficiency and  revenue under incomplete information, respectively. In Section 4.1 we determine whether pure-strategy  equilibria exist for the various auction formats, under complete information. In Section 4.2 we derive bounds on the  deviation from efficiency in the pure-strategy equilibria of  secondprice slot auctions. Our approach is positive rather than normative. We aim to clarify the incentive, efficiency, and revenue properties of two slot auction designs currently in use, under settings of  Other authors have also made this observation [5, 6]. 19 incomplete and complete information. We do not attempt to derive the optimal mechanism for a slot auction. Related work. Feng et al. [7] compare the revenue  performance of various ranking mechanisms for slot auctions in a model with incomplete information, much as we do in Section 3.4, but they obtain their results via simulations whereas we perform an equilibrium analysis. Liu and Chen [12] study properties of slot auctions under incomplete information. Their setting is essentially the same as ours, except they restrict their attention to a model with a single slot and a binary type for bidder relevance (high or low). They find that RBR is efficient, but that no general revenue ranking of RBB and RBR is possible, which agrees with our results. They also take a design approach and show how the auctioneer should assign relevance scores to optimize its revenue. Edelman et al. [6] model the slot auction problem both as a static game of complete information and a dynamic game of incomplete information. They study the locally  envyfree equilibria of the static game of complete information; this is a solution concept motivated by certain bidding  behaviors that arise due to the presence of budget constraints. They do not view slot auctions as static games of  incomplete information as we do, but do study them as dynamic games of incomplete information and derive results on the uniqueness and revenue properties of the resulting  equilibria. They also provide a nice description of the evolution of the market for sponsored search. Varian [18] also studies slot auctions under a setting of complete information. He focuses on symmetric  equilibria, which are a refinement of Nash equilibria appropriate for slot auctions. He provides bounds on the revenue obtained in equilibrium. He also gives bounds that can be used to infer bidder values given their bids, and performs some  empirical analysis using these results. In contrast, we focus instead on efficiency and provide bounds on the deviation from efficiency in complete-information equilibria. . PRELIMINARIES We focus on a slot auction for a single keyword. In a setting of incomplete information, a bidder knows only  distributions over others" private information (value per click and relevance). With complete information, a bidder knows others" private information, and so does not need to rely on distributions to strategize. We first describe the model for the case with incomplete information, and drop the  distributional information from the model when we come to the complete-information case in Section 4. .1 The Model There is a fixed number K of slots to be allocated among N bidders. We assume without loss of generality that K ≤ N, since superfluous slots can remain blank. Bidder i assigns a value of Xi to each click received on its advertisement, regardless of this advertisement"s rank.9 The probability that i"s advertisement will be clicked if viewed is Ai ∈ [0, 1]. We refer to Ai as bidder i"s relevance. We refer to Ri = AiXi as bidder i"s revenue. The Xi, Ai, and Ri are random  Indeed Kitts et al. [10] find that in their sample of actual click data, the correlation between rank and conversion rate is not statistically significant. However, for the purposes of our model it is also important that bidders believe that conversion rate does not vary with rank. variables and we denote their realizations by xi, αi, and ri respectively. The probability that an advertisement will be viewed if placed in slot j is γj ∈ [0, 1]. We assume γ1 > γ2 > . . . > γK. Hence bidder i"s advertisement will have a clickthrough rate of γjαi if placed in slot j. Of course, an advertisement does not receive any clicks if it is not allocated a slot. Each bidder"s value and relevance pair (Xi, Ai) is  independently and identically distributed on [0, ¯x] × [0, 1] according to a continuous density function f that has full support on its domain. The density f and slot probabilities γ1, . . . , γK are common knowledge. Only bidder i knows the  realization xi of its value per click Xi. Both bidder i and the seller know the realization αi of Ai, but this realization remains unobservable to the other bidders. We assume that bidders have quasi-linear utility  functions. That is, the expected utility to bidder i of obtaining the slot of rank j at a price of b per click is ui(j, b) = γjαi(xi − b) If the advertising firms bidding in the slot auction are  riskneutral and have ample liquidity, quasi-linearity is a  reasonable assumption. The assumptions of independence, symmetry, and  riskneutrality made above are all quite standard in single-item auction theory [11, 19]. The assumption that clickthrough rate decays monotonically with lower slots-by the same factors for each agent-is unique to the slot auction  problem. We view it as a main contribution of our work to show that this assumption allows for tractable analysis of the slot auction problem using standard tools from  singleitem auction theory. It also allows for interesting results in the complete information case. A common model of  decaying clickthrough rate is the exponential decay model, where γk = 1 δk−1 with decay δ > 1. Feng et al. [7] state that their actual clickthrough data is fitted extremely well by an exponential decay model with δ = 1.428. Our model lacks budget constraints, which are an  important feature of real slot auctions. With budget constraints keyword auctions cannot be considered independently of one another, because the budget must be allocated across  multiple keywords-a single advertiser typically bids on multiple keywords relevant to his business. Introducing this element into the model is an important next step for future work.10 .2 Auction Formats In a slot auction a bidder provides to the seller a declared value per click ˜xi(xi, αi) which depends on his true value and relevance. We often denote this declared value (bid) by ˜xi for short. Since a bidder"s relevance αi is observable to the seller, the bidder cannot misrepresent it. We denote the kth highest of the N declared values by ˜x(k) , and the kth highest of the N declared revenues by ˜r(k) , where the declared revenue of bidder i is ˜ri = αi ˜xi. We consider two types of allocation rules, rank by bid (RBB) and rank by revenue (RBR): 0 Models with budget constraints have begun to appear in this research area. Abrams [1] and Borgs et al. [3] design multi-unit auctions for budget-constrained bidders, which can be interpreted as slot auctions, with a focus on revenue optimization and truthfulness. Mehta et al. [14] address the problem of matching user queries to budget-constrained advertisers so as to maximize revenue. 20 RBB. Slot k goes to bidder i if and only if ˜xi = ˜x(k) . RBR. Slot k goes to bidder i if and only if ˜ri = ˜r(k) . We will commonly represent an allocation by a one-to-one function σ : [K] → [N], where [n] is the set of integers {1, 2, . . . , n}. Hence slot k goes to bidder σ(k). We also consider two different types of payment rules. Note that no matter what the payment rule, a bidder that is not allocated a slot will pay 0 since his listing cannot receive any clicks. First-price. The bidder allocated slot k, namely σ(k), pays ˜xσ(k) per click under both the RBB and RBR  allocation rules. Second-price. If k < N, bidder σ(k) pays ˜xσ(k+1) per click under the RBB rule, and pays ˜rσ(k+1)/ασ(k) per click under the RBR rule. If k = N, bidder σ(k) pays 0 per click.11 Intuitively, a second-price payment rule sets a bidder"s  payment to the lowest bid it could have declared while  maintaining the same ranking, given the allocation rule used. Overture introduced the first slot auction design in 1997, using a first-price RBB scheme. Google then followed in 000 with a second-price RBR scheme. In 2002, Overture (at this point acquired by Yahoo!) then switched to second pricing but still allocates using RBB. One possible reason for the switch is given in Section 4. We assume that ties are broken as follows in the event that two agents make the exact same bid or declare the same revenue. There is a permutation of the agents κ : [N] → [N] that is fixed beforehand. If the bids of agents i and j are tied, then agent i obtains a higher slot if and only if κ(i) < κ(j). This is consistent with the practice in real slot auctions where ties are broken by the bidders" order of arrival. . INCOMPLETE INFORMATION .1 Incentives It should be clear that with a first-price payment rule, truthful bidding is neither a dominant strategy nor an ex post Nash equilibrium using either RBB or RBR, because this guarantees a payoff of 0. There is always an incentive to shade true values with first pricing. The second-price payment rule is reminiscent of the  secondprice (Vickrey) auction used for selling a single item, and in a Vickrey auction it is a dominant strategy for a bidder to reveal his true value for the item [19]. However, using a second-price rule in a slot auction together with either  allocation rule above does not yield an incentive-compatible mechanism, either in dominant strategies or ex post Nash equilibrium.12 With a second-price rule there is no  incentive for a bidder to bid higher than his true value per click using either RBB or RBR: this either leads to no change 1 We are effectively assuming a reserve price of zero, but in practice search engines charge a non-zero reserve price per click. 2 Unless of course there is only a single slot available, since this is the single-item case. With a single slot both RBB and RBR with a second-price payment rule are  dominantstrategy incentive-compatible. in the outcome, or a situation in which he will have to pay more than his value per click for each click received,  resulting in a negative payoff.13 However, with either allocation rule there may be an incentive to shade true values with second pricing. Claim 1. With second pricing and K ≥ 2, truthful  bidding is not a dominant strategy nor an ex post Nash  equilibrium for either RBB or RBR. Example. There are two agents and two slots. The agents have relevance α1 = α2 = 1, whereas γ1 = 1 and γ2 = 1/2. Agent 1 has a value of x1 = 6 per click, and agent  has a value of x2 = 4 per click. Let us first consider the RBB rule. Suppose agent 2 bids truthfully. If agent 1 also bids truthfully, he wins the first slot and obtains a payoff of . However, if he shades his bid down below 4, he obtains the second slot at a cost of 0 per click yielding a payoff of . Since the agents have equal relevance, the exact same situation holds with the RBR rule. Hence truthful bidding is not a dominant strategy in either format, and neither is it an ex post Nash equilibrium. To find payments that make RBB and RBR  dominantstrategy incentive-compatible, we can apply Holmstrom"s lemma [9] (see also chapter 3 in Milgrom [15]). Under the restriction that a bidder with value 0 per click does not pay anything (even if he obtains a slot, which can occur if there are as many slots as bidders), this lemma implies that there is a unique payment rule that achieves dominant-strategy incentive compatibility for either allocation rule. For RBB, the bidder allocated slot k is charged per click KX i=k+1 (γi−1 − γi)˜x(i) + γK ˜x(K+1) (1) Note that if K = N, ˜x(K+1) = 0 since there is no K + 1th bidder. For RBR, the bidder allocated slot k is charged per click  ασ(k) KX i=k+1 (γi−1 − γi)˜r(i) + γK ˜r(K+1) ! (2) Using payment rule (2) and RBR, the auctioneer is aware of the true revenues of the bidders (since they reveal their values truthfully), and hence ranks them according to their true revenues. We show in Section 3.3 that this allocation is in fact efficient. Since the VCG mechanism is the unique mechanism that is efficient, truthful, and ensures bidders with value 0 pay nothing (by the Green-Laffont theorem [8]), the RBR rule and payment scheme (2) constitute exactly the VCG mechanism. In the VCG mechanism an agent pays the externality he imposes on others. To understand payment (2) in this sense, note that the first term is the added utility (due to an  increased clickthrough rate) agents in slots k + 1 to K would receive if they were all to move up a slot; the last term is the utility that the agent with the K +1st revenue would receive by obtaining the last slot as opposed to nothing. The  leading coefficient simply reduces the agent"s expected payment to a payment per click. 3 In a dynamic setting with second pricing, there may be an incentive to bid higher than one"s true value in order to  exhaust competitors" budgets. This phenomenon is commonly called bid jamming or antisocial bidding [4]. 21 .2 Equilibrium Analysis To understand the efficiency and revenue properties of the various auction formats, we must first understand which rankings of the bidders occur in equilibrium with different allocation and payment rule combinations. The following lemma essentially follows from the Monotonic Selection  Theorem by Milgrom and Shannon [16]. Lemma 1. In a RBB (RBR) auction with either a  firstor second-price payment rule, the symmetric Bayes-Nash equilibrium bid is strictly increasing with value ( revenue). As a consequence of this lemma, we find that RBB and RBR auctions allocate the slots greedily by the true values and revenues of the agents, respectively (whether using  firstor second-price payment rules). This will be relevant in Section 3.3 below. For a first-price payment rule, we can explicitly derive the symmetric Bayes-Nash equilibrium bid functions for RBB and RBR auctions. The purpose of this exercise is to lend qualitative insights into the parameters that influence an agent"s bidding, and to derive formulae for the expected revenue in RBB and RBR auctions in order to make a revenue ranking of these two allocation rules (in Section 3.4). Let G(y) be the expected resulting clickthrough rate, in a symmetric equilibrium of the RBB auction (with either payment rule), to a bidder with value y and relevance α = . Let H(y) be the analogous quantity for a bidder with revenue y and relevance 1 in a RBR auction. By Lemma 1, a bidder with value y will obtain slot k in a RBB auction if y is the kth highest of the true realized values. The same applies in a RBR auction when y is the kth highest of the true realized revenues. Let FX (y) be the distribution function for value, and let FR(y) be the distribution function for revenue. The probability that y is the kth highest out of N values is N − 1 k − 1 ! (1 − FX (y))k−1 FX (y)N−k whereas the probability that y is the kth highest out of N revenues is the same formula with FR replacing FX . Hence we have G(y) = KX k=1 γk N − 1 k − 1 ! (1 − FX (y))k−1 FX (y)N−k The H function is analogous to G with FR replacing FX . In the two propositions that follow, g and h are the  derivatives of G and H respectively. We omit the proof of the next proposition, because it is almost identical to the  derivation of the equilibrium bid in the single-item case (see  Krishna [11], Proposition 2.2). Proposition 1. The symmetric Bayes-Nash equilibrium strategies in a first-price RBB auction are given by ˜xB (x, α) =  G(x) Z x  y g(y)dy The first-price equilibrium above closely parallels the  firstprice equilibrium in the single-item model. With a single item g is the density of the second highest value among all N agent values, whereas in a slot auction it is a weighted combination of the densities for the second, third, etc.  highest values. Note that the symmetric Bayes-Nash equilibrium bid in a first-price RBB auction does not depend on a bidder"s relevance α. To see clearly why, note that a bidder chooses a bid b so as to maximize the objective αG(˜x−1 (b))(x − b) and here α is just a leading constant factor. So dropping it does not change the set of optimal solutions. Hence the equilibrium bid depends only on the value x and function G, and G in turn depends only on the marginal cumulative distribution of value FX . So really only the latter needs to be common knowledge to the bidders. On the other hand, we will now see that information about relevance is needed for bidders to play the equilibrium in the first-price RBR auction. So the informational requirements for a first-price RBB auction are much weaker than for a first-price RBR auction: in the RBB auction a bidder need not know his own relevance, and need not know any distributional information over others" relevance in order to play the equilibrium. Again we omit the next proposition"s proof since it is so similar to the one above. Proposition 2. The symmetric Bayes-Nash equilibrium strategies in a first-price RBR auction are given by ˜xR (x, α) =  αH(αx) Z αx  y h(y) dy Here it can be seen that the equilibrium bid is increasing with x, but not necessarily with α. This should not be much of a concern to the auctioneer, however, because in any case the declared revenue in equilibrium is always increasing in the true revenue. It would be interesting to obtain the equilibrium bids when using a second-price payment rule, but it appears that the resulting differential equations for this case do not have a neat analytical solution. Nonetheless, the same conclusions about the informational requirements of the RBB and RBR rules still hold, as can be seen simply by inspecting the  objective function associated with an agent"s bidding problem for the second-price case. .3 Efficiency A slot auction is efficient if in equilibrium the sum of the bidders" revenues from their allocated slots is maximized. Using symmetry as our equilibrium selection criterion, we find that the RBB auction is not efficient with either  payment rule. Claim 2. The RBB auction is not efficient with either first or second pricing. Example. There are two agents and one slot, with γ1 = . Agent 1 has a value of x1 = 6 per click and relevance α1 = 1/2. Agent 2 has a value of x2 = 4 per click and relevance α2 = 1. By Lemma 1, agents are ranked greedily by value. Hence agent 1 obtains the lone slot, for a total revenue of 3 to the agents. However, it is most efficient to allocate the slot to agent 2, for a total revenue of 4. Examples with more agents or more slots are simple to construct along the same lines. On the other hand, under our assumptions on how clickthrough rate decreases with lower rank, the RBR auction is efficient with either payment rule. 22 Theorem 1. The RBR auction is efficient with either first- or second-price payments rules. Proof. Since by Lemma 1 the agents" equilibrium bids are increasing functions of their revenues in the RBR  auction, slots are allocated greedily according to true revenues. Let σ be a non-greedy allocation. Then there are slots s, t with s < t and rσ(s) < rσ(t). We can switch the agents in slots s and t to obtain a new allocation, and the difference between the total revenue in this new allocation and the original allocation"s total revenue is ` γtrσ(s) + γsrσ(t) ´ − ` γsrσ(s) + γtrσ(t) ´ = (γs − γt) ` rσ(t) − rσ(s) ´ Both parenthesized terms above are positive. Hence the switch has increased the total revenue to the bidders. If we continue to perform such switches, we will eventually reach a greedy allocation of greater revenue than the initial  allocation. Since the initial allocation was arbitrary, it follows that a greedy allocation is always efficient, and hence the RBR auction"s allocation is efficient. Note that the assumption that clickthrough rate decays montonically by the same factors γ1, . . . , γK for all agents is crucial to this result. A greedy allocation scheme does not necessarily find an efficient solution if the clickthrough rates are monotonically decreasing in an independent fashion for each agent. .4 Revenue To obtain possible revenue rankings for the different  auction formats, we first note that when the allocation rule is fixed to RBB, then using either a first-price, second-price, or truthful payment rule leads to the same expected revenue in a symmetric, increasing Bayes-Nash equilibrium. Because a RBB auction ranks agents by their true values in  equilibrium for any of these payment rules (by Lemma 1), it follows that expected revenue is the same for all these  payment rules, following arguments that are virtually identical to those used to establish revenue equivalence in the  singleitem case (see e.g. Proposition 3.1 in Krishna [11]). The same holds for RBR auctions; however, the revenue ranking of the RBB and RBR allocation rules is still unclear.  Because of this revenue equivalence principle, we can choose whichever payment rule is most convenient for the purpose of making revenue comparisons. Using Propositions 1 and 2, it is a simple matter to  derive formulae for the expected revenue under both allocation rules. The payment of an agent in a RBB auction is mB (x, α) = αG(x)˜xV (x, α) The expected revenue is then N · E ˆ mV (X, A) ˜ , where the expectation is taken with respect to the joint density of value and relevance. The expected revenue formula for RBR  auctions is entirely analogous using ˜xR (x, α) and the H  function. With these in hand we can obtain revenue rankings for specific numbers of bidders and slots, and specific  distributions over values and relevance. Claim 3. For fixed K, N, and fixed γ1, . . . , γK, no  revenue ranking of RBB and RBR is possible for an arbitrary density f. Example. Assume there are 2 bidders, 2 slots, and that γ1 = 1, γ2 = 1/2. Assume that value-relevance pairs are uniformly distributed over [0, 1]× [0, 1]. For such a  distribution with a closed-form formula, it is most convenient to use the revenue formulae just derived. RBB dominates RBR in terms of revenue for these parameters. The formula for the expected revenue in a RBB auction yields 1/12, whereas for RBR auctions we have 7/108. Assume instead that with probability 1/2 an agent"s  valuerelevance pair is (1, 1/2), and that with probability 1/2 it is (1/2, 1). In this scenario it is more convenient to appeal to formulae (1) and (2). In a truthful auction the second agent will always pay 0. According to (1), in a truthful RBB auction the first agent makes an expected payment of E ˆ (γ1 − γ2)Aσ(1)Xσ(2) ˜ =   E ˆ Aσ(1) ˜ E ˆ Xσ(2) ˜ where we have used the fact that value and relevance are independently distributed for different agents. The expected relevance of the agent with the highest value is E ˆ Aσ(1) ˜ = /8. The expected second highest value is also E ˆ Xσ(2) ˜ = /8. The expected revenue for a RBB auction here is then 5/128. According to (2), in a truthful RBR auction the first agent makes an expected payment of E ˆ (γ1 − γ2)Rσ(2) ˜ =   E ˆ Rσ(2) ˜ In expectation the second highest revenue is E ˆ Rσ(2) ˜ = /2, so the expected revenue for a RBR auction is 1/4. Hence in this case the RBR auction yields higher expected revenue.1415 This example suggests the following conjecture: when value and relevance are either uncorrelated or positively  correlated, RBB dominates RBR in terms of revenue. When value and relevance are negatively correlated, RBR  dominates. . COMPLETE INFORMATION In typical slot auctions such as those run by Yahoo! and Google, bidders can adjust their bids up or down at any time. As B¨orgers et al. [2] and Edelman et al. [6] have noted, this can be viewed as a continuous-time process in which bidders learn each other"s bids. If the process  stabilizes the result can then be modeled as a Nash equilibrium in pure strategies of the static one-shot game of complete  information, since each bidder will be playing a best-response to the others" bids.16 This argument seems especially  appropriate for Yahoo!"s slot auction design where all bids are 4 To be entirely rigorous and consistent with our initial  assumptions, we should have constructed a continuous  probability density with full support over an appropriate domain. Taking the domain to be e.g. [0, 1] × [0, 1] and a continuous density with full support that is sufficiently concentrated around (1, 1/2) and (1/2, 1), with roughly equal mass around both, would yield the same conclusion. 5 Claim 3 should serve as a word of caution, because Feng et al. [7] find through their simulations that with a  bivariate normal distribution over value-relevance pairs, and with  slots, 15 bidders, and δ = 2, RBR dominates RBB in terms of revenue for any level of correlation between value and relevance. However, they assume that bidding behavior in a second-price slot auction can be well approximated by truthful bidding. 6 We do not claim that bidders will actually learn each  others" private information (value and relevance), just that for a stable set of bids there is a corresponding equilibrium of the complete information game. 23 made public. Google keeps bids private, but  experimentation can allow one to discover other bids, especially since second pricing automatically reveals to an agent the bid of the agent ranked directly below him. .1 Equilibrium Analysis In this section we ask whether a pure-strategy Nash  equilibrium exists in a RBB or RBR slot auction, with either first or second pricing. Before dealing with the first-price case there is a technical issue involving ties. In our model we allow bids to be  nonnegative real numbers for mathematical convenience, but this can become problematic because there is then no bid that is just higher than another. We brush over such issues by assuming that an agent can bid infinitesimally higher than another. This is imprecise but allows us to focus on the intuition behind the result that follows. See Reny [17] for a full treatment of such issues. For the remainder of the paper, we assume that there are as many slots as bidders. The following result shows that there can be no pure-strategy Nash equilibrium with first pricing.17 Note that the argument holds for both RBB and RBR allocation rules. For RBB, bids should be interpreted as declared values, and for RBR as declared revenues. Theorem 2. There exists no complete information Nash equilibrium in pure strategies in the first-price slot auction, for any possible values of the agents, whether using a RBB or RBR allocation rule. Proof. Let σ : [K] → [N] be the allocation of slots to the agents resulting from their bids. Let ri and bi be the revenue and bid of the agent ranked ith , respectively. Note that we cannot have bi > bi+1, or else the agent in slot i can make a profitable deviation by instead bidding bi − > bi+1 for small enough > 0. This does not change its allocation, but increases its profit. Hence we must have bi = bi+1 (i.e. with one bidder bidding infinitesimally higher than the other). Since this holds for any two consecutive bidders, it follows that in a Nash equilibrium all bidders must be bidding 0 (since the bidder ranked last matches the bid directly below him, which is 0 by default because there is no such bid). But this is impossible: consider the bidder ranked last. The identity of this bidder is always clear given the deterministic tie-breaking rule. This bidder can obtain the top spot and increase his revenue by (γ1 −γK)rK > 0 by bidding some > 0, and for small enough this is necessarily a profitable deviation. Hence there is no Nash equilibrium in pure strategies. On the other hand, we find that in a second-price slot  auction there can be a multitude of pure strategy Nash  equilibria. The next two lemmas give conditions that characterize the allocations that can occur as a result of an equilibrium profile of bids, given fixed agent values and revenues. Then if we can exhibit an allocation that satisfies these conditions, there must exist at least one equilibrium. We first consider the RBR case. 7 B¨orgers et al. [2] have proven this result in a model with three bidders and three slots, and we generalize their  argument. Edelman et al. [6] also point out this non-existence phenomenon. They only illustrate the fact with an example because the result is quite immediate. Lemma 2. Given an allocation σ, there exists a Nash  equilibrium profile of bids b leading to σ in a second-price RBR slot auction if and only if „  − γi γj+1 « rσ(i) ≤ rσ(j) for 1 ≤ j ≤ N − 2 and i ≥ j + 2. Proof. There exists a desired vector b which constitutes a Nash equilibrium if and only if the following set of  inequalities can be satisfied (the variables are the πi and bj): πi ≥ γj(rσ(i) − bj) ∀i, ∀j < i (3) πi ≥ γj(rσ(i) − bj+1) ∀i, ∀j > i (4) πi = γi(rσ(i) − bi+1) ∀i (5) bi ≥ bi+1 1 ≤ i ≤ N − 1 (6) πi ≥ 0, bi ≥ 0 ∀i Here rσ(i) is the revenue of the agent allocated slot i, and πi and bi may be interpreted as this agent"s surplus and declared revenue, respectively. We first argue that  constraints (6) can be removed, because the inequalities above can be satisfied if and only if the inequalities without (6) can be satisfied. The necessary direction is immediate. Assume we have a vector (π, b) which satisfies all inequalities above except (6). Then there is some i for which bi < bi+1.  Construct a new vector (π, b ) identical to the original except with bi+1 = bi. We now have bi = bi+1. An agent in slot k < i sees the price of slot i decrease from bi+1 to bi+1 = bi, but this does not make i more preferred than k to this agent because we have πk ≥ γi−1(rσ(k) − bi) ≥ γi(rσ(k) − bi) = γi(rσ(k) −bi+1) (i.e. because the agent in slot k did not  originally prefer slot i − 1 at price bi, he will not prefer slot i at price bi). A similar argument applies for agents in slots k > i + 1. The agent in slot i sees the price of this slot go down, which only makes it more preferred. Finally, the agent in slot i + 1 sees no change in the price of any slot, so his slot remains most preferred. Hence inequalities (3)-(5) remain valid at (π, b ). We first make this change to the bi+1 where bi < bi+1 and index i is smallest. We then recursively apply the change until we eventually obtain a vector that satisfies all inequalities. We safely ignore inequalities (6) from now on. By the Farkas lemma, the remaining inequalities can be satisfied if and only if there is no vector z such that X i,j (γj rσ(i)) zσ(i)j > 0 X i>j γjzσ(i)j + X i<j γj−1zσ(i)j−1 ≤ 0 ∀j (7) X j zσ(i)j ≤ 0 ∀i (8) zσ(i)j ≥ 0 ∀i, ∀j = i zσ(i)i free ∀i Note that a variable of the form zσ(i)i appears at most once in a constraint of type (8), so such a variable can never be positive. Also, zσ(i)1 = 0 for all i = 1 by constraint (7), since such variables never appear with another of the form zσ(i)i. Now if we wish to raise zσ(i)j above 0 by one unit for j = i, we must lower zσ(i)i by one unit because of the constraint of type (8). Because γjrσ(i) ≤ γirσ(i) for i < j, raising 24 zσ(i)j with i < j while adjusting other variables to maintain feasibility cannot make the objective P i,j(γjrσ(i))zσ(i)j  positive. If this objective is positive, then this is due to some component zσ(i)j with i > j being positive. Now for the constraints of type (7), if i > j then zσ(i)j appears with zσ(j−1)j−1 (for 1 < j < N). So to raise the former variable γ−1 j units and maintain feasibility, we must (I) lower zσ(i)i by γ−1 j units, and (II) lower zσ(j−1)j−1 by γ−1 j−1 units. Hence if the following inequalities hold: rσ(i) ≤ „ γi γj « rσ(i) + rσ(j−1) (9) for 2 ≤ j ≤ N − 1 and i > j, raising some zσ(i)j with i > j cannot make the objective positive, and there is no z that satisfies all inequalities above. Conversely, if some inequality (9) does not hold, the objective can be made  positive by raising the corresponding zσ(i)j and adjusting other variables so that feasibility is just maintained. By a slight reindexing, inequalities (9) yield the statement of the  theorem. The RBB case is entirely analogous. Lemma 3. Given an allocation σ, there exists a Nash  equilibrium profile of bids b leading to σ in a second-price RBB slot auction if and only if „  − γi γj+1 « xσ(i) ≤ xσ(j) for 1 ≤ j ≤ N − 2 and i ≥ j + 2. Proof Sketch. The proof technique is the same as in the previous lemma. The desired Nash equilibrium exists if and only if a related set of inequalities can be satisfied; by the Farkas lemma, this occurs if and only if an alternate set of inequalities cannot be satisfied. The conditions that  determine whether the latter holds are given in the statement of the lemma. The two lemmas above immediately lead to the following result. Theorem 3. There always exists a complete information Nash equilibrium in pure strategies in the second-price RBB slot auction. There always exists an efficient complete  information Nash equilibrium in pure strategies in the  secondprice RBR slot auction. Proof. First consider RBB. Suppose agents are ranked according to their true values. Since xσ(i) ≤ xσ(j) for i > j, the system of inequalities in Lemma 3 is satisfied, and the allocation is the result of some Nash equilibrium bid profile. By the same type of argument but appealing to Lemma 2 for RBR, there exists a Nash equilibrium bid profile such that bidders are ranked according to their true revenues. By Theorem 1, this latter allocation is efficient. This theorem establishes existence but not uniqueness. Indeed we expect that in many cases there will be multiple allocations (and hence equilibria) which satisfy the  conditions of Lemmas 2 and 3. In particular, not all equilibria of a second-price RBR auction will be efficient. For instance, according to Lemma 2, with two agents and two slots any allocation can arise in a RBR equilibrium because no  constraints apply. Theorems 2 and 3 taken together provide a possible  explanation for Yahoo!"s switch from first to second pricing. We saw in Section 3.1 that this does not induce truthfulness from bidders. With first pricing, there will always be some bidder that feels compelled to adjust his bid. Second pricing is more convenient because an equilibrium can be reached, and this reduces the cost of bid management. .2 Efficiency For a given allocation rule, we call the allocation that would result if the bidders reported their values truthfully the standard allocation. Hence in the standard RBB  allocation bidders are ranked by true values, and in the standard RBR allocation they are ranked by true revenues.  According to Lemmas 2 and 3, a ranking that results from a Nash equilibrium profile can only deviate from the standard  allocation by having agents with relatively similar values or revenues switch places. That is, if ri > rj then with RBR agent j can be ranked higher than i only if the ratio rj/ri is sufficiently large; similarly for RBB. This suggests that the value of an equilibrium allocation cannot differ too much from the value obtained in the standard allocation, and the following theorems confirms this. For an allocation σ of slots to agents, we denote its  total value by f(σ) = PN i=1 γirσ(i). We denote by g(σ) = PN i=1 γixσ(i) allocation σ"s value when assuming all agents have identical relevance, normalized to 1. Let L = min i=1,...,N−1 min  γi+1 γi , 1 − γi+2 γi+1 ff (where by default γN+1 = 0). Let ηx and ηr be the standard allocations when using RBB and RBR, respectively. Theorem 4. For an allocation σ that results from a  purestrategy Nash equilibrium of a second-price RBR slot  auction, we have f(σ) ≥ Lf(ηr). Proof. We number the agents so that agent i has the ith highest revenue, so r1 ≥ r2 ≥ . . . ≥ rN . Hence the standard allocation has value f(ηr) = PN i=1 γiri. To prove the theorem, we will make repeated use of the fact thatP k akP k bk ≥ mink ak bk when the ak and bk are positive. Note that according to Lemma 2, if agent i lies at least two slots below slot j, then rσ(j) ≥ ri   − γj+2 γj+1  . It may be the case that for some slot i, we have σ(i) > i and for slots k > i + 1 we have σ(k) > i. We then say that slot i is inverted. Let S be the set of agents with indices at least i + 1; there are N − i of these. If slot i is inverted, it is occupied by some agent from S. Also all slots strictly lower than i + 1 must be occupied by the remaining agents from S, since σ(k) > i for k ≥ i + 2. The agent in slot i + 1 must then have an index σ(i + 1) ≤ i (note this means slot i + 1 cannot be inverted). Now there are two cases. In the first case we have σ(i) = i + 1. Then γirσ(i) + γi+1rσ(i+1) γiri + γi+1ri+1 ≥ γi+1ri + γiri+1 γiri + γi+1ri+1 ≥ min  γi+1 γi , γi γi+1 ff = γi+1 γi In the second case we have σ(i) > i+1. Then since all agents in S except the one in slot i lie strictly below slot i + 1, and 25 the agent in slot i is not agent i + 1, it must be that agent i+1 is in a slot strictly below slot i+1. This means that it is at least two slots below the agent that actually occupies slot i, and by Lemma 2 we then have rσ(i) ≥ ri+1   − γi+2 γi+1  . Thus, γirσ(i) + γi+1rσ(i+1) γiri + γi+1ri+1 ≥ γi+1ri + γirσ(i) γiri + γi+1ri+1 ≥ min  γi+1 γi , 1 − γi+2 γi+1 ff If slot i is not inverted, then on one hand we may have σ(i) ≤ i, in which case rσ(i)/ri ≥ 1. On the other hand we may have σ(i) > i but there is some agent with index j ≤ i that lies at least two slots below slot i. Then by Lemma 2, rσ(i) ≥ rj   − γi+2 γi+1  ≥ ri   − γi+2 γi+1  . We write i ∈ I if slot i is inverted, and i ∈ I if neither i nor i − 1 are inverted. By our arguments above two consecutive slots cannot be inverted, so we can write f(σ) f(γr) = P i∈I ` γirσ(i) + γi+1rσ(i+1) ´ + P i∈I γirσ(i) P i∈I (γiri + γi+1ri+1) + P i∈I γiri ≥ min  min i∈I  γirσ(i) + γi+1rσ(i+1) γiri + γi+1ri+1 ff , min i∈I  γirσ(i) γiri ffff ≥ L and this completes the proof. Note that for RBR, the standard value is also the  efficient value by Theorem 1. Also note that for an exponential decay model, L = min ˘1 δ , 1 − 1 δ ¯ . With δ = 1.428 (see  Section 2.1), the factor is L ≈ 1/3.34, so the total value in a pure-strategy Nash equilibrium of a second-price RBR slot auction is always within a factor of 3.34 of the efficient value with such a discount. Again for RBB we have an analogous result. Theorem 5. For an allocation σ that results from a  purestrategy Nash equilibrium of a second-price RBB slot  auction, we have g(σ) ≥ Lg(ηx). Proof Sketch. Simply substitute bidder values for bidder revenues in the proof of Theorem 4, and appeal to Lemma 3. . CONCLUSIONS This paper analyzed stylized versions of the slot auction designs currently used by Yahoo! and Google, namely rank by bid (RBB) and rank by revenue (RBR), respectively. We also considered first and second pricing rules together with each of these allocation rules, since both have been used historically. We first studied the short-run setting with incomplete information, corresponding to the case where agents have just approached the mechanism. Our  equilibrium analysis revealed that RBB has much weaker  informational requirements than RBR, because bidders need not know any information about relevance (even their own) to play the Bayes-Nash equilibrium. However, RBR leads to an efficient allocation in equilibrium, whereas RBB does not. We showed that for an arbitrary distribution over value and relevance, no revenue ranking of RBB and RBR is possible. We hope that the tools we used to establish these results (revenue equivalence, the form of first-price equilibria, the truthful payments rules) will help others wanting to pursue further analyses of slot auctions. We also studied the long-run case where agents have experimented with their bids and each settled on one they find optimal. We argued that a stable set of bids in this setting can be modeled as a pure-strategy Nash equilibrium of the static game of complete information. We showed that no pure-strategy equilibrium exists with either RBB or RBR using first pricing, but that with second pricing there always exists such an equilibrium (in the case of RBR, an efficient equilibrium). In general second pricing allows for multiple pure-strategy equilibria, but we showed that the value of such equilibria diverges by only a constant factor from the value obtained if all agents bid truthfully (which in the case of RBR is the efficient value). . FUTURE WORK Introducing budget constraints into the model is a  natural next step for future work. The complication here lies in the fact that budgets are often set for entire campaigns rather than single keywords. Assuming that the optimal choice of budget can be made independent of the choice of bid for a specific keyword, it can be shown that it is a dominant-strategy to report this optimal budget with one"s bid. The problem is then to ascertain that bids and budgets can indeed be optimized separately, or to find a plausible model where deriving equilibrium bids and budgets together is tractable. Identifying a condition on the distribution over value and relevance that actually does yield a revenue ranking of RBB and RBR (such as correlation between value and relevance, perhaps) would yield a more satisfactory characterization of their relative revenue properties. Placing bounds on the revenue obtained in a complete information equilibrium is also a relevant question. Because the incomplete information case is such a close generalization of the most basic single-item auction model, it would be interesting to see which standard results from single-item auction theory (e.g. results with risk-averse  bidders, an endogenous number of bidders, asymmetries, etc...) automatically generalize and which do not, to fully  understand the structural differences between single-item and slot auctions. Acknowledgements David Pennock provided valuable guidance throughout this project. I would also like to thank David Parkes for helpful comments. . REFERENCES [1] Z. Abrams. Revenue maximization when bidders have budgets. In Proc. the ACM-SIAM Symposium on Discrete Algorithms, 2006. [2] T. B¨orgers, I. Cox, and M. Pesendorfer. Personal Communication. [3] C. Borgs, J. Chayes, N. Immorlica, M. Mahdian, and A. Saberi. Multi-unit auctions with budget-constrained bidders. In Proc. the Sixth ACM Conference on Electronic Commerce, Vancouver, BC, 005. [4] F. Brandt and G. Weiß. Antisocial agents and Vickrey auctions. In J.-J. C. Meyer and M. Tambe, editors, 26 Intelligent Agents VIII, volume 2333 of Lecture Notes in Artificial Intelligence. Springer Verlag, 2001. [5] B. Edelman and M. Ostrovsky. Strategic bidder behavior in sponsored search auctions. In Workshop on Sponsored Search Auctions, ACM Electronic Commerce, 2005. [6] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet advertising and the generalized second price auction: Selling billions of dollars worth of keywords. NBER working paper 11765, November 2005. [7] J. Feng, H. K. Bhargava, and D. M. Pennock. Implementing sponsored search in web search engines: Computational evaluation of alternative mechanisms. INFORMS Journal on Computing, 2005. Forthcoming. [8] J. Green and J.-J. Laffont. Characterization of satisfactory mechanisms for the revelation of preferences for public goods. Econometrica, 5:427-438, 1977. [9] B. Holmstrom. Groves schemes on restricted domains. Econometrica, 47(5):1137-1144, 1979. [10] B. Kitts, P. Laxminarayan, B. LeBlanc, and R. Meech. A formal analysis of search auctions including predictions on click fraud and bidding tactics. In Workshop on Sponsored Search Auctions, ACM Electronic Commerce, 2005. [11] V. Krishna. Auction Theory. Academic Press, 2002. [12] D. Liu and J. Chen. Designing online auctions with past performance information. Decision Support Systems, 2005. Forthcoming. [13] C. Meek, D. M. Chickering, and D. B. Wilson. Stochastic and contingent payment auctions. In Workshop on Sponsored Search Auctions, ACM Electronic Commerce, 2005. [14] A. Mehta, A. Saberi, U. Vazirani, and V. Vazirani. Adwords and generalized on-line matching. In Proc. 6th IEEE Symposium on Foundations of Computer Science, 2005. [15] P. Milgrom. Putting Auction Theory to Work. Cambridge University Press, 2004. [16] P. Milgrom and C. Shannon. Monotone comparative statics. Econometrica, 62(1):157-180, 1994. [17] P. J. Reny. On the existence of pure and mixed strategy Nash equilibria in discontinuous games. Econometrica, 67(5):1029-1056, 1999. [18] H. R. Varian. Position auctions. Working Paper, February 2006. [19] W. Vickrey. Counterspeculation, auctions and competitive sealed tenders. Journal of Finance, 6:8-37, 1961. 27
The Dynamics of Viral Marketing ∗ Jure Leskovec † Carnegie Mellon University Pittsburgh, PA 15213 jure@cs.cmu.edu Lada A. Adamic ‡ University of Michigan Ann Arbor, MI 48109 ladamic@umich.edu Bernardo A. Huberman HP Labs Palo Alto, CA 94304 bernardo.huberman@hp.com ABSTRACT We present an analysis of a person-to-person  recommendation network, consisting of 4 million people who made 16 million recommendations on half a million products. We observe the propagation of recommendations and the  cascade sizes, which we explain by a simple stochastic model. We then establish how the recommendation network grows over time and how effective it is from the viewpoint of the sender and receiver of the recommendations. While on  average recommendations are not very effective at inducing purchases and do not spread very far, we present a model that successfully identifies product and pricing categories for which viral marketing seems to be very effective. Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics General Terms Economics . INTRODUCTION With consumers showing increasing resistance to  traditional forms of advertising such as TV or newspaper ads, marketers have turned to alternate strategies, including  viral marketing. Viral marketing exploits existing social  networks by encouraging customers to share product  information with their friends. Previously, a few in depth  studies have shown that social networks affect the adoption of individual innovations and products (for a review see [15] or [16]). But until recently it has been difficult to measure how influential person-to-person recommendations actually are over a wide range of products. We were able to directly measure and model the effectiveness of recommendations by studying one online retailer"s incentivised viral marketing program. The website gave discounts to customers  recommending any of its products to others, and then tracked the resulting purchases and additional recommendations. Although word of mouth can be a powerful factor  influencing purchasing decisions, it can be tricky for advertisers to tap into. Some services used by individuals to  communicate are natural candidates for viral marketing, because the product can be observed or advertised as part of the  communication. Email services such as Hotmail and Yahoo had very fast adoption curves because every email sent through them contained an advertisement for the service and because they were free. Hotmail spent a mere $50,000 on traditional marketing and still grew from zero to 12 million users in 18 months [7]. Google"s Gmail captured a significant part of market share in spite of the fact that the only way to sign up for the service was through a referral. Most products cannot be advertised in such a direct way. At the same time the choice of products available to  consumers has increased manyfold thanks to online retailers who can supply a much wider variety of products than  traditional brick-and-mortar stores. Not only is the variety of products larger, but one observes a ‘fat tail"  phenomenon, where a large fraction of purchases are of relatively obscure items. On Amazon.com, somewhere between 20 to 0 percent of unit sales fall outside of its top 100,000 ranked products [2]. Rhapsody, a streaming-music service, streams more tracks outside than inside its top 10,000 tunes [1].  Effectively advertising these niche products using traditional advertising approaches is impractical. Therefore using more targeted marketing approaches is advantageous both to the merchant and the consumer, who would benefit from  learning about new products. The problem is partly addressed by the advent of  online product and merchant reviews, both at retail sites such as EBay and Amazon, and specialized product comparison sites such as Epinions and CNET. Quantitative marketing techniques have been proposed [12], and the rating of  products and merchants has been shown to effect the likelihood of an item being bought [13, 4]. Of further help to the consumer are collaborative filtering recommendations of the form people who bought x also bought y feature [11]. These refinements help consumers discover new products 28 and receive more accurate evaluations, but they cannot  completely substitute personalized recommendations that one receives from a friend or relative. It is human nature to be more interested in what a friend buys than what an  anonymous person buys, to be more likely to trust their opinion, and to be more influenced by their actions. Our friends are also acquainted with our needs and tastes, and can make appropriate recommendations. A Lucid Marketing survey found that 68% of individuals consulted friends and relatives before purchasing home electronics - more than the half who used search engines to find product information [3]. Several studies have attempted to model just this kind of network influence. Richardson and Domingos [14] used Epinions" trusted reviewer network to construct an  algorithm to maximize viral marketing efficiency assuming that individuals" probability of purchasing a product depends on the opinions on the trusted peers in their network. Kempe, Kleinberg and Tardos [8] evaluate the efficiency of several  algorithms for maximizing the size of influence set given  various models of adoption. While these models address the question of maximizing the spread of influence in a network, they are based on assumed rather than measured influence effects. In contrast, in our study we are able to directly observe the effectiveness of person to person word of mouth  advertising for hundreds of thousands of products for the first time. We find that most recommendation chains do not grow very large, often terminating with the initial purchase of a  product. However, occasionally a product will propagate through a very active recommendation network. We propose a simple stochastic model that seems to explain the propagation of recommendations. Moreover, the characteristics of  recommendation networks influence the purchase patterns of their members. For example, individuals" likelihood of  purchasing a product initially increases as they receive additional recommendations for it, but a saturation point is quickly reached. Interestingly, as more recommendations are sent between the same two individuals, the likelihood that they will be heeded decreases. We also propose models to identify products for which viral marketing is effective: We find that the category and price of product plays a role, with  recommendations of expensive products of interest to small, well connected communities resulting in a purchase more often. We also observe patterns in the timing of recommendations and purchases corresponding to times of day when people are likely to be shopping online or reading email. We report on these and other findings in the following sections. . THE RECOMMENDATION NETWORK .1 Dataset description Our analysis focuses on the recommendation referral  program run by a large retailer. The program rules were as follows. Each time a person purchases a book, music, or a movie he or she is given the option of sending emails  recommending the item to friends. The first person to purchase the same item through a referral link in the email gets a 10% discount. When this happens the sender of the  recommendation receives a 10% credit on their purchase. The recommendation dataset consists of 15,646,121  recommendations made among 3,943,084 distinct users. The data was collected from June 5 2001 to May 16 2003. In total, 548,523 products were recommended, 99% of them belonging to 4 main product groups: Books, DVDs, Music and Videos. In addition to recommendation data, we also crawled the retailer"s website to obtain product categories, reviews and ratings for all products. Of the products in our data set, 5813 (1%) were discontinued (the retailer no longer provided any information about them). Although the data gives us a detailed and accurate view of recommendation dynamics, it does have its limitations. The only indication of the success of a recommendation is the observation of the recipient purchasing the product through the same vendor. We have no way of knowing if the person had decided instead to purchase elsewhere,  borrow, or otherwise obtain the product. The delivery of the recommendation is also somewhat different from one person simply telling another about a product they enjoy, possibly in the context of a broader discussion of similar products. The recommendation is received as a form email including information about the discount program. Someone reading the email might consider it spam, or at least deem it less important than a recommendation given in the context of a conversation. The recipient may also doubt whether the friend is recommending the product because they think the recipient might enjoy it, or are simply trying to get a  discount for themselves. Finally, because the recommendation takes place before the recommender receives the product, it might not be based on a direct observation of the  product. Nevertheless, we believe that these recommendation networks are reflective of the nature of word of mouth  advertising, and give us key insights into the influence of social networks on purchasing decisions. .2 Recommendation network statistics For each recommendation, the dataset included the  product and product price, sender ID, receiver ID, the sent date, and a buy-bit, indicating whether the recommendation  resulted in a purchase and discount. The sender and receiver ID"s were shadowed. We represent this data set as a  directed multi graph. The nodes represent customers, and a directed edge contains all the information about the  recommendation. The edge (i, j, p, t) indicates that i  recommended product p to customer j at time t. The typical process generating edges in the  recommendation network is as follows: a node i first buys a product p at time t and then it recommends it to nodes j1, . . . , jn. The j nodes can they buy the product and further recommend it. The only way for a node to recommend a product is to first buy it. Note that even if all nodes j buy a product, only the edge to the node jk that first made the purchase (within a week after the recommendation) will be marked by a buy-bit. Because the buy-bit is set only for the first  person who acts on a recommendation, we identify additional purchases by the presence of outgoing recommendations for a person, since all recommendations must be preceded by a purchase. We call this type of evidence of purchase a  buyedge. Note that buy-edges provide only a lower bound on the total number of purchases without discounts. It is possible for a customer to not be the first to act on a  recommendation and also to not recommend the product to others. Unfortunately, this was not recorded in the data set. We consider, however, the buy-bits and buy-edges as proxies for the total number of purchases through recommendations. For each product group we took recommendations on all products from the group and created a network. Table 1 29  1 2 3 4 x 10       0 2 x 10  number of nodes sizeofgiantcomponent by month quadratic fit  10 20    x 10  m (month) n # nodes .7*10  m 0  0  0  0  0  0  0  0  0  0  kp (recommendations by a person for a product) N(x>=k p ) level 0 γ = 2.6 level 1 γ = 2.0 level 2 γ = 1.5 level 3 γ = 1.2 level 4 γ = 1.2 (a) Network growth (b) Recommending by level Figure 1: (a) The size of the largest connected  component of customers over time. The inset shows the linear growth in the number of customers n over time. (b) The number of recommendations sent by a user with each curve representing a different depth of the user in the recommendation chain. A power law exponent γ is fitted to all but the tail. (first 7 columns) shows the sizes of various product group recommendation networks with p being the total number of products in the product group, n the total number of nodes spanned by the group recommendation network and e the number of edges (recommendations). The column eu shows the number of unique edges - disregarding multiple recommendations between the same source and recipient. In terms of the number of different items, there are by far the most music CDs, followed by books and videos. There is a surprisingly small number of DVD titles. On the other hand, DVDs account for more half of all recommendations in the dataset. The DVD network is also the most dense,  having about 10 recommendations per node, while books and music have about 2 recommendations per node and videos have only a bit more than 1 recommendation per node. Music recommendations reached about the same number of people as DVDs but used more than 5 times fewer  recommendations to achieve the same coverage of the nodes. Book recommendations reached by far the most people - 2.8  million. Notice that all networks have a very small number of unique edges. For books, videos and music the number of unique edges is smaller than the number of nodes - this suggests that the networks are highly disconnected [5]. Figure 1(a) shows the fraction of nodes in largest weakly connected component over time. Notice the component is very small. Even if we compose a network using all the  recommendations in the dataset, the largest connected  component contains less than 2.5% (100,420) of the nodes, and the second largest component has only 600 nodes. Still, some smaller communities, numbering in the tens of thousands of purchasers of DVDs in categories such as westerns,  classics and Japanese animated films (anime), had connected components spanning about 20% of their members. The insert in figure 1(a) shows the growth of the  customer base over time. Surprisingly it was linear, adding on average 165,000 new users each month, which is an  indication that the service itself was not spreading epidemically. Further evidence of non-viral spread is provided by the  relatively high percentage (94%) of users who made their first recommendation without having previously received one. Back to table 1: given the total number of  recommendations e and purchases (bb + be) influenced by  recommendations we can estimate how many recommendations need to be independently sent over the network to induce a new purchase. Using this metric books have the most influential recommendations followed by DVDs and music. For books one out of 69 recommendations resulted in a purchase. For DVDs it increases to 108 recommendations per purchase and further increases to 136 for music and 203 for video. Even with these simple counts we can make the first few observations. It seems that some people got quite  heavily involved in the recommendation program, and that they tended to recommend a large number of products to the same set of friends (since the number of unique edges is so small). This shows that people tend to buy more DVDs and also like to recommend them to their friends, while they seem to be more conservative with books. One possible  reason is that a book is bigger time investment than a DVD: one usually needs several days to read a book, while a DVD can be viewed in a single evening. One external factor which may be affecting the  recommendation patterns for DVDs is the existence of referral websites (www.dvdtalk.com). On these websites people, who want to buy a DVD and get a discount, would ask for  recommendations. This way there would be recommendations made between people who don"t really know each other but rather have an economic incentive to cooperate. We were not able to find similar referral sharing sites for books or CDs. .3 Forward recommendations Not all people who make a purchase also decide to give recommendations. So we estimate what fraction of people that purchase also decide to recommend forward. To obtain this information we can only use the nodes with purchases that resulted in a discount. The last 3 columns of table 1 show that only about a third of the people that purchase also recommend the  product forward. The ratio of forward recommendations is much higher for DVDs than for other kinds of products. Videos also have a higher ratio of forward recommendations, while books have the lowest. This shows that people are most keen on recommending movies, while more conservative when  recommending books and music. Figure 1(b) shows the cumulative out-degree distribution, that is the number of people who sent out at least kp  recommendations, for a product. It shows that the deeper an individual is in the cascade, if they choose to make  recommendations, they tend to recommend to a greater number of people on average (the distribution has a higher  variance). This effect is probably due to only very heavily recommended products producing large enough cascades to reach a certain depth. We also observe that the probability of an individual making a recommendation at all (which can only occur if they make a purchase), declines after an initial increase as one gets deeper into the cascade. .4 Identifying cascades As customers continue forwarding recommendations, they contribute to the formation of cascades. In order to  identify cascades, i.e. the causal propagation of  recommendations, we track successful recommendations as they influence purchases and further recommendations. We define a  recommendation to be successful if it reached a node before its first purchase. We consider only the first purchase of an item, because there are many cases when a person made multiple 30 Group p n e eu bb be Purchases Forward Percent Book 103,161 2,863,977 5,741,611 2,097,809 65,344 17,769 65,391 15,769 24.2 DVD 19,829 805,285 8,180,393 962,341 17,232 58,189 16,459 7,336 44.6 Music 393,598 794,148 1,443,847 585,738 7,837 2,739 7,843 1,824 23.3 Video 26,131 239,583 280,270 160,683 909 467 909 250 27.6 Total 542,719 3,943,084 15,646,121 3,153,676 91,322 79,164 90,602 25,179 27.8 Table 1: Product group recommendation statistics. p: number of products, n: number of nodes, e: number of edges (recommendations), eu: number of unique edges, bb: number of buy bits, be: number of buy edges. Last  columns of the table: Fraction of people that purchase and also recommend forward. Purchases: number of nodes that purchased. Forward: nodes that purchased and then also recommended the product. 73 38 (a) Medical book (b) Japanese graphic novel Figure 2: Examples of two product recommendation networks: (a) First aid study guide First Aid for the USMLE Step, (b) Japanese graphic novel (manga) Oh My Goddess!: Mara Strikes Back. 0  0  0  0  0  0  0  Number of recommendations Count = 3.4e6 x−2.30 R2 =0.96 0  0  0  0  0  0  0  0  0  0  Number of purchases Count = 4.1e6 x−2.49 R2 =0.99 (a) Recommendations (b) Purchases Figure 3: Distribution of the number of  recommendations and number of purchases made by a node. purchases of the same product, and in between those  purchases she may have received new recommendations. In this case one cannot conclude that recommendations following the first purchase influenced the later purchases. Each cascade is a network consisting of customers (nodes) who purchased the same product as a result of each other"s recommendations (edges). We delete late recommendations - all incoming recommendations that happened after the first purchase of the product. This way we make the  network time increasing or causal - for each node all incoming edges (recommendations) occurred before all outgoing edges. Now each connected component represents a time obeying propagation of recommendations. Figure 2 shows two typical product recommendation  networks: (a) a medical study guide and (b) a Japanese graphic novel. Throughout the dataset we observe very similar  patters. Most product recommendation networks consist of a large number of small disconnected components where we do not observe cascades. Then there is usually a small  number of relatively small components with recommendations successfully propagating. This observation is reflected in the heavy tailed  distribution of cascade sizes (see figure 4), having a power-law exponent close to 1 for DVDs in particular. We also notice bursts of recommendations (figure 2(b)). Some nodes recommend to many friends, forming a star like pattern. Figure 3 shows the distribution of the  recommendations and purchases made by a single node in the  recommendation network. Notice the power-law distributions and long flat tails. The most active person made 83,729  recommendations and purchased 4,416 different items. Finally, we also sometimes observe ‘collisions", where nodes receive recommendations from two or more sources. A detailed  enumeration and analysis of observed topological cascade  patterns for this dataset is made in [10]. .5 The recommendation propagation model A simple model can help explain how the wide variance we observe in the number of recommendations made by  individuals can lead to power-laws in cascade sizes (figure 4). The model assumes that each recipient of a recommendation will forward it to others if its value exceeds an arbitrary  threshold that the individual sets for herself. Since exceeding this value is a probabilistic event, let"s call pt the probability that at time step t the recommendation exceeds the  thresh231 0  0  0  0  0  0  0  = 1.8e6 x−4.98 R2 =0.99 0  0  0  0  0  0  0  = 3.4e3 x−1.56 R2 =0.83 0  0  0  0  0  0  = 4.9e5 x−6.27 R2 =0.97 0  0  0  0  0  0  = 7.8e4 x−5.87 R2 =0.97 (a) Book (b) DVD (c) Music (d) Video Figure 4: Size distribution of cascades (size of cascade vs. count). Bold line presents a power-fit. old. In that case the number of recommendations Nt+1 at time (t + 1) is given in terms of the number of  recommendations at an earlier time by Nt+1 = ptNt (1) where the probability pt is defined over the unit interval. Notice that, because of the probabilistic nature of the threshold being exceeded, one can only compute the final distribution of recommendation chain lengths, which we now proceed to do. Subtracting from both sides of this equation the term Nt and diving by it we obtain N(t+1) − Nt Nt = pt − 1 (2) Summing both sides from the initial time to some very large time T and assuming that for long times the numerator is smaller than the denominator (a reasonable assumption) we get dN N = pt (3) The left hand integral is just ln(N), and the right hand side is a sum of random variables, which in the limit of a very large uncorrelated number of recommendations is normally distributed (central limit theorem). This means that the logarithm of the number of messages is normally distributed, or equivalently, that the number of messages passed is log-normally distributed. In other words the probability density for N is given by P(N) =  N √ πσ2 exp −(ln(N) − μ)2 σ2 (4) which, for large variances describes a behavior whereby the typical number of recommendations is small (the mode of the distribution) but there are unlikely events of large chains of recommendations which are also observable. Furthermore, for large variances, the lognormal  distribution can behave like a power law for a range of values. In order to see this, take the logarithms on both sides of the equation (equivalent to a log-log plot) and one obtains ln(P(N)) = − ln(N) − ln( √ πσ2) − (ln (N) − μ)2 σ2 (5) So, for large σ, the last term of the right hand side goes to zero, and since the the second term is a constant one obtains a power law behavior with exponent value of  minus one. There are other models which produce power-law distributions of cascade sizes, but we present ours for its simplicity, since it does not depend on network topology [6] or critical thresholds in the probability of a recommendation being accepted [18]. . SUCCESS OF RECOMMENDATIONS So far we only looked into the aggregate statistics of the recommendation network. Next, we ask questions about the effectiveness of recommendations in the  recommendation network itself. First, we analyze the probability of  purchasing as one gets more and more recommendations. Next, we measure recommendation effectiveness as two people  exchange more and more recommendations. Lastly, we  observe the recommendation network from the perspective of the sender of the recommendation. Does a node that makes more recommendations also influence more purchases? .1 Probability of buying versus number of incoming recommendations First, we examine how the probability of purchasing changes as one gets more and more recommendations. One would  expect that a person is more likely to buy a product if she gets more recommendations. On the other had one would also think that there is a saturation point - if a person hasn"t bought a product after a number of recommendations, they are not likely to change their minds after receiving even more of them. So, how many recommendations are too many? Figure 5 shows the probability of purchasing a product as a function of the number of incoming recommendations on the product. As we move to higher numbers of incoming recommendations, the number of observations drops rapidly. For example, there were 5 million cases with 1 incoming recommendation on a book, and only 58 cases where a  person got 20 incoming recommendations on a particular book. The maximum was 30 incoming recommendations. For these reasons we cut-off the plot when the number of observations becomes too small and the error bars too large. Figure 5(a) shows that, overall, book recommendations are rarely followed. Even more surprisingly, as more and more recommendations are received, their success decreases. We observe a peak in probability of buying at 2 incoming recommendations and then a slow drop. For DVDs (figure 5(b)) we observe a saturation around 10 incoming recommendations. This means that after a person gets 10 recommendations on a particular DVD, they  become immune to them - their probability of buying does not increase anymore. The number of observations is 2.5 million at 1 incoming recommendation and 100 at 60  incoming recommendations. The maximal number of received recommendations is 172 (and that person did not buy) 32  4 6 8 10  .01 .02 .03 .04 .05 .06 Incoming Recommendations ProbabilityofBuying 0 20 30 40 50 60  .02 .04 .06 .08 Incoming Recommendations ProbabilityofBuying (a) Books (b) DVD Figure 5: Probability of buying a book (DVD) given a number of incoming recommendations.  10 15 20 25 30 35 40    0 2 x 10 −3 Exchanged recommendations Probabilityofbuying  10 15 20 25 30 35 40 .02 .03 .04 .05 .06 .07 Exchanged recommendations Probabilityofbuying (a) Books (b) DVD Figure 6: The effectiveness of recommendations with the total number of exchanged  recommendations. .2 Success of subsequent recommendations Next, we analyze how the effectiveness of  recommendations changes as two persons exchange more and more  recommendations. A large number of exchanged  recommendations can be a sign of trust and influence, but a sender of too many recommendations can be perceived as a spammer. A person who recommends only a few products will have her friends" attention, but one who floods her friends with all sorts of recommendations will start to loose her influence. We measure the effectiveness of recommendations as a function of the total number of previously exchanged  recommendations between the two nodes. We construct the experiment in the following way. For every recommendation r on some product p between nodes u and v, we first  determine how many recommendations were exchanged between u and v before recommendation r. Then we check whether v, the recipient of recommendation, purchased p after  recommendation r arrived. For the experiment we consider only node pairs (u, v), where there were at least a total of 10  recommendations sent from u to v. We perform the experiment using only recommendations from the same product group. Figure 6 shows the probability of buying as a function of the total number of exchanged recommendations between two persons up to that point. For books we observe that the effectiveness of recommendation remains about constant up to 3 exchanged recommendations. As the number of  exchanged recommendations increases, the probability of  buying starts to decrease to about half of the original value and then levels off. For DVDs we observe an immediate and  consistent drop. This experiment shows that recommendations start to lose effect after more than two or three are passed between two people. We performed the experiment also for video and music, but the number of observations was too low and the measurements were noisy. .3 Success of outgoing recommendations In previous sections we examined the data from the  viewpoint of the receiver of the recommendation. Now we look from the viewpoint of the sender. The two interesting  questions are: how does the probability of getting a 10% credit change with the number of outgoing recommendations; and given a number of outgoing recommendations, how many purchases will they influence? One would expect that recommendations would be the most effective when recommended to the right subset of friends. If one is very selective and recommends to too few friends, then the chances of success are slim. One the other hand, recommending to everyone and spamming them with recommendations may have limited returns as well. The top row of figure 7 shows how the average number of purchases changes with the number of outgoing  recommendations. For books, music, and videos the number of purchases soon saturates: it grows fast up to around 10  outgoing recommendations and then the trend either slows or starts to drop. DVDs exhibit different behavior, with the expected number of purchases increasing throughout. But if we plot the probability of getting a 10% credit as a  function of the number of outgoing recommendations, as in the bottom row of figure 7, we see that the success of DVD recommendations saturates as well, while books, videos and music have qualitatively similar trends. The difference in the curves for DVD recommendations points to the presence of collisions in the dense DVD network, which has 10  recommendations per node and around 400 per product - an order of magnitude more than other product groups. This means that many different individuals are recommending to the same person, and after that person makes a purchase, even though all of them made a ‘successful recommendation" 33 0 20 30 40 50 60  .1 .2 .3 .4 .5 Outgoing Recommendations NumberofPurchases 0 40 60 80 100 120 140         Outgoing Recommendations NumberofPurchases  10 15 20  .05 .1 .15 .2 Outgoing Recommendations NumberofPurchases  4 6 8 10 12  .05 .1 .15 .2 .25 Outgoing Recommendations NumberofPurchases 0 20 30 40 50 60 70 80  .05 .1 .15 .2 .25 Outgoing Recommendations ProbabilityofCredit 0 20 30 40 50 60 70 80  .02 .04 .06 .08 .1 .12 Outgoing Recommendations ProbabilityofCredit  10 15 20  .02 .04 .06 .08 .1 Outgoing Recommendations ProbabilityofCredit  4 6 8 10 12 14  .02 .04 .06 .08 Outgoing Recommendations ProbabilityofCredit (a) Books (b) DVD (c) Music (d) Video Figure 7: Top row: Number of resulting purchases given a number of outgoing recommendations. Bottom row: Probability of getting a credit given a number of outgoing recommendations.  2 3 4 5 6 7 > 7  .05 .1 .15 .2 .25 .3 .35 Lag [day] ProportionofPurchases  2 3 4 5 6 7 > 7  .1 .2 .3 .4 .5 Lag [day] ProportionofPurchases (a) Books (b) DVD Figure 8: The time between the recommendation and the actual purchase. We use all purchases. by our definition, only one of them receives a credit. . TIMING OF RECOMMENDATIONS AND PURCHASES The recommendation referral program encourages people to purchase as soon as possible after they get a  recommendation, since this maximizes the probability of getting a  discount. We study the time lag between the recommendation and the purchase of different product groups, effectively how long it takes a person to both receive a recommendation, consider it, and act on it. We present the histograms of the thinking time, i.e. the difference between the time of purchase and the time the last recommendation was received for the product prior to the purchase (figure 8). We use a bin size of 1 day. Around  5%40% of book and DVD purchases occurred within a day after the last recommendation was received. For DVDs 16%  purchases occur more than a week after last recommendation, while this drops to 10% for books. In contrast, if we consider the lag between the purchase and the first recommendation, only 23% of DVD purchases are made within a day, while the proportion stays the same for books. This reflects a greater likelihood for a person to receive multiple recommendations for a DVD than for a book. At the same time, DVD  recommenders tend to send out many more recommendations, only one of which can result in a discount. Individuals then often miss their chance of a discount, which is reflected in the high ratio (78%) of recommended DVD purchases that did not a get discount (see table 1, columns bb and be). In contrast, for books, only 21% of purchases through  recommendations did not receive a discount. We also measure the variation in intensity by time of day for three different activities in the recommendation system: recommendations (figure 9(a)), all purchases (figure 9(b)), and finally just the purchases which resulted in a discount (figure 9(c)). Each is given as a total count by hour of day. The recommendations and purchases follow the same  pattern. The only small difference is that purchases reach a sharper peak in the afternoon (after 3pm Pacific Time, 6pm Eastern time). The purchases that resulted in a discount look like a negative image of the first two figures. This means that most of discounted purchases happened in the morning when the traffic (number of purchases/recommendations) on the retailer"s website was low. This makes a lot of sense since most of the recommendations happened during the day, and if the person wanted to get the discount by being the first one to purchase, she had the highest chances when the traffic on the website was the lowest. . RECOMMENDATION EFFECTIVENESS BY BOOK CATEGORY Social networks are a product of the contexts that bring people together. Some contexts result in social ties that are more effective at conducting an action. For example, in small world experiments, where participants attempt to reach a target individual through their chain of  acquaintances, profession trumped geography, which in turn was more useful in locating a target than attributes such as  religion or hobbies [9, 17]. In the context of product  recommendations, we can ask whether a recommendation for a work of fiction, which may be made by any friend or neighbor, is 34  5 10 15 20 25      0 x 10  Hour of the Day Recommendtions  5 10 15 20 25  .5  .5  x 10  Hour of the Day AllPurchases  5 10 15 20 25  000 000 000 000 000 000 000 Hour of the Day DiscountedPurchases (a) Recommendations (b) Purchases (c) Purchases with Discount Figure 9: Time of day for purchases and recommendations. (a) shows the distribution of recommendations over the day, (b) shows all purchases and (c) shows only purchases that resulted in getting discount. more or less influential than a recommendation for a  technical book, which may be made by a colleague at work or school. Table 2 shows recommendation trends for all top level book categories by subject. An analysis of other product types can be found in the extended version of the paper. For clarity, we group the results by 4 different category types: fiction, personal/leisure, professional/technical, and  nonfiction/other. Fiction encompasses categories such as Sci-Fi and Romance, as well as children"s and young adult books. Personal/Leisure encompasses everything from gardening, photography and cooking to health and religion. First, we compare the relative number of  recommendations to reviews posted on the site (column cav/rp1 of  table 2). Surprisingly, we find that the number of people  making personal recommendations was only a few times greater than the number of people posting a public review on the website. We observe that fiction books have relatively few recommendations compared to the number of reviews, while professional and technical books have more  recommendations than reviews. This could reflect several factors. One is that people feel more confident reviewing fiction than  technical books. Another is that they hesitate to recommend a work of fiction before reading it themselves, since the  recommendation must be made at the point of purchase. Yet another explanation is that the median price of a work of fiction is lower than that of a technical book. This means that the discount received for successfully recommending a mystery novel or thriller is lower and hence people have less incentive to send recommendations. Next, we measure the per category efficacy of  recommendations by observing the ratio of the number of purchases occurring within a week following a recommendation to the number of recommenders for each book subject category (column b of table 2). On average, only 2% of the  recommenders of a book received a discount because their  recommendation was accepted, and another 1% made a  recommendation that resulted in a purchase, but not a discount. We observe marked differences in the response to  recommendation for different categories of books. Fiction in general is not very effectively recommended, with only around 2% of recommenders succeeding. The efficacy was a bit higher (around 3%) for non-fiction books dealing with personal and leisure pursuits, but is significantly higher in the professional and technical category. Medical books have nearly double the average rate of recommendation acceptance. This could be in part attributed to the higher median price of medical books and technical books in general. As we will see in  Section 6, a higher product price increases the chance that a recommendation will be accepted. Recommendations are also more likely to be accepted for certain religious categories: 4.3% for Christian living and theology and 4.8% for Bibles. In contrast, books not tied to organized religions, such as ones on the subject of new age (2.5%) and occult (2.2%) spirituality, have lower  recommendation effectiveness. These results raise the interesting possibility that individuals have greater influence over one another in an organized context, for example through a  professional contact or a religious one. There are exceptions of course. For example, Japanese anime DVDs have a strong following in the US, and this is reflected in their frequency and success in recommendations. Another example is that of gardening. In general, recommendations for books relating to gardening have only a modest chance of being accepted, which agrees with the individual prerogative that  accompanies this hobby. At the same time, orchid cultivation can be a highly organized and social activity, with frequent ‘shows" and online communities devoted entirely to orchids. Perhaps because of this, the rate of acceptance of orchid book  recommendations is twice as high as those for books on vegetable or tomato growing. . MODELING THE RECOMMENDATION SUCCESS We have examined the properties of recommendation  network in relation to viral marketing, but one question still remains: what determines the product"s viral marketing  success? We present a model which characterizes product  categories for which recommendations are more likely to be accepted. We use a regression of the following product  attributes to correlate them with recommendation success: • r: number of recommendations • ns: number of senders of recommendations • nr: number of recipients of recommendations • p: price of the product • v: number of reviews of the product • t: average product rating 35 category np n cc rp1 vav cav/ pm b ∗ 100 rp1 Books general 370230 2,860,714 1.87 5.28 4.32 1.41 14.95 3.12 Fiction Children"s Books 46,451 390,283 2.82 6.44 4.52 1.12 8.76 2.06** Literature & Fiction 41,682 502,179 3.06 13.09 4.30 0.57 11.87 2.82* Mystery and Thrillers 10,734 123,392 6.03 20.14 4.08 0.36 9.60 2.40** Science Fiction & Fantasy 10,008 175,168 6.17 19.90 4.15 0.64 10.39 2.34** Romance 6,317 60,902 5.65 12.81 4.17 0.52 6.99 1.78** Teens 5,857 81,260 5.72 20.52 4.36 0.41 9.56 1.94** Comics & Graphic Novels 3,565 46,564 11.70 4.76 4.36 2.03 10.47 2.30* Horror 2,773 48,321 9.35 21.26 4.16 0.44 9.60 1.81** Personal/Leisure Religion and Spirituality 43,423 441,263 1.89 3.87 4.45 1.73 9.99 3.13 Health Mind and Body 33,751 572,704 1.54 4.34 4.41 2.39 13.96 3.04 History 28,458 28,3406 2.74 4.34 4.30 1.27 18.00 2.84 Home and Garden 19,024 180,009 2.91 1.78 4.31 3.48 15.37 2.26** Entertainment 18,724 258,142 3.65 3.48 4.29 2.26 13.97 2.66* Arts and Photography 17,153 179,074 3.49 1.56 4.42 3.85 20.95 2.87 Travel 12,670 113,939 3.91 2.74 4.26 1.87 13.27 2.39** Sports 10,183 120,103 1.74 3.36 4.34 1.99 13.97 2.26** Parenting and Families 8,324 182,792 0.73 4.71 4.42 2.57 11.87 2.81 Cooking Food and Wine 7,655 146,522 3.02 3.14 4.45 3.49 13.97 2.38* Outdoors & Nature 6,413 59,764 2.23 1.93 4.42 2.50 15.00 3.05 Professional/Technical Professional & Technical 41,794 459,889 1.72 1.91 4.30 3.22 32.50 4.54** Business and Investing 29,002 476,542 1.55 3.61 4.22 2.94 20.99 3.62** Science 25,697 271,391 2.64 2.41 4.30 2.42 28.00 3.90** Computers and Internet 18,941 375,712 2.22 4.51 3.98 3.10 34.95 3.61** Medicine 16,047 175,520 1.08 1.41 4.40 4.19 39.95 5.68** Engineering 10,312 107,255 1.30 1.43 4.14 3.85 59.95 4.10** Law 5,176 53,182 2.64 1.89 4.25 2.67 24.95 3.66* Nonfiction-other Nonfiction 55,868 560,552 2.03 3.13 4.29 1.89 18.95 3.28** Reference 26,834 371,959 1.94 2.49 4.19 3.04 17.47 3.21 Biographies and Memoirs 18,233 277,356 2.80 7.65 4.34 0.90 14.00 2.96 Table 2: Statistics by book category: np:number of products in category, n number of customers, cc percentage of customers in the largest connected component, rp1 av. # reviews in 2001 - 2003, rp2 av. # reviews st 6 months 2005, vav average star rating, cav average number of people recommending product, cav/rp1 ratio of recommenders to reviewers, pm median price, b ratio of the number of purchases resulting from a recommendation to the number of recommenders. The symbol ** denotes statistical significance at the 0.01 level, * at the 0.05 level. From the original set of half a million products, we  compute a success rate s for the 48,218 products that had at least one purchase made through a recommendation and for which a price was given. In section 5 we defined  recommendation success rate s as the ratio of the total number purchases made through recommendations and the number of senders of the recommendations. We decided to use this kind of normalization, rather than normalizing by the total number of recommendations sent, in order not to penalize communities where a few individuals send out many  recommendations (figure 2(b)). Since the variables follow a heavy tailed distribution, we use the following model: s = exp( i βi log(xi) + i) where xi are the product attributes (as described on  previous page), and i is random error. We fit the model using least squares and obtain the  coefficients βi shown on table 3. With the exception of the average rating, they are all significant. The only two  attributes with a positive coefficient are the number of  recommendations and price. This shows that more expensive and more recommended products have a higher success rate. The number of senders and receivers have large negative  coefficients, showing that successfully recommended products are more likely to be not so widely popular. They have relatively many recommendations with a small number of senders and receivers, which suggests a very dense  recommendation network where lots of recommendations were  exchanged between a small community of people. These insights could be to marketers - personal  recommendations are most effective in small, densely connected communities enjoying expensive products. 36 Variable Coefficient βi const -0.940 (0.025)** r 0.426 (0.013)** ns -0.782 (0.004)** nr -1.307 (0.015)** p 0.128 (0.004)** v -0.011 (0.002)** t -0.027 (0.014)* R2 .74 Table 3: Regression using the log of the  recommendation success rate, ln(s), as the dependent variable. For each coefficient we provide the standard error and the statistical significance level (**:0.01, *:0.1). . DISCUSSION AND CONCLUSION Although the retailer may have hoped to boost its  revenues through viral marketing, the additional purchases that resulted from recommendations are just a drop in the bucket of sales that occur through the website. Nevertheless, we were able to obtain a number of interesting insights into how viral marketing works that challenge common assumptions made in epidemic and rumor propagation modeling. Firstly, it is frequently assumed in epidemic models that individuals have equal probability of being infected every time they interact. Contrary to this we observe that the probability of infection decreases with repeated interaction. Marketers should take heed that providing excessive  incentives for customers to recommend products could backfire by weakening the credibility of the very same links they are trying to take advantage of. Traditional epidemic and innovation diffusion models also often assume that individuals either have a constant  probability of ‘converting" every time they interact with an  infected individual or that they convert once the fraction of their contacts who are infected exceeds a threshold. In both cases, an increasing number of infected contacts results in an increased likelihood of infection. Instead, we find that the probability of purchasing a product increases with the number of recommendations received, but quickly saturates to a constant and relatively low probability. This means  individuals are often impervious to the recommendations of their friends, and resist buying items that they do not want. In network-based epidemic models, extremely highly  connected individuals play a very important role. For example, in needle sharing and sexual contact networks these nodes become the super-spreaders by infecting a large number of people. But these models assume that a high degree node has as much of a probability of infecting each of its neighbors as a low degree node does. In contrast, we find that there are limits to how influential high degree nodes are in the recommendation network. As a person sends out more and more recommendations past a certain number for a product, the success per recommendation declines. This would seem to indicate that individuals have influence over a few of their friends, but not everybody they know. We also presented a simple stochastic model that allows for the presence of relatively large cascades for a few  products, but reflects well the general tendency of  recommendation chains to terminate after just a short number of steps. We saw that the characteristics of product reviews and  effectiveness of recommendations vary by category and price, with more successful recommendations being made on  technical or religious books, which presumably are placed in the social context of a school, workplace or place of worship. Finally, we presented a model which shows that smaller and more tightly knit groups tend to be more conducive to viral marketing. So despite the relative ineffectiveness of the viral marketing program in general, we found a number of new insights which we hope will have general applicability to marketing strategies and to future models of viral  information spread. . REFERENCES [1] Anonymous. Profiting from obscurity: What the long tail means for the economics of e-commerce. Economist, 2005. [2] E. Brynjolfsson, Y. Hu, and M. D. Smith. Consumer surplus in the digital economy: Estimating the value of increased product variety at online booksellers. Management Science, 49(11), 2003. [3] K. Burke. As consumer attitudes shift, so must marketing strategies. 2003. [4] J. Chevalier and D. Mayzlin. The effect of word of mouth on sales: Online book reviews. 2004. [5] P. Erd¨os and A. R´enyi. On the evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci., 1960. [6] D. Gruhl, R. Guha, D. Liben-Nowell, and A. Tomkins. Information diffusion through blogspace. In WWW "04, 2004. [7] S. Jurvetson. What exactly is viral marketing? Red Herring, 78:110-112, 2000. [8] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing the spread of infuence in a social network. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2003. [9] P. Killworth and H. Bernard. Reverse small world experiment. Social Networks, 1:159-192, 1978. [10] J. Leskovec, A. Singh, and J. Kleinberg. Patterns of influence in a recommendation network. In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 2006. [11] G. Linden, B. Smith, and J. York. Amazon.com recommendations: item-to-item collaborative filtering. IEEE Internet Computing, 7(1):76-80, 2003. [12] A. L. Montgomery. Applying quantitative marketing techniques to the internet. Interfaces, 30:90-108, 2001. [13] P. Resnick and R. Zeckhauser. Trust among strangers in internet transactions: Empirical analysis of ebays reputation system. In The Economics of the Internet and E-Commerce. Elsevier Science, 2002. [14] M. Richardson and P. Domingos. Mining knowledge-sharing sites for viral marketing. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2002. [15] E. M. Rogers. Diffusion of Innovations. Free Press, New York, fourth edition, 1995. [16] D. Strang and S. A. Soule. Diffusion in organizations and social movements: From hybrid corn to poison pills. Annual Review of Sociology, 24:265-290, 1998. [17] J. Travers and S. Milgram. An experimental study of the small world problem. Sociometry, 1969. [18] D. Watts. A simple model of global cascades on random networks. PNAS, 99(9):4766-5771, Apr 2002. 37
